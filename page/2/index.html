<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>kmk3593 blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="kmk3593 blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="kmk3593 blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="kmk3593 blog"><meta property="og:url" content="https://kmk3593.github.io/"><meta property="og:site_name" content="kmk3593 blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kmk3593.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kmk3593.github.io"},"headline":"kmk3593 blog","image":["https://kmk3593.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"kmk3593 blog","logo":{"@type":"ImageObject","url":"https://kmk3593.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-28T00:00:00.000Z" title="2022. 4. 28. 오전 9:00:00">2022-04-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-01T01:16:28.899Z" title="2022. 5. 1. 오전 10:16:28">2022-05-01</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 768 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/28/pyspark_practice03/">pyspark 실습03</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터밀널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 폴더, 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ 폴더 생성 : chapter02_get_cleansing</p>
<ul>
<li>슬랙에서 data.zip 을 다운로드</li>
<li>압축을 풀고 chapter02_get_cleansing 파일에 복사하여 옮긴다.</li>
</ul>
<p>→ 파일 생성 : pipeline.py</p>
<p><img src="/images/pyspark_practice03/Untitled.png" alt="Untitled"></p>
<ul>
<li>코드를 작성해본다.</li>
</ul>
<p>→ 코드 작성</p>
<p><code>from pyspark.sql import SparkSession</code></p>
<p><code>from pyspark.sql.functions import *</code></p>
<p><code>print(&quot;Hello!&quot;)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter02_get_cleansing</code></p>
<p>→ 실행 : <code>python pipeline.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ pipeline.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.functions import *</span><br><span class="line">from pyspark.sql import functions as F</span><br><span class="line"></span><br><span class="line"># print(&quot;Hello!!&quot;)</span><br><span class="line"></span><br><span class="line"># 스파크 세션을 생성</span><br><span class="line">spark = SparkSession.builder.master(&quot;local[1]&quot;).\</span><br><span class="line">    appName(&quot;quickpipeline&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">df = spark.read.csv(&quot;data\AA_DFW_2015_Departures_Short.csv.gz&quot;</span><br><span class="line">                    , header = True)</span><br><span class="line"></span><br><span class="line">print(&quot;file loaded&quot;)</span><br><span class="line"></span><br><span class="line">print(df.show())</span><br><span class="line"></span><br><span class="line"># remove duration = 0</span><br><span class="line">df = df.filter(df[3] &gt; 0)</span><br><span class="line"></span><br><span class="line"># ADD ID column</span><br><span class="line">df = df.withColumn(&#x27;id&#x27;, F.monotonically_increasing_id())</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">df.write.csv(&quot;data/output.csv&quot;, mode = &quot;overwrite&quot;)</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python pipeline.py</code></p>
<p>→ output.csv 가 생성되면 성공이다.</p>
<p><img src="/images/pyspark_practice03/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<ul>
<li>온도를 측정하는 코드를 작성해본다.</li>
<li>슬랙에서 다운로드<ul>
<li>1800.csv, book.txt, customer-orders.csv, fakefriends.csv</li>
</ul>
</li>
<li>chapter02_get_cleansing&#x2F;data 파일에 복사하여 옮긴다.</li>
</ul>
<p>파일 생성 : min_temp.py</p>
<p>→ 코드 작성</p>
<p><code>from pyspark import SparkConf, SparkContext</code></p>
<p><code>conf = SparkConf().setMaster(&#39;local&#39;).setAppName(&#39;MinTemperatures&#39;)</code></p>
<p><code>sc = SparkContext(conf = conf)</code></p>
<p><code>print(&quot;Hello&quot;)</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ min_temp.py를 다음과 같이 작성</p>
<p>from pyspark import SparkConf, SparkContext</p>
<p>conf &#x3D; SparkConf().setMaster(‘local’).setAppName(‘MinTemperatures’)</p>
<p>sc &#x3D; SparkContext(conf &#x3D; conf)</p>
<p>print(“Begins…”)</p>
<p>def parseLine(line):</p>
<p>fileds &#x3D; line.split(‘,’) # 문자열을 split</p>
<p>stationID &#x3D; fileds[0]</p>
<p>entryType &#x3D; fileds[2]</p>
<p>temperature &#x3D; float(fileds[3]) * 0.1 * (9.0 &#x2F; 5.0) + 32.0</p>
<p>return (stationID, entryType, temperature)</p>
<p>lines &#x3D; sc.textFile(‘data&#x2F;1800.csv’)</p>
<p>#print(lines)</p>
<p>parseLines &#x3D; lines.map(parseLine)</p>
<p>#print(parseLine)</p>
<p>minTemps &#x3D; parseLine.filter(lambda x : “TMIN” in x[1])</p>
<p>stationTemps &#x3D; minTemps.map(lambda x: (x[0], x[2]))</p>
<p>minTemps &#x3D; stationTemps.map(lambda x, y: min(x,y))</p>
<p>results &#x3D; minTemps.collect()</p>
<p>print(results)</p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<p><strong>pyspark 실습(3)</strong></p>
<ul>
<li>나이를 출력하는 코드를 작성해보자</li>
</ul>
<p>파일 생성 : friends-by-age.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;FriendsByAge&quot;)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">def parseLine(line):</span><br><span class="line">    fields = line.split(&#x27;,&#x27;)</span><br><span class="line">    age = int(fields[2])</span><br><span class="line">    numFriends = int(fields[3])</span><br><span class="line">    return (age, numFriends)</span><br><span class="line"></span><br><span class="line">lines = sc.textFile(&quot;logs/fakefriends.csv&quot;)</span><br><span class="line">rdd = lines.map(parseLine)</span><br><span class="line">totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))</span><br><span class="line">averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])</span><br><span class="line">results = averagesByAge.collect()</span><br><span class="line">for result in results:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python friends-by-age.py</code></p>
<p><strong>pyspark 실습(4)</strong></p>
<p>파일 생성 : totalspent.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 라이브러리 불러오기</span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"># 사용자 정의 함수</span><br><span class="line">def extractCusPrice(line):</span><br><span class="line">    fields = line.split(&quot;,&quot;)</span><br><span class="line">    return (int(fields[0]), float(fields[2]))</span><br><span class="line"></span><br><span class="line"># main 함수</span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    # 스파크 설정</span><br><span class="line">    conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&#x27;SpentbyCustomer&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    # 데이터 불러오기</span><br><span class="line">    input = sc.textFile(&quot;data/customer-orders.csv&quot;)</span><br><span class="line">    # print(&quot;is data?&quot;)</span><br><span class="line">    mappedInput = input.map(extractCusPrice)</span><br><span class="line">    totalByCustomer = mappedInput.reduceByKey(lambda x, y : x + y)</span><br><span class="line">		# 정렬</span><br><span class="line">    filpped = totalByCustomer.map(lambda x: (x[1], x[0]))</span><br><span class="line">    totalByCustomerStored = filpped.sortByKey()</span><br><span class="line"></span><br><span class="line">    results = totalByCustomer.collect()</span><br><span class="line">    for result in results:</span><br><span class="line">        print(result)</span><br><span class="line"></span><br><span class="line"># 실행 코드</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python totalspent.py</code></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-27T00:00:00.000Z" title="2022. 4. 27. 오전 9:00:00">2022-04-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-30T01:49:22.246Z" title="2022. 4. 30. 오전 10:49:22">2022-04-30</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">4 minutes read (About 632 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/27/pyspark_practice02/">pyspark 실습02</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step04_structype.py</p>
<p>키워드 : Struct Type</p>
<p>구글링 : Spark Struct Type, Spark Struct </p>
<p>참고 링크 :  </p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> Struct</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func </span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당 (필수)</span></span><br><span class="line"><span class="comment"># spark = SparkSession.builder.appName(&quot;&quot;)</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">toMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count().orderBy(func.desc(<span class="string">&#x27;count&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(movies_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python step04_structype.py</code></p>
<p>→ 다음 테이블이 출력되어야 한다.</p>
<p><img src="/images/pyspark_practice02/Untitled.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step05_advancestructype.py</p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadMovieNames</span>():</span><br><span class="line">    movieNames = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(<span class="string">&quot;ml-100k/u.ITEM&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;ISO-8859-1&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            fields = line.split(<span class="string">&quot;|&quot;</span>)</span><br><span class="line">            movieNames[<span class="built_in">int</span>(fields[<span class="number">0</span>])] = fields[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> movieNames</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이썬 딕셔너리 객체를 Spark 객체로 변환</span></span><br><span class="line">nameDict = spark.sparkContext.broadcast(loadMovieNames())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">topMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 딕셔너리</span></span><br><span class="line"><span class="comment"># key-value</span></span><br><span class="line"><span class="comment"># 키 값을 알면 value 자동으로 가져옴 (movieTitle)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lookupName</span>(<span class="params">movieID</span>):</span><br><span class="line">    <span class="keyword">return</span> nameDict.value[movieID]</span><br><span class="line"></span><br><span class="line">lookupNameUDF = func.udf(lookupName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MovieTitle 기존 topMovieIds 데이터에 추가</span></span><br><span class="line"><span class="comment"># 컬럼을 추가</span></span><br><span class="line">moviesWithNames = topMovieIds.withColumn(<span class="string">&quot;movieTitle&quot;</span>, lookupNameUDF(func.col(<span class="string">&quot;movieID&quot;</span>)))</span><br><span class="line"></span><br><span class="line">final_df = moviesWithNames.orderBy(func.desc(<span class="string">&quot;count&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step05_advancestructype.py</code></p>
<p>→ 다음과 같이 출력된다.</p>
<p><img src="/images/pyspark_practice02/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-26T00:00:00.000Z" title="2022. 4. 26. 오전 9:00:00">2022-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-29T12:29:53.952Z" title="2022. 4. 29. 오후 9:29:53">2022-04-29</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 685 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/26/pyspark_practice01/">pyspark 실습01</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>spark on windows 참고하여 세팅 </li>
<li>스파크를 설치한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<p><strong>pyspark 설치</strong></p>
<ul>
<li>git bash를 이용해 폴더를 생성하고 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>mkdir pyspk_project</code></p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><img src="/images/pyspark_practice01/Untitled.png" alt="Untitled"></p>
<ul>
<li>가상환경 생성 후 pyspark 설치</li>
</ul>
<p>→ <code>virtualenv venv</code></p>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ <code>pip install pyspark</code></p>
<p><img src="/images/pyspark_practice01/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습_1</strong></p>
<ul>
<li>폴더 파일 생성</li>
</ul>
<p>→ 폴더 생성 : chapter01_get_started</p>
<p>→ 파일 생성 : <code>step01_basic.py</code></p>
<p>→ 코드 작성</p>
<p><code>import pyspark</code></p>
<p><code>print(pyspark.__version__)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 실행 : <code>python step01_basic.py</code></p>
<p><img src="/images/pyspark_practice01/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ step01_basic.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import pyspark</span><br><span class="line">print(pyspark.__version__)</span><br><span class="line"></span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 스파크 세션 초기화</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;SampleTutorial&#x27;).getOrCreate()</span><br><span class="line">rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])</span><br><span class="line"></span><br><span class="line">print(&quot;rdd Count:&quot;, rdd.count())</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ 주소창에 입력 :  <a target="_blank" rel="noopener" href="http://localhost:4040/">http://localhost:4040/</a></p>
<p>→ 다음 화면이 출력된다.</p>
<ul>
<li>교재 278p</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%203.png" alt="Untitled"></p>
<p><strong>pyspark 실습_2</strong></p>
<ul>
<li>슬랙에서 dataset.zip 을 다운로드</li>
<li>압축을 풀고 chapter01_get_started 파일에 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step02_ratings.py</code></p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># SparkContext</span><br><span class="line"># RDD</span><br><span class="line"></span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line">import collections</span><br><span class="line"></span><br><span class="line">print(&quot;Hello&quot;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # MasterNode = local</span><br><span class="line">    # MapReduce</span><br><span class="line"></span><br><span class="line">    conf = SparkConf().setMaster(&#x27;local&#x27;).setAppName(&#x27;RatingsHistogram&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    lines = sc.textFile(&quot;ml-100k/u.logs&quot;)</span><br><span class="line">    ratings = lines.map(lambda x: x.split()[2])</span><br><span class="line">    print(&quot;ratings: &quot;, ratings)</span><br><span class="line"></span><br><span class="line">    result = ratings.countByValue()</span><br><span class="line">    print(&quot;result:&quot;, result)</span><br><span class="line"></span><br><span class="line">    sortedResults = collections.OrderedDict(sorted(result.items()))</span><br><span class="line">    for key, value in sortedResults.items():</span><br><span class="line">        print(&quot;%s %i&quot; % (key, value))</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step02_ratings.py</code></p>
<p>→ 다음 결과가 출력된다.</p>
<p><img src="/images/pyspark_practice01/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step03_dataloading.py</code></p>
<p>→ 코드 작성</p>
<p>→ pip install pandas</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># Spark SQL 적용</span><br><span class="line"></span><br><span class="line"># Spark Session</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 스파크 세션 생성</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">my_spark = SparkSession.builder.getOrCreate()</span><br><span class="line">print(my_spark)</span><br><span class="line"></span><br><span class="line"># 테이블을 확인하는 코드</span><br><span class="line">print(my_spark.catalog.listDatabases())</span><br><span class="line"></span><br><span class="line"># show database</span><br><span class="line">my_spark.sql(&#x27;show databases&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 현재 DB 확인</span><br><span class="line">my_spark.catalog.currentDatabase()</span><br><span class="line">my_spark.stop()</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># CSV 파일 불러오기</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;DBTutorial&#x27;).getOrCreate()</span><br><span class="line">flights = spark.read.option(&#x27;header&#x27;, &#x27;true&#x27;).csv(&#x27;data/flight_small.csv&#x27;)</span><br><span class="line"># flights.show(4)</span><br><span class="line"></span><br><span class="line"># spark.catalog.currentDatabase()</span><br><span class="line"># flights 테이블을 default DB에 추가함</span><br><span class="line">flights.createOrReplaceTempView(&#x27;flights&#x27;)</span><br><span class="line"></span><br><span class="line"># print(spark.catalog.listTables(&#x27;default&#x27;))</span><br><span class="line"># spark.sql(&#x27;show tables from default&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 쿼리 통해서 데이터 저장</span><br><span class="line">query = &quot;FROM Fligths SELECT * LIMIT 10&quot;</span><br><span class="line">query2 = &quot;SELECT * FROM flights 10&quot;</span><br><span class="line"></span><br><span class="line"># 스파크에 세션할당</span><br><span class="line">flights10 = spark.sql(query2)</span><br><span class="line">flights10.show()</span><br><span class="line"></span><br><span class="line"># Spark 데이터 프레임을 Pandas 데이터 프레임을 변환</span><br><span class="line">pd_flights10 = flights10.toPandas()</span><br><span class="line">print(pd_flights10.head())</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step03_dataloading.py</code></p>
<ul>
<li>Reference<ul>
<li>실무 예제로 배우는 데이터</li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-25T00:00:00.000Z" title="2022. 4. 25. 오전 9:00:00">2022-04-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-27T16:37:25.509Z" title="2022. 4. 28. 오전 1:37:25">2022-04-28</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">11 minutes read (About 1630 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/25/Spark_on_Windows/">Spark on Windows</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></p>
<h2 id="사전준비"><a href="#사전준비" class="headerlink" title="사전준비"></a>사전준비</h2><ul>
<li>스파크를 설치하는 과정이다.</li>
<li>사전에 파이썬 3가 설치되어 있어야 한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<h2 id="자바-다운로드"><a href="#자바-다운로드" class="headerlink" title="자바 다운로드"></a><strong>자바 다운로드</strong></h2><ul>
<li>자바를 설치한다. 설치 파일은 아래에서 다운로드 받는다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html">Java SE 8 Archive Downloads (JDK 8u211 and later)</a></strong></li>
</ul>
</li>
<li>설치 시, 오라클 로그인이 필요 할 수도 있다.</li>
</ul>
<h2 id="Spark-다운로드"><a href="#Spark-다운로드" class="headerlink" title="Spark 다운로드"></a>S<strong>park 다운로드</strong></h2><ul>
<li>이번에는 Spark를 설치한다.</li>
<li><strong>설치파일 다운로드</strong><ul>
<li>설치 URL: <strong><a target="_blank" rel="noopener" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz">https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></strong> (2022년 1월 기준)</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled.png" alt="Untitled"></p>
<h3 id="WinRAR-다운로드"><a href="#WinRAR-다운로드" class="headerlink" title="WinRAR 다운로드"></a><strong>WinRAR 다운로드</strong></h3><ul>
<li>이 때, <code>.tgz</code> 압축파일을 풀기 위해서는 <code>WinRAR</code> 을 설치한다.<ul>
<li>설치 파일: <strong><a target="_blank" rel="noopener" href="https://www.rarlab.com/download.htm">https://www.rarlab.com/download.htm</a></strong></li>
<li>본인 컴퓨터에 맞는 것을 설치한다.</li>
<li>WinRARx64 (64bit) 6.11 버전 다운로드</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%201.png" alt="Untitled"></p>
<h2 id="winutils-다운로드"><a href="#winutils-다운로드" class="headerlink" title="winutils 다운로드"></a><strong>winutils 다운로드</strong></h2><ul>
<li>이번에는 스파크가 윈도우 로컬 컴퓨터가 Hadoop으로 착각하게 만들 프로그램이 필요하다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://github.com/cdarlint/winutils">https://github.com/cdarlint/winutils</a></strong></li>
<li>여기에서 각 설치 버전에 맞는 winutils를 다운로드 받는다.</li>
</ul>
</li>
<li>이전에 받은 spark-3.2.0-bin-hadoob-3.2.tgz 와 버전이  일치하는 것을 선택해야 한다.<ul>
<li>3.2.0 버전을 다운로드 받았다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%202.png" alt="Untitled"></p>
<h2 id="자바-설치-진행"><a href="#자바-설치-진행" class="headerlink" title="자바 설치 진행"></a><strong>자바 설치 진행</strong></h2><ul>
<li>C 드라이브에 폴더 생성 : hadoob</li>
<li>다운로드 받은 파일 4개를 C&#x2F;hadoob 에 복사하여 옮긴다</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>관리자 권한으로 실행 : jdk-8u311-windows-x64</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>계속 Next 버튼 클릭 후, 아래 파일에서 경로를 수정한다. (이 때, <code>Program Files</code> 공백이 있는데, 이러한 공백은 환경 설치 시 문제가 될 수 있다.)</li>
<li>Development Tools 선택</li>
<li>change 버튼으로 변경을 진행한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로로 이동</li>
<li>Foldername: jdk 입력<ul>
<li>다음 그림과 같아야 한다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>Java를 다른 폴더에 설치하려 한다.</li>
<li>변경(C)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%207.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로에서 ‘새 폴더 만들기(M)’</li>
<li>폴더 생성 : jre</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%208.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설치 위치가 지정된다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%209.png" alt="Untitled"></p>
<ul>
<li>성공적으로 설치되었다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2010.png" alt="Untitled"></p>
<h3 id="winrar-설치-진행"><a href="#winrar-설치-진행" class="headerlink" title="winrar 설치 진행"></a><strong>winrar 설치 진행</strong></h3><ul>
<li>관리자 권한으로 실행 : winrar-x64-611</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2011.png" alt="Untitled"></p>
<ul>
<li>기본 설정으로 설치 진행</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2012.png" alt="Untitled"></p>
<h2 id="spark-설치-진행"><a href="#spark-설치-진행" class="headerlink" title="spark 설치 진행"></a><strong>spark 설치 진행</strong></h2><ul>
<li>Spark 설치를 진행한다.</li>
<li>설치 파일 우클릭 → Extract to “spark-3.2.0-bin-hadoop3.2|”</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2013.png" alt="Untitled"></p>
<h3 id="spark-폴더-생성-및-파일-이동"><a href="#spark-폴더-생성-및-파일-이동" class="headerlink" title="spark 폴더 생성 및 파일 이동"></a><strong>spark 폴더 생성 및 파일 이동</strong></h3><ul>
<li>위 과정 이후 폴더가 생성된다.</li>
<li>파일 이동을 하도록 한다.<ul>
<li>spark-3.2.0-bin-hadoop3.2 폴더 내 모든 파일을 복사한다.</li>
</ul>
</li>
<li>그 후, C드라이브 하단에 spark 폴더를 생성한 후, 모두 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2014.png" alt="Untitled"></p>
<h3 id="log4j-properties-파일-수정"><a href="#log4j-properties-파일-수정" class="headerlink" title="log4j.properties 파일 수정"></a><strong>log4j.properties 파일 수정</strong></h3><ul>
<li><code>C</code> -&gt; <code>spark</code> → <code>conf</code> → <code>[log4j.properties](http://log4j.properties)</code> 파일을 연다.</li>
<li>해당 파일을 메모장으로 연 후, 아래에서 <code>INFO</code> → <code>ERROR</code> 로 변경한다.<ul>
<li>작업 실행 시, 출력하는 모든 logs 값들을 없앨 수 있다.</li>
<li>다음과 같이 설정 후 저장</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2015.png" alt="Untitled"></p>
<h2 id="winutils-설치-진행"><a href="#winutils-설치-진행" class="headerlink" title="winutils 설치 진행"></a><strong>winutils 설치 진행</strong></h2><ul>
<li>C드라이브에서 winutils-bin 폴더를 차례로 생성한다.</li>
<li>다운로드 받은 winutils 파일을 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2016.png" alt="Untitled"></p>
<ul>
<li>이 파일이 Spark 실행 시, 오류 없이 실행될 수 있도록 파일 사용 권한을 얻도록 한다.<ul>
<li>이 때에는 CMD 관리자 권한으로 파일을 열어서 실행한다.</li>
</ul>
</li>
<li>관리자 권한으로 실행 : 명령 프롬프트</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2017.png" alt="Untitled"></p>
<ul>
<li>다음 코드들을 시행</li>
</ul>
<p>→ <code>cd c:\winutils\bin</code></p>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<ul>
<li><p>만약, ChangeFileModeByMask error (3) 에러 발생 시,</p>
<p>  C드라이브 하단에, <code>tmp\hive</code> 폴더를 차례대로 생성을 한다.</p>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2018.png" alt="Untitled"></p>
<ul>
<li>실행 결과, 에러가 발생했으므로 C드라이브에 폴더를 생성한다.</li>
<li>폴더 생성 : tmp<ul>
<li>폴더 생성 : hive</li>
</ul>
</li>
<li>다시 코드를 실행한다.</li>
</ul>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<p>→ 오류없이 실행되었다.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2019.png" alt="Untitled"></p>
<h2 id="환경변수-설정"><a href="#환경변수-설정" class="headerlink" title="환경변수 설정"></a><strong>환경변수 설정</strong></h2><ul>
<li>‘시스템 환경 변수 편집’ 열기</li>
</ul>
<p>→ <code>환경 변수(N)..</code> </p>
<p><img src="/images/Spark_on_Windows/Untitled%2020.png" alt="Untitled"></p>
<p>시스템 환경변수를 설정한다.</p>
<ul>
<li>각 사용자 계정에 <code>사용자 변수 - 새로 만들기 버튼</code>을 클릭한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2021.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설정</li>
<li><code>SPARK_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2022.png" alt="Untitled"></p>
<ul>
<li><code>JAVA_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2023.png" alt="Untitled"></p>
<ul>
<li><code>HADOOP_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2024.png" alt="Untitled"></p>
<ul>
<li>환경변수를 편집한다.</li>
<li>Path 선택 → 편집(E)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2025.png" alt="Untitled"></p>
<ul>
<li>아래 코드를 추가한다.</li>
<li>새로 만들기<ul>
<li><code>%SPARK_HOME%\bin</code></li>
<li><code>%JAVA_HOME%\bin</code></li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2026.png" alt="Untitled"></p>
<h2 id="파이썬-환경설정"><a href="#파이썬-환경설정" class="headerlink" title="파이썬 환경설정"></a><strong>파이썬 환경설정</strong></h2><ul>
<li>Python 환경설정을 추가한다.</li>
<li><code>PYSPARK_PYTHON</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2027.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON</code> 환경변수를 설정한다.</li>
<li>일단 지운다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2028.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON_OPTS</code> 환경변수를 설정한다.</li>
<li>일단 삭제한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2029.png" alt="Untitled"></p>
<h2 id="스파크-테스트"><a href="#스파크-테스트" class="headerlink" title="스파크 테스트"></a><strong>스파크 테스트</strong></h2><ul>
<li>명령  프롬프트에서 진행</li>
</ul>
<p>→ <code>c:\spark</code> 폴더로 경로를 설정 한다.</p>
<p>→ <code>pyspark</code></p>
<p><img src="/images/Spark_on_Windows/Untitled%2030.png" alt="Untitled"></p>
<ul>
<li>이번에는 <code>[README.md](http://README.md)</code> 파일을 불러와서 아래 코드가 실행되는지 확인한다.</li>
<li>다음 코드를 실행해 본다.</li>
</ul>
<p>→<code>rd = sc.textFile(&quot;README.md&quot;)</code></p>
<p>→<code>rd.count()</code></p>
<p>→ 다음 결과 출력 시 성공.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2031.png" alt="Untitled"></p>
<ul>
<li>Reference<ul>
<li><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark-_1-118d1109403e451e9f5b2f5a81627a7e">pyspark 실습_1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_2-4213c5f5b33f48c6b0156526d2023dc0">pyspark_실습_2</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_3-8bf9e94aab3942b0ae4759d21b236878">pyspark_실습_3</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-on-linux-0c14b4d491af46d787230fd974e9dde4">Spark on linux</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-UI-f2e00f267df64d16af47be23678d2c09">Spark UI</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-ML-017307a2900a4d028ad32817f42d400a">Spark ML</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-24T00:00:00.000Z" title="2022. 4. 24. 오전 9:00:00">2022-04-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-26T10:04:00.190Z" title="2022. 4. 26. 오후 7:04:00">2022-04-26</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/SQL/">SQL</a><span> / </span><a class="link-muted" href="/categories/SQL/postgreSQL/">postgreSQL</a></span><span class="level-item">4 minutes read (About 636 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/24/PSQL_practice_2/">PSQL practice 02</a></h1><div class="content"><ul>
<li><p>실무 예제로 배우는 데이터 공학 72p</p>
</li>
<li><p>파일 생성, 가상 환경 진입</p>
</li>
</ul>
<p>관리자 권한으로 실행 : Ubuntu</p>
<p>→ <code>cd ..</code>→ <code>cd ..</code>→ <code>cd mnt/c</code></p>
<p>→ <code>mkdir sql</code></p>
<p>→ <code>cd sql</code></p>
<p>→ <code>virtualenv venv</code></p>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>라이브러리 설치</li>
</ul>
<p>→ <code>pip3 install psycopg2-binary pandas faker</code></p>
<p>→ <code>pip3 install pandas</code></p>
<p>→ <code>pip3 install numpy</code></p>
<ul>
<li>실무 예제로 배우는 데이터 공학 72p 실습 진행</li>
</ul>
<p>→ <code>mkdir chapter04</code></p>
<p>→ <code>cd chapter04/</code></p>
<p>→ 파일 생성 : vi createrecord.py</p>
<p>→ 내용 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import psycopg2</span><br><span class="line"></span><br><span class="line">print(np.__version__)</span><br><span class="line">print(pd.__version__)</span><br><span class="line">print(psycopg2.__version__)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 코드 실행 : 버전 확인</p>
<p>→ <code>python3 createrecord.py</code></p>
<p>→ 버전이 출력되면 성공</p>
<ul>
<li>서비스 활성화</li>
</ul>
<p>→<code>sudo service postgresql status</code></p>
<p>→<code>sudo service postgresql stop</code></p>
<p>→<code>sudo service postgresql start</code></p>
<p>→ <a target="_blank" rel="noopener" href="http://createrecord.py/">createrecord.py</a>에 다음 내용을 추가한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import psycopg2 as db</span><br><span class="line">conn_string=&quot;dbname=&#x27;dataengineering&#x27; host=&#x27;localhost&#x27; user=&#x27;postgres&#x27; password=&#x27;postgres&#x27;&quot;</span><br><span class="line"># 집 pc에서는 201610974</span><br><span class="line">conn=db.connect(conn_string)</span><br><span class="line">cur=conn.cursor()</span><br><span class="line">print(&quot;Connected:&quot;, cur)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python3 createrecord.py</code></p>
<p>→ Connected : cursor…. 가 출력되면 성공.</p>
<ul>
<li>pgAdmin에서 실습 진행</li>
</ul>
<p>→ 관리자 권한으로 실행 : pgAdmin</p>
<p>→ 로그인 비밀번호 : 201610974</p>
<pre><code>test 서버 비밀번호 : postgres
</code></pre>
<p>→ dataengineering → Schema → public → Tables → users우클릭</p>
<p> → querytool</p>
<p><img src="/images/PSQL_practice_2/Untitled.png" alt="Untitled"></p>
<p>→ 내용 작성 : <code>SELECT * FROM public.users;</code> </p>
<p>→ F5 키로 실행한다.  </p>
<p>→ 다음과 같은 결과가 나온다.</p>
<p><img src="/images/PSQL_practice_2/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>실무 예제로 배우는 데이터 공학 77p</li>
<li>데이터 추출</li>
<li>Ubuntu에서 진행</li>
</ul>
<p>→ <a target="_blank" rel="noopener" href="http://createrecord.py/">createrecord.py</a>에 다음 내용을 추가한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 데이터 추출 예제</span><br><span class="line">print(&quot;step 2: ----- select -----&quot;)</span><br><span class="line">query = &quot;select * from users&quot;</span><br><span class="line">cur.execute(query)</span><br><span class="line">for record in cur:</span><br><span class="line">    print(record)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python3 createrecord.py</code></p>
<p>→ <a target="_blank" rel="noopener" href="http://createrecord.py/">createrecord.py</a>에 다음 내용을 추가한다.</p>
<p><code>#print(&quot;step is done!&quot;) print(cur.fetchall()) print(&quot;--------------&quot;) print(cur.fetchmany(3)) print(&quot;--------------&quot;) print(cur.fetchone()) print(&quot;----&quot;) print(cur.rowcount)</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python3 createrecord.py</code></p>
<p>→ <a target="_blank" rel="noopener" href="http://createrecord.py/">createrecord.py</a>에 다음 내용을 추가한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 78페이지 8번.</span><br><span class="line">conn = db.connect(conn_string)</span><br><span class="line">cur = conn.cursor()</span><br><span class="line">f = open(&#x27;fromdb.csv&#x27;, &#x27;w&#x27;)</span><br><span class="line">cur.copy_to(f, &#x27;users&#x27;, sep=&#x27;,&#x27;)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python3 createrecord.py</code></p>
<p>→ <code>ls</code></p>
<p>→ fromdb.csv 파일이 생성되면 성공</p>
<p>→ <a target="_blank" rel="noopener" href="http://createrecord.py/">createrecord.py</a>에 다음 내용을 추가한다.</p>
<p>#78p 11번 </p>
<p><code>f = open(&#39;fromdb.csv&#39;, &#39;r&#39;) f.read() print(&quot;reading data is done!&quot;)</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python3 createrecord.py</code></p>
<ul>
<li>새 폴더 생성</li>
</ul>
<p>→ 폴더 생성 : <code>vi querydf.py</code></p>
<p>→ 내용 작성</p>
<p><code>import psycopg2 as db import pandas as pd conn_string=&quot;dbname=&#39;dataengineering&#39; host=&#39;localhost&#39; user=&#39;postgres&#39; password=&#39;postgres&#39;&quot; conn=db.connect(conn_string)</code></p>
<p><code>df = pd.read_sql(&quot;select * from users&quot;, conn) print(df.head())</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python3 querydf.py</code></p>
<ul>
<li>Reference : 실무 예제로 배우는 데이터 공학</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-23T00:00:00.000Z" title="2022. 4. 23. 오전 9:00:00">2022-04-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-25T11:10:31.460Z" title="2022. 4. 25. 오후 8:10:31">2022-04-25</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/SQL/">SQL</a><span> / </span><a class="link-muted" href="/categories/SQL/postgreSQL/">postgreSQL</a></span><span class="level-item">4 minutes read (About 543 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/23/PSQL_practice0/">PSQL practice 01</a></h1><div class="content"><ul>
<li><p>pgAdmin은 GUI 툴 (있으나 없으나 상관이 없음)</p>
</li>
<li><p>sudo service postgresql start</p>
<p>  DB(형광등)—&gt; 쿼리</p>
<pre><code>         —&gt; Select, insert, ...

    —&gt; 형광등 켜야 불이 들어오듯 필수적이다.
</code></pre>
</li>
</ul>
<h3 id="실습"><a href="#실습" class="headerlink" title="실습"></a>실습</h3><ul>
<li>실무 예제로 배우는 데이터 공학 72p부터 따라한다.</li>
</ul>
<p>VSCord  에서 Ubuntu Terminal 열기</p>
<p>→ 폴더 생성 : chapter04</p>
<p>→ 파일 생성 : step01_createdf.py</p>
<p>→ 내용 작성</p>
<p><code>import psycopg2 as db</code></p>
<p><code># 호스트, 데이터베이스 이름, 사용자 이름, 패스워드</code></p>
<p><code>conn_string = &quot;dbname=&#39;dataengineering&#39; host = &#39;localhost&#39; user=&#39;postgres&#39; password=&#39;postgres&#39;&quot;</code></p>
<p>#집pc의 경우에는 <code>password=&#39;201610974</code>‘</p>
<p><code>conn = db.connect(conn_string)</code></p>
<p><code>cur = conn.cursor()</code></p>
<p><code>print(&quot;db connecting....&quot;)</code></p>
<p><code>print(cur)</code></p>
<p>( 아이디&#x2F; 비밀번호 모두 postgres인 듯하다)</p>
<p>→ 저장</p>
<p>→ cd .. → cd .. → cd mnt&#x2F;c → cd airflow-test → cd chapter04</p>
<p>→ 실행 : <code>python3 step01_createdf.py</code></p>
<p>→ 다음 내용이 출력되면 성공.</p>
<p>db connecting….<br>&lt;cursor object at 0x7fa097ba86d0; closed: 0&gt;</p>
<p>→ <code>step01_createdf.py</code> 파일에 다음 내용 추가하고 저장</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">query = &quot;insert into users (id,name,street,city,zip) values(&#123;&#125;,&#x27;&#123;&#125;&#x27;,&#x27;&#123;&#125;&#x27;,&#x27;&#123;&#125;&#x27;,&#x27;&#123;&#125;&#x27;)&quot;.format(1,&#x27;Big Bird&#x27;,&#x27;Sesame Street&#x27;,&#x27;Fakeville&#x27;,&#x27;12345&#x27;)</span><br><span class="line">print(cur.mogrify(query))</span><br><span class="line">query2 = &quot;insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)&quot;</span><br><span class="line">data=(1,&#x27;Big Bird&#x27;,&#x27;Sesame Street&#x27;,&#x27;Fakeville&#x27;,&#x27;12345&#x27;)</span><br><span class="line">print(cur.mogrify(query2,data))</span><br><span class="line">cur.execute(query2,data)</span><br><span class="line">conn.commit()</span><br></pre></td></tr></table></figure>

<p>→ 실행</p>
<ul>
<li>pgAdmin에서 실습 진행</li>
</ul>
<p>→ 관리자 권한으로 실행 : pgAdmin</p>
<p>→ 비밀번호 : postgres</p>
<p>→ dataengineering 우클릭 → querytool</p>
<p>→ 내용 작성 : <code>SELECT * FROM public.users;</code> </p>
<p>→ F5 키로 실행한다.  </p>
<p>→ 다음과 같은 결과가 나온다.</p>
<p><img src="/images/PSQL_practice0/Untitled.png" alt="Untitled"></p>
<ul>
<li>VSCord 에서 새로 파일을 작성한다.</li>
</ul>
<p>→ 파일 생성 : step02_insertmany.py</p>
<p>→ 내용 작성 ( 실무 예제로 배우는 데이터 공학 75p )</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import psycopg2 as db</span><br><span class="line">from faker import Faker</span><br><span class="line">fake=Faker()</span><br><span class="line">data=[]</span><br><span class="line">i=2</span><br><span class="line">for r in range(1000):</span><br><span class="line">    data.append((i,fake.name(),fake.street_address(), fake.city(),fake.zipcode()))</span><br><span class="line">    i+=1</span><br><span class="line">data_for_db=tuple(data)</span><br><span class="line">print(data_for_db)</span><br><span class="line">conn_string=&quot;dbname=&#x27;dataengineering&#x27; host=&#x27;localhost&#x27; user=&#x27;postgres&#x27; password=&#x27;postgres&#x27;&quot;</span><br><span class="line"># 집pc의 경우에는 password=&#x27;201610974&#x27;</span><br><span class="line"></span><br><span class="line">conn=db.connect(conn_string)</span><br><span class="line">cur=conn.cursor()</span><br><span class="line">query = &quot;insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)&quot;</span><br><span class="line">print(cur.mogrify(query,data_for_db[1]))</span><br><span class="line">cur.executemany(query,data_for_db)</span><br><span class="line">conn.commit()</span><br><span class="line">query2 = &quot;select * from users&quot;</span><br><span class="line"></span><br><span class="line">cur.execute(query2)</span><br><span class="line">print(cur.fetchall())</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ 실행 완료</p>
<ul>
<li>pdAdmin 으로 이동</li>
</ul>
<p>→ F5 키로 다시 실행</p>
<p>→ 다음과 같이 1000개의 데이터가 추가된다.</p>
<p><img src="/images/PSQL_practice0/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Referencd : 실무 예제로 배우는 데이터 공학</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-22T00:00:00.000Z" title="2022. 4. 22. 오전 9:00:00">2022-04-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-24T02:09:24.895Z" title="2022. 4. 24. 오전 11:09:24">2022-04-24</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">5 minutes read (About 701 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/22/Airfow_practice_3/">Airflow 실습03</a></h1><div class="content"><h2 id="Elastic-search-질의"><a href="#Elastic-search-질의" class="headerlink" title="Elastic search 질의"></a>Elastic search 질의</h2><ul>
<li>실무 예제로 배우는 데이터 공학 83p</li>
</ul>
<p>관리자 권한으로 실행 : Ubuntu</p>
<p>→ 경로 이동 : …airflow&#x2F;</p>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>code .</code></p>
<p>→ VSCord가 자동 실행된다 </p>
<p>→파일 생성 : e_query.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from pandas.io.json import json_normalize</span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line"></span><br><span class="line"># Elasticsearch 객체 생성</span><br><span class="line">es = Elasticsearch()</span><br><span class="line"></span><br><span class="line"># 일래스틱서치에 보낼 문서 본문(질의 요청) JSON 객체를 만든다.</span><br><span class="line"># Matchall 검색 사용</span><br><span class="line">doc = &#123;&quot;query&quot; : &#123;&quot;match_all&quot;: &#123;&#125;&#125;&#125;</span><br><span class="line">res = es.search(index=&quot;users&quot;, body = doc, size = 500)</span><br><span class="line"># print(res[&#x27;hits&#x27;][&#x27;hits&#x27;])</span><br><span class="line"></span><br><span class="line"># 루프로 문서를 훑으면서 각 문서의 _source 필드만 출력한다.</span><br><span class="line"># for doc in res[&#x27;hits&#x27;][&#x27;hits&#x27;]:</span><br><span class="line">#    print(doc[&#x27;_source&#x27;])</span><br><span class="line"></span><br><span class="line"># 질의 결과를 pandas DataFrame에 넣는 것도 가능</span><br><span class="line">df = json_normalize(res[&#x27;hits&#x27;][&#x27;hits&#x27;])</span><br><span class="line">print(df.head())</span><br><span class="line">print(df.info())</span><br><span class="line"></span><br><span class="line">print(df[&#x27;_source.city&#x27;].value_counts())</span><br></pre></td></tr></table></figure>

<h3 id="postgreSQL-→-Elastic-search-데이터-전송"><a href="#postgreSQL-→-Elastic-search-데이터-전송" class="headerlink" title="postgreSQL → Elastic search 데이터 전송"></a>postgreSQL → Elastic search 데이터 전송</h3><ul>
<li>교재 88p</li>
<li>Elastic search 가동된 상태에서 진행</li>
</ul>
<p>→ 선행 학습 링크 참고 : <a target="_blank" rel="noopener" href="https://www.notion.so/postgreSQL-2a8e7bf9156b4514b28aafbd93421a79">postgreSQL 실습 (notion.so)</a></p>
<ul>
<li>pgAdmin 준비된 상태에서 진행</li>
</ul>
<p>→ 다음과 같이 출력되는 상태여야 한다.</p>
<p><img src="/images/Airflow_practice_3/Untitled.png" alt="Untitled"></p>
<ul>
<li>VSCord 에서 작업</li>
<li>교재 88p</li>
</ul>
<p>dags 폴더 아래에 파일 생성</p>
<p>→ 파일 생성 : airflodb.py</p>
<p>→ 코드 작성</p>
<p><code>import datetime as dt</code></p>
<p><code>from datetime import timedelta</code></p>
<p><code>from airflow import DAG</code></p>
<p><code>from airflow.operators.bash import BashOperator</code></p>
<p><code>from airflow.operators.python import PythonOperator</code></p>
<p><code>import pandas as pd</code></p>
<p><code>import psycopg2 as db</code></p>
<p><code>from elasticsearch import Elasticsearch</code></p>
<p><code>print(&quot;Hello&quot;)</code></p>
<p>→ 경로 이동 : (venv) kmk3593@DESKTOP-LNQ780K:&#x2F;mnt&#x2F;c&#x2F;airflow-test&#x2F;dags$ </p>
<p>→ 실행</p>
<p>→ Hello 가 출력되었으므로 성공.</p>
<p><img src="/images/Airflow_practice_3/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>코드 추가 작성</li>
<li>다음 내용을 airflodb.py에 작성한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import datetime as dt</span><br><span class="line">from datetime import timedelta</span><br><span class="line">from airflow import DAG</span><br><span class="line">from airflow.operators.bash import BashOperator</span><br><span class="line">from airflow.operators.python import PythonOperator</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import psycopg2 as db</span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line"></span><br><span class="line"># queryPostgresql 지정</span><br><span class="line">def queryPostgresql():</span><br><span class="line">    conn_string=&quot;dbname=&#x27;dataengineering&#x27; host=&#x27;localhost&#x27; user=&#x27;postgres&#x27; password=&#x27;postgres&#x27;&quot;</span><br><span class="line">    conn=db.connect(conn_string)</span><br><span class="line">    print(&quot;DB connecting....&quot;, conn)</span><br><span class="line"></span><br><span class="line">    # 데이터 추출</span><br><span class="line">    df = pd.read_sql(&quot;select name, city from users&quot;, conn)</span><br><span class="line">    df.to_csv(&quot;postgresqldata.csv&quot;)</span><br><span class="line">    print(&quot;----Data Saved----&quot;)</span><br><span class="line"></span><br><span class="line"># insertElasticSearch</span><br><span class="line">def insertDataElasticsearch():</span><br><span class="line"></span><br><span class="line">    # Elastic 인스턴스 생성</span><br><span class="line">    es = Elasticsearch()</span><br><span class="line"></span><br><span class="line">    # 데이터 불러오기</span><br><span class="line">    df = pd.read_csv(&quot;postgresqldata.csv&quot;)</span><br><span class="line">    for i, r in df.iterrows():</span><br><span class="line">        doc = r.to_json()</span><br><span class="line">        res = es.index(</span><br><span class="line">            index=&quot;frompostgresql&quot;</span><br><span class="line">            , doc_type=&quot;doc&quot;, body=doc</span><br><span class="line">        )</span><br><span class="line">        print(res)</span><br><span class="line"></span><br><span class="line"># DAG를 위한 인수들을 지정</span><br><span class="line">default_args = &#123;</span><br><span class="line">    &#x27;owner&#x27; : &#x27;human&#x27;,</span><br><span class="line">    &#x27;start_date&#x27; : dt.datetime(2022, 4, 18),</span><br><span class="line">    &#x27;retries&#x27; : 1,</span><br><span class="line">    &#x27;retry_delay&#x27;: dt.timedelta(minutes = 5)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">with DAG(&#x27;MyDBdag&#x27;,</span><br><span class="line">         default_args = default_args,</span><br><span class="line">         schedule_interval = timedelta(minutes=5), # &#x27;0 * * * * &#x27;,</span><br><span class="line">     ) as dag:</span><br><span class="line"></span><br><span class="line">    getData = PythonOperator(</span><br><span class="line">        task_id = &quot;QueryPostgreSQL&quot;</span><br><span class="line">        , python_callable=queryPostgresql</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    insertData = PythonOperator(</span><br><span class="line">        task_id = &quot;InsertDataElasticsearch&quot;</span><br><span class="line">        , python_callable = insertDataElasticsearch</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">getData &gt;&gt; insertData</span><br></pre></td></tr></table></figure>

<ul>
<li>Airflow 가동</li>
</ul>
<p>→ 저장 후 실행</p>
<p>→ <code>python3 airflodb.py</code></p>
<p>→ airflow 실행</p>
<p>→ <code>airflow db init</code></p>
<p>→(재시도할 경우, 실행 : <code>airflow db reset</code> )</p>
<p>→ Terminal 2개 준비하고 다음 명령 실행</p>
<p>→<code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code></p>
<p>→ 다음 주소로 진입</p>
<p><a target="_blank" rel="noopener" href="http://localhost:8080/">http://localhost:8080/</a> </p>
<p>→ Dags</p>
<p>→ 활성화 : MyDBdag</p>
<p>→ 더블 클릭 : MyDBdag</p>
<p><img src="/images/Airflow_practice_3/Untitled%202.png" alt="Untitled"></p>
<p>→ Tree </p>
<p>→ Update</p>
<p>→ 다음과 같이 출력되면 성공</p>
<p><img src="/images/Airflow_practice_3/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>Reference : 실무 예제로 배우는 데이터 공학</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-21T00:00:00.000Z" title="2022. 4. 21. 오전 9:00:00">2022-04-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-24T01:55:54.877Z" title="2022. 4. 24. 오전 10:55:54">2022-04-24</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">4 minutes read (About 582 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/21/Airflow_practice_2/">Airflow 실습02</a></h1><div class="content"><h2 id="데이터베이스를-위한-아파치-에어플로-데이터-파이프라인-구축"><a href="#데이터베이스를-위한-아파치-에어플로-데이터-파이프라인-구축" class="headerlink" title="데이터베이스를 위한 아파치 에어플로 데이터 파이프라인 구축"></a>데이터베이스를 위한 아파치 에어플로 데이터 파이프라인 구축</h2><p>실무 예제로 배우는 데이터 공학 87 ~ 91p</p>
<p>관리자 권한으로 실행 : ubuntu</p>
<p>→ elasticsearch 가동하기</p>
<p><img src="/images/Airflow_practice_2/Untitled.png" alt="Untitled"></p>
<p>→ Kibana 가동하기 </p>
<p><img src="/images/Airflow_practice_2/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>경로 이동, 가상 환경 진입</li>
</ul>
<p>→ <code>cd ..</code>→ <code>cd ..</code>→ <code>cd mnt/c/airflow-test</code></p>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>교재의 elastic search 버전을 참고하여 설치</li>
</ul>
<p>→ <code>pip3 install elasticsearch==7.17.2</code></p>
<p><img src="/images/Airflow_practice_2/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>교재 80p</li>
<li>일단 vi 대신에 code . 를 사용한다.</li>
</ul>
<p>→ <code>code .</code></p>
<p>( 안 될 경우, Ubuntu를 다시 시작한다)</p>
<p>→ 코드 실행 시, VSCord가 자동으로 시작된다</p>
<p><img src="/images/Airflow_practice_2/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>폴더 생성</li>
</ul>
<p>→ 폴더 생성 : chapter04</p>
<p>→ 파일 생성 : e_search.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">from elasticsearch import helpers</span><br><span class="line">from faker import Faker</span><br><span class="line"></span><br><span class="line">fake=Faker()</span><br><span class="line">es = Elasticsearch() #or pi &#123;127.0.0.1&#125;</span><br><span class="line"></span><br><span class="line">doc=&#123;&quot;name&quot;: fake.name(),&quot;street&quot;: fake.street_address(), &quot;city&quot;: fake.city(),&quot;zip&quot;:fake.zipcode()&#125;</span><br><span class="line"></span><br><span class="line">res=es.index(index=&quot;users&quot;,doc_type=&quot;doc&quot;,body=doc)</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line">doc=&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;_id&quot;:&quot;pDYlOHEBxMEH3Xr-2QPk&quot;&#125;&#125;&#125;</span><br><span class="line">res=es.search(index=&quot;users&quot;,body=doc,size=10)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>

<ul>
<li>가상환경 가동 후 실행</li>
</ul>
<p>→ 저장</p>
<p>→ 터미널 </p>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>cd chapter04/</code></p>
<p>→<code>python3 e_search.py</code></p>
<ul>
<li>교재 81p</li>
</ul>
<p>→ 파일 작성 : e_search02.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">from elasticsearch import helpers</span><br><span class="line">from faker import Faker</span><br><span class="line"></span><br><span class="line">fake=Faker()</span><br><span class="line">es = Elasticsearch() #or pi &#123;127.0.0.1&#125;</span><br><span class="line"></span><br><span class="line">actions = [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;_index&quot;: &quot;users&quot;,</span><br><span class="line">    &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">	&quot;name&quot;: fake.name(),</span><br><span class="line">	&quot;street&quot;: fake.street_address(),</span><br><span class="line">	&quot;city&quot;: fake.city(),</span><br><span class="line">	&quot;zip&quot;:fake.zipcode()&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  for x in range(998) # or for i,r in df.iterrows()</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = helpers.bulk(es, actions)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python3 e_search02.py</code></p>
<p>→ 다음과 같이 (998,[]) 출력되면 성공</p>
<p><img src="/images/Airflow_practice_2/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>Kibana 페이지 실행</li>
</ul>
<p>→ 주소창에 입력 : localhost:5601&#x2F;</p>
<p>→ 메뉴바</p>
<p>→ Stack Management</p>
<p><img src="/images/Airflow_practice_2/Untitled%205.png" alt="Untitled"></p>
<p>→ Index Patterns</p>
<p><img src="/images/Airflow_practice_2/Untitled%206.png" alt="Untitled"></p>
<p>→ Create index pattern</p>
<p>→ 이름 : users</p>
<p><img src="/images/Airflow_practice_2/Untitled%207.png" alt="Untitled"></p>
<p>→ Create index pattern</p>
<p><img src="/images/Airflow_practice_2/Untitled%208.png" alt="Untitled"></p>
<p>→ 햄버거 메뉴바 열기</p>
<p>→ Discover </p>
<p><img src="/images/Airflow_practice_2/Untitled%209.png" alt="Untitled"></p>
<p>→ 앞에서 추가한 index의 문서를 확인할 수 있다.</p>
<p><img src="/images/Airflow_practice_2/Untitled%2010.png" alt="Untitled"></p>
<h3 id="데이터-저장소"><a href="#데이터-저장소" class="headerlink" title="데이터 저장소"></a>데이터 저장소</h3><ul>
<li>RDBMS</li>
</ul>
<p>— 종류 : Oracle, PostgreSQL, MySQL, 빅쿼리(구글),…</p>
<p>— 표준 SQL (하나를 잘 알면, 거의 비슷!)</p>
<ul>
<li>NoSQL</li>
</ul>
<p>— 종류 : Elasticsearch, 몽고 DB (무료 버전)</p>
<p>어려운 것 조회 하는 방법이 RDMBS ≠ NoSQL 다름 (완전 다름!)</p>
<ul>
<li>Reference <ul>
<li>실무 예제로 배우는 데이터 공학</li>
<li><a target="_blank" rel="noopener" href="https://www.notion.so/Elasticsearch-36546819d5b44c778d6a9c08f18c8339">Elasticsearch (notion.so)</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-20T00:00:00.000Z" title="2022. 4. 20. 오전 9:00:00">2022-04-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-22T08:45:17.980Z" title="2022. 4. 22. 오후 5:45:17">2022-04-22</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">9 minutes read (About 1349 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/20/Airflow_pipeline0/">Airflow 재설치 및 데이터 파이프라인 구축</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/apache_airflow_using_wsl2/">Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe</a></p>
<p><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/">Airflow 데이터 파이프라인 구축 예제 - Data Science | DSChloe</a></p>
<ul>
<li>체크포인트</li>
</ul>
<ol>
<li><p>가상환경을 만들 수 있는냐 (virtualenv 라이브러리)</p>
</li>
<li><p>경로 이동이 자유로운가? cd 사용</p>
</li>
<li><p>환경 변수를 이해하고 잡을 수 있는가?</p>
<p> vi 편집기를 자유자재로 쓸 수 있는가?</p>
</li>
<li><p>파이썬 라이브러리를 가상환경에 자유자재로 설치 할 수 있는가?</p>
</li>
<li><p>가상 환경에 자유롭게 출입할 수 있는가?</p>
</li>
</ol>
<ul>
<li>사전 준비</li>
</ul>
<p>VSCord 의 airflow.cfg 에서 진행</p>
<p>→ 내용 변경 : <code>load_examples = True</code> ⇒ <code>False</code>  </p>
<p>→ c드라이브 → airflow_test → dags와 chapter03, chapter04 를 배경화면에 빼둔다.</p>
<p><img src="/images/Airflow_pipeline0/Untitled.png" alt="Untitled"></p>
<ul>
<li>airflow-test 내용물 삭제</li>
</ul>
<p>Ubuntu 의 airflow 경로에서 진행</p>
<p>→<code>deactivate</code></p>
<p>→<code>sudo rm -rf *</code></p>
<ul>
<li>다시 가상환경 생성</li>
</ul>
<p>→<code>virtualenv venv</code></p>
<p>→<code>ls</code></p>
<ul>
<li>필요한 내용이 작성되어 있는지 확인</li>
</ul>
<p>→ <code>vi ~/.bashrc</code></p>
<p>→ 내용 확인 : <code>export AIRFLOW_HOME=/mnt/c/airflow-test</code></p>
<p>→ <code>source ~/.bashrc</code> </p>
<p>→ <code>echo $AIRFLOW_HOME</code></p>
<p>→<code>pwd</code></p>
<ul>
<li>가상환경 on</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>라이브러리 설치</li>
</ul>
<p>→ <code>pip3 install &#39;apache-airflow[postgres, slack, celery]&#39;</code></p>
<ul>
<li>db 설정</li>
</ul>
<p>→ <code>airflow db init</code></p>
<ul>
<li>계정 등록</li>
<li>firstname이 실행 결과에 영향을 주는가</li>
</ul>
<p>→ <code>airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com</code></p>
<ul>
<li>VSCord 에서 진행</li>
</ul>
<p>→ 폴더 생성 : ( file → open folder → airflow-test )</p>
<p>→ airflow.cfg 파일</p>
<p>→ 내용 변경 : <code>load_examples=True</code> ⇒ <code>False</code></p>
<p><img src="/images/Airflow_pipeline0/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Ubuntu 에서 진행</li>
</ul>
<p>→ <code>airflow db reset</code></p>
<p>→ 가상 환경 상태에서 다음 코드 실행</p>
<p>→ <code>airflow webserver -p 8080</code></p>
<ul>
<li>그리고, 해당 링크에 <a target="_blank" rel="noopener" href="http://localhost:8080/login/">http://localhost:8080/login/</a> 접속하면 아래와 같은 화면이 나타난다.</li>
</ul>
<p><img src="/images/Airflow_pipeline0/Untitled%202.png" alt="Untitled"></p>
<p>→ ctrl + c 로 빠져나온다.</p>
<h1 id="데이터-파이프라인-구축"><a href="#데이터-파이프라인-구축" class="headerlink" title="데이터 파이프라인 구축"></a>데이터 파이프라인 구축</h1><h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a><strong>개요</strong></h2><ul>
<li>이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다.</li>
</ul>
<p><strong><strong>Step 01. Dags 폴더 생성</strong></strong></p>
<ul>
<li><p>프로젝트 Root 하단에 Dags 폴더를 만든다.</p>
<ul>
<li>dags 폴더를 확인한다.</li>
</ul>
</li>
<li><p>dags 파일 생성</p>
</li>
</ul>
<p>→<code>mkdir dags</code></p>
<p>→<code>ls</code></p>
<p><strong><strong>Step 02. 가상의 데이터 생성</strong></strong></p>
<ul>
<li>라이브러리 설치</li>
</ul>
<p>→ 가상 환경에서 진행</p>
<p>→ <code>pip3 install faker pandas</code></p>
<ul>
<li>폴더, 파일 생성</li>
</ul>
<p>→ <code>mkdir data</code></p>
<p>→ <code>cd data</code></p>
<p>→ <code>vi step01_writecsv.py</code></p>
<p>→ 코드 작성.</p>
<pre><code>+ 앞으로는 이런 방식으로 코드를 작성한다.

+실무에서 필요한 습관이다.
</code></pre>
<ul>
<li>faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data&#x2F;step01_writecsv.py)</li>
</ul>
<p><img src="/images/Airflow_pipeline0/Untitled%203.png" alt="Untitled"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from faker import Faker</span><br><span class="line">import csv</span><br><span class="line">output=open(&#x27;data.csv&#x27;,&#x27;w&#x27;)</span><br><span class="line">fake=Faker()</span><br><span class="line">header=[&#x27;name&#x27;,&#x27;age&#x27;,&#x27;street&#x27;,&#x27;city&#x27;,&#x27;state&#x27;,&#x27;zip&#x27;,&#x27;lng&#x27;,&#x27;lat&#x27;]</span><br><span class="line">mywriter=csv.writer(output)</span><br><span class="line">mywriter.writerow(header)</span><br><span class="line">for r in range(1000):</span><br><span class="line">    mywriter.writerow([fake.name(),</span><br><span class="line">											fake.random_int(min=18, max=80, step=1), </span><br><span class="line">											fake.street_address(), </span><br><span class="line">											fake.city(),</span><br><span class="line">											fake.state(),</span><br><span class="line">											fake.zipcode(),</span><br><span class="line">											fake.longitude(),</span><br><span class="line">											fake.latitude()])</span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>코드를 실행한다.</li>
<li>VSCord에서 data.csv 파일이 생성되어야 한다.</li>
</ul>
<p>→ <code>python3 step01_writecsv.py</code></p>
<p>→ <code>ls</code></p>
<p>→ <code>cat data.csv</code></p>
<p><strong><strong>Step 03. csv2json 파일 구축</strong></strong></p>
<ul>
<li>이번에는 CSV와 JSON 변환 파일을 구축하는 코드를 작성한다. (파일 경로 : dags&#x2F;<strong><a target="_blank" rel="noopener" href="http://csv2json.py/">csv2json.py</a></strong>)\</li>
<li>주요 목적 함수 csvToJson()의 역할은 <code>data/data.csv</code> 파일을 불러와서 <code>fromAirflow.json</code> 파일로 변경하는 것이다.</li>
<li>DAG는 csvToJson 함수를 하나의 작업으로 등록하는 과정을 담는다. 작업의 소유자, 시작일시, 실패 시 재시도 횟수, 재시도 지연시 시간을 지정한다.<ul>
<li>자세한 옵션은 도움말을 참조한다. <strong><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html">https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html</a></strong></li>
</ul>
</li>
<li><code>print_starting &gt;&gt; csvJson</code> 에서 <code>&gt;&gt;</code> 는 하류 설정 연산자라고 부른다. (동의어 비트 자리이동 연산자)</li>
</ul>
<p>→<code>cd ..</code></p>
<p>→<code>cd dags</code></p>
<p>→<code>vi csv2json.py</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import datetime as dt</span><br><span class="line">from datetime import timedelta</span><br><span class="line"></span><br><span class="line">from airflow import DAG</span><br><span class="line">from airflow.operators.bash import BashOperator</span><br><span class="line">from airflow.operators.python import PythonOperator</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def csvToJson():</span><br><span class="line">    df=pd.read_csv(&#x27;data/data.csv&#x27;)</span><br><span class="line">    for i,r in df.iterrows():</span><br><span class="line">        print(r[&#x27;name&#x27;])</span><br><span class="line">    df.to_json(&#x27;fromAirflow.json&#x27;,orient=&#x27;records&#x27;)</span><br><span class="line"></span><br><span class="line">default_args = &#123;</span><br><span class="line">    &#x27;owner&#x27;: &#x27;human&#x27;,</span><br><span class="line">    &#x27;start_date&#x27;: dt.datetime(2020, 3, 18),</span><br><span class="line">    &#x27;retries&#x27;: 1,</span><br><span class="line">    &#x27;retry_delay&#x27;: dt.timedelta(minutes=5),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">with DAG(&#x27;MyCSVDAG&#x27;,</span><br><span class="line">         default_args=default_args,</span><br><span class="line">         schedule_interval=timedelta(minutes=5),      # &#x27;0 * * * *&#x27;,</span><br><span class="line">         ) as dag:</span><br><span class="line"></span><br><span class="line">    print_starting = BashOperator(task_id=&#x27;starting&#x27;,</span><br><span class="line">                               bash_command=&#x27;echo &quot;I am reading the CSV now.....&quot;&#x27;)</span><br><span class="line"></span><br><span class="line">    csvJson = PythonOperator(task_id=&#x27;convertCSVtoJson&#x27;,</span><br><span class="line">                                 python_callable=csvToJson)</span><br><span class="line"></span><br><span class="line">print_starting &gt;&gt; csvJson</span><br></pre></td></tr></table></figure>

<ul>
<li>코드를 실행한다.</li>
<li>VSCord에서 json 파일이 생성되어야 한다.</li>
</ul>
<p>→<code>python3 csv2json.py</code></p>
<h2 id="Step-04-Airflow-Webserver-및-Scheduler-동시-실행"><a href="#Step-04-Airflow-Webserver-및-Scheduler-동시-실행" class="headerlink" title="Step 04. Airflow Webserver 및 Scheduler 동시 실행"></a><strong>Step 04. Airflow Webserver 및 Scheduler 동시 실행</strong></h2><ul>
<li>이제 웹서버와 스케쥴러를 동시에 실행한다. (터미널을 2개 열어야 함에 주의한다.)</li>
</ul>
<p>VSCord 에서 WSL 터미널을 2개 띄운다.</p>
<p>→ <code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code> </p>
<p><img src="/images/Airflow_pipeline0/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>error 발생할 경우 대처</li>
</ul>
<p>airflow.cfg의 endproint_url &#x3D; 8080 체크</p>
<p>→<code>airflow db reset</code></p>
<p>→<code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code></p>
<p>→ 이 과정을 반복</p>
<p>→ 그래도 안 되면 airflow 지우고 다시 시작</p>
<p>이제 WebUI를 확인하면 정상적으로 작동하는 것을 확인할 수 있다</p>
<h2 id="Step-05-작업-결과물-확인"><a href="#Step-05-작업-결과물-확인" class="headerlink" title="Step 05. 작업 결과물 확인"></a><strong>Step 05. 작업 결과물 확인</strong></h2><ul>
<li><p>최초 목적인 <code>fromAirflow.json</code> 로 정상적으로 변환되었는지 확인하도록 한다.</p>
<ul>
<li><code>fromAirflow.json</code> 파일이 확인된다면, 정상적으로 작업이 끝난 것이다.</li>
</ul>
<p>  → <code>ls</code></p>
<p>  → 다음 내용이 출력되면 성공</p>
<p>  → <code>airflow-webserver.pid  airflow.cfg  airflow.db  dags  data  fromAirflow.json  logs  venv  webserver_config.py</code></p>
<ul>
<li>팁</li>
</ul>
<p>  human@DESKTOP-V24TVMS:&#x2F;mnt&#x2F;c&#x2F;airflow$ <code>export AIRFLOW_HOME=&quot;$(pwd)&quot;</code></p>
<p>  human@DESKTOP-V24TVMS:&#x2F;mnt&#x2F;c&#x2F;airflow$ <code>echo $AIRFLOW_HOME</code>
  </p>
</li>
<li><p>Reference : 실무 예제로 배우는 데이터 공학</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-19T00:00:00.000Z" title="2022. 4. 19. 오전 9:00:00">2022-04-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-21T08:34:18.341Z" title="2022. 4. 21. 오후 5:34:18">2022-04-21</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/VScode/">VScode</a></span><span class="level-item">8 minutes read (About 1258 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/19/VSCode_install/">VSCord Install</a></h1><div class="content"><h1 id="VSCode-Remote-WSL"><a href="#VSCode-Remote-WSL" class="headerlink" title="VSCode Remote WSL"></a>VSCode Remote WSL</h1><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/vscode_wsl2/">VSCode Remote WLS 연동 - Data Science | DSChloe</a></p>
<ul>
<li>eclipse 보다 가볍다</li>
</ul>
<h2 id="VSCode-설치"><a href="#VSCode-설치" class="headerlink" title="VSCode 설치"></a><strong>VSCode 설치</strong></h2><ul>
<li>우선 VSCode를 설치한다.<ul>
<li>URL : <strong><a target="_blank" rel="noopener" href="https://code.visualstudio.com/download">https://code.visualstudio.com/download</a></strong></li>
</ul>
</li>
<li>이 때, 관리자로 실행할 것이기 때문에 System Installer를 다운로드 받는다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled.png" alt="Untitled"></p>
<ul>
<li>설치 시, 환경 변수 체크란 잘 확인한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>설치가 다 끝난 후에는 재부팅을 실시한다.</li>
<li>관리자 권한으로 실행 : visual studio</li>
</ul>
<h2 id="Remote-WSL-연동"><a href="#Remote-WSL-연동" class="headerlink" title="Remote WSL 연동"></a><strong>Remote WSL 연동</strong></h2><ul>
<li>좌측 탭에서 Extension 버튼을 클릭한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>검색 창에서 Remote WSL을 검색 후, 설치를 진행한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>모두 클릭 후, Mark Done을 선택한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>Open Folder를 클릭한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>WSL에서 설치했던 airflow-test 폴더를 선택한다.</li>
</ul>
<p>file → Open Folder → c 드라이브 → airflow_test 열기</p>
<p><img src="/images/VSCode_install/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>메뉴 바에 Terminal 선택 후, 화면 하단에서 WSL이 있는지 확인한다.</li>
<li>Terminal 열어서 Ubuntu 실행한다.</li>
</ul>
<p>Terminal </p>
<p>→ new terminal </p>
<p>→ 우측의 + 버튼으로 Ubuntu(WSL) 열기</p>
<p><img src="/images/VSCode_install/Untitled%207.png" alt="Untitled"></p>
<h3 id="사용법"><a href="#사용법" class="headerlink" title="사용법"></a>사용법</h3><ul>
<li>해당 메뉴를 클릭하면 아래와 같이 터미널이 변경된 것을 확인할 수 있다.</li>
<li>이번엔 서버를 가동해본다.</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>airflow webserver -p 8081</code></p>
<ul>
<li>사용해본다.</li>
</ul>
<p>→ <code>which python3</code></p>
<h3 id="라이브러리-설치"><a href="#라이브러리-설치" class="headerlink" title="라이브러리 설치"></a>라이브러리 설치</h3><ul>
<li>앞으로 ubuntu를 키지 않고 VScode에서 사용한다.</li>
<li>라이브러리를 설치한다.</li>
</ul>
<p>→<code>pip3 install faker</code></p>
<p>→<code>pip3 install pandas</code></p>
<h3 id="실습"><a href="#실습" class="headerlink" title="실습"></a>실습</h3><ul>
<li>파이썬 사용</li>
</ul>
<p>폴더 생성 : 폴더 그림+ 버튼</p>
<p>→ chapter03 폴더 생성</p>
<p>→ 파일 생성 : 파일 그림+ 버튼</p>
<p>→ <a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 파일 생성</p>
<p>→ 내용 작성 : print(”Hello World!”)</p>
<p>→ save ( ctrl + s)</p>
<p><img src="/images/VSCode_install/Untitled%208.png" alt="Untitled"></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 를 실행한다.</li>
</ul>
<p>wsl Terminal 에서 다음 내용 작성</p>
<p>→ <code>cd chapter 03/</code></p>
<p>→ <code>python3 hello.py</code></p>
<p>→ <a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 실행되면 성공</p>
<p><img src="/images/VSCode_install/Untitled%209.png" alt="Untitled"></p>
<ul>
<li>가상파일 만들기</li>
</ul>
<p>파일 생성 : step01_writecsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 44p </p>
<p><code>from faker import Faker import csv output=open(&#39;data.csv&#39;,&#39;w&#39;) fake=Faker() header=[&#39;name&#39;,&#39;age&#39;,&#39;street&#39;,&#39;city&#39;,&#39;state&#39;,&#39;zip&#39;,&#39;lng&#39;,&#39;lat&#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.writerow([[fake.name](http://fake.name/)(),fake.random_int(min=18, max=80, step=1), fake.street_address(), fake.city(),fake.state(),fake.zipcode(),fake.longitude(),fake.latitude()]) output.close()</code></p>
<p>→ 저장 후 실행 : <code>python3 step1_writecsv.py</code></p>
<p>→ data.csv 파일이 생성된다.</p>
<p>파일 생성 : step02_readcsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 44 ~ 45p </p>
<p><code>import csv</code></p>
<p><code>with open(&#39;data.csv&#39;) as f:</code></p>
<p><code>myreader = csv.DictReader(f)</code></p>
<p><code>headers = next(myreader)</code></p>
<p><code>for row in myreader:</code></p>
<p><code>print(row[&#39;name&#39;])</code></p>
<p>→ 저장 후 실행 : <code>python3 step2_readcsv.py</code></p>
<p>→ 여러 사람의 이름이 출력되면 성공</p>
<p>파일 생성 : step03_pandas.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 p </p>
<p><code>import pandas as pd</code></p>
<p><code>df = pd.read_csv(&#39;data.csv&#39;)</code></p>
<p><code>df.head(10)</code></p>
<p><code>df.to_csv(&#39;fromdf.csv&#39;, index=False)</code></p>
<p>→ 저장 후 실행</p>
<p>→ data.csv 파일 내용과 동일한 fromdf.csv 파일이 생성된다.</p>
<p>파일 생성 : step04_writejson.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 48p </p>
<p><code>from faker import Faker</code></p>
<p><code>import json</code></p>
<p><code>output = open(&#39;data.json&#39;, &#39;w&#39;)</code></p>
<p><code>fake = Faker()</code></p>
<p><code>alldata = &#123;&#125;</code></p>
<p><code>alldata[&#39;records&#39;] = []</code></p>
<p><code>for x in range(1000):</code></p>
<p><code>data = &#123;</code></p>
<p><code>&quot;name&quot;   : fake.name(),</code></p>
<p><code>&quot;age&quot;    : fake.random_int(min=18, max=80, step=1),</code></p>
<p><code>&quot;street&quot; : fake.street_address(),</code></p>
<p><code>&quot;city&quot;   : fake.city(),</code></p>
<p><code>&quot;state&quot;  : fake.state(),</code></p>
<p><code>&quot;zip&quot;    : fake.zipcode(),</code></p>
<p><code>&quot;lng&quot;    : float(fake.longitude()),</code></p>
<p><code>&quot;lat&quot;    : float(fake.latitude())&#125;</code></p>
<p><code>alldata[&#39;records&#39;].append(data)</code></p>
<p><code>json.dump(alldata, output)</code></p>
<p>→ 저장 후 실행</p>
<p>→ data.json 이 생성된다.</p>
<h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><p>파일 생성 : step05_readjson.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 49p </p>
<p><code>import json</code></p>
<p><code>with open(&#39;data.json&#39;, &#39;r&#39;) as f:</code></p>
<p><code>data = json.load(f)</code></p>
<p><code>print(&quot;Data Type is &quot;, type(data))</code></p>
<p><code>print(data[&#39;records&#39;][0][&#39;name&#39;])</code></p>
<p>→ 저장 후 실행</p>
<p>→ 사람 이름이 출력된다.</p>
<p>파일 생성 : step06_pandas.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 49p </p>
<p><code>import pandas.io.json as pd_JSON</code></p>
<p><code>import pandas as pd</code></p>
<p><code>f = open(&#39;data.json&#39;, &#39;r&#39;)</code></p>
<p><code>data = pd_JSON.loads(f.read())</code></p>
<p><code>df = pd.json_normalize(data, record_path=&#39;records&#39;)</code></p>
<p><code>print(df.head(2))</code></p>
<p><code>print(df.head(2).to_json())</code></p>
<p><code>print(df.head(2).to_json(orient=&#39;records&#39;))</code></p>
<p>→ 저장 후 실행</p>
<p>→이름, 거리, 도시 등이 출력된다.</p>
<h3 id="전처리-순서"><a href="#전처리-순서" class="headerlink" title="전처리 순서"></a>전처리 순서</h3><p>CSV —&gt; 데이터 프레임 변환 —&gt; 오라클 or PostgreSQL</p>
<h3 id="비정형-데이터"><a href="#비정형-데이터" class="headerlink" title="비정형 데이터"></a>비정형 데이터</h3><p>-이미지 &#x2F; 텍스트</p>
<p>JSON —&gt; Pandas 데이터 프레임 변환 —&gt; 전처리 </p>
<p>—&gt; JSON(NoSQL) —&gt; ElasticSearch —&gt; 시각화(Kibana)</p>
<p>파일 생성 : step07_airflowcsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 51 ~ 54 p </p>
<p>→ 저장 후 실행</p>
<p>톱니바퀴 모양의 ‘airflow’를 연다</p>
<p>→ 다음 그림과 같이 경로가 잡혀있다.</p>
<p><img src="/images/VSCode_install/Untitled%2010.png" alt="Untitled"></p>
<h3 id="이-부분은-일단-넘어간다"><a href="#이-부분은-일단-넘어간다" class="headerlink" title="이 부분은 일단 넘어간다."></a>이 부분은 일단 넘어간다.</h3><p>폴더 생성 : airflowcsv.py</p>
<p>→ 파일 복사 붙여넣기 : data.csv </p>
<ul>
<li>Apache-Airflow 세팅 참고하여 진행</li>
</ul>
<p>-<a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/apache_airflow_using_wsl2/">Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe</a></p>
<p>→<code>airflow dbinit</code></p>
<p>→<code>airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com</code></p>
<p>→<code>airflow webserver -p 8081</code></p>
<p>→<code>source venv/bin/acivate</code></p>
<p>→<code>airflow scheduler</code></p>
<p>로그인</p>
<p>아이디 :airflow</p>
<p>비번 : </p>
<p><code>cd dags</code></p>
<p><code>airflow dbinit</code></p>
<p><code>aiflow us,,,,</code></p>
<p><code>airflow webserber -p 8081</code></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">61</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">23</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="level-start"><span class="level-item">생활코딩</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/%EA%B8%B0%EC%B4%88/"><span class="level-start"><span class="level-item">기초</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"><span class="level-start"><span class="level-item">분석 방법</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/SQL/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/git/github-blog/"><span class="level-start"><span class="level-item">github blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/"><span class="level-start"><span class="level-item">library</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/numpy/"><span class="level-start"><span class="level-item">numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pandas/"><span class="level-start"><span class="level-item">pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pyspark/"><span class="level-start"><span class="level-item">pyspark</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/visualization/"><span class="level-start"><span class="level-item">visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/machine-learning/"><span class="level-start"><span class="level-item">machine learning</span></span><span class="level-end"><span class="level-item tag">22</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">데이터 전처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"><span class="level-start"><span class="level-item">비지도학습</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"><span class="level-start"><span class="level-item">알고리즘</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"><span class="level-start"><span class="level-item">인공신경망</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"><span class="level-start"><span class="level-item">자료형, 반복문, 조건문</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"><span class="level-start"><span class="level-item">클래스</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"><span class="level-start"><span class="level-item">함수</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/NiFi/"><span class="level-start"><span class="level-item">NiFi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/airflow/"><span class="level-start"><span class="level-item">airflow</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/anaconda/"><span class="level-start"><span class="level-item">anaconda</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/crawling/"><span class="level-start"><span class="level-item">crawling</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/elasticsearch/"><span class="level-start"><span class="level-item">elasticsearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/wsl2/"><span class="level-start"><span class="level-item">wsl2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-08T00:00:00.000Z">2022-05-08</time></p><p class="title"><a href="/2022/05/08/Oracle_practice_4/">Oracle_practice4</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-07T00:00:00.000Z">2022-05-07</time></p><p class="title"><a href="/2022/05/07/Oracle_practice_3/">Oracle_practice3</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-06T00:00:00.000Z">2022-05-06</time></p><p class="title"><a href="/2022/05/06/Oracle_practice_2/">Oracle_practice2</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-05T00:00:00.000Z">2022-05-05</time></p><p class="title"><a href="/2022/05/05/Oracle_practice1/">Oracle_practice1</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-04T00:00:00.000Z">2022-05-04</time></p><p class="title"><a href="/2022/05/04/Oracle_setting/">Oracle_setting</a></p><p class="categories"><a href="/categories/setting/">setting</a> / <a href="/categories/setting/oracle/">oracle</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NiFi/"><span class="tag">NiFi</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Notion/"><span class="tag">Notion</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R-Markdown/"><span class="tag">R Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VScord/"><span class="tag">VScord</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anaconda/"><span class="tag">anaconda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawling/"><span class="tag">crawling</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-blog/"><span class="tag">github blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/oracle/"><span class="tag">oracle</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgreSQL/"><span class="tag">postgreSQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="tag">생활코딩</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>