<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>kmk3593 blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="kmk3593 blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="kmk3593 blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="kmk3593 blog"><meta property="og:url" content="https://kmk3593.github.io/"><meta property="og:site_name" content="kmk3593 blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kmk3593.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kmk3593.github.io"},"headline":"kmk3593 blog","image":["https://kmk3593.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"kmk3593 blog","logo":{"@type":"ImageObject","url":"https://kmk3593.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-04T00:00:00.000Z" title="2022. 5. 4. 오전 9:00:00">2022-05-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-07T07:32:45.697Z" title="2022. 5. 7. 오후 4:32:45">2022-05-07</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/oracle/">oracle</a></span><span class="level-item">10 minutes read (About 1436 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/04/Oracle_setting/">Oracle_setting</a></h1><div class="content"><h2 id="사전준비"><a href="#사전준비" class="headerlink" title="사전준비"></a>사전준비</h2><ul>
<li>오라클을 설치한다.</li>
</ul>
<p>구글링 : oracle database 19c download</p>
<p><a target="_blank" rel="noopener" href="https://www.oracle.com/kr/database/technologies/oracle19c-windows-downloads.html">Oracle Database 19c Download for Microsoft Windows x64 (64-bit) | Oracle 대한민국</a></p>
<p><img src="/images/Oracle_setting/Untitled.png" alt="Untitled"></p>
<ul>
<li>SQL Developer 설치한다.</li>
</ul>
<p>구글링 : sql developer</p>
<p><a target="_blank" rel="noopener" href="https://www.oracle.com/tools/downloads/sqldev-downloads.html">Oracle SQL Developer Downloads</a></p>
<p><img src="/images/Oracle_setting/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>c 드라이브  경로에 폴더 생성 : sql_lecture</li>
</ul>
<p>앞서 다운로드한 설치 파일을 sql_lecture 폴더에 정리한다.</p>
<ul>
<li>압축 해제한다.</li>
</ul>
<p>우클릭 후에 “extract WINDOWS.X64\”</p>
<ul>
<li>관리자 권한으로 실행 : setup</li>
<li>다음 경로로 이동하여 실행하면 된다.</li>
</ul>
<p>c 드라이브 → sql_lecture 폴더 → WINDOWS.X64_193000_db_home 폴더 → setup</p>
<p><img src="/images/Oracle_setting/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>체크 : 단일 인스턴스 데이터베이스 생성 및 구성</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>체크 : 데스크톱 클래스</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>체크 : 가상 계정 사용</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>오라클 SQL과 PL&#x2F;SQL을 다루는 기술 22p 참고하여 설정한다.</li>
<li>전역 데이터베이스 이름 : myoracle</li>
<li>비밀번호 : 1234</li>
<li>체크 해제 : 컨테이너 베이스로 생성</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>설치까지 진행한다.</li>
<li>설치 완료</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%207.png" alt="Untitled"></p>
<h2 id="1단계-sqlplus-실행하기"><a href="#1단계-sqlplus-실행하기" class="headerlink" title="1단계 sqlplus 실행하기"></a><strong>1단계 sqlplus 실행하기</strong></h2><ul>
<li>관리자 권한으로 실행  : SQL Plus</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%208.png" alt="Untitled"></p>
<ul>
<li>정보를 입력한다.</li>
</ul>
<p>→사용자명 : <code>system</code></p>
<p>→비밀번호 : <code>1234</code></p>
<p><img src="/images/Oracle_setting/Untitled%209.png" alt="Untitled"></p>
<h2 id="2단계-테이블-스페이스-생성하기"><a href="#2단계-테이블-스페이스-생성하기" class="headerlink" title="2단계 : 테이블 스페이스 생성하기"></a><strong>2단계 : 테이블 스페이스 생성하기</strong></h2><ul>
<li>오라클 SQL과 PL&#x2F;SQL을 다루는 기술  27p 참고</li>
<li>다음 코드를 사용하여 테이블 스페이스를 생성한다.<ul>
<li>테이블 스페이스는 myts라 명명하고 100MB 크기로 생성</li>
<li>만약 데이터가 증가하면 5MB씩 자동 증가 옵션 추가</li>
</ul>
</li>
</ul>
<p>→<code>CREATE TABLESPACE myts DATAFILE &#39;C:\sql_lecture\oradata\MYORACLE\myts.dbf&#39; SIZE 100M AUTOEXTEND ON NEXT 5M;</code></p>
<p><img src="/images/Oracle_setting/Untitled%2010.png" alt="Untitled"></p>
<h2 id="3단계-사용자-생성"><a href="#3단계-사용자-생성" class="headerlink" title="3단계 : 사용자 생성"></a><strong>3단계 : 사용자 생성</strong></h2><ul>
<li><p>해당 사용자에게 롤(Role, 권한)을 부여해야 한다. 현 시점에서는 ‘ora_user’ 사용자에게 DBA라는 롤을 부여한다.</p>
<ul>
<li>이 권한을 부여받으면 오라클에서 제공하는 웬만한 기능을 모두 사용한다.</li>
</ul>
</li>
<li><p>사용자를 생성하는 코드를 작성한다.</p>
</li>
</ul>
<p>(패스워드를 evan으로 할 경우, 다음과 같이 작성)</p>
<p>→<code>CREATE USER ora_user IDENTIFIED BY evan DEFAULT TABLESPACE MYTS TEMPORARY TABLESPACE TEMP;</code></p>
<p><img src="/images/Oracle_setting/Untitled%2011.png" alt="Untitled"></p>
<h2 id="4단계-사용자-계정으로-DB에-접속하기"><a href="#4단계-사용자-계정으로-DB에-접속하기" class="headerlink" title="4단계 : 사용자 계정으로 DB에 접속하기"></a><strong>4단계 : 사용자 계정으로 DB에 접속하기</strong></h2><ul>
<li>ora_user로 접속한다.</li>
</ul>
<p>→<code>GRANT DBA TO ora_user;</code></p>
<p>→<code>connect ora_user/evan;</code></p>
<ul>
<li>접속 후, show user; 입력하면 현재 로그인한 사용자 이름이 출력된다.</li>
</ul>
<p>→  <code>show user;</code></p>
<p><img src="/images/Oracle_setting/Untitled%2012.png" alt="Untitled"></p>
<h2 id="SQL-Developer-실행"><a href="#SQL-Developer-실행" class="headerlink" title="SQL Developer 실행"></a><strong>SQL Developer 실행</strong></h2><ul>
<li><p>새 접속 화면이 나타나면 접속 이름, 사용자 이름을 ora_user로 입력, 비밀번호는 입력, SID 항목에는 처음 설치 시 이름인 myoracle을 입력하고 테스트를 실행한다.</p>
</li>
<li><p>압축 해제한다.</p>
</li>
</ul>
<p>우클릭 후에 “extract sqldeveloper214.3…”</p>
<ul>
<li>관리자 권한으로 실행 : sqldeveloper</li>
<li>다음 경로로 이동하여 실행하면 된다.</li>
</ul>
<p>c 드라이브 → sql_lecture 폴더 → sqldeveloper-21.4.3.063.0100-x64 폴더</p>
<p>→ sqldeveloper 폴더 → sqldeveloper</p>
<ul>
<li>만약 다음 확인 창이 출력되면 ‘아니오’ 선택한다.</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2013.png" alt="Untitled"></p>
<ul>
<li>Oracle 접속을 새로 만든다.</li>
</ul>
<p>우클릭 : Oracle 접속 → 새 접속</p>
<p><img src="/images/Oracle_setting/Untitled%2014.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설정하고 ‘테스트’<ul>
<li>사용자 이름 : ora_user</li>
<li>비밀번호 : evan</li>
</ul>
</li>
<li>상태 : 성공</li>
<li>성공했다면 ‘접속’</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2015.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 출력된다.</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2016.png" alt="Untitled"></p>
<h3 id="환경설정"><a href="#환경설정" class="headerlink" title="환경설정"></a>환경설정</h3><ul>
<li>다음 환결설정에서 인코딩을 UTF-8로 변경한다.<ul>
<li>메뉴 바 → 도구 → 환경 설정 → 환경 → 인코딩 : UTF-8</li>
</ul>
</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2017.png" alt="Untitled"></p>
<h2 id="SQL-Developer-날짜-기록"><a href="#SQL-Developer-날짜-기록" class="headerlink" title="SQL Developer 날짜 기록"></a><strong>SQL Developer 날짜 기록</strong></h2><ul>
<li>다음 경로로 [NLS] 항목을 선택한다.<ul>
<li>메뉴 바 → 도구 → 환경 설정 → 데이터 베이스 → NLS</li>
</ul>
</li>
<li>NLS에서 ‘시간 기록 형식’을 수정.<ul>
<li>다음과 같이 수정한다.</li>
<li>시간 기록 형식 : <code>YYYY/MM/DD HH24:MI:SS</code></li>
</ul>
</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2018.png" alt="Untitled"></p>
<h2 id="샘플-스키마-설치"><a href="#샘플-스키마-설치" class="headerlink" title="샘플 스키마 설치"></a><strong>샘플 스키마 설치</strong></h2><ul>
<li>expall.dmp와 expcust.dmp 파일을 내려 받는다.<ul>
<li>URL : <strong><a target="_blank" rel="noopener" href="https://github.com/gilbutITbook/006696/tree/master/01%EC%9E%A5%20%ED%99%98%EA%B2%BD%EC%84%A4%EC%A0%95">https://github.com/gilbutITbook/006696/tree/master/01장 환경설정</a></strong></li>
</ul>
</li>
<li>c 드라이브에 폴더 생성<ul>
<li>폴더 생성 : backup</li>
</ul>
</li>
<li>backup 폴더에 expall.dmp와 expcust.dmp 파일을 옮긴다.</li>
</ul>
<p><img src="/images/Oracle_setting/Untitled%2019.png" alt="Untitled"></p>
<ul>
<li>관리자 권한으로 실행 : 명령 프롬프트</li>
<li>C:\backup 경로로 이동한다.</li>
<li>다음 코드 실행 : expall.dmp 을 올린다.</li>
</ul>
<p>→ <code>imp ora_user/evan file=expall.dmp log=empall.log ignore=y grants=y rows=y indexes=y full=y</code></p>
<ul>
<li>다음 코드 실행 : expcust.dmp 을 올린다.</li>
</ul>
<p>→ <code>imp ora_user/evan file=expcust.dmp log=expcust.log ignore=y grants=y rows=y indexes=y full=y</code></p>
<p><img src="/images/Oracle_setting/Untitled%2020.png" alt="Untitled"></p>
<ul>
<li>임포트가 정상 종료되었다면 Oracle SQL로 이동하여 작업</li>
<li>다음 코드를 작성</li>
</ul>
<p>→ <code>SELECT table_name FROM user_tables;</code></p>
<p>→ 실행 : ctrl + enter</p>
<p>→ 다음과 같이 출력되면 성공.</p>
<p><img src="/images/Oracle_setting/Untitled%2021.png" alt="Untitled"></p>
<ul>
<li>Git 연동</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://dschloe.github.io/sql/sql_developer_git/">SQL Developer with Git - Data Science | DSChloe</a></p>
<ul>
<li>Reference<ul>
<li><a target="_blank" rel="noopener" href="https://dschloe.github.io/sql/oracle_basic_settings/">오라클 19c 기본 세팅 - Data Science | DSChloe</a></li>
<li>오라클 SQL과 PL&#x2F;SQL을 다루는 기술</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-01-258c74449f7a4702ac7467e8a6b0f625">Oracle 실습01</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-02-636623398364433b83a639c7d38180d4">Oracle 실습02</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-03-87b53c73e8de435784c75d42ccbe2ea3">Oracle 실습03</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-04-9d7e412bb0a04a3bbcdf4f51c2bd8a3d">Oracle 실습04</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-05-d2556785ba544df08bffc522d8a091a3">Oracle 실습05</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-06-e6d9ef003103443599879907fc62cedd">Oracle 실습06</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Oracle-on-Jupyter-Lab-309b8ea23af042dea205e8664c8c6387">Oracle on Jupyter Lab</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-03T00:00:00.000Z" title="2022. 5. 3. 오전 9:00:00">2022-05-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-06T02:41:40.139Z" title="2022. 5. 6. 오전 11:41:40">2022-05-06</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/crawling/">crawling</a></span><span class="level-item">3 minutes read (About 509 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/03/Crawling_practice0/">Crawling_practice</a></h1><div class="content"><ul>
<li>웹 크롤링을 시도해본다.</li>
<li>우선 Pycharm 환경에서 가상환경을 생성해야 한다.</li>
</ul>
<p>바탕화면에 crawling 폴더 생성</p>
<p>→ 우클릭하여 pycharm으로 열기</p>
<p>→ File → Settings</p>
<p>→ Project : crawling → python interpreter</p>
<p>→ 톱니모양 → add</p>
<p><img src="/images/Crawling_practice0/Untitled.png" alt="Untitled"></p>
<ul>
<li>필요한 패키지들을 설치한다.</li>
</ul>
<p>→ git bash 터미널</p>
<p>→<code>pip install beautifulsoup4</code></p>
<p>→<code>pip install numpy pandas matplotlib seaborn</code></p>
<p>→<code>pip install requests</code></p>
<ul>
<li>브라우저에서 검색을 진행</li>
</ul>
<p>→ 검색 : 확진자수</p>
<p>→ 우클릭 → 검사</p>
<p><img src="/images/Crawling_practice0/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>원하는 정보가 포함된 코드를 선택 가능</li>
</ul>
<p><img src="/images/Crawling_practice0/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>index.html을 생성한다.</li>
</ul>
<p>crawling 폴더 우클릭 → New → HTML.file</p>
<p><img src="/images/Crawling_practice0/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 입력하고 index 파일을 열어본다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;titl&gt;test&lt;/titl&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;h1&gt;aaaaaaaa&lt;/h1&gt;</span><br><span class="line">    &lt;h2&gt;dddd&lt;/h2&gt;</span><br><span class="line">    &lt;div class=&quot;chapter01&quot;&gt;</span><br><span class="line">        &lt;p&gt;Don&#x27;t Crawl here &lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    &lt;div class=&quot;chapter02&quot;&gt;</span><br><span class="line">        &lt;p&gt;Just Crawling here&lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>index 파일을 열면 index.html에 작성한 대로 출력된다.</li>
</ul>
<p><img src="/images/Crawling_practice0/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>이번에는 다른 파일에 코드를 작성해보자.<ul>
<li>일단 main.py에 작성한다.</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"># 첫 번째 작업 index.html 파일을 BeautifulSoup 객체로 변환</span><br><span class="line">## 클래스 변환 --&gt; 클래스 내부의 메서드 사용</span><br><span class="line"></span><br><span class="line"># html 파일을 변환</span><br><span class="line">soup = BeautifulSoup(open(&quot;index.html&quot;, encoding=&#x27;UTF-8&#x27;), &quot;html.parser&quot;)</span><br><span class="line"># print(type(soup))</span><br><span class="line"></span><br><span class="line"># print(soup.find(&quot;div&quot;, class_=&quot;chapter02&quot;))</span><br><span class="line"># print(soup.find(&quot;p&quot;))</span><br><span class="line">results = soup.find_all(&quot;p&quot;)</span><br><span class="line">print(results[1])</span><br></pre></td></tr></table></figure>

<ul>
<li>Index.html에서 크롤링하여 다음과 같이 출력된다.</li>
</ul>
<p>→ <code>python main.py</code></p>
<p><img src="/images/Crawling_practice0/Untitled%205.png" alt="Untitled"></p>
<p><img src="/images/Crawling_practice0/Untitled%206.png" alt="Untitled"></p>
<h3 id="팁"><a href="#팁" class="headerlink" title="팁"></a>팁</h3><ul>
<li>정렬 : ctrl + alt + l</li>
</ul>
<p>Python</p>
<p>웹상에 있는 데이터를 숩집하는 도구</p>
<ul>
<li>BeautifulSoup 가장 일반적인 수집 도구 (CSS 통해서 수집)</li>
<li>Scrapy (CSS, XAPTH 통해서 데이터 수집 + JavaScript)</li>
<li>Selenium (CSS, XPATH 통해서 데이터 수집 + JAVAScript)</li>
</ul>
<p>—&gt; 자바 필요 + 여러가지 설치 도구 필요</p>
<p>웹 사이트 만드는 3대 조건 + 1</p>
<ul>
<li>HTML, CSS, JavaScript, Ajax (비동기처리)</li>
</ul>
<p>웹 사이트 구동 방식</p>
<ul>
<li><p>GET &#x2F; POST</p>
</li>
<li><p>Reference</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup">Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation (crummy.com)</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Crawling-6bb1358155b54b478339f3d93d77037e">Crawling 실습</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-02T00:00:00.000Z" title="2022. 5. 2. 오전 9:00:00">2022-05-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-04T15:08:01.480Z" title="2022. 5. 5. 오전 12:08:01">2022-05-05</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/crawling/">crawling</a></span><span class="level-item">3 minutes read (About 509 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/02/Crawling_setting/">Crawling_setting</a></h1><div class="content"><ul>
<li>웹 크롤링을 시도해본다.</li>
<li>우선 Pycharm 환경에서 가상환경을 생성해야 한다.</li>
</ul>
<p>바탕화면에 crawling 폴더 생성</p>
<p>→ 우클릭하여 pycharm으로 열기</p>
<p>→ File → Settings</p>
<p>→ Project : crawling → python interpreter</p>
<p>→ 톱니모양 → add</p>
<p><img src="/images/Crawling_setting/Untitled.png" alt="Untitled"></p>
<ul>
<li>필요한 패키지들을 설치한다.</li>
</ul>
<p>→ git bash 터미널</p>
<p>→<code>pip install beautifulsoup4</code></p>
<p>→<code>pip install numpy pandas matplotlib seaborn</code></p>
<p>→<code>pip install requests</code></p>
<ul>
<li>브라우저에서 검색을 진행</li>
</ul>
<p>→ 검색 : 확진자수</p>
<p>→ 우클릭 → 검사</p>
<p><img src="/images/Crawling_setting/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>원하는 정보가 포함된 코드를 선택 가능</li>
</ul>
<p><img src="/images/Crawling_setting/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>index.html을 생성한다.</li>
</ul>
<p>crawling 폴더 우클릭 → New → HTML.file</p>
<p><img src="/images/Crawling_setting/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 입력하고 index 파일을 열어본다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;titl&gt;test&lt;/titl&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;h1&gt;aaaaaaaa&lt;/h1&gt;</span><br><span class="line">    &lt;h2&gt;dddd&lt;/h2&gt;</span><br><span class="line">    &lt;div class=&quot;chapter01&quot;&gt;</span><br><span class="line">        &lt;p&gt;Don&#x27;t Crawl here &lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    &lt;div class=&quot;chapter02&quot;&gt;</span><br><span class="line">        &lt;p&gt;Just Crawling here&lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>index 파일을 열면 index.html에 작성한 대로 출력된다.</li>
</ul>
<p><img src="/images/Crawling_setting/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>이번에는 다른 파일에 코드를 작성해보자.<ul>
<li>일단 main.py에 작성한다.</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"># 첫 번째 작업 index.html 파일을 BeautifulSoup 객체로 변환</span><br><span class="line">## 클래스 변환 --&gt; 클래스 내부의 메서드 사용</span><br><span class="line"></span><br><span class="line"># html 파일을 변환</span><br><span class="line">soup = BeautifulSoup(open(&quot;index.html&quot;, encoding=&#x27;UTF-8&#x27;), &quot;html.parser&quot;)</span><br><span class="line"># print(type(soup))</span><br><span class="line"></span><br><span class="line"># print(soup.find(&quot;div&quot;, class_=&quot;chapter02&quot;))</span><br><span class="line"># print(soup.find(&quot;p&quot;))</span><br><span class="line">results = soup.find_all(&quot;p&quot;)</span><br><span class="line">print(results[1])</span><br></pre></td></tr></table></figure>

<ul>
<li>Index.html에서 크롤링하여 다음과 같이 출력된다.</li>
</ul>
<p>→ <code>python main.py</code></p>
<p><img src="/images/Crawling_setting/Untitled%205.png" alt="Untitled"></p>
<p><img src="/images/Crawling_setting/Untitled%206.png" alt="Untitled"></p>
<h3 id="팁"><a href="#팁" class="headerlink" title="팁"></a>팁</h3><ul>
<li>정렬 : ctrl + alt + l</li>
</ul>
<p>Python</p>
<p>웹상에 있는 데이터를 숩집하는 도구</p>
<ul>
<li>BeautifulSoup 가장 일반적인 수집 도구 (CSS 통해서 수집)</li>
<li>Scrapy (CSS, XAPTH 통해서 데이터 수집 + JavaScript)</li>
<li>Selenium (CSS, XPATH 통해서 데이터 수집 + JAVAScript)</li>
</ul>
<p>—&gt; 자바 필요 + 여러가지 설치 도구 필요</p>
<p>웹 사이트 만드는 3대 조건 + 1</p>
<ul>
<li>HTML, CSS, JavaScript, Ajax (비동기처리)</li>
</ul>
<p>웹 사이트 구동 방식</p>
<ul>
<li><p>GET &#x2F; POST</p>
</li>
<li><p>Reference</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup">Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation (crummy.com)</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Crawling-6bb1358155b54b478339f3d93d77037e">Crawling 실습</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-01T00:00:00.000Z" title="2022. 5. 1. 오전 9:00:00">2022-05-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-03T23:41:30.416Z" title="2022. 5. 4. 오전 8:41:30">2022-05-04</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">7 minutes read (About 1109 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/01/Spark_ML/">Spark ML</a></h1><div class="content"><ul>
<li>Spark로 머신러닝을 사용해 본다.</li>
<li>실용성과 별개로 경험삼아 작성해보는 코드이다.</li>
<li>머신러닝(ML)은 Scikit-Learn을 중점적으로 공부해야 한다.</li>
<li>딥러닝(DL)은 Tensorflow, Pytorch에 포커스를 맞춰야 한다.</li>
</ul>
<p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터밀널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark_ml 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 폴더, 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ 폴더 생성 : chapter03_ml</p>
<p>→ <code>cd chapter03_ml</code></p>
<ul>
<li>슬랙에서 data.zip 을 다운로드</li>
<li>압축을 풀고  chapter03_ml 폴더에 복사하여 옮긴다.</li>
</ul>
<p>→ 파일 생성 : step01_regression.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.regression import DecisionTreeRegressor</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.ml.feature import VectorAssembler</span><br><span class="line"></span><br><span class="line"># 세션 할당</span><br><span class="line">spark = SparkSession.builder.appName(&quot;DecisionTree&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line"># StructType 이 과정 생략</span><br><span class="line">data = spark.read.option(&quot;header&quot;, &quot;true&quot;).option(&quot;inferSchema&quot;, &quot;true&quot;).csv(&quot;data/realestate.csv&quot;)</span><br><span class="line"></span><br><span class="line"># 데이터 프레임을 행렬로 변환</span><br><span class="line">assembler = VectorAssembler().setInputCols([&#x27;HouseAge&#x27;, &#x27;DistanceToMRT&#x27;, &#x27;NumberConvenienceStores&#x27;]).setOutputCol(&quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 타겟데이터 설정</span><br><span class="line">df = assembler.transform(data).select(&quot;PriceofUnitArea&quot;, &quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 데이터 분리</span><br><span class="line">trainTest = df.randomSplit([0.5, 0.5])</span><br><span class="line">trainingDF = trainTest[0]</span><br><span class="line">testDF = trainTest[1]</span><br><span class="line"></span><br><span class="line"># Decision Tree 클래스 정의</span><br><span class="line">dtr = DecisionTreeRegressor().setFeaturesCol(&quot;features&quot;).setLabelCol(&quot;PriceofUnitArea&quot;)</span><br><span class="line"></span><br><span class="line"># 모델 학습</span><br><span class="line">model = dtr.fit(trainingDF)</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line"># 모델 예측</span><br><span class="line">fullPredictions = model.transform(testDF).cache()</span><br><span class="line"></span><br><span class="line"># 예측값과 Label을 분리</span><br><span class="line">predictions = fullPredictions.select(&quot;prediction&quot;).rdd.map(lambda x: x[0])</span><br><span class="line"></span><br><span class="line"># 실제데이터</span><br><span class="line">labels = fullPredictions.select(&quot;PriceofUnitArea&quot;).rdd.map(lambda x: x[0])</span><br><span class="line"></span><br><span class="line"># zip</span><br><span class="line">preds_label = predictions.zip(labels).collect()</span><br><span class="line"></span><br><span class="line">for prediction in preds_label:</span><br><span class="line">    print(prediction)</span><br><span class="line"></span><br><span class="line"># print(data.show())</span><br><span class="line"></span><br><span class="line"># 세션 종료</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step01_regression.py</code></p>
<p>→ 다음과 같이 출력된다.</p>
<p><img src="/images/Spark_ML/Untitled.png" alt="Untitled"></p>
<p><strong>pyspark_ml 실습(2)</strong></p>
<p>→ 파일 생성 : step02_logistic_regression.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 세션 할당</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.ml.classification import LogisticRegression # 기억</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(&quot;AppName&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">training = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)</span><br><span class="line">print(&quot;hello&quot;)</span><br><span class="line"></span><br><span class="line"># 모델 만들기</span><br><span class="line"># Scikit-Learn 문법과 비슷</span><br><span class="line">mlr = LogisticRegression() # 기억</span><br><span class="line">mlr_model = mlr.fit(training) # 기억</span><br><span class="line"></span><br><span class="line"># 로지스틱 회귀, 선형 모델.. 기울기와 상수</span><br><span class="line">print(&quot;Coefficients: &quot; + str(mlr_model.coefficients))</span><br><span class="line">print(&quot;Intercept: &quot; + str(mlr_model.intercept))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step02_logistic_regression.py</code></p>
<p><strong>pyspark_ml 실습(3)</strong></p>
<ul>
<li>pyspark_pipeline</li>
</ul>
<p>→ 파일 생성 : step03_pipeline.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">from tokenize import Token</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.classification import LogisticRegression</span><br><span class="line">from pyspark.ml.feature import HashingTF, Tokenizer</span><br><span class="line"></span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 세션 할당</span><br><span class="line">spark = SparkSession.builder.appName(&quot;MLPipeline&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 가상의 데이터 만들기</span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (0, &quot;a b c d e spark&quot;, 1.0),</span><br><span class="line">    (1, &quot;b d&quot;, 0.0),</span><br><span class="line">    (2, &quot;spark f g h&quot;, 1.0),</span><br><span class="line">    (3, &quot;hadoop mapreduce&quot;, 0.0)</span><br><span class="line">], [&quot;id&quot;, &quot;text&quot;, &quot;label&quot;])</span><br><span class="line"></span><br><span class="line"># Feature Engineering</span><br><span class="line"># 요리 작업</span><br><span class="line"></span><br><span class="line"># 요리준비 1단계 : 텍스트를 단어로 분리</span><br><span class="line">tokenizer = Tokenizer(inputCol=&#x27;text&#x27;, outputCol=&#x27;words&#x27;)</span><br><span class="line"></span><br><span class="line"># 요리준비 2단계 : 변환된 텍스트를 숫자로 변환</span><br><span class="line">hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 요리준비 3단계 : 모델을 가져옴</span><br><span class="line">lr = LogisticRegression(maxIter=5, regParam=0.01)</span><br><span class="line"></span><br><span class="line"># 요리 시작</span><br><span class="line">pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line"># 메인재료 투하</span><br><span class="line">model = pipeline.fit(training)</span><br><span class="line"></span><br><span class="line"># Prepare test documents, which are unlabeled (id, text) tuples.</span><br><span class="line">test = spark.createDataFrame([</span><br><span class="line">    (4, &quot;spark i j k&quot;),</span><br><span class="line">    (5, &quot;l m n&quot;),</span><br><span class="line">    (6, &quot;spark hadoop spark&quot;),</span><br><span class="line">    (7, &quot;apache hadoop&quot;)</span><br><span class="line">], [&quot;id&quot;, &quot;text&quot;])</span><br><span class="line"></span><br><span class="line"># 예측</span><br><span class="line">prediction = model.transform(test)</span><br><span class="line">selected = prediction.select(&quot;id&quot;, &quot;text&quot;, &quot;probability&quot;, &quot;prediction&quot;)</span><br><span class="line">for row in selected.collect():</span><br><span class="line">    row_id, text, prob, prediction = row # 튜플</span><br><span class="line">    print(</span><br><span class="line">        # 문자열 포맷팅</span><br><span class="line">        &quot;(%d, %s) -------&gt; probability=%s, prediction=%f&quot; % (row_id, text, str(prob), prediction)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"># training.show()</span><br><span class="line"></span><br><span class="line"># 세션 종료</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step03_pipeline.py</code></p>
<p><img src="/images/Spark_ML/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark_ml 실습(3)</strong></p>
<p>→ 파일 생성 : step03_randomforest.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">from cProfile import label</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 머신러닝 라이브러리</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.classification import RandomForestClassifier</span><br><span class="line">from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">spark = SparkSession.builder.appName(&quot;RandomForest&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line">data = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)</span><br><span class="line">print(type(data))</span><br><span class="line"></span><br><span class="line"># Feature Engineering</span><br><span class="line"># label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&#x27;label&#x27;, outputCol=&#x27;indexedLabel&#x27;).fit(data)</span><br><span class="line"></span><br><span class="line"># 범주형 데이터 체크, 인덱스화</span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&#x27;features&#x27;,</span><br><span class="line">                               outputCol=&#x27;IndexedFeatures&#x27;, maxCategories=4).fit(data)</span><br><span class="line"></span><br><span class="line"># 데이터 분리</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.7, 0.3])</span><br><span class="line"></span><br><span class="line"># 모델</span><br><span class="line">rf = RandomForestClassifier(labelCol=&#x27;indexedLabel&#x27;, # 종속변수</span><br><span class="line">                            featuresCol=&#x27;IndexedFeatures&#x27;, # 독립변수</span><br><span class="line">                            numTrees=10)</span><br><span class="line"></span><br><span class="line"># outputCol=&#x27;indexedLabel&#x27; --&gt; original label로 변환</span><br><span class="line">labelConvereter = IndexToString(inputCol=&#x27;prediction&#x27;,</span><br><span class="line">                                outputCol=&#x27;predictedLabel&#x27;, labels=labelIndexer.labels)</span><br><span class="line"></span><br><span class="line"># 파이프라인 구축</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConvereter])</span><br><span class="line"></span><br><span class="line"># 모델 학습</span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"># 모델 예측</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"># 행에 표시할 것 추출</span><br><span class="line">predictions.select(&quot;predictedLabel&quot;, &#x27;label&#x27;, &#x27;features&#x27;).show(5)</span><br><span class="line"></span><br><span class="line"># 모형 평가</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %f &quot; % (1.0 - accuracy))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step04_randomforest.py</code></p>
<p><img src="/images/Spark_ML/Untitled%202.png" alt="Untitled"></p>
<h3 id="팁"><a href="#팁" class="headerlink" title="팁"></a>팁</h3><p>venv 생성되어 있는 경로로 이동</p>
<p>→ pip install jupyterlab</p>
<p>→ jupyter lab</p>
<p>→ 주피터랩에서 블로그에 올릴 자료 작성 가능.</p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-30T00:00:00.000Z" title="2022. 4. 30. 오전 9:00:00">2022-04-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-03T09:58:36.846Z" title="2022. 5. 3. 오후 6:58:36">2022-05-03</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">3 minutes read (About 487 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/Spark_UI/">Spark UI</a></h1><div class="content"><ul>
<li>가상환경을 생성한다.</li>
</ul>
<p>&#x2F;mnt&#x2F;c 경로에서 실행</p>
<p>→<code>mkdir temp</code></p>
<p>→<code>cd temp</code></p>
<p>→<code>virtualenv venv</code></p>
<p><img src="/images/Spark_UI/Untitled.png" alt="Untitled"></p>
<ul>
<li>가상환경에서 pyspark를 설치한다.</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>pip install pyspark</code></p>
<ul>
<li>다음 링크 접속</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">Quick Start - Spark 3.2.1 Documentation (apache.org)</a></p>
<ul>
<li>다음 내용을 복사한다.</li>
</ul>
<p><img src="/images/Spark_UI/Untitled%201.png" alt="Untitled"></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://read.md/">README.md</a> 파일 내용이다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">This program just counts the number of lines containing &#x27;a&#x27; and the number containing &#x27;b&#x27; in a text file. Note that you&#x27;ll need to replace YOUR_SPARK_HOME with the location where Spark is installed. As with the Scala and Java examples, we use a SparkSession to create Datasets. For applications that use custom classes or third-party libraries, we can also add code dependencies to spark-submit through its --py-files argument by packaging them into a .zip file (see spark-submit --help for details). SimpleApp is simple enough that we do not need to specify any code dependencies.</span><br><span class="line"></span><br><span class="line">We can run this application using the bin/spark-submit script:</span><br></pre></td></tr></table></figure>

<p>→<code>mkdir data</code></p>
<p>→<code>cd data</code></p>
<p>→<code>ls</code></p>
<p>→<code>vi README.md</code></p>
<p>→ 위에서 복사한 내용을 붙여넣는다.</p>
<p>→ <code>:wq</code></p>
<p>→ 내용 확인<code>cat README.md</code></p>
<p>→ <code>cd ..</code></p>
<p>→ <code>vi SimpleApp.py</code></p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">logFile = &quot;data/README.md&quot;  # Should be some file on your system</span><br><span class="line">spark = SparkSession.builder.appName(&quot;SimpleApp&quot;).getOrCreate()</span><br><span class="line">logData = spark.read.text(logFile).cache()</span><br><span class="line"></span><br><span class="line">numAs = logData.filter(logData.value.contains(&#x27;a&#x27;)).count()</span><br><span class="line">numBs = logData.filter(logData.value.contains(&#x27;b&#x27;)).count()</span><br><span class="line"></span><br><span class="line">print(&quot;Lines with a: %i, lines with b: %i&quot; % (numAs, numBs))</span><br><span class="line"></span><br><span class="line">input(&quot;Typing....&quot;)</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ python3 SimpleApp.py</p>
<p>→ 경로 확인 : <code>echo $SPARK_HOME</code></p>
<p>→ <code>$SPARK_HOME/bin/spark-submit --master local[4] SimpleApp.py</code></p>
<p><img src="/images/Spark_UI/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>코드 샐행 후</li>
<li>위 결과 참고하여 address 복사</li>
</ul>
<p>→ 뒤에 :4041을 추가하여 주소창에 입력한다. </p>
<p>(코드 실행 후 나오는 텍스트에서 SparkUI를 확인하자)</p>
<p>→ 주소창에 입력하여 접속 : <a target="_blank" rel="noopener" href="http://172.19.91.118:4041/">http://172.19.91.118:4041</a></p>
<p>→ 다음 화면 출력 시 성공.</p>
<p><img src="/images/Spark_UI/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>Reference :<ul>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">Quick Start - Spark 3.2.1 Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">(apache.org)</a><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-29T00:00:00.000Z" title="2022. 4. 29. 오전 9:00:00">2022-04-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-01T15:41:24.323Z" title="2022. 5. 2. 오전 12:41:24">2022-05-02</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">3 minutes read (About 392 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/29/Spark_on_linux/">Spark on Linux</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/spark_install_using_wsl/">WSL2에서의 Spark 설치 - Data Science | DSChloe</a></p>
<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a><strong>개요</strong></h2><ul>
<li>간단하게 PySpark를 설치해보는 과정을 작성한다.</li>
<li>WSL2 설치 방법은 다루지 않는다.</li>
</ul>
<h2 id="필수-파일-설치"><a href="#필수-파일-설치" class="headerlink" title="필수 파일 설치"></a><strong>필수 파일 설치</strong></h2><ul>
<li>설치가 안 되었을 경우에 설치한다.</li>
<li>자바 및 Spark 파일을 설치하도록 한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-8-jdk</span><br><span class="line">$ sudo wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</span><br><span class="line">$ sudo tar -xvzf spark-3.2.0-bin-hadoop3.2.tgz</span><br></pre></td></tr></table></figure>

<h2 id="bashrc-파일-수정"><a href="#bashrc-파일-수정" class="headerlink" title=".bashrc 파일 수정"></a><strong>.bashrc 파일 수정</strong></h2><ul>
<li>경로를 다음과 같이 설정한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">evan@evan:/mnt/c/hadoop$ pwd</span><br><span class="line">/mnt/c/hadoop</span><br></pre></td></tr></table></figure>

<ul>
<li>설치한 파일은 다음과 같다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">evan@evan:/mnt/c/hadoop$ ls</span><br><span class="line">spark-3.2.0-bin-hadoop3.2  spark-3.2.0-bin-hadoop3.2.tgz</span><br></pre></td></tr></table></figure>

<ul>
<li><code>vi ~/.bashrc</code> 파일을 열고 다음과 같이 코드를 작성한다.<ul>
<li>다른 코드는 건드리지 않는다.</li>
<li>마지막 라인에서 작성한다.</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span><br><span class="line">export SPARK_HOME=/mnt/c/spark</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export PATH=$SPARK_HOME/bin:$PATH</span><br><span class="line">export PYSPARK_PYTHON=/usr/bin/python3</span><br></pre></td></tr></table></figure>

<p><img src="/images/Spark_on_linux/Untitled.png" alt="Untitled"></p>
<h2 id="테스트"><a href="#테스트" class="headerlink" title="테스트"></a><strong>테스트</strong></h2><ul>
<li>pyspark를 실행한다. (경로에 주의한다)</li>
<li>SPARK_HOME을 다음과 같이 설정했으니 해당 경로에서 실행.</li>
<li>export SPARK_HOME&#x3D;&#x2F;mnt&#x2F;c&#x2F;spark</li>
</ul>
<p>경로 이동 : <code>cd ..</code> </p>
<p>→ <code>cd spark/</code></p>
<p>→<code>source ~/.bashrc</code></p>
<p>→<code>pyspark</code></p>
<p><img src="/images/Spark_on_linux/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>정상적으로 작동한지 테스트한다.</li>
<li>해당 경로에 <a target="_blank" rel="noopener" href="http://readme.md/">README.md</a> 파일이 있다면 시행해보자.</li>
</ul>
<p>→<code>rd = sc.textFile(&quot;README.md&quot;)</code></p>
<p>→<code>rd.count()</code></p>
<p>→ 다음과 같이 출력된다면 성공이다.</p>
<p><img src="/images/Spark_on_linux/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/spark_install_using_wsl/">WSL2에서의 Spark 설치 - Data Science | DSChloe</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-28T00:00:00.000Z" title="2022. 4. 28. 오전 9:00:00">2022-04-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-01T01:16:28.899Z" title="2022. 5. 1. 오전 10:16:28">2022-05-01</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 768 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/28/pyspark_practice03/">pyspark 실습03</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터밀널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 폴더, 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ 폴더 생성 : chapter02_get_cleansing</p>
<ul>
<li>슬랙에서 data.zip 을 다운로드</li>
<li>압축을 풀고 chapter02_get_cleansing 파일에 복사하여 옮긴다.</li>
</ul>
<p>→ 파일 생성 : pipeline.py</p>
<p><img src="/images/pyspark_practice03/Untitled.png" alt="Untitled"></p>
<ul>
<li>코드를 작성해본다.</li>
</ul>
<p>→ 코드 작성</p>
<p><code>from pyspark.sql import SparkSession</code></p>
<p><code>from pyspark.sql.functions import *</code></p>
<p><code>print(&quot;Hello!&quot;)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter02_get_cleansing</code></p>
<p>→ 실행 : <code>python pipeline.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ pipeline.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.functions import *</span><br><span class="line">from pyspark.sql import functions as F</span><br><span class="line"></span><br><span class="line"># print(&quot;Hello!!&quot;)</span><br><span class="line"></span><br><span class="line"># 스파크 세션을 생성</span><br><span class="line">spark = SparkSession.builder.master(&quot;local[1]&quot;).\</span><br><span class="line">    appName(&quot;quickpipeline&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">df = spark.read.csv(&quot;data\AA_DFW_2015_Departures_Short.csv.gz&quot;</span><br><span class="line">                    , header = True)</span><br><span class="line"></span><br><span class="line">print(&quot;file loaded&quot;)</span><br><span class="line"></span><br><span class="line">print(df.show())</span><br><span class="line"></span><br><span class="line"># remove duration = 0</span><br><span class="line">df = df.filter(df[3] &gt; 0)</span><br><span class="line"></span><br><span class="line"># ADD ID column</span><br><span class="line">df = df.withColumn(&#x27;id&#x27;, F.monotonically_increasing_id())</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">df.write.csv(&quot;data/output.csv&quot;, mode = &quot;overwrite&quot;)</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python pipeline.py</code></p>
<p>→ output.csv 가 생성되면 성공이다.</p>
<p><img src="/images/pyspark_practice03/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<ul>
<li>온도를 측정하는 코드를 작성해본다.</li>
<li>슬랙에서 다운로드<ul>
<li>1800.csv, book.txt, customer-orders.csv, fakefriends.csv</li>
</ul>
</li>
<li>chapter02_get_cleansing&#x2F;data 파일에 복사하여 옮긴다.</li>
</ul>
<p>파일 생성 : min_temp.py</p>
<p>→ 코드 작성</p>
<p><code>from pyspark import SparkConf, SparkContext</code></p>
<p><code>conf = SparkConf().setMaster(&#39;local&#39;).setAppName(&#39;MinTemperatures&#39;)</code></p>
<p><code>sc = SparkContext(conf = conf)</code></p>
<p><code>print(&quot;Hello&quot;)</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ min_temp.py를 다음과 같이 작성</p>
<p>from pyspark import SparkConf, SparkContext</p>
<p>conf &#x3D; SparkConf().setMaster(‘local’).setAppName(‘MinTemperatures’)</p>
<p>sc &#x3D; SparkContext(conf &#x3D; conf)</p>
<p>print(“Begins…”)</p>
<p>def parseLine(line):</p>
<p>fileds &#x3D; line.split(‘,’) # 문자열을 split</p>
<p>stationID &#x3D; fileds[0]</p>
<p>entryType &#x3D; fileds[2]</p>
<p>temperature &#x3D; float(fileds[3]) * 0.1 * (9.0 &#x2F; 5.0) + 32.0</p>
<p>return (stationID, entryType, temperature)</p>
<p>lines &#x3D; sc.textFile(‘data&#x2F;1800.csv’)</p>
<p>#print(lines)</p>
<p>parseLines &#x3D; lines.map(parseLine)</p>
<p>#print(parseLine)</p>
<p>minTemps &#x3D; parseLine.filter(lambda x : “TMIN” in x[1])</p>
<p>stationTemps &#x3D; minTemps.map(lambda x: (x[0], x[2]))</p>
<p>minTemps &#x3D; stationTemps.map(lambda x, y: min(x,y))</p>
<p>results &#x3D; minTemps.collect()</p>
<p>print(results)</p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<p><strong>pyspark 실습(3)</strong></p>
<ul>
<li>나이를 출력하는 코드를 작성해보자</li>
</ul>
<p>파일 생성 : friends-by-age.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;FriendsByAge&quot;)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">def parseLine(line):</span><br><span class="line">    fields = line.split(&#x27;,&#x27;)</span><br><span class="line">    age = int(fields[2])</span><br><span class="line">    numFriends = int(fields[3])</span><br><span class="line">    return (age, numFriends)</span><br><span class="line"></span><br><span class="line">lines = sc.textFile(&quot;logs/fakefriends.csv&quot;)</span><br><span class="line">rdd = lines.map(parseLine)</span><br><span class="line">totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))</span><br><span class="line">averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])</span><br><span class="line">results = averagesByAge.collect()</span><br><span class="line">for result in results:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python friends-by-age.py</code></p>
<p><strong>pyspark 실습(4)</strong></p>
<p>파일 생성 : totalspent.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 라이브러리 불러오기</span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"># 사용자 정의 함수</span><br><span class="line">def extractCusPrice(line):</span><br><span class="line">    fields = line.split(&quot;,&quot;)</span><br><span class="line">    return (int(fields[0]), float(fields[2]))</span><br><span class="line"></span><br><span class="line"># main 함수</span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    # 스파크 설정</span><br><span class="line">    conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&#x27;SpentbyCustomer&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    # 데이터 불러오기</span><br><span class="line">    input = sc.textFile(&quot;data/customer-orders.csv&quot;)</span><br><span class="line">    # print(&quot;is data?&quot;)</span><br><span class="line">    mappedInput = input.map(extractCusPrice)</span><br><span class="line">    totalByCustomer = mappedInput.reduceByKey(lambda x, y : x + y)</span><br><span class="line">		# 정렬</span><br><span class="line">    filpped = totalByCustomer.map(lambda x: (x[1], x[0]))</span><br><span class="line">    totalByCustomerStored = filpped.sortByKey()</span><br><span class="line"></span><br><span class="line">    results = totalByCustomer.collect()</span><br><span class="line">    for result in results:</span><br><span class="line">        print(result)</span><br><span class="line"></span><br><span class="line"># 실행 코드</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python totalspent.py</code></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-27T00:00:00.000Z" title="2022. 4. 27. 오전 9:00:00">2022-04-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-30T01:49:22.246Z" title="2022. 4. 30. 오전 10:49:22">2022-04-30</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">4 minutes read (About 632 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/27/pyspark_practice02/">pyspark 실습02</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step04_structype.py</p>
<p>키워드 : Struct Type</p>
<p>구글링 : Spark Struct Type, Spark Struct </p>
<p>참고 링크 :  </p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> Struct</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func </span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당 (필수)</span></span><br><span class="line"><span class="comment"># spark = SparkSession.builder.appName(&quot;&quot;)</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">toMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count().orderBy(func.desc(<span class="string">&#x27;count&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(movies_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python step04_structype.py</code></p>
<p>→ 다음 테이블이 출력되어야 한다.</p>
<p><img src="/images/pyspark_practice02/Untitled.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step05_advancestructype.py</p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadMovieNames</span>():</span><br><span class="line">    movieNames = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(<span class="string">&quot;ml-100k/u.ITEM&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;ISO-8859-1&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            fields = line.split(<span class="string">&quot;|&quot;</span>)</span><br><span class="line">            movieNames[<span class="built_in">int</span>(fields[<span class="number">0</span>])] = fields[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> movieNames</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이썬 딕셔너리 객체를 Spark 객체로 변환</span></span><br><span class="line">nameDict = spark.sparkContext.broadcast(loadMovieNames())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">topMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 딕셔너리</span></span><br><span class="line"><span class="comment"># key-value</span></span><br><span class="line"><span class="comment"># 키 값을 알면 value 자동으로 가져옴 (movieTitle)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lookupName</span>(<span class="params">movieID</span>):</span><br><span class="line">    <span class="keyword">return</span> nameDict.value[movieID]</span><br><span class="line"></span><br><span class="line">lookupNameUDF = func.udf(lookupName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MovieTitle 기존 topMovieIds 데이터에 추가</span></span><br><span class="line"><span class="comment"># 컬럼을 추가</span></span><br><span class="line">moviesWithNames = topMovieIds.withColumn(<span class="string">&quot;movieTitle&quot;</span>, lookupNameUDF(func.col(<span class="string">&quot;movieID&quot;</span>)))</span><br><span class="line"></span><br><span class="line">final_df = moviesWithNames.orderBy(func.desc(<span class="string">&quot;count&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step05_advancestructype.py</code></p>
<p>→ 다음과 같이 출력된다.</p>
<p><img src="/images/pyspark_practice02/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-26T00:00:00.000Z" title="2022. 4. 26. 오전 9:00:00">2022-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-29T12:29:53.952Z" title="2022. 4. 29. 오후 9:29:53">2022-04-29</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 685 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/26/pyspark_practice01/">pyspark 실습01</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>spark on windows 참고하여 세팅 </li>
<li>스파크를 설치한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<p><strong>pyspark 설치</strong></p>
<ul>
<li>git bash를 이용해 폴더를 생성하고 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>mkdir pyspk_project</code></p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><img src="/images/pyspark_practice01/Untitled.png" alt="Untitled"></p>
<ul>
<li>가상환경 생성 후 pyspark 설치</li>
</ul>
<p>→ <code>virtualenv venv</code></p>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ <code>pip install pyspark</code></p>
<p><img src="/images/pyspark_practice01/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습_1</strong></p>
<ul>
<li>폴더 파일 생성</li>
</ul>
<p>→ 폴더 생성 : chapter01_get_started</p>
<p>→ 파일 생성 : <code>step01_basic.py</code></p>
<p>→ 코드 작성</p>
<p><code>import pyspark</code></p>
<p><code>print(pyspark.__version__)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 실행 : <code>python step01_basic.py</code></p>
<p><img src="/images/pyspark_practice01/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ step01_basic.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import pyspark</span><br><span class="line">print(pyspark.__version__)</span><br><span class="line"></span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 스파크 세션 초기화</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;SampleTutorial&#x27;).getOrCreate()</span><br><span class="line">rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])</span><br><span class="line"></span><br><span class="line">print(&quot;rdd Count:&quot;, rdd.count())</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ 주소창에 입력 :  <a target="_blank" rel="noopener" href="http://localhost:4040/">http://localhost:4040/</a></p>
<p>→ 다음 화면이 출력된다.</p>
<ul>
<li>교재 278p</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%203.png" alt="Untitled"></p>
<p><strong>pyspark 실습_2</strong></p>
<ul>
<li>슬랙에서 dataset.zip 을 다운로드</li>
<li>압축을 풀고 chapter01_get_started 파일에 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step02_ratings.py</code></p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># SparkContext</span><br><span class="line"># RDD</span><br><span class="line"></span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line">import collections</span><br><span class="line"></span><br><span class="line">print(&quot;Hello&quot;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # MasterNode = local</span><br><span class="line">    # MapReduce</span><br><span class="line"></span><br><span class="line">    conf = SparkConf().setMaster(&#x27;local&#x27;).setAppName(&#x27;RatingsHistogram&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    lines = sc.textFile(&quot;ml-100k/u.logs&quot;)</span><br><span class="line">    ratings = lines.map(lambda x: x.split()[2])</span><br><span class="line">    print(&quot;ratings: &quot;, ratings)</span><br><span class="line"></span><br><span class="line">    result = ratings.countByValue()</span><br><span class="line">    print(&quot;result:&quot;, result)</span><br><span class="line"></span><br><span class="line">    sortedResults = collections.OrderedDict(sorted(result.items()))</span><br><span class="line">    for key, value in sortedResults.items():</span><br><span class="line">        print(&quot;%s %i&quot; % (key, value))</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step02_ratings.py</code></p>
<p>→ 다음 결과가 출력된다.</p>
<p><img src="/images/pyspark_practice01/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step03_dataloading.py</code></p>
<p>→ 코드 작성</p>
<p>→ pip install pandas</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># Spark SQL 적용</span><br><span class="line"></span><br><span class="line"># Spark Session</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 스파크 세션 생성</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">my_spark = SparkSession.builder.getOrCreate()</span><br><span class="line">print(my_spark)</span><br><span class="line"></span><br><span class="line"># 테이블을 확인하는 코드</span><br><span class="line">print(my_spark.catalog.listDatabases())</span><br><span class="line"></span><br><span class="line"># show database</span><br><span class="line">my_spark.sql(&#x27;show databases&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 현재 DB 확인</span><br><span class="line">my_spark.catalog.currentDatabase()</span><br><span class="line">my_spark.stop()</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># CSV 파일 불러오기</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;DBTutorial&#x27;).getOrCreate()</span><br><span class="line">flights = spark.read.option(&#x27;header&#x27;, &#x27;true&#x27;).csv(&#x27;data/flight_small.csv&#x27;)</span><br><span class="line"># flights.show(4)</span><br><span class="line"></span><br><span class="line"># spark.catalog.currentDatabase()</span><br><span class="line"># flights 테이블을 default DB에 추가함</span><br><span class="line">flights.createOrReplaceTempView(&#x27;flights&#x27;)</span><br><span class="line"></span><br><span class="line"># print(spark.catalog.listTables(&#x27;default&#x27;))</span><br><span class="line"># spark.sql(&#x27;show tables from default&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 쿼리 통해서 데이터 저장</span><br><span class="line">query = &quot;FROM Fligths SELECT * LIMIT 10&quot;</span><br><span class="line">query2 = &quot;SELECT * FROM flights 10&quot;</span><br><span class="line"></span><br><span class="line"># 스파크에 세션할당</span><br><span class="line">flights10 = spark.sql(query2)</span><br><span class="line">flights10.show()</span><br><span class="line"></span><br><span class="line"># Spark 데이터 프레임을 Pandas 데이터 프레임을 변환</span><br><span class="line">pd_flights10 = flights10.toPandas()</span><br><span class="line">print(pd_flights10.head())</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step03_dataloading.py</code></p>
<ul>
<li>Reference<ul>
<li>실무 예제로 배우는 데이터</li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-25T00:00:00.000Z" title="2022. 4. 25. 오전 9:00:00">2022-04-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-27T16:37:25.509Z" title="2022. 4. 28. 오전 1:37:25">2022-04-28</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">11 minutes read (About 1630 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/25/Spark_on_Windows/">Spark on Windows</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></p>
<h2 id="사전준비"><a href="#사전준비" class="headerlink" title="사전준비"></a>사전준비</h2><ul>
<li>스파크를 설치하는 과정이다.</li>
<li>사전에 파이썬 3가 설치되어 있어야 한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<h2 id="자바-다운로드"><a href="#자바-다운로드" class="headerlink" title="자바 다운로드"></a><strong>자바 다운로드</strong></h2><ul>
<li>자바를 설치한다. 설치 파일은 아래에서 다운로드 받는다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html">Java SE 8 Archive Downloads (JDK 8u211 and later)</a></strong></li>
</ul>
</li>
<li>설치 시, 오라클 로그인이 필요 할 수도 있다.</li>
</ul>
<h2 id="Spark-다운로드"><a href="#Spark-다운로드" class="headerlink" title="Spark 다운로드"></a>S<strong>park 다운로드</strong></h2><ul>
<li>이번에는 Spark를 설치한다.</li>
<li><strong>설치파일 다운로드</strong><ul>
<li>설치 URL: <strong><a target="_blank" rel="noopener" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz">https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></strong> (2022년 1월 기준)</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled.png" alt="Untitled"></p>
<h3 id="WinRAR-다운로드"><a href="#WinRAR-다운로드" class="headerlink" title="WinRAR 다운로드"></a><strong>WinRAR 다운로드</strong></h3><ul>
<li>이 때, <code>.tgz</code> 압축파일을 풀기 위해서는 <code>WinRAR</code> 을 설치한다.<ul>
<li>설치 파일: <strong><a target="_blank" rel="noopener" href="https://www.rarlab.com/download.htm">https://www.rarlab.com/download.htm</a></strong></li>
<li>본인 컴퓨터에 맞는 것을 설치한다.</li>
<li>WinRARx64 (64bit) 6.11 버전 다운로드</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%201.png" alt="Untitled"></p>
<h2 id="winutils-다운로드"><a href="#winutils-다운로드" class="headerlink" title="winutils 다운로드"></a><strong>winutils 다운로드</strong></h2><ul>
<li>이번에는 스파크가 윈도우 로컬 컴퓨터가 Hadoop으로 착각하게 만들 프로그램이 필요하다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://github.com/cdarlint/winutils">https://github.com/cdarlint/winutils</a></strong></li>
<li>여기에서 각 설치 버전에 맞는 winutils를 다운로드 받는다.</li>
</ul>
</li>
<li>이전에 받은 spark-3.2.0-bin-hadoob-3.2.tgz 와 버전이  일치하는 것을 선택해야 한다.<ul>
<li>3.2.0 버전을 다운로드 받았다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%202.png" alt="Untitled"></p>
<h2 id="자바-설치-진행"><a href="#자바-설치-진행" class="headerlink" title="자바 설치 진행"></a><strong>자바 설치 진행</strong></h2><ul>
<li>C 드라이브에 폴더 생성 : hadoob</li>
<li>다운로드 받은 파일 4개를 C&#x2F;hadoob 에 복사하여 옮긴다</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>관리자 권한으로 실행 : jdk-8u311-windows-x64</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>계속 Next 버튼 클릭 후, 아래 파일에서 경로를 수정한다. (이 때, <code>Program Files</code> 공백이 있는데, 이러한 공백은 환경 설치 시 문제가 될 수 있다.)</li>
<li>Development Tools 선택</li>
<li>change 버튼으로 변경을 진행한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로로 이동</li>
<li>Foldername: jdk 입력<ul>
<li>다음 그림과 같아야 한다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>Java를 다른 폴더에 설치하려 한다.</li>
<li>변경(C)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%207.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로에서 ‘새 폴더 만들기(M)’</li>
<li>폴더 생성 : jre</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%208.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설치 위치가 지정된다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%209.png" alt="Untitled"></p>
<ul>
<li>성공적으로 설치되었다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2010.png" alt="Untitled"></p>
<h3 id="winrar-설치-진행"><a href="#winrar-설치-진행" class="headerlink" title="winrar 설치 진행"></a><strong>winrar 설치 진행</strong></h3><ul>
<li>관리자 권한으로 실행 : winrar-x64-611</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2011.png" alt="Untitled"></p>
<ul>
<li>기본 설정으로 설치 진행</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2012.png" alt="Untitled"></p>
<h2 id="spark-설치-진행"><a href="#spark-설치-진행" class="headerlink" title="spark 설치 진행"></a><strong>spark 설치 진행</strong></h2><ul>
<li>Spark 설치를 진행한다.</li>
<li>설치 파일 우클릭 → Extract to “spark-3.2.0-bin-hadoop3.2|”</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2013.png" alt="Untitled"></p>
<h3 id="spark-폴더-생성-및-파일-이동"><a href="#spark-폴더-생성-및-파일-이동" class="headerlink" title="spark 폴더 생성 및 파일 이동"></a><strong>spark 폴더 생성 및 파일 이동</strong></h3><ul>
<li>위 과정 이후 폴더가 생성된다.</li>
<li>파일 이동을 하도록 한다.<ul>
<li>spark-3.2.0-bin-hadoop3.2 폴더 내 모든 파일을 복사한다.</li>
</ul>
</li>
<li>그 후, C드라이브 하단에 spark 폴더를 생성한 후, 모두 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2014.png" alt="Untitled"></p>
<h3 id="log4j-properties-파일-수정"><a href="#log4j-properties-파일-수정" class="headerlink" title="log4j.properties 파일 수정"></a><strong>log4j.properties 파일 수정</strong></h3><ul>
<li><code>C</code> -&gt; <code>spark</code> → <code>conf</code> → <code>[log4j.properties](http://log4j.properties)</code> 파일을 연다.</li>
<li>해당 파일을 메모장으로 연 후, 아래에서 <code>INFO</code> → <code>ERROR</code> 로 변경한다.<ul>
<li>작업 실행 시, 출력하는 모든 logs 값들을 없앨 수 있다.</li>
<li>다음과 같이 설정 후 저장</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2015.png" alt="Untitled"></p>
<h2 id="winutils-설치-진행"><a href="#winutils-설치-진행" class="headerlink" title="winutils 설치 진행"></a><strong>winutils 설치 진행</strong></h2><ul>
<li>C드라이브에서 winutils-bin 폴더를 차례로 생성한다.</li>
<li>다운로드 받은 winutils 파일을 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2016.png" alt="Untitled"></p>
<ul>
<li>이 파일이 Spark 실행 시, 오류 없이 실행될 수 있도록 파일 사용 권한을 얻도록 한다.<ul>
<li>이 때에는 CMD 관리자 권한으로 파일을 열어서 실행한다.</li>
</ul>
</li>
<li>관리자 권한으로 실행 : 명령 프롬프트</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2017.png" alt="Untitled"></p>
<ul>
<li>다음 코드들을 시행</li>
</ul>
<p>→ <code>cd c:\winutils\bin</code></p>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<ul>
<li><p>만약, ChangeFileModeByMask error (3) 에러 발생 시,</p>
<p>  C드라이브 하단에, <code>tmp\hive</code> 폴더를 차례대로 생성을 한다.</p>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2018.png" alt="Untitled"></p>
<ul>
<li>실행 결과, 에러가 발생했으므로 C드라이브에 폴더를 생성한다.</li>
<li>폴더 생성 : tmp<ul>
<li>폴더 생성 : hive</li>
</ul>
</li>
<li>다시 코드를 실행한다.</li>
</ul>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<p>→ 오류없이 실행되었다.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2019.png" alt="Untitled"></p>
<h2 id="환경변수-설정"><a href="#환경변수-설정" class="headerlink" title="환경변수 설정"></a><strong>환경변수 설정</strong></h2><ul>
<li>‘시스템 환경 변수 편집’ 열기</li>
</ul>
<p>→ <code>환경 변수(N)..</code> </p>
<p><img src="/images/Spark_on_Windows/Untitled%2020.png" alt="Untitled"></p>
<p>시스템 환경변수를 설정한다.</p>
<ul>
<li>각 사용자 계정에 <code>사용자 변수 - 새로 만들기 버튼</code>을 클릭한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2021.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설정</li>
<li><code>SPARK_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2022.png" alt="Untitled"></p>
<ul>
<li><code>JAVA_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2023.png" alt="Untitled"></p>
<ul>
<li><code>HADOOP_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2024.png" alt="Untitled"></p>
<ul>
<li>환경변수를 편집한다.</li>
<li>Path 선택 → 편집(E)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2025.png" alt="Untitled"></p>
<ul>
<li>아래 코드를 추가한다.</li>
<li>새로 만들기<ul>
<li><code>%SPARK_HOME%\bin</code></li>
<li><code>%JAVA_HOME%\bin</code></li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2026.png" alt="Untitled"></p>
<h2 id="파이썬-환경설정"><a href="#파이썬-환경설정" class="headerlink" title="파이썬 환경설정"></a><strong>파이썬 환경설정</strong></h2><ul>
<li>Python 환경설정을 추가한다.</li>
<li><code>PYSPARK_PYTHON</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2027.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON</code> 환경변수를 설정한다.</li>
<li>일단 지운다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2028.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON_OPTS</code> 환경변수를 설정한다.</li>
<li>일단 삭제한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2029.png" alt="Untitled"></p>
<h2 id="스파크-테스트"><a href="#스파크-테스트" class="headerlink" title="스파크 테스트"></a><strong>스파크 테스트</strong></h2><ul>
<li>명령  프롬프트에서 진행</li>
</ul>
<p>→ <code>c:\spark</code> 폴더로 경로를 설정 한다.</p>
<p>→ <code>pyspark</code></p>
<p><img src="/images/Spark_on_Windows/Untitled%2030.png" alt="Untitled"></p>
<ul>
<li>이번에는 <code>[README.md](http://README.md)</code> 파일을 불러와서 아래 코드가 실행되는지 확인한다.</li>
<li>다음 코드를 실행해 본다.</li>
</ul>
<p>→<code>rd = sc.textFile(&quot;README.md&quot;)</code></p>
<p>→<code>rd.count()</code></p>
<p>→ 다음 결과 출력 시 성공.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2031.png" alt="Untitled"></p>
<ul>
<li>Reference<ul>
<li><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark-_1-118d1109403e451e9f5b2f5a81627a7e">pyspark 실습_1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_2-4213c5f5b33f48c6b0156526d2023dc0">pyspark_실습_2</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_3-8bf9e94aab3942b0ae4759d21b236878">pyspark_실습_3</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-on-linux-0c14b4d491af46d787230fd974e9dde4">Spark on linux</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-UI-f2e00f267df64d16af47be23678d2c09">Spark UI</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-ML-017307a2900a4d028ad32817f42d400a">Spark ML</a></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">67</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">23</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="level-start"><span class="level-item">생활코딩</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/%EA%B8%B0%EC%B4%88/"><span class="level-start"><span class="level-item">기초</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"><span class="level-start"><span class="level-item">분석 방법</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/SQL/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/git/github-blog/"><span class="level-start"><span class="level-item">github blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/"><span class="level-start"><span class="level-item">library</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/numpy/"><span class="level-start"><span class="level-item">numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pandas/"><span class="level-start"><span class="level-item">pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pyspark/"><span class="level-start"><span class="level-item">pyspark</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/visualization/"><span class="level-start"><span class="level-item">visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/machine-learning/"><span class="level-start"><span class="level-item">machine learning</span></span><span class="level-end"><span class="level-item tag">22</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">데이터 전처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"><span class="level-start"><span class="level-item">비지도학습</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"><span class="level-start"><span class="level-item">알고리즘</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"><span class="level-start"><span class="level-item">인공신경망</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"><span class="level-start"><span class="level-item">자료형, 반복문, 조건문</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"><span class="level-start"><span class="level-item">클래스</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"><span class="level-start"><span class="level-item">함수</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/NiFi/"><span class="level-start"><span class="level-item">NiFi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/airflow/"><span class="level-start"><span class="level-item">airflow</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/anaconda/"><span class="level-start"><span class="level-item">anaconda</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/crawling/"><span class="level-start"><span class="level-item">crawling</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/elasticsearch/"><span class="level-start"><span class="level-item">elasticsearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/wsl2/"><span class="level-start"><span class="level-item">wsl2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-14T00:00:00.000Z">2022-05-14</time></p><p class="title"><a href="/2022/05/14/Oracle_ch07_0428/">Oracle_practice7</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-13T00:00:00.000Z">2022-05-13</time></p><p class="title"><a href="/2022/05/13/Oracle_ch06_0428_2/">Oracle_practice6_3</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-12T00:00:00.000Z">2022-05-12</time></p><p class="title"><a href="/2022/05/12/Oracle_ch06_0428/">Oracle_practice6_2</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-11T00:00:00.000Z">2022-05-11</time></p><p class="title"><a href="/2022/05/11/Oracle_on_Jupyter_Lab/">Oracle on Jupyter Lab</a></p><p class="categories"><a href="/categories/setting/">setting</a> / <a href="/categories/setting/oracle/">oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-10T00:00:00.000Z">2022-05-10</time></p><p class="title"><a href="/2022/05/10/Oracle_practice_6/">Oracle_practice6</a></p><p class="categories"><a href="/categories/SQL/">SQL</a> / <a href="/categories/SQL/oracle/">oracle</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NiFi/"><span class="tag">NiFi</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Notion/"><span class="tag">Notion</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R-Markdown/"><span class="tag">R Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VScord/"><span class="tag">VScord</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anaconda/"><span class="tag">anaconda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawling/"><span class="tag">crawling</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-blog/"><span class="tag">github blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/oracle/"><span class="tag">oracle</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgreSQL/"><span class="tag">postgreSQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="tag">생활코딩</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>