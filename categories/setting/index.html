<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: setting - kmk3593 blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="kmk3593 blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="kmk3593 blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="kmk3593 blog"><meta property="og:url" content="https://kmk3593.github.io/"><meta property="og:site_name" content="kmk3593 blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kmk3593.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kmk3593.github.io"},"headline":"kmk3593 blog","image":["https://kmk3593.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"kmk3593 blog","logo":{"@type":"ImageObject","url":"https://kmk3593.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">setting</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-30T00:00:00.000Z" title="2022. 4. 30. 오전 9:00:00">2022-04-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-03T09:58:36.846Z" title="2022. 5. 3. 오후 6:58:36">2022-05-03</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">3 minutes read (About 487 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/Spark_UI/">Spark UI</a></h1><div class="content"><ul>
<li>가상환경을 생성한다.</li>
</ul>
<p>&#x2F;mnt&#x2F;c 경로에서 실행</p>
<p>→<code>mkdir temp</code></p>
<p>→<code>cd temp</code></p>
<p>→<code>virtualenv venv</code></p>
<p><img src="/images/Spark_UI/Untitled.png" alt="Untitled"></p>
<ul>
<li>가상환경에서 pyspark를 설치한다.</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>pip install pyspark</code></p>
<ul>
<li>다음 링크 접속</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">Quick Start - Spark 3.2.1 Documentation (apache.org)</a></p>
<ul>
<li>다음 내용을 복사한다.</li>
</ul>
<p><img src="/images/Spark_UI/Untitled%201.png" alt="Untitled"></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://read.md/">README.md</a> 파일 내용이다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">This program just counts the number of lines containing &#x27;a&#x27; and the number containing &#x27;b&#x27; in a text file. Note that you&#x27;ll need to replace YOUR_SPARK_HOME with the location where Spark is installed. As with the Scala and Java examples, we use a SparkSession to create Datasets. For applications that use custom classes or third-party libraries, we can also add code dependencies to spark-submit through its --py-files argument by packaging them into a .zip file (see spark-submit --help for details). SimpleApp is simple enough that we do not need to specify any code dependencies.</span><br><span class="line"></span><br><span class="line">We can run this application using the bin/spark-submit script:</span><br></pre></td></tr></table></figure>

<p>→<code>mkdir data</code></p>
<p>→<code>cd data</code></p>
<p>→<code>ls</code></p>
<p>→<code>vi README.md</code></p>
<p>→ 위에서 복사한 내용을 붙여넣는다.</p>
<p>→ <code>:wq</code></p>
<p>→ 내용 확인<code>cat README.md</code></p>
<p>→ <code>cd ..</code></p>
<p>→ <code>vi SimpleApp.py</code></p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">logFile = &quot;data/README.md&quot;  # Should be some file on your system</span><br><span class="line">spark = SparkSession.builder.appName(&quot;SimpleApp&quot;).getOrCreate()</span><br><span class="line">logData = spark.read.text(logFile).cache()</span><br><span class="line"></span><br><span class="line">numAs = logData.filter(logData.value.contains(&#x27;a&#x27;)).count()</span><br><span class="line">numBs = logData.filter(logData.value.contains(&#x27;b&#x27;)).count()</span><br><span class="line"></span><br><span class="line">print(&quot;Lines with a: %i, lines with b: %i&quot; % (numAs, numBs))</span><br><span class="line"></span><br><span class="line">input(&quot;Typing....&quot;)</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ python3 SimpleApp.py</p>
<p>→ 경로 확인 : <code>echo $SPARK_HOME</code></p>
<p>→ <code>$SPARK_HOME/bin/spark-submit --master local[4] SimpleApp.py</code></p>
<p><img src="/images/Spark_UI/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>코드 샐행 후</li>
<li>위 결과 참고하여 address 복사</li>
</ul>
<p>→ 뒤에 :4041을 추가하여 주소창에 입력한다. </p>
<p>(코드 실행 후 나오는 텍스트에서 SparkUI를 확인하자)</p>
<p>→ 주소창에 입력하여 접속 : <a target="_blank" rel="noopener" href="http://172.19.91.118:4041/">http://172.19.91.118:4041</a></p>
<p>→ 다음 화면 출력 시 성공.</p>
<p><img src="/images/Spark_UI/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>Reference :<ul>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">Quick Start - Spark 3.2.1 Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/quick-start.html">(apache.org)</a><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-29T00:00:00.000Z" title="2022. 4. 29. 오전 9:00:00">2022-04-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-01T15:41:24.323Z" title="2022. 5. 2. 오전 12:41:24">2022-05-02</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">3 minutes read (About 392 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/29/Spark_on_linux/">Spark on Linux</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/spark_install_using_wsl/">WSL2에서의 Spark 설치 - Data Science | DSChloe</a></p>
<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a><strong>개요</strong></h2><ul>
<li>간단하게 PySpark를 설치해보는 과정을 작성한다.</li>
<li>WSL2 설치 방법은 다루지 않는다.</li>
</ul>
<h2 id="필수-파일-설치"><a href="#필수-파일-설치" class="headerlink" title="필수 파일 설치"></a><strong>필수 파일 설치</strong></h2><ul>
<li>설치가 안 되었을 경우에 설치한다.</li>
<li>자바 및 Spark 파일을 설치하도록 한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-8-jdk</span><br><span class="line">$ sudo wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</span><br><span class="line">$ sudo tar -xvzf spark-3.2.0-bin-hadoop3.2.tgz</span><br></pre></td></tr></table></figure>

<h2 id="bashrc-파일-수정"><a href="#bashrc-파일-수정" class="headerlink" title=".bashrc 파일 수정"></a><strong>.bashrc 파일 수정</strong></h2><ul>
<li>경로를 다음과 같이 설정한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">evan@evan:/mnt/c/hadoop$ pwd</span><br><span class="line">/mnt/c/hadoop</span><br></pre></td></tr></table></figure>

<ul>
<li>설치한 파일은 다음과 같다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">evan@evan:/mnt/c/hadoop$ ls</span><br><span class="line">spark-3.2.0-bin-hadoop3.2  spark-3.2.0-bin-hadoop3.2.tgz</span><br></pre></td></tr></table></figure>

<ul>
<li><code>vi ~/.bashrc</code> 파일을 열고 다음과 같이 코드를 작성한다.<ul>
<li>다른 코드는 건드리지 않는다.</li>
<li>마지막 라인에서 작성한다.</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span><br><span class="line">export SPARK_HOME=/mnt/c/spark</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export PATH=$SPARK_HOME/bin:$PATH</span><br><span class="line">export PYSPARK_PYTHON=/usr/bin/python3</span><br></pre></td></tr></table></figure>

<p><img src="/images/Spark_on_linux/Untitled.png" alt="Untitled"></p>
<h2 id="테스트"><a href="#테스트" class="headerlink" title="테스트"></a><strong>테스트</strong></h2><ul>
<li>pyspark를 실행한다. (경로에 주의한다)</li>
<li>SPARK_HOME을 다음과 같이 설정했으니 해당 경로에서 실행.</li>
<li>export SPARK_HOME&#x3D;&#x2F;mnt&#x2F;c&#x2F;spark</li>
</ul>
<p>경로 이동 : <code>cd ..</code> </p>
<p>→ <code>cd spark/</code></p>
<p>→<code>source ~/.bashrc</code></p>
<p>→<code>pyspark</code></p>
<p><img src="/images/Spark_on_linux/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>정상적으로 작동한지 테스트한다.</li>
<li>해당 경로에 <a target="_blank" rel="noopener" href="http://readme.md/">README.md</a> 파일이 있다면 시행해보자.</li>
</ul>
<p>→<code>rd = sc.textFile(&quot;README.md&quot;)</code></p>
<p>→<code>rd.count()</code></p>
<p>→ 다음과 같이 출력된다면 성공이다.</p>
<p><img src="/images/Spark_on_linux/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/spark_install_using_wsl/">WSL2에서의 Spark 설치 - Data Science | DSChloe</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-25T00:00:00.000Z" title="2022. 4. 25. 오전 9:00:00">2022-04-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-27T16:37:25.509Z" title="2022. 4. 28. 오전 1:37:25">2022-04-28</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/spark/">spark</a></span><span class="level-item">11 minutes read (About 1630 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/25/Spark_on_Windows/">Spark on Windows</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></p>
<h2 id="사전준비"><a href="#사전준비" class="headerlink" title="사전준비"></a>사전준비</h2><ul>
<li>스파크를 설치하는 과정이다.</li>
<li>사전에 파이썬 3가 설치되어 있어야 한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<h2 id="자바-다운로드"><a href="#자바-다운로드" class="headerlink" title="자바 다운로드"></a><strong>자바 다운로드</strong></h2><ul>
<li>자바를 설치한다. 설치 파일은 아래에서 다운로드 받는다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html">Java SE 8 Archive Downloads (JDK 8u211 and later)</a></strong></li>
</ul>
</li>
<li>설치 시, 오라클 로그인이 필요 할 수도 있다.</li>
</ul>
<h2 id="Spark-다운로드"><a href="#Spark-다운로드" class="headerlink" title="Spark 다운로드"></a>S<strong>park 다운로드</strong></h2><ul>
<li>이번에는 Spark를 설치한다.</li>
<li><strong>설치파일 다운로드</strong><ul>
<li>설치 URL: <strong><a target="_blank" rel="noopener" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz">https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></strong> (2022년 1월 기준)</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled.png" alt="Untitled"></p>
<h3 id="WinRAR-다운로드"><a href="#WinRAR-다운로드" class="headerlink" title="WinRAR 다운로드"></a><strong>WinRAR 다운로드</strong></h3><ul>
<li>이 때, <code>.tgz</code> 압축파일을 풀기 위해서는 <code>WinRAR</code> 을 설치한다.<ul>
<li>설치 파일: <strong><a target="_blank" rel="noopener" href="https://www.rarlab.com/download.htm">https://www.rarlab.com/download.htm</a></strong></li>
<li>본인 컴퓨터에 맞는 것을 설치한다.</li>
<li>WinRARx64 (64bit) 6.11 버전 다운로드</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%201.png" alt="Untitled"></p>
<h2 id="winutils-다운로드"><a href="#winutils-다운로드" class="headerlink" title="winutils 다운로드"></a><strong>winutils 다운로드</strong></h2><ul>
<li>이번에는 스파크가 윈도우 로컬 컴퓨터가 Hadoop으로 착각하게 만들 프로그램이 필요하다.<ul>
<li>설치파일: <strong><a target="_blank" rel="noopener" href="https://github.com/cdarlint/winutils">https://github.com/cdarlint/winutils</a></strong></li>
<li>여기에서 각 설치 버전에 맞는 winutils를 다운로드 받는다.</li>
</ul>
</li>
<li>이전에 받은 spark-3.2.0-bin-hadoob-3.2.tgz 와 버전이  일치하는 것을 선택해야 한다.<ul>
<li>3.2.0 버전을 다운로드 받았다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%202.png" alt="Untitled"></p>
<h2 id="자바-설치-진행"><a href="#자바-설치-진행" class="headerlink" title="자바 설치 진행"></a><strong>자바 설치 진행</strong></h2><ul>
<li>C 드라이브에 폴더 생성 : hadoob</li>
<li>다운로드 받은 파일 4개를 C&#x2F;hadoob 에 복사하여 옮긴다</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>관리자 권한으로 실행 : jdk-8u311-windows-x64</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>계속 Next 버튼 클릭 후, 아래 파일에서 경로를 수정한다. (이 때, <code>Program Files</code> 공백이 있는데, 이러한 공백은 환경 설치 시 문제가 될 수 있다.)</li>
<li>Development Tools 선택</li>
<li>change 버튼으로 변경을 진행한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로로 이동</li>
<li>Foldername: jdk 입력<ul>
<li>다음 그림과 같아야 한다.</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>Java를 다른 폴더에 설치하려 한다.</li>
<li>변경(C)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%207.png" alt="Untitled"></p>
<ul>
<li>c 드라이브 경로에서 ‘새 폴더 만들기(M)’</li>
<li>폴더 생성 : jre</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%208.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설치 위치가 지정된다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%209.png" alt="Untitled"></p>
<ul>
<li>성공적으로 설치되었다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2010.png" alt="Untitled"></p>
<h3 id="winrar-설치-진행"><a href="#winrar-설치-진행" class="headerlink" title="winrar 설치 진행"></a><strong>winrar 설치 진행</strong></h3><ul>
<li>관리자 권한으로 실행 : winrar-x64-611</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2011.png" alt="Untitled"></p>
<ul>
<li>기본 설정으로 설치 진행</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2012.png" alt="Untitled"></p>
<h2 id="spark-설치-진행"><a href="#spark-설치-진행" class="headerlink" title="spark 설치 진행"></a><strong>spark 설치 진행</strong></h2><ul>
<li>Spark 설치를 진행한다.</li>
<li>설치 파일 우클릭 → Extract to “spark-3.2.0-bin-hadoop3.2|”</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2013.png" alt="Untitled"></p>
<h3 id="spark-폴더-생성-및-파일-이동"><a href="#spark-폴더-생성-및-파일-이동" class="headerlink" title="spark 폴더 생성 및 파일 이동"></a><strong>spark 폴더 생성 및 파일 이동</strong></h3><ul>
<li>위 과정 이후 폴더가 생성된다.</li>
<li>파일 이동을 하도록 한다.<ul>
<li>spark-3.2.0-bin-hadoop3.2 폴더 내 모든 파일을 복사한다.</li>
</ul>
</li>
<li>그 후, C드라이브 하단에 spark 폴더를 생성한 후, 모두 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2014.png" alt="Untitled"></p>
<h3 id="log4j-properties-파일-수정"><a href="#log4j-properties-파일-수정" class="headerlink" title="log4j.properties 파일 수정"></a><strong>log4j.properties 파일 수정</strong></h3><ul>
<li><code>C</code> -&gt; <code>spark</code> → <code>conf</code> → <code>[log4j.properties](http://log4j.properties)</code> 파일을 연다.</li>
<li>해당 파일을 메모장으로 연 후, 아래에서 <code>INFO</code> → <code>ERROR</code> 로 변경한다.<ul>
<li>작업 실행 시, 출력하는 모든 logs 값들을 없앨 수 있다.</li>
<li>다음과 같이 설정 후 저장</li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2015.png" alt="Untitled"></p>
<h2 id="winutils-설치-진행"><a href="#winutils-설치-진행" class="headerlink" title="winutils 설치 진행"></a><strong>winutils 설치 진행</strong></h2><ul>
<li>C드라이브에서 winutils-bin 폴더를 차례로 생성한다.</li>
<li>다운로드 받은 winutils 파일을 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2016.png" alt="Untitled"></p>
<ul>
<li>이 파일이 Spark 실행 시, 오류 없이 실행될 수 있도록 파일 사용 권한을 얻도록 한다.<ul>
<li>이 때에는 CMD 관리자 권한으로 파일을 열어서 실행한다.</li>
</ul>
</li>
<li>관리자 권한으로 실행 : 명령 프롬프트</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2017.png" alt="Untitled"></p>
<ul>
<li>다음 코드들을 시행</li>
</ul>
<p>→ <code>cd c:\winutils\bin</code></p>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<ul>
<li><p>만약, ChangeFileModeByMask error (3) 에러 발생 시,</p>
<p>  C드라이브 하단에, <code>tmp\hive</code> 폴더를 차례대로 생성을 한다.</p>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2018.png" alt="Untitled"></p>
<ul>
<li>실행 결과, 에러가 발생했으므로 C드라이브에 폴더를 생성한다.</li>
<li>폴더 생성 : tmp<ul>
<li>폴더 생성 : hive</li>
</ul>
</li>
<li>다시 코드를 실행한다.</li>
</ul>
<p>→ <code>winutils.exe chmod 777 \tmp\hive</code></p>
<p>→ 오류없이 실행되었다.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2019.png" alt="Untitled"></p>
<h2 id="환경변수-설정"><a href="#환경변수-설정" class="headerlink" title="환경변수 설정"></a><strong>환경변수 설정</strong></h2><ul>
<li>‘시스템 환경 변수 편집’ 열기</li>
</ul>
<p>→ <code>환경 변수(N)..</code> </p>
<p><img src="/images/Spark_on_Windows/Untitled%2020.png" alt="Untitled"></p>
<p>시스템 환경변수를 설정한다.</p>
<ul>
<li>각 사용자 계정에 <code>사용자 변수 - 새로 만들기 버튼</code>을 클릭한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2021.png" alt="Untitled"></p>
<ul>
<li>다음과 같이 설정</li>
<li><code>SPARK_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2022.png" alt="Untitled"></p>
<ul>
<li><code>JAVA_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2023.png" alt="Untitled"></p>
<ul>
<li><code>HADOOP_HOME</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2024.png" alt="Untitled"></p>
<ul>
<li>환경변수를 편집한다.</li>
<li>Path 선택 → 편집(E)…</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2025.png" alt="Untitled"></p>
<ul>
<li>아래 코드를 추가한다.</li>
<li>새로 만들기<ul>
<li><code>%SPARK_HOME%\bin</code></li>
<li><code>%JAVA_HOME%\bin</code></li>
</ul>
</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2026.png" alt="Untitled"></p>
<h2 id="파이썬-환경설정"><a href="#파이썬-환경설정" class="headerlink" title="파이썬 환경설정"></a><strong>파이썬 환경설정</strong></h2><ul>
<li>Python 환경설정을 추가한다.</li>
<li><code>PYSPARK_PYTHON</code> 환경변수를 설정한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2027.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON</code> 환경변수를 설정한다.</li>
<li>일단 지운다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2028.png" alt="Untitled"></p>
<ul>
<li><code>PYSPARK_DRIVER_PYTHON_OPTS</code> 환경변수를 설정한다.</li>
<li>일단 삭제한다.</li>
</ul>
<p><img src="/images/Spark_on_Windows/Untitled%2029.png" alt="Untitled"></p>
<h2 id="스파크-테스트"><a href="#스파크-테스트" class="headerlink" title="스파크 테스트"></a><strong>스파크 테스트</strong></h2><ul>
<li>명령  프롬프트에서 진행</li>
</ul>
<p>→ <code>c:\spark</code> 폴더로 경로를 설정 한다.</p>
<p>→ <code>pyspark</code></p>
<p><img src="/images/Spark_on_Windows/Untitled%2030.png" alt="Untitled"></p>
<ul>
<li>이번에는 <code>[README.md](http://README.md)</code> 파일을 불러와서 아래 코드가 실행되는지 확인한다.</li>
<li>다음 코드를 실행해 본다.</li>
</ul>
<p>→<code>rd = sc.textFile(&quot;README.md&quot;)</code></p>
<p>→<code>rd.count()</code></p>
<p>→ 다음 결과 출력 시 성공.</p>
<p><img src="/images/Spark_on_Windows/Untitled%2031.png" alt="Untitled"></p>
<ul>
<li>Reference<ul>
<li><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/">Spark Installation on Windows 10 - Data Science | DSChloe</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark-_1-118d1109403e451e9f5b2f5a81627a7e">pyspark 실습_1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_2-4213c5f5b33f48c6b0156526d2023dc0">pyspark_실습_2</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/pyspark_-_3-8bf9e94aab3942b0ae4759d21b236878">pyspark_실습_3</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-on-linux-0c14b4d491af46d787230fd974e9dde4">Spark on linux</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-UI-f2e00f267df64d16af47be23678d2c09">Spark UI</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Spark-ML-017307a2900a4d028ad32817f42d400a">Spark ML</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-22T00:00:00.000Z" title="2022. 4. 22. 오전 9:00:00">2022-04-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-24T02:09:24.895Z" title="2022. 4. 24. 오전 11:09:24">2022-04-24</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">5 minutes read (About 701 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/22/Airfow_practice_3/">Airflow 실습03</a></h1><div class="content"><h2 id="Elastic-search-질의"><a href="#Elastic-search-질의" class="headerlink" title="Elastic search 질의"></a>Elastic search 질의</h2><ul>
<li>실무 예제로 배우는 데이터 공학 83p</li>
</ul>
<p>관리자 권한으로 실행 : Ubuntu</p>
<p>→ 경로 이동 : …airflow&#x2F;</p>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>code .</code></p>
<p>→ VSCord가 자동 실행된다 </p>
<p>→파일 생성 : e_query.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from pandas.io.json import json_normalize</span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line"></span><br><span class="line"># Elasticsearch 객체 생성</span><br><span class="line">es = Elasticsearch()</span><br><span class="line"></span><br><span class="line"># 일래스틱서치에 보낼 문서 본문(질의 요청) JSON 객체를 만든다.</span><br><span class="line"># Matchall 검색 사용</span><br><span class="line">doc = &#123;&quot;query&quot; : &#123;&quot;match_all&quot;: &#123;&#125;&#125;&#125;</span><br><span class="line">res = es.search(index=&quot;users&quot;, body = doc, size = 500)</span><br><span class="line"># print(res[&#x27;hits&#x27;][&#x27;hits&#x27;])</span><br><span class="line"></span><br><span class="line"># 루프로 문서를 훑으면서 각 문서의 _source 필드만 출력한다.</span><br><span class="line"># for doc in res[&#x27;hits&#x27;][&#x27;hits&#x27;]:</span><br><span class="line">#    print(doc[&#x27;_source&#x27;])</span><br><span class="line"></span><br><span class="line"># 질의 결과를 pandas DataFrame에 넣는 것도 가능</span><br><span class="line">df = json_normalize(res[&#x27;hits&#x27;][&#x27;hits&#x27;])</span><br><span class="line">print(df.head())</span><br><span class="line">print(df.info())</span><br><span class="line"></span><br><span class="line">print(df[&#x27;_source.city&#x27;].value_counts())</span><br></pre></td></tr></table></figure>

<h3 id="postgreSQL-→-Elastic-search-데이터-전송"><a href="#postgreSQL-→-Elastic-search-데이터-전송" class="headerlink" title="postgreSQL → Elastic search 데이터 전송"></a>postgreSQL → Elastic search 데이터 전송</h3><ul>
<li>교재 88p</li>
<li>Elastic search 가동된 상태에서 진행</li>
</ul>
<p>→ 선행 학습 링크 참고 : <a target="_blank" rel="noopener" href="https://www.notion.so/postgreSQL-2a8e7bf9156b4514b28aafbd93421a79">postgreSQL 실습 (notion.so)</a></p>
<ul>
<li>pgAdmin 준비된 상태에서 진행</li>
</ul>
<p>→ 다음과 같이 출력되는 상태여야 한다.</p>
<p><img src="/images/Airflow_practice_3/Untitled.png" alt="Untitled"></p>
<ul>
<li>VSCord 에서 작업</li>
<li>교재 88p</li>
</ul>
<p>dags 폴더 아래에 파일 생성</p>
<p>→ 파일 생성 : airflodb.py</p>
<p>→ 코드 작성</p>
<p><code>import datetime as dt</code></p>
<p><code>from datetime import timedelta</code></p>
<p><code>from airflow import DAG</code></p>
<p><code>from airflow.operators.bash import BashOperator</code></p>
<p><code>from airflow.operators.python import PythonOperator</code></p>
<p><code>import pandas as pd</code></p>
<p><code>import psycopg2 as db</code></p>
<p><code>from elasticsearch import Elasticsearch</code></p>
<p><code>print(&quot;Hello&quot;)</code></p>
<p>→ 경로 이동 : (venv) kmk3593@DESKTOP-LNQ780K:&#x2F;mnt&#x2F;c&#x2F;airflow-test&#x2F;dags$ </p>
<p>→ 실행</p>
<p>→ Hello 가 출력되었으므로 성공.</p>
<p><img src="/images/Airflow_practice_3/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>코드 추가 작성</li>
<li>다음 내용을 airflodb.py에 작성한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import datetime as dt</span><br><span class="line">from datetime import timedelta</span><br><span class="line">from airflow import DAG</span><br><span class="line">from airflow.operators.bash import BashOperator</span><br><span class="line">from airflow.operators.python import PythonOperator</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import psycopg2 as db</span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line"></span><br><span class="line"># queryPostgresql 지정</span><br><span class="line">def queryPostgresql():</span><br><span class="line">    conn_string=&quot;dbname=&#x27;dataengineering&#x27; host=&#x27;localhost&#x27; user=&#x27;postgres&#x27; password=&#x27;postgres&#x27;&quot;</span><br><span class="line">    conn=db.connect(conn_string)</span><br><span class="line">    print(&quot;DB connecting....&quot;, conn)</span><br><span class="line"></span><br><span class="line">    # 데이터 추출</span><br><span class="line">    df = pd.read_sql(&quot;select name, city from users&quot;, conn)</span><br><span class="line">    df.to_csv(&quot;postgresqldata.csv&quot;)</span><br><span class="line">    print(&quot;----Data Saved----&quot;)</span><br><span class="line"></span><br><span class="line"># insertElasticSearch</span><br><span class="line">def insertDataElasticsearch():</span><br><span class="line"></span><br><span class="line">    # Elastic 인스턴스 생성</span><br><span class="line">    es = Elasticsearch()</span><br><span class="line"></span><br><span class="line">    # 데이터 불러오기</span><br><span class="line">    df = pd.read_csv(&quot;postgresqldata.csv&quot;)</span><br><span class="line">    for i, r in df.iterrows():</span><br><span class="line">        doc = r.to_json()</span><br><span class="line">        res = es.index(</span><br><span class="line">            index=&quot;frompostgresql&quot;</span><br><span class="line">            , doc_type=&quot;doc&quot;, body=doc</span><br><span class="line">        )</span><br><span class="line">        print(res)</span><br><span class="line"></span><br><span class="line"># DAG를 위한 인수들을 지정</span><br><span class="line">default_args = &#123;</span><br><span class="line">    &#x27;owner&#x27; : &#x27;human&#x27;,</span><br><span class="line">    &#x27;start_date&#x27; : dt.datetime(2022, 4, 18),</span><br><span class="line">    &#x27;retries&#x27; : 1,</span><br><span class="line">    &#x27;retry_delay&#x27;: dt.timedelta(minutes = 5)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">with DAG(&#x27;MyDBdag&#x27;,</span><br><span class="line">         default_args = default_args,</span><br><span class="line">         schedule_interval = timedelta(minutes=5), # &#x27;0 * * * * &#x27;,</span><br><span class="line">     ) as dag:</span><br><span class="line"></span><br><span class="line">    getData = PythonOperator(</span><br><span class="line">        task_id = &quot;QueryPostgreSQL&quot;</span><br><span class="line">        , python_callable=queryPostgresql</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    insertData = PythonOperator(</span><br><span class="line">        task_id = &quot;InsertDataElasticsearch&quot;</span><br><span class="line">        , python_callable = insertDataElasticsearch</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">getData &gt;&gt; insertData</span><br></pre></td></tr></table></figure>

<ul>
<li>Airflow 가동</li>
</ul>
<p>→ 저장 후 실행</p>
<p>→ <code>python3 airflodb.py</code></p>
<p>→ airflow 실행</p>
<p>→ <code>airflow db init</code></p>
<p>→(재시도할 경우, 실행 : <code>airflow db reset</code> )</p>
<p>→ Terminal 2개 준비하고 다음 명령 실행</p>
<p>→<code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code></p>
<p>→ 다음 주소로 진입</p>
<p><a target="_blank" rel="noopener" href="http://localhost:8080/">http://localhost:8080/</a> </p>
<p>→ Dags</p>
<p>→ 활성화 : MyDBdag</p>
<p>→ 더블 클릭 : MyDBdag</p>
<p><img src="/images/Airflow_practice_3/Untitled%202.png" alt="Untitled"></p>
<p>→ Tree </p>
<p>→ Update</p>
<p>→ 다음과 같이 출력되면 성공</p>
<p><img src="/images/Airflow_practice_3/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>Reference : 실무 예제로 배우는 데이터 공학</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-21T00:00:00.000Z" title="2022. 4. 21. 오전 9:00:00">2022-04-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-24T01:55:54.877Z" title="2022. 4. 24. 오전 10:55:54">2022-04-24</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">4 minutes read (About 582 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/21/Airflow_practice_2/">Airflow 실습02</a></h1><div class="content"><h2 id="데이터베이스를-위한-아파치-에어플로-데이터-파이프라인-구축"><a href="#데이터베이스를-위한-아파치-에어플로-데이터-파이프라인-구축" class="headerlink" title="데이터베이스를 위한 아파치 에어플로 데이터 파이프라인 구축"></a>데이터베이스를 위한 아파치 에어플로 데이터 파이프라인 구축</h2><p>실무 예제로 배우는 데이터 공학 87 ~ 91p</p>
<p>관리자 권한으로 실행 : ubuntu</p>
<p>→ elasticsearch 가동하기</p>
<p><img src="/images/Airflow_practice_2/Untitled.png" alt="Untitled"></p>
<p>→ Kibana 가동하기 </p>
<p><img src="/images/Airflow_practice_2/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>경로 이동, 가상 환경 진입</li>
</ul>
<p>→ <code>cd ..</code>→ <code>cd ..</code>→ <code>cd mnt/c/airflow-test</code></p>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>교재의 elastic search 버전을 참고하여 설치</li>
</ul>
<p>→ <code>pip3 install elasticsearch==7.17.2</code></p>
<p><img src="/images/Airflow_practice_2/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>교재 80p</li>
<li>일단 vi 대신에 code . 를 사용한다.</li>
</ul>
<p>→ <code>code .</code></p>
<p>( 안 될 경우, Ubuntu를 다시 시작한다)</p>
<p>→ 코드 실행 시, VSCord가 자동으로 시작된다</p>
<p><img src="/images/Airflow_practice_2/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>폴더 생성</li>
</ul>
<p>→ 폴더 생성 : chapter04</p>
<p>→ 파일 생성 : e_search.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">from elasticsearch import helpers</span><br><span class="line">from faker import Faker</span><br><span class="line"></span><br><span class="line">fake=Faker()</span><br><span class="line">es = Elasticsearch() #or pi &#123;127.0.0.1&#125;</span><br><span class="line"></span><br><span class="line">doc=&#123;&quot;name&quot;: fake.name(),&quot;street&quot;: fake.street_address(), &quot;city&quot;: fake.city(),&quot;zip&quot;:fake.zipcode()&#125;</span><br><span class="line"></span><br><span class="line">res=es.index(index=&quot;users&quot;,doc_type=&quot;doc&quot;,body=doc)</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line">doc=&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;_id&quot;:&quot;pDYlOHEBxMEH3Xr-2QPk&quot;&#125;&#125;&#125;</span><br><span class="line">res=es.search(index=&quot;users&quot;,body=doc,size=10)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>

<ul>
<li>가상환경 가동 후 실행</li>
</ul>
<p>→ 저장</p>
<p>→ 터미널 </p>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>cd chapter04/</code></p>
<p>→<code>python3 e_search.py</code></p>
<ul>
<li>교재 81p</li>
</ul>
<p>→ 파일 작성 : e_search02.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">from elasticsearch import helpers</span><br><span class="line">from faker import Faker</span><br><span class="line"></span><br><span class="line">fake=Faker()</span><br><span class="line">es = Elasticsearch() #or pi &#123;127.0.0.1&#125;</span><br><span class="line"></span><br><span class="line">actions = [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;_index&quot;: &quot;users&quot;,</span><br><span class="line">    &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">	&quot;name&quot;: fake.name(),</span><br><span class="line">	&quot;street&quot;: fake.street_address(),</span><br><span class="line">	&quot;city&quot;: fake.city(),</span><br><span class="line">	&quot;zip&quot;:fake.zipcode()&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  for x in range(998) # or for i,r in df.iterrows()</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = helpers.bulk(es, actions)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python3 e_search02.py</code></p>
<p>→ 다음과 같이 (998,[]) 출력되면 성공</p>
<p><img src="/images/Airflow_practice_2/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>Kibana 페이지 실행</li>
</ul>
<p>→ 주소창에 입력 : localhost:5601&#x2F;</p>
<p>→ 메뉴바</p>
<p>→ Stack Management</p>
<p><img src="/images/Airflow_practice_2/Untitled%205.png" alt="Untitled"></p>
<p>→ Index Patterns</p>
<p><img src="/images/Airflow_practice_2/Untitled%206.png" alt="Untitled"></p>
<p>→ Create index pattern</p>
<p>→ 이름 : users</p>
<p><img src="/images/Airflow_practice_2/Untitled%207.png" alt="Untitled"></p>
<p>→ Create index pattern</p>
<p><img src="/images/Airflow_practice_2/Untitled%208.png" alt="Untitled"></p>
<p>→ 햄버거 메뉴바 열기</p>
<p>→ Discover </p>
<p><img src="/images/Airflow_practice_2/Untitled%209.png" alt="Untitled"></p>
<p>→ 앞에서 추가한 index의 문서를 확인할 수 있다.</p>
<p><img src="/images/Airflow_practice_2/Untitled%2010.png" alt="Untitled"></p>
<h3 id="데이터-저장소"><a href="#데이터-저장소" class="headerlink" title="데이터 저장소"></a>데이터 저장소</h3><ul>
<li>RDBMS</li>
</ul>
<p>— 종류 : Oracle, PostgreSQL, MySQL, 빅쿼리(구글),…</p>
<p>— 표준 SQL (하나를 잘 알면, 거의 비슷!)</p>
<ul>
<li>NoSQL</li>
</ul>
<p>— 종류 : Elasticsearch, 몽고 DB (무료 버전)</p>
<p>어려운 것 조회 하는 방법이 RDMBS ≠ NoSQL 다름 (완전 다름!)</p>
<ul>
<li>Reference <ul>
<li>실무 예제로 배우는 데이터 공학</li>
<li><a target="_blank" rel="noopener" href="https://www.notion.so/Elasticsearch-36546819d5b44c778d6a9c08f18c8339">Elasticsearch (notion.so)</a></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-20T00:00:00.000Z" title="2022. 4. 20. 오전 9:00:00">2022-04-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-22T08:45:17.980Z" title="2022. 4. 22. 오후 5:45:17">2022-04-22</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">9 minutes read (About 1349 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/20/Airflow_pipeline0/">Airflow 재설치 및 데이터 파이프라인 구축</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/apache_airflow_using_wsl2/">Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe</a></p>
<p><a target="_blank" rel="noopener" href="https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/">Airflow 데이터 파이프라인 구축 예제 - Data Science | DSChloe</a></p>
<ul>
<li>체크포인트</li>
</ul>
<ol>
<li><p>가상환경을 만들 수 있는냐 (virtualenv 라이브러리)</p>
</li>
<li><p>경로 이동이 자유로운가? cd 사용</p>
</li>
<li><p>환경 변수를 이해하고 잡을 수 있는가?</p>
<p> vi 편집기를 자유자재로 쓸 수 있는가?</p>
</li>
<li><p>파이썬 라이브러리를 가상환경에 자유자재로 설치 할 수 있는가?</p>
</li>
<li><p>가상 환경에 자유롭게 출입할 수 있는가?</p>
</li>
</ol>
<ul>
<li>사전 준비</li>
</ul>
<p>VSCord 의 airflow.cfg 에서 진행</p>
<p>→ 내용 변경 : <code>load_examples = True</code> ⇒ <code>False</code>  </p>
<p>→ c드라이브 → airflow_test → dags와 chapter03, chapter04 를 배경화면에 빼둔다.</p>
<p><img src="/images/Airflow_pipeline0/Untitled.png" alt="Untitled"></p>
<ul>
<li>airflow-test 내용물 삭제</li>
</ul>
<p>Ubuntu 의 airflow 경로에서 진행</p>
<p>→<code>deactivate</code></p>
<p>→<code>sudo rm -rf *</code></p>
<ul>
<li>다시 가상환경 생성</li>
</ul>
<p>→<code>virtualenv venv</code></p>
<p>→<code>ls</code></p>
<ul>
<li>필요한 내용이 작성되어 있는지 확인</li>
</ul>
<p>→ <code>vi ~/.bashrc</code></p>
<p>→ 내용 확인 : <code>export AIRFLOW_HOME=/mnt/c/airflow-test</code></p>
<p>→ <code>source ~/.bashrc</code> </p>
<p>→ <code>echo $AIRFLOW_HOME</code></p>
<p>→<code>pwd</code></p>
<ul>
<li>가상환경 on</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>라이브러리 설치</li>
</ul>
<p>→ <code>pip3 install &#39;apache-airflow[postgres, slack, celery]&#39;</code></p>
<ul>
<li>db 설정</li>
</ul>
<p>→ <code>airflow db init</code></p>
<ul>
<li>계정 등록</li>
<li>firstname이 실행 결과에 영향을 주는가</li>
</ul>
<p>→ <code>airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com</code></p>
<ul>
<li>VSCord 에서 진행</li>
</ul>
<p>→ 폴더 생성 : ( file → open folder → airflow-test )</p>
<p>→ airflow.cfg 파일</p>
<p>→ 내용 변경 : <code>load_examples=True</code> ⇒ <code>False</code></p>
<p><img src="/images/Airflow_pipeline0/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Ubuntu 에서 진행</li>
</ul>
<p>→ <code>airflow db reset</code></p>
<p>→ 가상 환경 상태에서 다음 코드 실행</p>
<p>→ <code>airflow webserver -p 8080</code></p>
<ul>
<li>그리고, 해당 링크에 <a target="_blank" rel="noopener" href="http://localhost:8080/login/">http://localhost:8080/login/</a> 접속하면 아래와 같은 화면이 나타난다.</li>
</ul>
<p><img src="/images/Airflow_pipeline0/Untitled%202.png" alt="Untitled"></p>
<p>→ ctrl + c 로 빠져나온다.</p>
<h1 id="데이터-파이프라인-구축"><a href="#데이터-파이프라인-구축" class="headerlink" title="데이터 파이프라인 구축"></a>데이터 파이프라인 구축</h1><h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a><strong>개요</strong></h2><ul>
<li>이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다.</li>
</ul>
<p><strong><strong>Step 01. Dags 폴더 생성</strong></strong></p>
<ul>
<li><p>프로젝트 Root 하단에 Dags 폴더를 만든다.</p>
<ul>
<li>dags 폴더를 확인한다.</li>
</ul>
</li>
<li><p>dags 파일 생성</p>
</li>
</ul>
<p>→<code>mkdir dags</code></p>
<p>→<code>ls</code></p>
<p><strong><strong>Step 02. 가상의 데이터 생성</strong></strong></p>
<ul>
<li>라이브러리 설치</li>
</ul>
<p>→ 가상 환경에서 진행</p>
<p>→ <code>pip3 install faker pandas</code></p>
<ul>
<li>폴더, 파일 생성</li>
</ul>
<p>→ <code>mkdir data</code></p>
<p>→ <code>cd data</code></p>
<p>→ <code>vi step01_writecsv.py</code></p>
<p>→ 코드 작성.</p>
<pre><code>+ 앞으로는 이런 방식으로 코드를 작성한다.

+실무에서 필요한 습관이다.
</code></pre>
<ul>
<li>faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data&#x2F;step01_writecsv.py)</li>
</ul>
<p><img src="/images/Airflow_pipeline0/Untitled%203.png" alt="Untitled"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from faker import Faker</span><br><span class="line">import csv</span><br><span class="line">output=open(&#x27;data.csv&#x27;,&#x27;w&#x27;)</span><br><span class="line">fake=Faker()</span><br><span class="line">header=[&#x27;name&#x27;,&#x27;age&#x27;,&#x27;street&#x27;,&#x27;city&#x27;,&#x27;state&#x27;,&#x27;zip&#x27;,&#x27;lng&#x27;,&#x27;lat&#x27;]</span><br><span class="line">mywriter=csv.writer(output)</span><br><span class="line">mywriter.writerow(header)</span><br><span class="line">for r in range(1000):</span><br><span class="line">    mywriter.writerow([fake.name(),</span><br><span class="line">											fake.random_int(min=18, max=80, step=1), </span><br><span class="line">											fake.street_address(), </span><br><span class="line">											fake.city(),</span><br><span class="line">											fake.state(),</span><br><span class="line">											fake.zipcode(),</span><br><span class="line">											fake.longitude(),</span><br><span class="line">											fake.latitude()])</span><br><span class="line">output.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>코드를 실행한다.</li>
<li>VSCord에서 data.csv 파일이 생성되어야 한다.</li>
</ul>
<p>→ <code>python3 step01_writecsv.py</code></p>
<p>→ <code>ls</code></p>
<p>→ <code>cat data.csv</code></p>
<p><strong><strong>Step 03. csv2json 파일 구축</strong></strong></p>
<ul>
<li>이번에는 CSV와 JSON 변환 파일을 구축하는 코드를 작성한다. (파일 경로 : dags&#x2F;<strong><a target="_blank" rel="noopener" href="http://csv2json.py/">csv2json.py</a></strong>)\</li>
<li>주요 목적 함수 csvToJson()의 역할은 <code>data/data.csv</code> 파일을 불러와서 <code>fromAirflow.json</code> 파일로 변경하는 것이다.</li>
<li>DAG는 csvToJson 함수를 하나의 작업으로 등록하는 과정을 담는다. 작업의 소유자, 시작일시, 실패 시 재시도 횟수, 재시도 지연시 시간을 지정한다.<ul>
<li>자세한 옵션은 도움말을 참조한다. <strong><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html">https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html</a></strong></li>
</ul>
</li>
<li><code>print_starting &gt;&gt; csvJson</code> 에서 <code>&gt;&gt;</code> 는 하류 설정 연산자라고 부른다. (동의어 비트 자리이동 연산자)</li>
</ul>
<p>→<code>cd ..</code></p>
<p>→<code>cd dags</code></p>
<p>→<code>vi csv2json.py</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import datetime as dt</span><br><span class="line">from datetime import timedelta</span><br><span class="line"></span><br><span class="line">from airflow import DAG</span><br><span class="line">from airflow.operators.bash import BashOperator</span><br><span class="line">from airflow.operators.python import PythonOperator</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def csvToJson():</span><br><span class="line">    df=pd.read_csv(&#x27;data/data.csv&#x27;)</span><br><span class="line">    for i,r in df.iterrows():</span><br><span class="line">        print(r[&#x27;name&#x27;])</span><br><span class="line">    df.to_json(&#x27;fromAirflow.json&#x27;,orient=&#x27;records&#x27;)</span><br><span class="line"></span><br><span class="line">default_args = &#123;</span><br><span class="line">    &#x27;owner&#x27;: &#x27;human&#x27;,</span><br><span class="line">    &#x27;start_date&#x27;: dt.datetime(2020, 3, 18),</span><br><span class="line">    &#x27;retries&#x27;: 1,</span><br><span class="line">    &#x27;retry_delay&#x27;: dt.timedelta(minutes=5),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">with DAG(&#x27;MyCSVDAG&#x27;,</span><br><span class="line">         default_args=default_args,</span><br><span class="line">         schedule_interval=timedelta(minutes=5),      # &#x27;0 * * * *&#x27;,</span><br><span class="line">         ) as dag:</span><br><span class="line"></span><br><span class="line">    print_starting = BashOperator(task_id=&#x27;starting&#x27;,</span><br><span class="line">                               bash_command=&#x27;echo &quot;I am reading the CSV now.....&quot;&#x27;)</span><br><span class="line"></span><br><span class="line">    csvJson = PythonOperator(task_id=&#x27;convertCSVtoJson&#x27;,</span><br><span class="line">                                 python_callable=csvToJson)</span><br><span class="line"></span><br><span class="line">print_starting &gt;&gt; csvJson</span><br></pre></td></tr></table></figure>

<ul>
<li>코드를 실행한다.</li>
<li>VSCord에서 json 파일이 생성되어야 한다.</li>
</ul>
<p>→<code>python3 csv2json.py</code></p>
<h2 id="Step-04-Airflow-Webserver-및-Scheduler-동시-실행"><a href="#Step-04-Airflow-Webserver-및-Scheduler-동시-실행" class="headerlink" title="Step 04. Airflow Webserver 및 Scheduler 동시 실행"></a><strong>Step 04. Airflow Webserver 및 Scheduler 동시 실행</strong></h2><ul>
<li>이제 웹서버와 스케쥴러를 동시에 실행한다. (터미널을 2개 열어야 함에 주의한다.)</li>
</ul>
<p>VSCord 에서 WSL 터미널을 2개 띄운다.</p>
<p>→ <code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code> </p>
<p><img src="/images/Airflow_pipeline0/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>error 발생할 경우 대처</li>
</ul>
<p>airflow.cfg의 endproint_url &#x3D; 8080 체크</p>
<p>→<code>airflow db reset</code></p>
<p>→<code>airflow webserver -p 8080</code></p>
<p>→<code>airflow scheduler</code></p>
<p>→ 이 과정을 반복</p>
<p>→ 그래도 안 되면 airflow 지우고 다시 시작</p>
<p>이제 WebUI를 확인하면 정상적으로 작동하는 것을 확인할 수 있다</p>
<h2 id="Step-05-작업-결과물-확인"><a href="#Step-05-작업-결과물-확인" class="headerlink" title="Step 05. 작업 결과물 확인"></a><strong>Step 05. 작업 결과물 확인</strong></h2><ul>
<li><p>최초 목적인 <code>fromAirflow.json</code> 로 정상적으로 변환되었는지 확인하도록 한다.</p>
<ul>
<li><code>fromAirflow.json</code> 파일이 확인된다면, 정상적으로 작업이 끝난 것이다.</li>
</ul>
<p>  → <code>ls</code></p>
<p>  → 다음 내용이 출력되면 성공</p>
<p>  → <code>airflow-webserver.pid  airflow.cfg  airflow.db  dags  data  fromAirflow.json  logs  venv  webserver_config.py</code></p>
<ul>
<li>팁</li>
</ul>
<p>  human@DESKTOP-V24TVMS:&#x2F;mnt&#x2F;c&#x2F;airflow$ <code>export AIRFLOW_HOME=&quot;$(pwd)&quot;</code></p>
<p>  human@DESKTOP-V24TVMS:&#x2F;mnt&#x2F;c&#x2F;airflow$ <code>echo $AIRFLOW_HOME</code>
  </p>
</li>
<li><p>Reference : 실무 예제로 배우는 데이터 공학</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-19T00:00:00.000Z" title="2022. 4. 19. 오전 9:00:00">2022-04-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-21T08:34:18.341Z" title="2022. 4. 21. 오후 5:34:18">2022-04-21</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/VScode/">VScode</a></span><span class="level-item">8 minutes read (About 1258 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/19/VSCode_install/">VSCord Install</a></h1><div class="content"><h1 id="VSCode-Remote-WSL"><a href="#VSCode-Remote-WSL" class="headerlink" title="VSCode Remote WSL"></a>VSCode Remote WSL</h1><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/vscode_wsl2/">VSCode Remote WLS 연동 - Data Science | DSChloe</a></p>
<ul>
<li>eclipse 보다 가볍다</li>
</ul>
<h2 id="VSCode-설치"><a href="#VSCode-설치" class="headerlink" title="VSCode 설치"></a><strong>VSCode 설치</strong></h2><ul>
<li>우선 VSCode를 설치한다.<ul>
<li>URL : <strong><a target="_blank" rel="noopener" href="https://code.visualstudio.com/download">https://code.visualstudio.com/download</a></strong></li>
</ul>
</li>
<li>이 때, 관리자로 실행할 것이기 때문에 System Installer를 다운로드 받는다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled.png" alt="Untitled"></p>
<ul>
<li>설치 시, 환경 변수 체크란 잘 확인한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>설치가 다 끝난 후에는 재부팅을 실시한다.</li>
<li>관리자 권한으로 실행 : visual studio</li>
</ul>
<h2 id="Remote-WSL-연동"><a href="#Remote-WSL-연동" class="headerlink" title="Remote WSL 연동"></a><strong>Remote WSL 연동</strong></h2><ul>
<li>좌측 탭에서 Extension 버튼을 클릭한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>검색 창에서 Remote WSL을 검색 후, 설치를 진행한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%203.png" alt="Untitled"></p>
<ul>
<li>모두 클릭 후, Mark Done을 선택한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>Open Folder를 클릭한다.</li>
</ul>
<p><img src="/images/VSCode_install/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>WSL에서 설치했던 airflow-test 폴더를 선택한다.</li>
</ul>
<p>file → Open Folder → c 드라이브 → airflow_test 열기</p>
<p><img src="/images/VSCode_install/Untitled%206.png" alt="Untitled"></p>
<ul>
<li>메뉴 바에 Terminal 선택 후, 화면 하단에서 WSL이 있는지 확인한다.</li>
<li>Terminal 열어서 Ubuntu 실행한다.</li>
</ul>
<p>Terminal </p>
<p>→ new terminal </p>
<p>→ 우측의 + 버튼으로 Ubuntu(WSL) 열기</p>
<p><img src="/images/VSCode_install/Untitled%207.png" alt="Untitled"></p>
<h3 id="사용법"><a href="#사용법" class="headerlink" title="사용법"></a>사용법</h3><ul>
<li>해당 메뉴를 클릭하면 아래와 같이 터미널이 변경된 것을 확인할 수 있다.</li>
<li>이번엔 서버를 가동해본다.</li>
</ul>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ <code>airflow webserver -p 8081</code></p>
<ul>
<li>사용해본다.</li>
</ul>
<p>→ <code>which python3</code></p>
<h3 id="라이브러리-설치"><a href="#라이브러리-설치" class="headerlink" title="라이브러리 설치"></a>라이브러리 설치</h3><ul>
<li>앞으로 ubuntu를 키지 않고 VScode에서 사용한다.</li>
<li>라이브러리를 설치한다.</li>
</ul>
<p>→<code>pip3 install faker</code></p>
<p>→<code>pip3 install pandas</code></p>
<h3 id="실습"><a href="#실습" class="headerlink" title="실습"></a>실습</h3><ul>
<li>파이썬 사용</li>
</ul>
<p>폴더 생성 : 폴더 그림+ 버튼</p>
<p>→ chapter03 폴더 생성</p>
<p>→ 파일 생성 : 파일 그림+ 버튼</p>
<p>→ <a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 파일 생성</p>
<p>→ 내용 작성 : print(”Hello World!”)</p>
<p>→ save ( ctrl + s)</p>
<p><img src="/images/VSCode_install/Untitled%208.png" alt="Untitled"></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 를 실행한다.</li>
</ul>
<p>wsl Terminal 에서 다음 내용 작성</p>
<p>→ <code>cd chapter 03/</code></p>
<p>→ <code>python3 hello.py</code></p>
<p>→ <a target="_blank" rel="noopener" href="http://hello.py/">hello.py</a> 실행되면 성공</p>
<p><img src="/images/VSCode_install/Untitled%209.png" alt="Untitled"></p>
<ul>
<li>가상파일 만들기</li>
</ul>
<p>파일 생성 : step01_writecsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 44p </p>
<p><code>from faker import Faker import csv output=open(&#39;data.csv&#39;,&#39;w&#39;) fake=Faker() header=[&#39;name&#39;,&#39;age&#39;,&#39;street&#39;,&#39;city&#39;,&#39;state&#39;,&#39;zip&#39;,&#39;lng&#39;,&#39;lat&#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.writerow([[fake.name](http://fake.name/)(),fake.random_int(min=18, max=80, step=1), fake.street_address(), fake.city(),fake.state(),fake.zipcode(),fake.longitude(),fake.latitude()]) output.close()</code></p>
<p>→ 저장 후 실행 : <code>python3 step1_writecsv.py</code></p>
<p>→ data.csv 파일이 생성된다.</p>
<p>파일 생성 : step02_readcsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 44 ~ 45p </p>
<p><code>import csv</code></p>
<p><code>with open(&#39;data.csv&#39;) as f:</code></p>
<p><code>myreader = csv.DictReader(f)</code></p>
<p><code>headers = next(myreader)</code></p>
<p><code>for row in myreader:</code></p>
<p><code>print(row[&#39;name&#39;])</code></p>
<p>→ 저장 후 실행 : <code>python3 step2_readcsv.py</code></p>
<p>→ 여러 사람의 이름이 출력되면 성공</p>
<p>파일 생성 : step03_pandas.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 p </p>
<p><code>import pandas as pd</code></p>
<p><code>df = pd.read_csv(&#39;data.csv&#39;)</code></p>
<p><code>df.head(10)</code></p>
<p><code>df.to_csv(&#39;fromdf.csv&#39;, index=False)</code></p>
<p>→ 저장 후 실행</p>
<p>→ data.csv 파일 내용과 동일한 fromdf.csv 파일이 생성된다.</p>
<p>파일 생성 : step04_writejson.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 48p </p>
<p><code>from faker import Faker</code></p>
<p><code>import json</code></p>
<p><code>output = open(&#39;data.json&#39;, &#39;w&#39;)</code></p>
<p><code>fake = Faker()</code></p>
<p><code>alldata = &#123;&#125;</code></p>
<p><code>alldata[&#39;records&#39;] = []</code></p>
<p><code>for x in range(1000):</code></p>
<p><code>data = &#123;</code></p>
<p><code>&quot;name&quot;   : fake.name(),</code></p>
<p><code>&quot;age&quot;    : fake.random_int(min=18, max=80, step=1),</code></p>
<p><code>&quot;street&quot; : fake.street_address(),</code></p>
<p><code>&quot;city&quot;   : fake.city(),</code></p>
<p><code>&quot;state&quot;  : fake.state(),</code></p>
<p><code>&quot;zip&quot;    : fake.zipcode(),</code></p>
<p><code>&quot;lng&quot;    : float(fake.longitude()),</code></p>
<p><code>&quot;lat&quot;    : float(fake.latitude())&#125;</code></p>
<p><code>alldata[&#39;records&#39;].append(data)</code></p>
<p><code>json.dump(alldata, output)</code></p>
<p>→ 저장 후 실행</p>
<p>→ data.json 이 생성된다.</p>
<h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><p>파일 생성 : step05_readjson.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 49p </p>
<p><code>import json</code></p>
<p><code>with open(&#39;data.json&#39;, &#39;r&#39;) as f:</code></p>
<p><code>data = json.load(f)</code></p>
<p><code>print(&quot;Data Type is &quot;, type(data))</code></p>
<p><code>print(data[&#39;records&#39;][0][&#39;name&#39;])</code></p>
<p>→ 저장 후 실행</p>
<p>→ 사람 이름이 출력된다.</p>
<p>파일 생성 : step06_pandas.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 49p </p>
<p><code>import pandas.io.json as pd_JSON</code></p>
<p><code>import pandas as pd</code></p>
<p><code>f = open(&#39;data.json&#39;, &#39;r&#39;)</code></p>
<p><code>data = pd_JSON.loads(f.read())</code></p>
<p><code>df = pd.json_normalize(data, record_path=&#39;records&#39;)</code></p>
<p><code>print(df.head(2))</code></p>
<p><code>print(df.head(2).to_json())</code></p>
<p><code>print(df.head(2).to_json(orient=&#39;records&#39;))</code></p>
<p>→ 저장 후 실행</p>
<p>→이름, 거리, 도시 등이 출력된다.</p>
<h3 id="전처리-순서"><a href="#전처리-순서" class="headerlink" title="전처리 순서"></a>전처리 순서</h3><p>CSV —&gt; 데이터 프레임 변환 —&gt; 오라클 or PostgreSQL</p>
<h3 id="비정형-데이터"><a href="#비정형-데이터" class="headerlink" title="비정형 데이터"></a>비정형 데이터</h3><p>-이미지 &#x2F; 텍스트</p>
<p>JSON —&gt; Pandas 데이터 프레임 변환 —&gt; 전처리 </p>
<p>—&gt; JSON(NoSQL) —&gt; ElasticSearch —&gt; 시각화(Kibana)</p>
<p>파일 생성 : step07_airflowcsv.py</p>
<p>→ 코드 작성 : 실무 예제로 배우는 데이터 공학 51 ~ 54 p </p>
<p>→ 저장 후 실행</p>
<p>톱니바퀴 모양의 ‘airflow’를 연다</p>
<p>→ 다음 그림과 같이 경로가 잡혀있다.</p>
<p><img src="/images/VSCode_install/Untitled%2010.png" alt="Untitled"></p>
<h3 id="이-부분은-일단-넘어간다"><a href="#이-부분은-일단-넘어간다" class="headerlink" title="이 부분은 일단 넘어간다."></a>이 부분은 일단 넘어간다.</h3><p>폴더 생성 : airflowcsv.py</p>
<p>→ 파일 복사 붙여넣기 : data.csv </p>
<ul>
<li>Apache-Airflow 세팅 참고하여 진행</li>
</ul>
<p>-<a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/apache_airflow_using_wsl2/">Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe</a></p>
<p>→<code>airflow dbinit</code></p>
<p>→<code>airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com</code></p>
<p>→<code>airflow webserver -p 8081</code></p>
<p>→<code>source venv/bin/acivate</code></p>
<p>→<code>airflow scheduler</code></p>
<p>로그인</p>
<p>아이디 :airflow</p>
<p>비번 : </p>
<p><code>cd dags</code></p>
<p><code>airflow dbinit</code></p>
<p><code>aiflow us,,,,</code></p>
<p><code>airflow webserber -p 8081</code></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-18T00:00:00.000Z" title="2022. 4. 18. 오전 9:00:00">2022-04-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-20T08:48:56.143Z" title="2022. 4. 20. 오후 5:48:56">2022-04-20</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/postgreSQL/">postgreSQL</a></span><span class="level-item">9 minutes read (About 1313 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/18/PSQL_install/">PSQL Install</a></h1><div class="content"><h2 id="PostgreSQL-Installation-on-WSL2-and-Windows"><a href="#PostgreSQL-Installation-on-WSL2-and-Windows" class="headerlink" title="PostgreSQL Installation on WSL2 and Windows"></a><strong><strong>PostgreSQL Installation on WSL2 and Windows</strong></strong></h2><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/sql/postgreslq_wsl2/">PostgreSQL Installation on WSL2 and Windows - Data Science | DSChloe</a></p>
<p>(password : 2016*****)</p>
<p>( 서버 password : postgres )</p>
<h3 id="개요"><a href="#개요" class="headerlink" title="개요"></a><strong>개요</strong></h3><ul>
<li>WSL2에서 PostgreSQL을 설치한다.</li>
<li>pgAdmin은 Windows에 설치한다.</li>
</ul>
<h3 id="터미널-업그레이드"><a href="#터미널-업그레이드" class="headerlink" title="터미널 업그레이드"></a><strong>터미널 업그레이드</strong></h3><ul>
<li>먼저 WSL 터미널을 열고, Ubuntu 패키지를 모두 업데이트 및 업그레이드를 한다.</li>
</ul>
<p>Windows Terminal → wsl bash </p>
<p>또는</p>
<p>Ubuntu → ..cd → ..cd</p>
<p>→<code>sudo apt update</code></p>
<p>→<code>sudo apt-get upgrade</code></p>
<h3 id="PostgreSQL-Installation-in-WSL2"><a href="#PostgreSQL-Installation-in-WSL2" class="headerlink" title="PostgreSQL Installation in WSL2"></a><strong>PostgreSQL Installation in WSL2</strong></h3><ul>
<li>이번에는 WSL2에서 PostgreSQL을 설치한다. 설치가 종료되면, 반드시 버전을 확인한다.</li>
</ul>
<p>→<code>sudo apt install postgresql postgresql-contrib</code></p>
<p>→<code>psql --version</code></p>
<ul>
<li>설치 이후에는 Database를 접근 가능하도록 활성화해야 한다.<ul>
<li>포트가 활성화 되어 있지 않다면 아래와 같은 메시지가 나타날 것이다.</li>
</ul>
</li>
</ul>
<p>→<code>sudo service postgresql status</code></p>
<ul>
<li>이번에는 활성화를 해보도록 한다. 온라인이라는 메시지가 나타난다면 활성화가 되었다는 것을 의미한다.</li>
</ul>
<p>→<code>sudo service postgresql start</code></p>
<p>→<code>sudo service postgresql status</code></p>
<p>이번에는 활성화된 데이터베이스를 종료시킨다</p>
<p>→<code>sudo service postgresql stop</code></p>
<p>→<code>sudo service postgresql status</code></p>
<h3 id="사용자-계정-Password-설정"><a href="#사용자-계정-Password-설정" class="headerlink" title="사용자 계정 Password 설정"></a><strong>사용자 계정 Password 설정</strong></h3><ul>
<li>기본적으로 admin 사용자로 등록이 되어 있다. 보통 DB 초기 세팅 시에는 패스워드를 입력받아야 한다. ( password : 2016*****  )</li>
</ul>
<p>→<code>sudo passwd postgres</code></p>
<p>• 여기까지 했다면, WSL2에서 추가로 설정할 것은 더 없다.</p>
<h3 id="pgAdmin-Installation-on-Windows"><a href="#pgAdmin-Installation-on-Windows" class="headerlink" title="pgAdmin Installation on Windows"></a><strong>pgAdmin Installation on Windows</strong></h3><ul>
<li>이번에는 pgAdmin을 설치한다. (최신버전 설치, pgAdmin 4 v6.8)웹사이트 : <strong><a target="_blank" rel="noopener" href="https://www.pgadmin.org/download/pgadmin-4-windows/">https://www.pgadmin.org/download/pgadmin-4-windows/</a></strong></li>
<li>설치 할 때는 관리자로 실행하며, 아래 그림과 나타난다면, install for all users를 선택한다.</li>
</ul>
<p><img src="/images/PSQL_install/Untitled.png" alt="Untitled"></p>
<ul>
<li>설치가 완료된 뒤에는 pgAdmin 이 검색되는지를 확인한다.</li>
<li>WSL2 에서 PostgreSQL 서비스를 활성화 해야 한다.</li>
<li>처음 실행 시 나타나는 화면에 나오는 Password 설정</li>
<li>WSL2에서 설정한 Password를 입력한다. (password : 2016*****)<ul>
<li>이번에는 서버를 설정하도록 한다  ( 서버 password : postgres )</li>
</ul>
</li>
</ul>
<p><img src="/images/PSQL_install/Untitled%201.png" alt="Untitled"></p>
<p>server 우 클릭</p>
<p>→ register → server</p>
<p>→ 내용 작성</p>
<p>→ General Tab 의 Name에 입력 : test</p>
<p><img src="/images/PSQL_install/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>connection tab 에서 작성</li>
</ul>
<p>→ host 에 입력 : 127.0.0.1 </p>
<p>→ Password는 WSL2에서 입력했던 Password를 입력한다.</p>
<ul>
<li>만약에 아래와 같이 Password 에러가 나면 계정 Password를 변경 또는 재 지정해야 한다.<ul>
<li>참고자료 : <strong><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/12720967/how-to-change-postgresql-user-password/12721095#12721095">https://stackoverflow.com/questions/12720967/how-to-change-postgresql-user-password/12721095#12721095</a></strong></li>
</ul>
</li>
</ul>
<p><img src="/images/PSQL_install/Untitled%203.png" alt="Untitled"></p>
<p>서비스를 활성화한다.</p>
<p><code>sudo service postgresql start</code></p>
<p>다음과 같이 Password를 설정하도록 한다</p>
<p><code>sudo -u postgres psql -c &quot;ALTER USER postgres PASSWORD &#39;&lt;new-password&gt;&#39;;&quot;</code></p>
<p><code>sudo -u postgres psql -c &quot;ALTER USER postgres PASSWORD &#39;postgres&#39;;&quot;</code></p>
<ul>
<li>위 설정이 끝난 후, 재 접속하면 정상적으로 접근이 되는 것을 확인할 수 있다.</li>
<li>비밀번호가 <code>postgres</code> 로 변경되었다.</li>
</ul>
<h3 id="DB-생성-및-확인"><a href="#DB-생성-및-확인" class="headerlink" title="DB 생성 및 확인"></a><strong>DB 생성 및 확인</strong></h3><ul>
<li>test 서버에 접속을 했다면, 이제 DB생성을 해본 후, pgAdmin과 WSL2에서 각각 확인을 한다.</li>
<li>먼저, Database에서 마우스 우클릭 후, 아래와 같이 순차적으로 클릭한다.</li>
</ul>
<p>Databases 우클릭</p>
<p>→ create → database..</p>
<p>→ 새로운 데이터베이스명은 dataengineering으로 명명한다.</p>
<p><img src="/images/PSQL_install/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>이번에는 아래 그림과 같이 dataengineering 데이터베이스의 노드 중 shemas를 확장하고 다시 public을 확장한다.</li>
</ul>
<p><img src="/images/PSQL_install/Untitled%205.png" alt="Untitled"></p>
<p>dataengineering </p>
<p>→ shemas</p>
<p>→ public</p>
<p>→ tables 우클릭</p>
<p>→ Create → Table</p>
<p>→ General 탭 Name 입력 :  users</p>
<p>→ Column 탭에서는 아래와 같이 테이블 열을 추가한다</p>
<p>→ 우측의 + 버튼을 이용한다.</p>
<p><img src="/images/PSQL_install/Untitled%206.png" alt="Untitled"></p>
<p>wsl2 가상환경 : postgresql 서버 &amp; DB</p>
<p>윈도우 : GUI - pgAdmin</p>
<ul>
<li><p>이번에는 psql에 접속 후 dataengineering DB와 생성된 테이블을 조회하는 쿼리를 실행한다.</p>
<ul>
<li>dataengineering 테이블이 조회되는지 확인한다.</li>
</ul>
<p>  <img src="/images/PSQL_install/Untitled%207.png" alt="Untitled"></p>
<p>  → <code>sudo -u postgres psql</code>  (psql 접속 명령)</p>
<p>  → postgres&#x3D;#  형태의 프롬프트가 출력된다.</p>
<p>  → 그림 맨 밑줄처럼  <code>\l</code> 을 입력하고 enter</p>
<p>  → dataengineering 이 출력되면 성공</p>
</li>
</ul>
<p>이번에는 생성된 dataengineering DB에 연결 후, 테이블을 조회한다</p>
<p>→ <code>sudo -u postgres psql</code>  ( psql에 접속)</p>
<p>→ postgres&#x3D;#  형태의 프롬프트가 출력된다.</p>
<p>→ <code>\c dataengineering</code> </p>
<p>→ (dataengineering DB에 연결되어</p>
<pre><code>dataengineering=# 형태로 바뀐다. )
</code></pre>
<p>→  <code>\dt</code></p>
<p>→ users 테이블이 출력 되면 성공</p>
<p>→ <code>\q</code> 하여 빠져나온다.</p>
<p>→ <code>sudo service postgresql stop</code> 하여 DB 종료</p>
<p>→ 반드시 종료하자</p>
<h3 id="Refefence"><a href="#Refefence" class="headerlink" title="Refefence"></a>Refefence</h3><ul>
<li><a target="_blank" rel="noopener" href="https://dschloe.github.io/sql/postgreslq_wsl2/">PostgreSQL Installation on WSL2 and Windows - Data Science | DSChloe</a></li>
<li><strong>Set up PostgreSQL on WSL2 and Access with pgAdmin on Windows,</strong> <strong><a target="_blank" rel="noopener" href="https://chloesun.medium.com/set-up-postgresql-on-wsl2-and-connect-to-postgresql-with-pgadmin-on-windows-ca7f0b7f38ab">https://chloesun.medium.com/set-up-postgresql-on-wsl2-and-connect-to-postgresql-with-pgadmin-on-windows-ca7f0b7f38ab</a></strong></li>
<li><strong>PostgreSQL Show Tables,</strong> <strong><a target="_blank" rel="noopener" href="https://www.postgresqltutorial.com/postgresql-administration/postgresql-show-tables/">https://www.postgresqltutorial.com/postgresql-administration/postgresql-show-tables/</a></strong></li>
<li>실무 예제로 배우는 데이터 공학</li>
</ul>
<p>SQLAlchemy : 반드시 사용하자.</p>
<p>나중에라도 파이썬에 연결하여 사용한다.</p>
<p><a target="_blank" rel="noopener" href="https://www.sqlalchemy.org/">https://www.sqlalchemy.org/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/postgreSQL-2a8e7bf9156b4514b28aafbd93421a79">postgreSQL 실습</a></p>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/postgreSQL-_2-e4bd3b39f87c457889449caee9f7bc2d">postgreSQL 실습_2</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-17T00:00:00.000Z" title="2022. 4. 17. 오전 9:00:00">2022-04-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-19T11:36:56.441Z" title="2022. 4. 19. 오후 8:36:56">2022-04-19</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/elasticsearch/">elasticsearch</a></span><span class="level-item">5 minutes read (About 682 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/17/Elastic_Search_install/">Elasticsearch Install</a></h1><div class="content"><h2 id="ElasticSearch-amp-Kibana-설치-in-WSL2"><a href="#ElasticSearch-amp-Kibana-설치-in-WSL2" class="headerlink" title="ElasticSearch &amp; Kibana 설치 in WSL2"></a><strong><strong>ElasticSearch &amp; Kibana 설치 in WSL2</strong></strong></h2><p><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/elasticsearch_kibana_wsl2/">ElasticSearch &amp; Kibana 설치 in WSL2 - Data Science | DSChloe</a></p>
<p><strong><strong>Step 1. 사전 필수 패키지 설치</strong></strong></p>
<p>0.우선 시스템 패키지를 업데이트 하고, HTTPS와 관련된 패키지를 설치한다.</p>
<p>Windows Terminal → wsl bash </p>
<p>또는</p>
<p>Ubuntu → ..cd → ..cd</p>
<p>→<code>sudo apt-get update &amp;&amp; sudo apt-get upgrade</code></p>
<p>→ <code>sudo apt update</code></p>
<p>→ <code>sudo apt install apt-transport-https</code></p>
<ol>
<li>자바를 설치한다.</li>
</ol>
<ul>
<li>이미 설치가 되어 있다면 버전만 확인한다.</li>
</ul>
<p>→ <code>sudo apt install openjdk-11-jdk</code></p>
<p>→ <code>java -version</code></p>
<ol start="2">
<li>자바 환경 변수를 설정하기 위해 아래와 같이 에디터를 입력한다.</li>
</ol>
<p>→ <code>sudo vi /etc/environment</code></p>
<p>→ (그리고 다음내용을 추가한다.)</p>
<p>→ 인서트 모드에서 <code>JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot;</code></p>
<p>→ esc → :wq 하여 저장하고 나간다.</p>
<p>• 환경변수를 업데이트 한다.</p>
<p>• 그리고 실제 경로가 나오는지 확인한다.</p>
<p>→ <code>source /etc/environment</code></p>
<p>→ <code>echo $JAVA_HOME</code></p>
<p>→ &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64 가 출력되면 성공.</p>
<p><strong><strong>Step 2. ElasticSearch 설치</strong></strong></p>
<p>• GPG Keys를 확인하여 설치를 진행한다.</p>
<p>→ <code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -</code></p>
<p>• 라이브러리를 아래와 같이 추가한다.</p>
<p>→ <code>sudo sh -c &#39;echo &quot;deb https://artifacts.elastic.co/packages/7.x/apt stable main&quot; &gt; /etc/apt/sources.list.d/elastic-7.x.list&#39;</code></p>
<p>• 이제 elasticsearch를 설치한다.</p>
<p>→ <code>sudo apt-get update</code></p>
<p>→ <code>sudo apt-get install elasticsearch</code></p>
<p><strong><strong>Step 3. Elasticsearch 서비스 시작</strong></strong></p>
<p>• 이번에는 elasticsearch 서비스를 시작한다.</p>
<p>→<code>sudo systemctl start elasticsearch</code></p>
<p>에러 발생 :</p>
<p>System has not been booted with systemd as init system (PID 1). Can’t operate.<br>Failed to connect to bus: Host is down</p>
<p>에러 해결 : </p>
<p> <a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1379425/system-has-not-been-booted-with-systemd-as-init-system-pid-1-cant-operate">boot - 시스템이 init system(PID 1)으로 systemd로 부팅되지 않았습니다. 작동 할 수 없음 - 우분투에게 물어보십시오. (askubuntu.com)</a></p>
<p>→ <code>sudo -b unshare --pid --fork --mount-proc /lib/systemd/systemd --system-unit=basic.target</code></p>
<p>→ <code>sudo -E nsenter --all -t $(pgrep -xo systemd) runuser -P -l $USER -c &quot;exec $SHELL&quot;</code></p>
<p>• 서비스가 가능하도록 한다.</p>
<p>• 그리고 서비스를 시작한다.</p>
<p>→ <code>sudo systemctl enable elasticsearch</code></p>
<p>→ <code>sudo systemctl start elasticsearch</code></p>
<p>• 실제 서비스가 작동하는지 확인한다.</p>
<p>→ <code>curl -X GET &quot;localhost:9200/&quot;</code></p>
<p>→ 주소창에 입력 : localhost:9200&#x2F;</p>
<p>→ windows Terminal과 같은 내용이 출력되면 성공</p>
<p><strong><strong>Step 4. Kibana 설치 및 서비스 시작</strong></strong></p>
<p>• 우선 kibana를 설치한다.</p>
<p>• 그리고 서비스를 활성화한다.</p>
<p>→ <code>sudo apt-get install kibana</code></p>
<p>→ <code>sudo systemctl enable kibana</code></p>
<p>• 서비스를 시작하고, 확인해본다</p>
<p>→ <code>sudo systemctl start kibana</code></p>
<p>→ <code>sudo systemctl status kibana</code></p>
<p><strong><strong>Step 5. Kibana WebUI 확인</strong></strong></p>
<p>• <strong><a target="_blank" rel="noopener" href="http://localhost:5601/">http://localhost:5601/</a></strong> 에서 확인해본다.</p>
<p>[Reference]</p>
<ul>
<li>Sayan Dey, <strong><strong>How to install &amp; uninstall Elasticsearch on Ubuntu 19.04, 18.04 &amp; 16.04,</strong></strong> <strong><a target="_blank" rel="noopener" href="https://www.how2shout.com/how-to/install-uninstall-elasticsearch-ubuntu-19-04-18-04-16-04.html">https://www.how2shout.com/how-to/install-uninstall-elasticsearch-ubuntu-19-04-18-04-16-04.html</a></strong></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-16T00:00:00.000Z" title="2022. 4. 16. 오전 9:00:00">2022-04-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-18T09:04:25.482Z" title="2022. 4. 18. 오후 6:04:25">2022-04-18</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/setting/">setting</a><span> / </span><a class="link-muted" href="/categories/setting/airflow/">airflow</a></span><span class="level-item">4 minutes read (About 658 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/16/Apache_Airflow_install/">Apache Nifi Install</a></h1><div class="content"><h1 id="Apache-airflow"><a href="#Apache-airflow" class="headerlink" title="Apache airflow"></a>Apache airflow</h1><h2 id="Apache-Airflow-in-windows-설치"><a href="#Apache-Airflow-in-windows-설치" class="headerlink" title="Apache-Airflow in windows 설치"></a>Apache-Airflow in windows 설치</h2><p>• Windows WSL2에서 airflow를 설치한다.</p>
<p><strong><strong>Step 1. Install pip on WSL</strong></strong></p>
<p>• c드라이브에 들어간다.</p>
<p>관리자 권한으로 실행 : Ubuntu</p>
<p>→ <code>cd..</code></p>
<p>→ <code>cd..</code></p>
<p>→<code>cd mnt/c</code></p>
<p>• 폴더를 만든다</p>
<p>→ <code>mkdir airflow-test</code></p>
<p>→ <code>ls</code></p>
<p>→ <code>cd airflow-test/</code></p>
<p>• pip를 설치한다.</p>
<p>→ <code>sudo apt-get update &amp;&amp; sudo apt-get upgrade</code></p>
<p>→ <code>sudo apt install python3-pip</code></p>
<p><strong><strong>Step 2. Install virtualenv package</strong></strong></p>
<p>• virtualenv 라이브러리를 설치한다.</p>
<p>→ <code>sudo pip3 install virtualenv</code></p>
<p><strong><strong>Step 3. Create a virtual environment</strong></strong></p>
<p>• 이제 가상환경을 생성한다.</p>
<p>→ <code>virtualenv venv</code></p>
<p>• 가상환경에 접속을 한다.</p>
<p>→ airflowtest 경로에서 해야 한다.</p>
<p>→ <code>source venv/bin/activate</code></p>
<p>→ 경로 확인 </p>
<p>→ <code>pwd</code></p>
<p>• 이번에는 .bashrc 파일을 수정한다.</p>
<p>• 파일을 열고, 맨 밑줄에 다음과 같은 코드를 추가한다.</p>
<p>→ <code>vi ~/.bashrc</code></p>
<p>→ 내용 추가 : <code>export AIRFLOW_HOME=/mnt/c/airflow-test</code></p>
<p>→ ESC → :wq 하여 저장</p>
<p>• 수정된 코드를 업데이트 하기 위해서는 아래와 같이 반영한다.</p>
<p>→ <code>source ~/.bashrc</code></p>
<p>• 실제로 코드가 반영되었는지 확인하기 위해서는 다음과 같이 확인해본다.</p>
<p>• 다시 가상환경에 접속하고 수행</p>
<p>→<code>source venv/bin/activate</code></p>
<p>→ <code>echo $AIRFLOW_HOME</code></p>
<p>→ &#x2F;mnt&#x2F;c&#x2F;airflow-test 출력되면 성공.</p>
<p><strong><strong>Step 4. Apache Airflow 설치</strong></strong></p>
<p>• PostgreSQL, Slack, Celery 패키지를 동시에 설치하는 코드를 작성한다.</p>
<p>→ <code>sudo apt-get update &amp;&amp; sudo apt-get upgrade</code></p>
<p>→ <code>pip3 install &#39;apache-airflow[postgres, slack, celery]&#39;</code></p>
<p>• airflow 실행을 위해 DB 초기화를 해줘야 한다.</p>
<p>→ <code>airflow db init</code></p>
<p>• 실제로 잘 구현이 되었는지 확인하기 위해 webserver를 실행한다</p>
<p>→ <code>airflow webserver -p 8081</code></p>
<p>→ port 번호 8081을 뜻한다.</p>
<p>• 그리고, 해당 링크 <strong><a target="_blank" rel="noopener" href="http://localhost:8081/login/">http://localhost:8081/login/</a></strong> 에 접속하면 아래와 같은 화면이 나타난다.</p>
<p><img src="/images/Apache_Airflow_install/Untitled.png" alt="Untitled"></p>
<p>• 그런데, 여기에서 문제는 username을 생성하지 않았다. 따라서, username을 추가하도록 한다</p>
<p>→ ctrl + c 로 빠져나온다.</p>
<p>→ <code>airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com</code></p>
<p> • 다시 웹서버 실행</p>
<p>→ <code>airflow webserver -p 8081</code></p>
<p>• 해당 링크 <strong><a target="_blank" rel="noopener" href="http://localhost:8081/login/">http://localhost:8081/login/</a></strong> 에 접속</p>
<p>• 다음 정보로 로그인한다</p>
<p>→ id : airflow</p>
<p>password : airflow</p>
<p>→ 다음 화면이 나오면 성공.</p>
<p><img src="/images/Apache_Airflow_install/Untitled%201.png" alt="Untitled"></p>
<h3 id="설정완료-후에-가상환경-키는-법"><a href="#설정완료-후에-가상환경-키는-법" class="headerlink" title="설정완료 후에 가상환경 키는 법"></a>설정완료 후에 가상환경 키는 법</h3><p>ubuntu </p>
<p>→ cd .. → cd .. → cd mnt&#x2F;c → cd airflow-test </p>
<p>→ <code>source venv/bin/activate</code></p>
<ul>
<li>Reference :<br><a target="_blank" rel="noopener" href="https://dschloe.github.io/settings/apache_airflow_using_wsl2/">Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe</a></li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.notion.so/Airflow-57e8167632db4f09a62f7aa1d64a8d22">Airflow 재설치 및 데이터 파이프라인 구축</a></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/setting/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/setting/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/setting/">1</a></li><li><a class="pagination-link" href="/categories/setting/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">54</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">35</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="level-start"><span class="level-item">생활코딩</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/%EA%B8%B0%EC%B4%88/"><span class="level-start"><span class="level-item">기초</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"><span class="level-start"><span class="level-item">분석 방법</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/SQL/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/git/github-blog/"><span class="level-start"><span class="level-item">github blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/"><span class="level-start"><span class="level-item">library</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/numpy/"><span class="level-start"><span class="level-item">numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pandas/"><span class="level-start"><span class="level-item">pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pyspark/"><span class="level-start"><span class="level-item">pyspark</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/visualization/"><span class="level-start"><span class="level-item">visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/machine-learning/"><span class="level-start"><span class="level-item">machine learning</span></span><span class="level-end"><span class="level-item tag">22</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">데이터 전처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"><span class="level-start"><span class="level-item">비지도학습</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"><span class="level-start"><span class="level-item">알고리즘</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"><span class="level-start"><span class="level-item">인공신경망</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"><span class="level-start"><span class="level-item">자료형, 반복문, 조건문</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"><span class="level-start"><span class="level-item">클래스</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"><span class="level-start"><span class="level-item">함수</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/NiFi/"><span class="level-start"><span class="level-item">NiFi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/airflow/"><span class="level-start"><span class="level-item">airflow</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/anaconda/"><span class="level-start"><span class="level-item">anaconda</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/elasticsearch/"><span class="level-start"><span class="level-item">elasticsearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/wsl2/"><span class="level-start"><span class="level-item">wsl2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-01T00:00:00.000Z">2022-05-01</time></p><p class="title"><a href="/2022/05/01/Spark_ML/">Spark ML</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/library/">library</a> / <a href="/categories/python/library/pyspark/">pyspark</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-30T00:00:00.000Z">2022-04-30</time></p><p class="title"><a href="/2022/04/30/Spark_UI/">Spark UI</a></p><p class="categories"><a href="/categories/setting/">setting</a> / <a href="/categories/setting/spark/">spark</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-29T00:00:00.000Z">2022-04-29</time></p><p class="title"><a href="/2022/04/29/Spark_on_linux/">Spark on Linux</a></p><p class="categories"><a href="/categories/setting/">setting</a> / <a href="/categories/setting/spark/">spark</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-28T00:00:00.000Z">2022-04-28</time></p><p class="title"><a href="/2022/04/28/pyspark_practice03/">pyspark 실습03</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/library/">library</a> / <a href="/categories/python/library/pyspark/">pyspark</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-27T00:00:00.000Z">2022-04-27</time></p><p class="title"><a href="/2022/04/27/pyspark_practice02/">pyspark 실습02</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/library/">library</a> / <a href="/categories/python/library/pyspark/">pyspark</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NiFi/"><span class="tag">NiFi</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Notion/"><span class="tag">Notion</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R-Markdown/"><span class="tag">R Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VScord/"><span class="tag">VScord</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anaconda/"><span class="tag">anaconda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-blog/"><span class="tag">github blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgreSQL/"><span class="tag">postgreSQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="tag">생활코딩</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>