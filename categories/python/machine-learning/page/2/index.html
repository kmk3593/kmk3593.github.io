<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: machine learning - kmk3593 blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="kmk3593 blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="kmk3593 blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="kmk3593 blog"><meta property="og:url" content="https://kmk3593.github.io/"><meta property="og:site_name" content="kmk3593 blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kmk3593.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kmk3593.github.io"},"headline":"kmk3593 blog","image":["https://kmk3593.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"kmk3593 blog","logo":{"@type":"ImageObject","url":"https://kmk3593.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/python/">python</a></li><li class="is-active"><a href="#" aria-current="page">machine learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-06T00:00:00.000Z" title="2022. 4. 6. 오전 9:00:00">2022-04-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T11:19:17.406Z" title="2022. 4. 9. 오후 8:19:17">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/">비지도학습</a></span><span class="level-item">6 minutes read (About 972 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/06/chapter_6_1/">chapter_6_1</a></h1><div class="content"><h1 id="비지도-학습"><a href="#비지도-학습" class="headerlink" title="비지도 학습"></a>비지도 학습</h1><ul>
<li>vs 지도 학습<ul>
<li>종속 변수가 있다 &#x3D; 타겟이 있다</li>
</ul>
</li>
<li>비지도 학습은 종속변수 및 타겟이 없다.</li>
<li>분류<ul>
<li>다중분류</li>
<li>전제조건 : (다양한 유형) 데이터가 많아야 함</li>
<li>딥러닝과 연관이 됨(자연어 처리, 이미지)</li>
</ul>
</li>
</ul>
<h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><ul>
<li>과일가게 문제 : 많은 과일 사진을 각 과일 별로 분류해야 한다.</li>
<li>다음을 참고하라 : <a target="_blank" rel="noopener" href="http://bit.ly/hg-06-1">http://bit.ly/hg-06-1</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 03:09:03--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 03:09:03--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.121.4
Connecting to github.com (github.com)|140.82.121.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 03:09:03--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.03s   

2022-03-31 03:09:03 (107 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<ul>
<li>numpy 파일을 불러옴</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape) </span><br><span class="line"><span class="built_in">print</span>(fruits.ndim)  <span class="comment"># 차원 수 확인</span></span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
3
</code></pre>
<ul>
<li>첫 번째 차원(300) &#x3D; 샘플의 개수</li>
<li>두 번째 차원(100) &#x3D; 이미지 높이</li>
<li>세 번째 차원(100) &#x3D; 이미지 너비</li>
<li>이미지 크기 100 x 100</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 첫 번째 행에 있는 픽셀 100개에 들어있는 값을 출력</span></span><br><span class="line">fruits[<span class="number">0</span>, <span class="number">0</span>, :]</span><br></pre></td></tr></table></figure>




<pre><code>array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   2,   1,   2,   2,   2,   2,   2,   2,   1,   1,
         1,   1,   1,   1,   1,   1,   2,   3,   2,   1,   2,   1,   1,
         1,   1,   2,   1,   3,   2,   1,   3,   1,   4,   1,   2,   5,
         5,   5,  19, 148, 192, 117,  28,   1,   1,   2,   1,   4,   1,
         1,   3,   1,   1,   1,   1,   1,   2,   2,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1], dtype=uint8)
</code></pre>
<ul>
<li>이미지 시각화<ul>
<li>흑백 사진을 담고 있다.</li>
<li>0~255까지의 정숫값을 가진다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># cmap 은 옵션</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_8_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap=<span class="string">&#x27;gray_r&#x27;</span>)  <span class="comment"># cmap 은 옵션</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 밝은 부분은 0에 가깝다</span></span><br><span class="line"><span class="comment"># 어두운 부분은 255에 가깝다</span></span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_9_0.png" alt="png"></p>
<ul>
<li>여러 이미지 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">axs[<span class="number">0</span>].imshow(fruits[<span class="number">100</span>], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(fruits[<span class="number">200</span>], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_11_0.png" alt="png"></p>
<h3 id="픽셀값-분석"><a href="#픽셀값-분석" class="headerlink" title="픽셀값 분석"></a>픽셀값 분석</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apple = fruits[<span class="number">0</span>:<span class="number">100</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)  <span class="comment"># 두 번째와 세 번째 차원 크기가 100이므로.</span></span><br><span class="line">pineapple = fruits[<span class="number">100</span>:<span class="number">200</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line">banana = fruits[<span class="number">200</span>:<span class="number">300</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(apple.shape)</span><br><span class="line"><span class="built_in">print</span>(pineapple.shape)</span><br><span class="line"><span class="built_in">print</span>(banana.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(100, 10000)
(100, 10000)
(100, 10000)
</code></pre>
<ul>
<li><p>axis &#x3D; 0 vs axis &#x3D; 1 차이 확인 (p.293)</p>
</li>
<li><p>각 이미지에 대한 픽셀 평균값 비교</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis = 1 = 열</span></span><br><span class="line"><span class="built_in">print</span>(apple.mean(axis = <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[ 88.3346  97.9249  87.3709  98.3703  92.8705  82.6439  94.4244  95.5999
  90.681   81.6226  87.0578  95.0745  93.8416  87.017   97.5078  87.2019
  88.9827 100.9158  92.7823 100.9184 104.9854  88.674   99.5643  97.2495
  94.1179  92.1935  95.1671  93.3322 102.8967  94.6695  90.5285  89.0744
  97.7641  97.2938 100.7564  90.5236 100.2542  85.8452  96.4615  97.1492
  90.711  102.3193  87.1629  89.8751  86.7327  86.3991  95.2865  89.1709
  96.8163  91.6604  96.1065  99.6829  94.9718  87.4812  89.2596  89.5268
  93.799   97.3983  87.151   97.825  103.22    94.4239  83.6657  83.5159
 102.8453  87.0379  91.2742 100.4848  93.8388  90.8568  97.4616  97.5022
  82.446   87.1789  96.9206  90.3135  90.565   97.6538  98.0919  93.6252
  87.3867  84.7073  89.1135  86.7646  88.7301  86.643   96.7323  97.2604
  81.9424  87.1687  97.2066  83.4712  95.9781  91.8096  98.4086 100.7823
 101.556  100.7027  91.6098  88.8976]
</code></pre>
<ul>
<li>각 과일에 대한 히스토그램 작성<ul>
<li>히스토그램은 값이 발생하는 빈도를 그래프로 표시한 것.</li>
<li>보통 x축은 값의 구간이고, y축은 발생 빈도이다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(np.mean(apple, axis = <span class="number">1</span>), alpha = <span class="number">0.8</span>)     <span class="comment"># alpha 는 투명도 조절하는 매개변수</span></span><br><span class="line">plt.hist(np.mean(pineapple, axis = <span class="number">1</span>), alpha = <span class="number">0.8</span>)</span><br><span class="line">plt.hist(np.mean(banana, axis = <span class="number">1</span>), alpha = <span class="number">0.8</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;pixel average&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;prequency&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_18_0.png" alt="png"></p>
<ul>
<li><p>위 결과에서 banana는 픽셀 평균값이 다른 두 과일과 확연히 다르다.</p>
<ul>
<li>banana는 픽셀 평균값으로 구분하기 쉽다.</li>
</ul>
</li>
<li><p>이번에는 샘플의 평균값이 아니라 픽셀별 평균값을 비교해 본다.</p>
</li>
<li><p>즉, 전체 샘플에 대해 각 픽셀의 평균을 조사한다.</p>
</li>
<li><p>axis&#x3D;0으로 지정하여 픽셀의 평균을 계산하면 된다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(apple, axis=<span class="number">0</span>))</span><br><span class="line">axs[<span class="number">1</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(pineapple, axis=<span class="number">0</span>))</span><br><span class="line">axs[<span class="number">2</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(banana, axis=<span class="number">0</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_21_0.png" alt="png"></p>
<ul>
<li>대표 이미지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apple_mean = np.mean(apple, axis=<span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">pineapple_mean = np.mean(pineapple, axis=<span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">banana_mean = np.mean(banana, axis=<span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].imshow(apple_mean, cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(pineapple_mean, cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].imshow(banana_mean, cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_23_0.png" alt="png"></p>
<h3 id="평균값과-가까운-사진-고르기"><a href="#평균값과-가까운-사진-고르기" class="headerlink" title="평균값과 가까운 사진 고르기"></a>평균값과 가까운 사진 고르기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">abs_diff = np.<span class="built_in">abs</span>(fruits - apple_mean)</span><br><span class="line">abs_mean = np.mean(abs_diff, axis=(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(abs_mean.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300,)
</code></pre>
<ul>
<li>오차의 값이 가장 작은 순서대로 100개를 골라본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apple_index = np.argsort(abs_mean)[:<span class="number">100</span>]</span><br><span class="line">fig, axs = plt.subplots(<span class="number">10</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_27_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apple_index = np.argsort(abs_mean)[:<span class="number">100</span>]</span><br><span class="line">fig, axs = plt.subplots(<span class="number">10</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):     <span class="comment"># 2중 for문</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        axs[i, j].imshow(fruits[apple_index[i*<span class="number">10</span> + j]], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_1/output_28_0.png" alt="png"></p>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-06T00:00:00.000Z" title="2022. 4. 6. 오전 9:00:00">2022-04-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T11:22:58.975Z" title="2022. 4. 9. 오후 8:22:58">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/">비지도학습</a></span><span class="level-item">11 minutes read (About 1634 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/06/chapter_6_3/">chapter_6_3</a></h1><div class="content"><h1 id="주성분-분석-PCA"><a href="#주성분-분석-PCA" class="headerlink" title="주성분 분석 (PCA)"></a>주성분 분석 (PCA)</h1><h3 id="PCA-주성분-분석"><a href="#PCA-주성분-분석" class="headerlink" title="PCA (주성분 분석)"></a>PCA (주성분 분석)</h3><ul>
<li><p>차원축소의 개념</p>
</li>
<li><p>PCA 개념</p>
</li>
<li><p>과일 사진의 겨우, 10,000개의 픽셀 (높이 x 너비)</p>
</li>
<li><p>10,000개의 특성이 있는 셈(차원)</p>
</li>
<li><p>정형데이터에서도 활용 가능</p>
<ul>
<li>문자열 데이터, 수치형 데이터 (연속형 데이터, 비연속형 데이터)</li>
<li>캐글 대회 : 수치형 컬럼 304개<ul>
<li>연산은 RAM에서 처리</li>
<li>라면을 5개 끓여야 함 &#x2F; 냄비 크기는 3개 용량</li>
</ul>
</li>
</ul>
</li>
<li><p>차원축소 &#x3D; 일부 특성을 선택하여 데이터 크기를 줄임</p>
<ul>
<li>머신러닝 측면 : 과대적합 방지 &amp; 성능 향상</li>
<li>데이터가 너무 많으니까 RAM에 부하가 걸린다. </li>
<li>따라서 데이터를 줄이고 과대적합을 방지하기 위한 것</li>
</ul>
</li>
<li><p>양적 데이터 사이의 분산-공분산 관계를 이용해서 선형결합으로 표시되는 주성분을 찾음</p>
</li>
<li><p>2~3개의 주성분으로 전체 변동을 찾는 것이 PCA</p>
</li>
</ul>
<p>p326</p>
<ul>
<li><p>그래프를 보면, 처음 10개의 주성분이 (10,000개의 픽셀)</p>
</li>
<li><p>굳이 10,000개의 픽셀을 전부 쓸 필요가 없다.</p>
</li>
<li><p>알고리즘 구성할 때, 필요한 데이터 픽셀 수, 300 x 10,000개 픽셀</p>
</li>
<li><p>원래는 300 x 10,000개 픽셀 필요</p>
</li>
<li><p>그런데, 300 x pc 10 주성분으로 줄임</p>
</li>
<li><p>기존 1시간 걸림 &#x2F; 이제 10분 걸림</p>
</li>
<li><p>그럼에도 불구하고, 분류가 더 잘되더라.</p>
</li>
</ul>
<h2 id="PCA-클래스"><a href="#PCA-클래스" class="headerlink" title="PCA 클래스"></a>PCA 클래스</h2><h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 06:16:36--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 06:16:36--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 192.30.255.113
Connecting to github.com (github.com)|192.30.255.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 06:16:36--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.04s   

2022-03-31 06:16:36 (64.8 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<ul>
<li>배열로 업로드</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">fruits = np.load(<span class="string">&quot;fruits_300.npy&quot;</span>)</span><br><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>*<span class="number">100</span>)</span><br><span class="line">fruits_2d.shape</span><br></pre></td></tr></table></figure>




<pre><code>(300, 10000)
</code></pre>
<ul>
<li>sklearn.decomposition 모듈<ul>
<li>사이킷런은 이 모듈 아래 PCA 클래스로 주성분 분석 알고리즘을 제공한다.</li>
<li>k-평균과 마찬가지로 비지도 학습이기 때문에 fit()메서드에 타깃값을 제공하지 않는다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components = <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA 50개 성분으로 300 x 10000 픽셀값을 압축</span></span><br><span class="line">pca.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>PCA(n_components=50)
</code></pre>
<ul>
<li>PCA 클래스가 찾은 주성분은 components_ 속성에 저장되어 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.components_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(50, 10000)
</code></pre>
<ul>
<li>그래프 그리기<ul>
<li>draw_fuits()함수를 사용해서 이 주성분을 그림으로 그려보자.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">draw_fruits(pca.components_.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_3/output_16_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 50)
</code></pre>
<ul>
<li>데이터의 원래 크기 대비해서 1&#x2F;200 줄임</li>
<li>용량이 줄었다는 것과 똑같음</li>
</ul>
<h3 id="원본-데이터-재구성"><a href="#원본-데이터-재구성" class="headerlink" title="원본 데이터 재구성"></a>원본 데이터 재구성</h3><ul>
<li>10,000개의 특성을 50개로 줄임</li>
<li>100% 재구성은 어렵지만, 그래도 쓸만하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_inverse = pca.inverse_transform(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(fruits_inverse.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 10000)
</code></pre>
<ul>
<li>그래프 작성<ul>
<li>10000개의 데이터가 복원되었다.</li>
<li>이 데이터를 100 x 100 크기로 바꾸어 100개씩 나누어 출력한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_reconstruct = fruits_inverse.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits_reconstruct.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 압축을 풀고 사용하는 연쇄적인 과정</span></span><br><span class="line"><span class="keyword">for</span> start <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">100</span>, <span class="number">200</span>]:</span><br><span class="line">  draw_fruits(fruits_reconstruct[start:start + <span class="number">100</span>])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_3/output_23_0.png" alt="png"></p>
<p><img src="/images/chapter_6_3/output_23_2.png" alt="png"></p>
<p><img src="/images/chapter_6_3/output_23_4.png" alt="png"></p>
<h3 id="설명된-분산"><a href="#설명된-분산" class="headerlink" title="설명된 분산"></a>설명된 분산</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(pca.explained_variance_ratio_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_3/output_25_0.png" alt="png"></p>
<ul>
<li>처음 10개의 주성분이 대부분의 분산을 표현한다.</li>
<li>11개 주성분부터 ~50개까지는 잘 설명이 안됨</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_))</span><br></pre></td></tr></table></figure>

<pre><code>0.9215782334086065
</code></pre>
<h3 id="다른-알고리즘과-함께-사용하기"><a href="#다른-알고리즘과-함께-사용하기" class="headerlink" title="다른 알고리즘과 함께 사용하기"></a>다른 알고리즘과 함께 사용하기</h3><ul>
<li>3개의 과일 사진 분류 위해 로지스틱 회귀</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line">target = np.array([<span class="number">0</span>]*<span class="number">100</span> + [<span class="number">1</span>]*<span class="number">100</span> + [<span class="number">2</span>]*<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2]
</code></pre>
<ul>
<li>교차검증 진행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(lr, fruits_2d, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9966666666666667
1.5795912265777587
</code></pre>
<ul>
<li>PCA 수행 후, 학습 시간 비교</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>1.0
0.12322616577148438
</code></pre>
<ul>
<li><p>PCA 수행 후, fit_time이 짧게 단축되었다.</p>
<ul>
<li>1.57 -&gt; 0.12 로 시간이 짧아졌다.</li>
<li>그러니 특성이 너무 많으면 PCA를 사용하자.</li>
</ul>
</li>
<li><p>주 성분의 매개변수 개수 지정, 분산비율 지정</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">0.5</span>)</span><br><span class="line">pca.fit(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(pca.n_components_)</span><br></pre></td></tr></table></figure>

<pre><code>2
</code></pre>
<ul>
<li>주성분을 2개로 압축시킴.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9933333333333334
0.051814031600952146


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
</code></pre>
<ul>
<li>차원 축소된 데이터를 k-평균 알고리즘에 추가한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">km.fit(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(np.unique(km.labels_, return_counts = <span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2], dtype=int32), array([110,  99,  91]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">3</span>):</span><br><span class="line">  draw_fruits(fruits[km.labels_ == label])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_3/output_42_0.png" alt="png"></p>
<p><img src="/images/chapter_6_3/output_42_2.png" alt="png"></p>
<p><img src="/images/chapter_6_3/output_42_4.png" alt="png"></p>
<ul>
<li>시각화로 뿌려주기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">3</span>):</span><br><span class="line">  data = fruits_pca[km.labels_ == label]</span><br><span class="line">  plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>])</span><br><span class="line">plt.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_6_3/output_44_0.png" alt="png"></p>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-05T00:00:00.000Z" title="2022. 4. 5. 오전 9:00:00">2022-04-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.262Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">6 minutes read (About 916 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/05/chapter_5_3/">chapter_5_3</a></h1><div class="content"><h1 id="트리의-앙상블"><a href="#트리의-앙상블" class="headerlink" title="트리의 앙상블"></a>트리의 앙상블</h1><ul>
<li>lightGBM 기억!<ul>
<li>GBM –&gt; XGBoost –&gt; LightGBM</li>
<li>참고 1. 모델개발속도가 빨라졌나?</li>
<li>참고 2. 모델의 성능이 좋아졌나?</li>
</ul>
</li>
<li>TabNet(2019)<ul>
<li>딥러닝 컨셉!</li>
</ul>
</li>
</ul>
<h3 id="랜덤-포레스트-Forest"><a href="#랜덤-포레스트-Forest" class="headerlink" title="랜덤 포레스트(Forest)"></a>랜덤 포레스트(Forest)</h3><ul>
<li><p>결정 트리를 랜덤하게 만들어 결정 트리의 숲을 만든다.</p>
</li>
<li><p>결정 트리 나무를 500개 심기</p>
</li>
<li><p>최종적인 결정은 투표 방식</p>
<ul>
<li>나무-1 : 양성</li>
<li>나무_2 : 음성</li>
<li>나무_3 : 양성<br>..</li>
<li>나무-500 : 양성</li>
</ul>
</li>
<li><p>데이터 불러오기</p>
</li>
<li><p>넘파이 배열로 변환</p>
</li>
<li><p>데이터 세트 나누기</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(data, </span><br><span class="line">                                                                      target, </span><br><span class="line">                                                                      test_size=<span class="number">0.2</span>, </span><br><span class="line">                                                                      random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>267p<ul>
<li>cross_validate()함수 : 교차 검증 수행 </li>
<li>RandomForestClassifier는 기본적으로 100개의 트리를 사용하므로 n_jops&#x3D;-1로 지정하여 모든 CPU 코어를 사용한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">rf = RandomForestClassifier(n_jobs=-<span class="number">1</span>, random_state=<span class="number">42</span>)   <span class="comment"># n_jobs = -1은 pc의 모든 코어를 사용하겠다는 뜻</span></span><br><span class="line">scores = cross_validate(rf, train_input, train_target,</span><br><span class="line">                        return_train_score = <span class="literal">True</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9973541965122431 0.8905151032797809
</code></pre>
<ul>
<li>랜덤 포레스트는 결정 트리의 앙상블이기 때문에 DecisionTreeClassifier가 제공하는 매개변수를 모두 제공한다.</li>
<li>또한 결정 트리의 큰 장점 중 하나인 특성 중요도를 계산한다.</li>
<li>랜덤 포레스트 모델을 훈련 세트에 훈련한 후 특성 중요도를 출력해 본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.23167441 0.50039841 0.26792718]
</code></pre>
<ul>
<li><p>두 번째 특성인 sugar가 가장 중요도가 높다는 것을 알 수 있다.</p>
</li>
<li><p>RandomForestClassifier는 자체적으로 모델을 평가하는 점수를 얻을 수도 있다.</p>
</li>
<li><p>이 점수를 얻으려면 RandomForestClassifier 클래스의 oob_score 매개변수를 True로 지정해야 한다.</p>
</li>
<li><p>oob_score &#x3D; True로 지정하고 모델을 훈련하여 OOB 점수를 출력해보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestClassifier(oob_score = <span class="literal">True</span>, n_jobs=-<span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.oob_score_)</span><br></pre></td></tr></table></figure>

<pre><code>0.8934000384837406
</code></pre>
<ul>
<li>교차 검즈에서 얻은 점수와 매우 비슷한 결과를 얻었다.</li>
</ul>
<h3 id="그래이디언트-부스팅"><a href="#그래이디언트-부스팅" class="headerlink" title="그래이디언트 부스팅"></a>그래이디언트 부스팅</h3><ul>
<li>그 이전 트리의 오차를 보완하는 방식으로 사용</li>
<li>깊이가 얕은 트리를 사용.</li>
<li>학습률 매개변수로 속도를 조절.</li>
<li>단점 : 속도가 느림.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">gb = GradientBoostingClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb, train_input, train_target,</span><br><span class="line">                        return_train_score = <span class="literal">True</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8881086892152563 0.8720430147331015
</code></pre>
<ul>
<li>거의 과대적합이 되지 않았다.</li>
<li>그래디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강하다.</li>
<li>학습률을 증가시키고 트리의 개수를 늘리면 조금 더 성능이 향상될 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gb = GradientBoostingClassifier(n_estimators = <span class="number">500</span>, learning_rate = <span class="number">0.2</span>, random_state = <span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb, train_input, train_target,</span><br><span class="line">                        return_train_score = <span class="literal">True</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9464595437171814 0.8780082549788999
</code></pre>
<ul>
<li>결정 트리 개수를 500개로 늘렸다. 5배로 늘렸지만 과대적합을 잘 억제하고 있다.</li>
<li>학습률 learning_rate의 기본값은 0.1이다.</li>
<li>그레이디언트 부스팅도 특성 중요도를 제공한다.</li>
<li>결과에서 볼 수 있듯이 그레이디언트 부스팅이 랜덤 포레스트보다 일부 특성(당도)에 더 집중한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gb.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(gb.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.15872278 0.68010884 0.16116839]
</code></pre>
<ul>
<li><p>흐름</p>
<ul>
<li><ol start="0">
<li>데이터 전처리 &#x2F; 시각화</li>
</ol>
</li>
<li><ol>
<li>기본 모형으로 전체 흐름을 설계</li>
</ol>
</li>
<li><ol start="2">
<li>여러 모형으로 비교 대조</li>
</ol>
</li>
<li><ol start="3">
<li>교차 검증, 하이퍼 파라미터 성능 비교</li>
</ol>
</li>
<li>…</li>
<li>1등 하는 그날까지</li>
</ul>
</li>
<li><p>Reference : 혼자 공부하는 머신러닝 + 딥러닝</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-04T00:00:00.000Z" title="2022. 4. 4. 오전 9:00:00">2022-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.219Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">15 minutes read (About 2261 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/04/chapter_5_1/">chapter_5_1</a></h1><div class="content"><h1 id="결정-트리"><a href="#결정-트리" class="headerlink" title="결정 트리"></a>결정 트리</h1><ul>
<li>결정 트리로 다음 문제를 해결해 보자<ul>
<li>와인 캔에 인쇄된 알코올 도수, 당도, pH값으로 와인 종류를 구별해야 한다.</li>
</ul>
</li>
</ul>
<h3 id="로지스틱-회귀로-와인-분류하기"><a href="#로지스틱-회귀로-와인-분류하기" class="headerlink" title="로지스틱 회귀로 와인 분류하기"></a>로지스틱 회귀로 와인 분류하기</h3><ul>
<li>우선 로지스틱 회귀로 문제 해결을 시도해본다.</li>
</ul>
<h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><ul>
<li>와인데이터<ul>
<li>alcohol(알고올 도수), sugar(당도), pH(산도)</li>
<li>클래스 0 &#x3D; 레드 와인</li>
<li>클래스 1 &#x3D; 화이트 와인</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line">wine.head(<span class="number">5</span>) <span class="comment"># 데이터 잘 들어왔는지 확인</span></span><br></pre></td></tr></table></figure>





  <div id="df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;/images/chapter_5_1/output_type&#39;] = &#39;display_data&#39;;
      await google.colab./images/chapter_5_1/output.render/images/chapter_5_1/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>info()<ul>
<li>결측치 확인 &#x2F; 변수 타입</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)
memory usage: 203.2 KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wine.describe()</span><br><span class="line"><span class="comment"># 표준화가 안되어 있음을 알 수 있다.</span></span><br></pre></td></tr></table></figure>





  <div id="df-decc42d0-d914-4603-8cd7-d87f4c9e480a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.491801</td>
      <td>5.443235</td>
      <td>3.218501</td>
      <td>0.753886</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.192712</td>
      <td>4.757804</td>
      <td>0.160787</td>
      <td>0.430779</td>
    </tr>
    <tr>
      <th>min</th>
      <td>8.000000</td>
      <td>0.600000</td>
      <td>2.720000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>9.500000</td>
      <td>1.800000</td>
      <td>3.110000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.300000</td>
      <td>3.000000</td>
      <td>3.210000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11.300000</td>
      <td>8.100000</td>
      <td>3.320000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.900000</td>
      <td>65.800000</td>
      <td>4.010000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-decc42d0-d914-4603-8cd7-d87f4c9e480a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-decc42d0-d914-4603-8cd7-d87f4c9e480a button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-decc42d0-d914-4603-8cd7-d87f4c9e480a&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;/images/chapter_5_1/output_type&#39;] = &#39;display_data&#39;;
      await google.colab./images/chapter_5_1/output.render/images/chapter_5_1/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<h3 id="표준화-작업"><a href="#표준화-작업" class="headerlink" title="표준화 작업"></a>표준화 작업</h3><ul>
<li>배열로 바꿔서 진행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()  <span class="comment"># 참고할 데이터</span></span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()                   <span class="comment"># class = 타깃값 = 어떤 와인인지 구분하는 것이 목표 </span></span><br></pre></td></tr></table></figure>

<h3 id="훈련데이터와-테스트데이터로-분리"><a href="#훈련데이터와-테스트데이터로-분리" class="headerlink" title="훈련데이터와 테스트데이터로 분리"></a>훈련데이터와 테스트데이터로 분리</h3><ul>
<li>train_test_split() 함수는 설정값을 지정하지 않으면 25%를 테스트 세트로 지정한다.</li>
<li>이번엔 샘플 개수가 충분히 많으므로 20% 정도만 테스트 세트로 나눈다.</li>
<li>test &#x3D; 0.2 에는 이러한 의도가 담겨 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>    <span class="comment"># test_size=0.2 는 20%를 테스트 세트로 한다는 뜻.</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<ul>
<li>이제 표준화 진행하자</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h3 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h3><h3 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h3><ul>
<li>표준변환된 train_scaled와 test_scaled를 사용해 로지스틱 회귀 모델을 훈련한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
[[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
</code></pre>
<ul>
<li>점수가 높게 나오지 않았다.</li>
<li>결정 트리를 이용하여 좀 더 쉽게 문제를 해결해보자</li>
</ul>
<p>로지스틱 회귀</p>
<ul>
<li>수식</li>
</ul>
<p>의사결정트리의 기본 알고리즘을 활용해서, MS, 구글 등 이런 회사들이 신규 알고리즘을 만듬</p>
<ul>
<li>XGBoost, lightGBM, CatBoost</li>
<li>캐글 정형데이터</li>
<li>lightGBM (지금 현재 실무에서 많이 쓰임)<ul>
<li>4월 말까지는 코드에 집중. 대회 나감</li>
<li>PPT (알고리즘 소개)</li>
</ul>
</li>
</ul>
<h3 id="결정-트리-Decision-Tree"><a href="#결정-트리-Decision-Tree" class="headerlink" title="결정 트리 (Decision Tree)"></a>결정 트리 (Decision Tree)</h3><ul>
<li>스무 고개와 같다.</li>
<li>질문을 하나씩 던져서 정답과 맞춰가는 것이다.</li>
<li>표준화된 훈련 세트를 이용하여 결정트리를 사용해 본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target)) <span class="comment"># 훈련 세트</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))   <span class="comment"># 테스트 세트</span></span><br></pre></td></tr></table></figure>

<pre><code>0.996921300750433
0.8592307692307692
</code></pre>
<ul>
<li>위 코드의 두 결과는 차이가 있다.</li>
<li>두 결과가 유사하게 나와야 한다.</li>
<li>앞으로 ‘가지치기’에서 차이를 좁히는 과정을 진행한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 현재 트리의 형태를 출력해본다.</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_5_1/output_21_0.png" alt="png"></p>
<ul>
<li>과대적합이 나오는 이유 : 조건식을 걸기 때문</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot_tree()함수에서 트리의 깊이를 제한하여 출력해 본다.</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt, max_depth=<span class="number">1</span>, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_5_1/output_23_0.png" alt="png"></p>
<ul>
<li>불순도 : 운동회 ox 퀴즈에서 정답을 맞힌 사람만 살아남는 것과 같은 원리</li>
</ul>
<h3 id="가지치기"><a href="#가지치기" class="headerlink" title="가지치기"></a>가지치기</h3><ul>
<li>과대적합을 방지하기 위한 것</li>
<li>가지치기를 통해 두 결과가 유사하게 출력된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(max_depth = <span class="number">3</span>, random_state=<span class="number">42</span>) <span class="comment"># max_depth 매개변수 조절을 통해 가지치기 한다.</span></span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target)) <span class="comment"># 훈련 세트</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))   <span class="comment"># 데이터 세트</span></span><br></pre></td></tr></table></figure>

<pre><code>0.8454877814123533
0.8415384615384616
</code></pre>
<ul>
<li>훈련 세트와 테스트 성능이 유사하게 출력되었다.</li>
<li>이런 모델을 트리 그래프로 그린다면 훨씬 이해햐기 쉬울 것이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">plot_tree(dt, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_5_1/output_28_0.png" alt="png"></p>
<ul>
<li><p>훨씬 보기 좋게 출력되었다.</p>
</li>
<li><p>루트 노트</p>
<ul>
<li>당도(sugar)를 기준으로 훈련세트를 나눈다.</li>
</ul>
</li>
<li><p>깊이 1의 노드</p>
<ul>
<li>모두 당도(sugar)를 기준으로 훈련 세트를 나눈다.</li>
</ul>
</li>
<li><p>깊이 2의 노드</p>
<ul>
<li>맨 왼쪽의 노드만 당도를 기준으로 나눈다.</li>
<li>왼쪽에서 두 번째 노드는 알고올 도수(alcohol)를 기준으로 나눈다.</li>
<li>오른쪽 두 노드는 pH를 기준으로 나눈다.</li>
</ul>
</li>
<li><p>리프 노드</p>
<ul>
<li>왼쪽에서 3번째에 있는 노드만 음성 클래스가 더 많다.<ul>
<li>이 노드에 도착해야만 레드 와인으로 예측한다.</li>
<li>이 노드에 도달하려면 -0.802 &lt; sugar &lt; -0.239, alcohol &lt; -0.454 라는 조건을 만족해야 한다.</li>
<li>즉, -0.802 &lt; sugar &lt; -0.239, alcohol &lt; -0.454 이면 레드와인이다</li>
</ul>
</li>
</ul>
</li>
<li><p>그런데 -0.802라는 음수로 된 당도를 어떻게 설명해야할까?</p>
<ul>
<li>좀 더 설명하기 쉽게 바꿔보자.</li>
</ul>
</li>
<li><p>특성값의 스케일은 결정 트리 알고리즘에 아무런 영향을 미치지 않는다.</p>
</li>
<li><p>따라서 표준화 전처리를 할 필요가 없다.</p>
</li>
<li><p>전처리하기 전의 훈련 세트(train_input)와 테스트 세트(test_input)로 결정 트리 모델을 다시 훈련해 본다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 가지치기 때와 달리 train_scaled를 사용하지 않았다. 표준화 전처리 할 필요가 없기 때문인 듯.</span></span><br><span class="line">dt.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8454877814123533
0.8454877814123533
</code></pre>
<ul>
<li>정확히 같은 결과가 나왔다.</li>
<li>트리도 그려보자.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">plot_tree(dt, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_5_1/output_33_0.png" alt="png"></p>
<ul>
<li><p>같은 트리지만 특성값을 표준점수로 바꾸지 않았기에 이해하기 훨씬 쉽다.</p>
<ul>
<li>적어도 당도를 음수로 표기하는 것보단 보기 좋다.</li>
</ul>
</li>
<li><p>다음 조건을 만족하는 것이 레드 와인이다.</p>
<ul>
<li>(1.625 &lt; sugar &lt; 4.325) AND (alcohol &lt; 11.025) &#x3D; 레드 와인</li>
</ul>
</li>
<li><p>특성 중요도</p>
<ul>
<li>결정 트리는 어떤 특성이 가장 유용한지 나타내는 특성 중요도를 계산해준다.</li>
<li>이 트리의 루트 노드와 깊이 1에서 sugar를 사용했기 때문에 아마 sugar가 가장 유용한 특성 중 하나일 것이다.</li>
<li>특성 중요도는 결정 트리 모델의 feature_importances_ 속성에 저장되어 있다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(dt.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.12345626 0.86862934 0.0079144 ]
</code></pre>
<ul>
<li><p>alcohol ,sugar, ph 순서이기 때문에 두 번째인 sugar의 중요도가 가장 높은 것을 알 수 있다.</p>
</li>
<li><p>번외</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line"><span class="comment"># DOT data</span></span><br><span class="line">dot_data = tree.export_graphviz(dt, out_file=<span class="literal">None</span>, </span><br><span class="line">                                feature_names = [<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>],  </span><br><span class="line">                                filled=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw graph</span></span><br><span class="line">graph = graphviz.Source(dot_data, <span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>) </span><br><span class="line">graph</span><br><span class="line">graph.render(<span class="string">&quot;decision_tree_graphivz&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#39;decision_tree_graphivz.png&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap, to_rgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">artists = plot_tree(dt, filled = <span class="literal">True</span>, </span><br><span class="line">          feature_names = [<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> artist, impurity, value <span class="keyword">in</span> <span class="built_in">zip</span>(artists, dt.tree_.impurity, dt.tree_.value):</span><br><span class="line">    r, g, b = to_rgb(colors[np.argmax(value)])</span><br><span class="line">    f = impurity * <span class="number">2</span></span><br><span class="line">    artist.get_bbox_patch().set_facecolor((f + (<span class="number">1</span>-f)*r, f + (<span class="number">1</span>-f)*g, f + (<span class="number">1</span>-f)*b))</span><br><span class="line">    artist.get_bbox_patch().set_edgecolor(<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_5_1/output_40_0.png" alt="png"></p>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-04T00:00:00.000Z" title="2022. 4. 4. 오전 9:00:00">2022-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.228Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">8 minutes read (About 1185 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/04/chapter_5_2/">chapter_5_2</a></h1><div class="content"><h1 id="교차-검증과-그리드-서치"><a href="#교차-검증과-그리드-서치" class="headerlink" title="교차 검증과 그리드 서치"></a>교차 검증과 그리드 서치</h1><ul>
<li>키워드 : 하이퍼 파라미터</li>
<li>데이터가 작을 때, 주로 사용</li>
<li>하이퍼 파라미터<ul>
<li>max_depth : 3, 정확도가 84%</li>
</ul>
</li>
<li>결론<ul>
<li>모르면 디폴트만 쓰자!</li>
<li>가성비 (시간 대비 성능 보장 안됨!)</li>
</ul>
</li>
</ul>
<h3 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h3><ul>
<li>테스트 세트(1회성)</li>
<li>훈련 데이터를 훈련 데이터 + 검증 데이터로 재 분할</li>
</ul>
<h3 id="현실"><a href="#현실" class="headerlink" title="현실"></a>현실</h3><ul>
<li><p>테스트 데이터가 별도로 존재하지 않음!</p>
</li>
<li><p>전체 데이터 &#x3D; 훈련 (6) : 검증 (2) : 테스트 (2)</p>
<ul>
<li>테스트 데이터는 모르는 데이터로 생각!</li>
</ul>
</li>
<li><p>캐글</p>
<ul>
<li>캐글에서는 훈련, 테스트 데이터가 제공된다. 훈련 데이터만 한 번 쪼개서 사용하면 된다.</li>
</ul>
</li>
</ul>
<h3 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h3><ul>
<li>사이킷 런 : <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a></li>
<li>구글링 : 그리드 탐색(서치) vs 랜덤 탐색(서치)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&quot;https://bit.ly/wine_csv_data&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sub_input, val_input, sub_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="모델-만든-후-평가"><a href="#모델-만든-후-평가" class="headerlink" title="모델 만든 후 평가"></a>모델 만든 후 평가</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input, sub_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(sub_input, sub_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(val_input, val_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9971133028626413
0.864423076923077
</code></pre>
<h3 id="교차-검증"><a href="#교차-검증" class="headerlink" title="교차 검증"></a>교차 검증</h3><ul>
<li>많이 하면 많이 할수록 좋다.</li>
<li>교차 검증의 목적 : 좋은 모델이 만들어진다!<ul>
<li>좋은 모델 !&#x3D; 성능 좋은 모델</li>
<li>좋은 모델 &#x3D; 과대 적합이 아닌 모델 &#x3D; 모형의 오차가 적은 모델 &#x3D; 안정적인 모델</li>
</ul>
</li>
<li>교재 245p<ul>
<li>모델 평가 1 : 90%</li>
<li>모델 평가 2 : 85%</li>
<li>모델 평가 3 : 80%</li>
</ul>
</li>
<li>단점 : 시간이 오래 걸림</li>
</ul>
<h3 id="교차-검증-함수"><a href="#교차-검증-함수" class="headerlink" title="교차 검증 함수"></a>교차 검증 함수</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(dt, train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.01164412, 0.00772762, 0.00744891, 0.00796771, 0.00716805]), &#39;score_time&#39;: array([0.00128865, 0.00070405, 0.0007143 , 0.00097823, 0.00069904]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
</code></pre>
<ul>
<li>최종점수 평균 구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.855300214703487
</code></pre>
<ul>
<li>훈련 세트 섞은 후, 10-폴드 교차검증</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">splitter = StratifiedKFold(n_splits = <span class="number">10</span>, shuffle = <span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv = splitter)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8574181117533719
</code></pre>
<h3 id="하이퍼-파라미터-튜닝-꼭-하고-싶다"><a href="#하이퍼-파라미터-튜닝-꼭-하고-싶다" class="headerlink" title="하이퍼 파라미터 튜닝 꼭 하고 싶다!"></a>하이퍼 파라미터 튜닝 꼭 하고 싶다!</h3><ul>
<li>랜덤 서치 사용하자! <ul>
<li>그리드 서치보다 편리하다</li>
</ul>
</li>
<li>자동으로 잡아주는 라이브러리들이 등장하기 시작함<ul>
<li>hyperopt</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier(random_state=42)</span></span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>

<pre><code>CPU times: user 83.8 ms, sys: 1.66 ms, total: 85.5 ms
Wall time: 264 ms
</code></pre>
<ul>
<li>pamas에 2줄을 쓰면 시간이 2배 이상 더 걸린다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span> : [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier(random_state=42)</span></span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>

<pre><code>CPU times: user 191 ms, sys: 1.13 ms, total: 192 ms
Wall time: 674 ms
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span> : [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier(random_state=42)</span></span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005,
                       random_state=42)
0.8830094285164518
&#123;&#39;max_depth&#39;: 7, &#39;min_impurity_decrease&#39;: 0.0005&#125;
CPU times: user 284 ms, sys: 38.7 ms, total: 323 ms
Wall time: 2.15 s
</code></pre>
<ul>
<li>이 부분에 의해 결과가 (5x5&#x3D;)25개 출력된다.<ul>
<li>‘min_impurity_decrease’ : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]</li>
<li>‘max_depth’ : [3, 4, 5, 6, 7]</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.84125583 0.84125583 0.84125583 0.84125583 0.84125583 0.85337806
 0.85337806 0.85337806 0.85337806 0.85318557 0.85780355 0.85799604
 0.85857352 0.85857352 0.85838102 0.85645721 0.85799678 0.85876675
 0.85972866 0.86088306 0.85607093 0.85761031 0.85799511 0.85991893
 0.86280466]
</code></pre>
<h3 id="랜덤-서치"><a href="#랜덤-서치" class="headerlink" title="랜덤 서치"></a>랜덤 서치</h3><ul>
<li>p252. 매개변수 값의목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있도록 확률 분포 객체를 전달.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform, randint</span><br><span class="line">rgen = randint(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line">rgen.rvs(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([7, 9, 7, 4, 2, 0, 4, 8, 6, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.unique(rgen.rvs(<span class="number">1000</span>), return_counts = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([103,  90,  88, 110,  84, 115, 105, 102, 104,  99]))
</code></pre>
<ul>
<li>254p</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : uniform(<span class="number">0.0001</span>, <span class="number">0.001</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span> : randint(<span class="number">20</span>,<span class="number">50</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>),</span><br><span class="line">                        params, n_iter = <span class="number">100</span>, n_jobs = -<span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                   n_iter=100, n_jobs=-1,
                   param_distributions=&#123;&#39;max_depth&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa6910bdd90&gt;,
                                        &#39;min_impurity_decrease&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa6907f3810&gt;&#125;,
                   random_state=42)
</code></pre>
<ul>
<li>위 parmas에 정의된 매개변수 범위에서 총 100번(n_iter 매개변수)을 샘플링하여 교차 검증을 수행하고 최적의 매개변수 조합을 찾는다.</li>
<li>앞서 그리드 서치보다 훨씬 교차 검증 수를 줄이면서 넓은 영역을 효과적으로 탐색할 수 있다.</li>
<li>결과를 확인해보자. 먼저 최적의 매개변수 조합을 출력한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;max_depth&#39;: 29, &#39;min_impurity_decrease&#39;: 0.000437615171403628&#125;
</code></pre>
<ul>
<li>최고의 교차 검증 점수도 확인한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8689635004071962
</code></pre>
<ul>
<li>최적의 모델은 이미 전체 훈련 세트(train_input, train_target)로 훈련되어 best_estimator_속성에 저장되어 있다. </li>
<li>이 모델을 최종 모델로 결정하고 테스트 세트의 성능을 확인해 보자</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8638461538461538
</code></pre>
<ul>
<li><p>테스트 세트 점수는 검증 세트에 대한 점수보다 조금 작은 것이 일반적이다.</p>
</li>
<li><p>여기까지 두 서치를 사용해 본 결과, 랜덤 서치가 더 사용하기 용이하였다.</p>
</li>
<li><p>Reference : 혼자 공부하는 머신러닝 + 딥러닝</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-03T00:00:00.000Z" title="2022. 4. 3. 오전 9:00:00">2022-04-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.236Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">11 minutes read (About 1669 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/03/chapter_4_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/">chapter4_2</a></h1><div class="content"><h1 id="확률적-경사-하강법"><a href="#확률적-경사-하강법" class="headerlink" title="확률적 경사 하강법"></a>확률적 경사 하강법</h1><ul>
<li><p>1차 가장 큰 차이 (기존 ML모형)</p>
<ul>
<li>샘플링 방식이 달라짐</li>
<li>샘플링을 좀 더 세분화함</li>
</ul>
</li>
<li><p>2차 가장 큰 차이</p>
<ul>
<li>오차를 보정 (200p~201p)<ul>
<li>기울기 보정이다.<ul>
<li>미분으로 기울기(경사)를 구한다.</li>
<li>기울기가 0에 가까워질 때까지 반복한다.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>경사하강법이 쓰인 여러 알고리즘</p>
<ul>
<li>(이미지, 텍스트) 딥러닝 기초 알고리즘</li>
<li>트리 알고리즘 + 경사하강법 융햡 &#x3D; 부스팅 계열<ul>
<li>: 대표 알고리즘 : LightGBM, Xgboost, Catboost</li>
<li>: 1등으로 자주 쓰인 알고리즘 &#x3D; lightGBM, Xgboost</li>
<li>: 하이퍼 파라미터의 개수가 80개 넘음</li>
</ul>
</li>
</ul>
</li>
<li><p>머신러닝의 목적 : 오차를 줄이는 것</p>
<ul>
<li>오차 &#x3D; 손실(Cost)</li>
</ul>
</li>
<li><p>손실 함수(loss function)</p>
<ul>
<li>손실(Cost) &#x3D; 오차</li>
</ul>
</li>
</ul>
<h1 id="SGDClassifier"><a href="#SGDClassifier" class="headerlink" title="SGDClassifier"></a>SGDClassifier</h1><ul>
<li>확률적 경사하강법 분류기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;https://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 159 entries, 0 to 158
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Species   159 non-null    object 
 1   Weight    159 non-null    float64
 2   Length    159 non-null    float64
 3   Diagonal  159 non-null    float64
 4   Height    159 non-null    float64
 5   Width     159 non-null    float64
dtypes: float64(5), object(1)
memory usage: 7.6+ KB
</code></pre>
<ul>
<li>배열로 변환하는 코드<ul>
<li>독립변수 &#x3D; fish_input</li>
<li>종속변수 &#x3D; fish_target</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>, <span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]]  <span class="comment"># Diagonal = 대각선</span></span><br><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련 데이터와 테스트 데이터<ul>
<li>이제 데이터를 훈련 세트와 테스트 세트로 나눈다.</li>
<li>외워야 할 정도로 중요. 자주 쓰다보면 외워진다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((119, 5), (40, 5), (119,), (40,))
</code></pre>
<ul>
<li>표준화 처리<ul>
<li>다시 한 번 강조하지만 꼭 훈련 세트에서 학습한 통계값으로 테스트 세트도 변환한다.</li>
<li>키워드 : Data Leakage 방지</li>
<li>데이터 분석 희망자! 필수 공부!</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ss 훈련데이터만 활용해서 학습(?)이 끝난 상태</span></span><br><span class="line"><span class="comment"># 표준화 처리를 훈련데이터와 테스트데이터에 동시 적용</span></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h3 id="모델-학습"><a href="#모델-학습" class="headerlink" title="모델 학습"></a>모델 학습</h3><ul>
<li>2개의 매개 변수 지정</li>
<li>loss &#x3D; “log” &#x3D; 로지스틱 손실 함수로 지정</li>
<li>max_iter &#x3D; 에포크 횟수 지정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 매개변수 지정</span></span><br><span class="line"><span class="comment"># 하이퍼파라미터 설정</span></span><br><span class="line"><span class="comment">## 매개변수 값을 dictionary 형태로 추가하는 코드 작성 가능</span></span><br><span class="line"><span class="comment">## 강사는 입문자들에게는 비추천</span></span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&quot;log&quot;</span>, max_iter = <span class="number">40</span>, random_state=<span class="number">42</span>)\</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형학습</span></span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스코어 확인 (정확도)</span></span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8571428571428571
0.8
</code></pre>
<ul>
<li>에포크<ul>
<li>최적의 기울기를 찾아야 한다.</li>
<li>적절한 에포크 숫자를 찾자</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss= <span class="string">&quot;log&quot;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">train_score=[]</span><br><span class="line">test_score=[]</span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">300</span>):</span><br><span class="line">  sc.partial_fit(train_scaled, train_target, classes=classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 정확도</span></span><br><span class="line"><span class="built_in">print</span>(train_score[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(test_score[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.5294117647058824, 0.6218487394957983, 0.6386554621848739, 0.7310924369747899, 0.7226890756302521]
[0.65, 0.55, 0.575, 0.7, 0.7]
</code></pre>
<ul>
<li>모형 학습 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(train_score)   <span class="comment"># 푸른색</span></span><br><span class="line">ax.plot(test_score)    <span class="comment"># 주황색</span></span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Epoch&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_4_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_17_0.png" alt="png"></p>
<ul>
<li><p>위 결과 25쯤에서 과소적합.</p>
</li>
<li><p>위 결과 125쯤에서 과대적합.</p>
</li>
<li><p>이 모델의 경우 100번째 Epoch가 적절한 반복 횟수로 보인다.</p>
</li>
<li><p>그럼 SGDClassifier의 반복 횟루를 100에 맞추고 모델을 다시 훈련한다.</p>
</li>
<li><p>그리고 최종적으로 훈련 세트와 테스트 세트에서 점수를 출련한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sc = SGDClassifier(loss = <span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.957983193277311
0.925
</code></pre>
<ul>
<li><p>SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다.</p>
</li>
<li><p>tol 매개변수에서 향상될 최솟값을 지정한다.</p>
</li>
<li><p>앞의 코드에서는 tol매개변수를 None으로 지정하여 자동으로 멈추지 않고 max_iter&#x3D;100 만큼 무조건 반복하도록 했다.</p>
</li>
<li><p>결과적으로 점수가 높게 나왔다.</p>
</li>
<li><p>확률적 경사 하강법을 사용한 생선 분류 문제를 성공적으로 수행했다. </p>
</li>
<li><p>loss 매개변수</p>
<ul>
<li>SGDClassifier의 매개변수이다.</li>
<li>loss 매개변수의 기본값은 ‘hinge’이다.</li>
<li>‘힌지 손실’은 ‘서포트 벡터 머신’ 이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수이다.</li>
<li>한 마디로 loss 매개변수는 여러 알고리즘에서 쓰이는 매개변수이다.</li>
</ul>
</li>
<li><p>loss 매개변수와 힌지 손실 예시</p>
<ul>
<li>간단한 예로 힌지 손실을 사용해 같은 반복 횟수 동안 모델을 훈련해보자.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;hinge&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9495798319327731
0.925
</code></pre>
<h3 id="전체-소스-코드"><a href="#전체-소스-코드" class="headerlink" title="전체 소스 코드"></a>전체 소스 코드</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 확률적 경사 하강법</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SGDClassifier</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;https://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line"></span><br><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>, <span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]]  <span class="comment"># Diagonal = 대각선</span></span><br><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ss 훈련데이터만 활용해서 학습(?)이 끝난 상태</span></span><br><span class="line"><span class="comment"># 표준화 처리를 훈련데이터와 테스트데이터에 동시 적용</span></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 매개변수 지정</span></span><br><span class="line"><span class="comment"># 하이퍼파라미터 설정</span></span><br><span class="line"><span class="comment">## 매개변수 값을 dictionary 형태로 추가하는 코드 작성 가능</span></span><br><span class="line"><span class="comment">## 강사는 입문자들에게는 비추천</span></span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&quot;log&quot;</span>, max_iter = <span class="number">40</span>, random_state=<span class="number">42</span>)\</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형학습</span></span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스코어 확인 (정확도)</span></span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">sc.partial_fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 에포크와 과대/과소적합</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss= <span class="string">&quot;log&quot;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">train_score=[]</span><br><span class="line">test_score=[]</span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">300</span>):</span><br><span class="line">  sc.partial_fit(train_scaled, train_target, classes=classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 정확도</span></span><br><span class="line"><span class="built_in">print</span>(train_score[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(test_score[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(train_score)   <span class="comment"># 푸른색</span></span><br><span class="line">ax.plot(test_score)    <span class="comment"># 주황색</span></span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Epoch&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;hinge&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8571428571428571
0.8
0.957983193277311
0.925
0.9411764705882353
0.925
[0.5294117647058824, 0.6218487394957983, 0.6386554621848739, 0.7310924369747899, 0.7226890756302521]
[0.65, 0.55, 0.575, 0.7, 0.7]
</code></pre>
<p><img src="/images/chapter_4_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_25_1.png" alt="png"></p>
<pre><code>0.957983193277311
0.925
0.9495798319327731
0.925
</code></pre>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-02T00:00:00.000Z" title="2022. 4. 2. 오전 9:00:00">2022-04-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.205Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">14 minutes read (About 2162 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/02/chapter_4_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/">chapter4_1</a></h1><div class="content"><h1 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h1><ul>
<li>대상이 어떤 타깃에 속할 확률을 구한다.</li>
</ul>
<h3 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h3><ul>
<li>컬럼 설명 177p 그림</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fish = pd.read_csv(<span class="string">&#x27;https://bit.ly/fish_csv_data&#x27;</span>)</span><br><span class="line">fish.head()</span><br></pre></td></tr></table></figure>





  <div id="df-3c5195bb-ad65-485c-8b95-563887f303f2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length</th>
      <th>Diagonal</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-3c5195bb-ad65-485c-8b95-563887f303f2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-3c5195bb-ad65-485c-8b95-563887f303f2 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-3c5195bb-ad65-485c-8b95-563887f303f2&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>unique()<ul>
<li>어떤 종류의 생선이 있는지 species 열에서 고유한 값을 추출한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pd.unique(fish[<span class="string">&#x27;Species&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Roach&#39; &#39;Whitefish&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Smelt&#39;]
</code></pre>
<h3 id="데이터-변환"><a href="#데이터-변환" class="headerlink" title="데이터 변환"></a>데이터 변환</h3><ul>
<li>배열로 변환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>, <span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]]  <span class="comment"># Diagonal = 대각선</span></span><br><span class="line">fish_input.shape</span><br></pre></td></tr></table></figure>




<pre><code>(159, 5)
</code></pre>
<ul>
<li>target 배열로 변환</li>
<li>종속변수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<h3 id="훈련-데이터와-테스트-데이터"><a href="#훈련-데이터와-테스트-데이터" class="headerlink" title="훈련 데이터와 테스트 데이터"></a>훈련 데이터와 테스트 데이터</h3><ul>
<li>이제 데이터를 훈련 세트와 테스트 세트로 나눈다.</li>
<li>외워야 할 정도로 중요. 자주 쓰다보면 외워진다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state = <span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>표준화 전처리<ul>
<li>이유가 중요하다</li>
<li>사이킷런의 StandardScaler 클래스를 사용해 훈련 세트와 테스트 세트를 표준화 전처리한다.</li>
<li>반드시 훈련 세트의 통계값으로 테스트 세트를 변환해야 한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(train_scaled[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>     Weight  Length  Diagonal   Height   Width
26    720.0    35.0      40.6  16.3618  6.0900
137   500.0    45.0      48.0   6.9600  4.8960
146     7.5    10.5      11.6   1.9720  1.1600
90    110.0    22.0      23.5   5.5225  3.9950
66    140.0    20.7      23.2   8.5376  3.2944
[[ 0.91965782  0.60943175  0.81041221  1.85194896  1.00075672]
 [ 0.30041219  1.54653445  1.45316551 -0.46981663  0.27291745]
 [-1.0858536  -1.68646987 -1.70848587 -1.70159849 -2.0044758 ]
 [-0.79734143 -0.60880176 -0.67486907 -0.82480589 -0.27631471]
 [-0.71289885 -0.73062511 -0.70092664 -0.0802298  -0.7033869 ]]
</code></pre>
<h3 id="k-최근접-이웃-분류기의-확률-예측"><a href="#k-최근접-이웃-분류기의-확률-예측" class="headerlink" title="k-최근접 이웃 분류기의 확률 예측"></a>k-최근접 이웃 분류기의 확률 예측</h3><ul>
<li>필요한 데이터를 모두 준비했다.</li>
<li>이제 k-최근접 이웃 분류기로 테스트 세트에 들어 있느 확률을 예측한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">kn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)  <span class="comment"># 최근접 이웃 개수를 3으로 지정</span></span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(kn.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(kn.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8907563025210085
0.85
</code></pre>
<ul>
<li><p>182p</p>
</li>
<li><p>다중 분류( multi-class classification)</p>
<ul>
<li>앞서 fish  데이터프레임에서 7종류의 생선이 있었다.</li>
<li>fish[‘Species’]를 사용해 타깃 데이터를 만들었기에 두 세트의 타깃 데이터에도 7개의 생선 종류가 들어가 있다.</li>
<li>이렇게 타깃 데이터에 2개 이상의 클래스가 포함된 문제를 ‘다중 분류’라 부른다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict_proba() 메서드로 클래스별 확률 값을 반환한다.</span></span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># round()함수. 소수점 네번째 자리로 반올림</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals = <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 타깃값을 그대로 사이킷런 모델에 전달하면 순서가 알파벨 순으로 매겨진다.</span></span><br><span class="line"><span class="built_in">print</span>(kn.classes_)   </span><br></pre></td></tr></table></figure>

<pre><code>[[0.     0.     1.     0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     1.     0.     0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<ul>
<li>위 코드의 결과는 어떤 물고기일지에 대한 확률이다.<ul>
<li>예를 들어, 1번째 샘플은 100% 확률로 perch이다.</li>
<li>에를 들어, 4번째 샘플은 66% 확률로 perch이고, 33% 확률로 Roach이다.</li>
</ul>
</li>
</ul>
<h1 id="로지스틱-회귀-1"><a href="#로지스틱-회귀-1" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h1><ul>
<li><p>중요도 : 최상</p>
</li>
<li><p>오늘 유튜브 영상 반드시 시청</p>
<ul>
<li>개념 재복습 반드시 필요</li>
</ul>
</li>
<li><p>Why?</p>
<ul>
<li>로지스틱 회귀<ul>
<li>기초 통계로도 활용 (의학통계)</li>
<li>머신러닝 부류모형의 기초 모형인데, 성능이 생각보다 나쁘지 않음<ul>
<li>데이터셋, 수치 테이터 기반</li>
</ul>
</li>
<li>딥러닝 : 초기모형에 해당됨.</li>
</ul>
</li>
</ul>
</li>
<li><p>이름은 회귀이지만 분류 모델이다.</p>
</li>
<li><p>선형 회귀와 동일하게 선형 방정식을 학습한다.</p>
<ul>
<li>예를 들어 다음과 같다.<ul>
<li>z &#x3D; a x (weight) + b x (length) + c x (Diagonal) + d x (Height) + e x (width) + f</li>
<li>여기에서 a, b, c, d, e는 가중치 혹은 계수이다.</li>
<li>z 가 확률이 되려면 0~1 사이의 값이어야 한다.</li>
<li>이를 위해 사용하는 것이 시그모이드 함수( 또는 로지스틱 함수)이다.</li>
</ul>
</li>
</ul>
</li>
<li><p>1 &#x2F; ( 1 + e^(-z) ) </p>
<ul>
<li>이 식이 로지스틱 함수( 시그모이드 함수) 이다.</li>
</ul>
</li>
<li><p>넘파이를 사용하여 z의 그래프를 그려보자.</p>
<ul>
<li>-5와 5 사이에서 0.1 간격으로 배열 z를 만든 다음 z 위치마다 로지스틱 함수를 계산한다.</li>
<li>함수 계산은 np.exp() 함수를 사용한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">z = np.arange(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">0.1</span>)</span><br><span class="line">phi = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))  <span class="comment"># exp는 거듭제곱, z는 범위 표시</span></span><br><span class="line"><span class="comment"># print(z)</span></span><br><span class="line"><span class="comment"># print(phi)</span></span><br><span class="line"></span><br><span class="line">plt.plot(z, phi)  <span class="comment"># 문서를 봐야 함</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;phi&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter_4_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_23_0.png" alt="png"></p>
<ul>
<li><p>개발자 취업을 원한다면</p>
<ul>
<li>공부 별도로 하지 않는다!</li>
<li>다만 알고리즘의 컨셉은 이해해야 한다.</li>
<li>얘기가 서로 통해야 하기 때문에</li>
</ul>
</li>
<li><p>데이터 분석 관련 지망이라면</p>
<ul>
<li>공부해야 한다.</li>
</ul>
</li>
</ul>
<h3 id="로지스틱-회귀로-이진-분류-수행하기"><a href="#로지스틱-회귀로-이진-분류-수행하기" class="headerlink" title="로지스틱 회귀로 이진 분류 수행하기"></a>로지스틱 회귀로 이진 분류 수행하기</h3><ul>
<li><p>사이킷런에는 로지스틱 회귀모델인 LogisticRegression 클래스가 준비되어 있다.</p>
</li>
<li><p>이진 분류이 경우</p>
<ul>
<li>로지스틱 함수의 출력이 0.5보다 크면 양성 클래스</li>
<li>로지스틱 함수의 출력이 0.5보다 작으면 음성 클래스</li>
</ul>
</li>
<li><p>불리언 인덱싱 (boolean indexing)</p>
<ul>
<li>넘파일 배열은 True, False 값을 전달하여 행을 선택할 수 있다.</li>
<li>이를 불리언 인덱싱이라고 부른다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">char_arr = np.array([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(char_arr[[<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>]])</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;A&#39; &#39;C&#39;]
</code></pre>
<ul>
<li>A 와 C만 True이므로 위 결과가 나온다.</li>
<li>이와 같은 방식으로 훈련 세트에서 도미(bream)와 빙어(smelt)의 행만 골라낸다.</li>
<li>비교 연산자를  사용하면 도미와 빙어의 행을 True로 만들 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OR 연산자(|) 를 사용하여 비교 결과를 합친다.</span></span><br><span class="line">bream_smelt_indexes = (train_target == <span class="string">&#x27;Bream&#x27;</span>) | (train_target == <span class="string">&#x27;Smelt&#x27;</span>)</span><br><span class="line">train_bream_smelt = train_scaled[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt = train_target[bream_smelt_indexes]</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위에서 bream_smelt_indexes 배열은 도미와 빙어일 경우만 True값이 들어간다.</p>
</li>
<li><p>이 배열을 사용해 train_scaled와 train_targt 배열에 불리언 인덱싱을 적용하여 도미와 빙어 데이터만 골라낼 수 있다.</p>
</li>
<li><p>186p</p>
</li>
<li><p>모형 만들고 예측하기!</p>
</li>
<li><p>이제 이 데이터로 로지스틱 회귀 모델을 훈련한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment">#         독립변수             종속변수</span></span><br><span class="line">lr.fit(train_bream_smelt, target_bream_smelt)</span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression()
</code></pre>
<ul>
<li>훈련한 모델을 사용해 train_bream_smelt에 있는 처음 5개 샘플을 예측한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측하기</span></span><br><span class="line"><span class="comment"># 클래스로 분류</span></span><br><span class="line"><span class="comment"># 확률값 -&gt; 0.5</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict(train_bream_smelt[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<ul>
<li>2 번째 샘플을 제외하고 모두 도미로 예측했다.</li>
<li>예측 확률은 predict_proba() 메서드에서 제공한다.</li>
<li>처음 5개 샘플의 예측 확률을 출력해 본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict_proba(train_bream_smelt[:<span class="number">5</span>]))  <span class="comment"># predict_proba에서 예측 확률 제공</span></span><br><span class="line"><span class="built_in">print</span>(lr.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]
[&#39;Bream&#39; &#39;Smelt&#39;]
</code></pre>
<ul>
<li><p>위에서 첫번째 열이 음성 클래스(0)에 대한 확률이다.</p>
</li>
<li><p>위에서 두번째 열이 양성 클래스(1)에 대한 확률이다.</p>
</li>
<li><p>bream이 음성이고, smelt가 양성 클래스이다.  </p>
</li>
<li><p>이진 분류를 수행 완료했다.</p>
</li>
<li><p>이제 선형 회귀에서터럼 로지스틱 회귀가 학습한 계수를 확인한다.</p>
</li>
<li><p>방정식의 각 기울기와 상수를 구하는 코드</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
</code></pre>
<ul>
<li><p>이 로지스틱 회귀 모델이 학습한 방정식은 다음과 같다.</p>
<ul>
<li>z &#x3D; -0.404 x (weight) -0.576 x (length) -0.663 x (Diagonal) -1.103 x (Height) -0.732 x (width) -2.161</li>
<li>확실히 로지스틱 회귀는 선형 회귀와 비슷하다.</li>
</ul>
</li>
<li><p>LogistricRegression 모델로 z값을 계산해 보자.</p>
</li>
<li><p>z식</p>
</li>
<li><p>z값을 출력하자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decisions = lr.decision_function(train_bream_smelt[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(decisions)</span><br></pre></td></tr></table></figure>

<pre><code>[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
</code></pre>
<ul>
<li>이 z값을 로지스틱 함수에 통과시키면 확률을 얻을 수 있다.</li>
<li>expit() 함수를 이용해 편하게 계산 가능하다.</li>
<li>이 함수를 이용해 decisions 배열의 값을 확률로 변환한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="built_in">print</span>(expit(decisions))</span><br></pre></td></tr></table></figure>

<pre><code>[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre>
<ul>
<li><p>양성 클래스에 대한 z값을 반환했다.</p>
</li>
<li><p>지금까지 이진 분류를 통해 2종류의 생선 샘플을 골라냈고 이를 이용해 로지스틱 회귀 모델을 훈련했다.</p>
</li>
<li><p>188p</p>
</li>
<li><p>Reference : 혼자 공부하는 머신러닝 + 딥러닝</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-31T00:00:00.000Z" title="2022. 3. 31. 오전 9:00:00">2022-03-31</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.270Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">31 minutes read (About 4662 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/31/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/">chapter3_3</a></h1><div class="content"><h1 id="특성-공학과-규제"><a href="#특성-공학과-규제" class="headerlink" title="특성 공학과 규제"></a>특성 공학과 규제</h1><ul>
<li>선형 회귀는 특성이 많을수록 효과가 좋아진다.<ul>
<li>무게와 길이뿐만 아니라 높이와 두께도 활용해보자.</li>
<li>사이킷런의 PolynomialFeatures  클래스를 사용한다.</li>
</ul>
</li>
</ul>
<h3 id="포인트"><a href="#포인트" class="headerlink" title="포인트"></a><em><strong>포인트</strong></em></h3><ul>
<li>모델에 규제를 추가함<ul>
<li>모형의 과대적합을 방지하기 위해!<ul>
<li>훈련 데이터는 예측 성능이 좋고! 테스트 데이터는 예측성능이 떨어지는 현상</li>
</ul>
</li>
<li>릿지, 라쏘 회귀 (중요도 하)</li>
</ul>
</li>
<li>하이퍼 파라미터 (개념 이해 중요!)<ul>
<li>머신러닝 모델이 학습할수 없고 사람이 알려줘야 하는 파라미터 (161p 참고)</li>
</ul>
<ul>
<li>실무에서는 그렇게 큰 의미가 없음</li>
<li>이유 : 가성비가 떨어짐 (작업시간 대비 성능 보장이 안 됨)</li>
</ul>
</li>
</ul>
<h3 id="하이퍼-파라미터"><a href="#하이퍼-파라미터" class="headerlink" title="하이퍼 파라미터"></a>하이퍼 파라미터</h3><ul>
<li>기본 모델에서 과대적합이 발생함</li>
<li>모델의 성능을 높여주기 위해 여러 옵션을 선택 및 값 조정<ul>
<li>문제 : 항상 선응이 보장이 안됨</li>
<li>모델마다 하이퍼 파라미터 새팅하는 방법이 다 다름 (종류가 제 각각)</li>
<li>scikit-learn 라이브러리 내 모델의 갯수가 103개</li>
<li>어떤 모델은 하이퍼 파라미터 새팅 위해 필요한 매개 변수가 1개인 경우도 있음</li>
<li>어떤 모델은 하이퍼 파라미터의 매개변수가 80개가 넘어가는 것도 있음<ul>
<li>하이퍼 파라미터 기존에 세팅되어 있는대로 사용 권유 (조건: 그 모델에 잘 모르면!!)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="다중-회귀-multiple-regression"><a href="#다중-회귀-multiple-regression" class="headerlink" title="다중 회귀 (multiple regression)"></a>다중 회귀 (multiple regression)</h3><ul>
<li>여러 개의 특성을 사용한 선형 회귀를 다중 회귀라고 부른다.</li>
</ul>
<h3 id="특성-공학-feagure-engineering"><a href="#특성-공학-feagure-engineering" class="headerlink" title="특성 공학(feagure engineering)"></a>특성 공학(feagure engineering)</h3><ul>
<li>기존의 각 특성을 서로 곱해서 또 다른 특성을 만들 수 있다.</li>
<li>예를 들어, ‘농어 길이 x 농어 높이’를 새로운 특성으로 삼을 수 있다.</li>
<li>이렇게 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업을 특성 공학이라고 부른다.</li>
</ul>
<h3 id="데이터-준비"><a href="#데이터-준비" class="headerlink" title="데이터 준비"></a>데이터 준비</h3><ul>
<li><p>이전과 달리 농어의 특성 3개를 사용한다.</p>
</li>
<li><p>판다스를 이용하여 간편하게 데이터를 입력한다.</p>
</li>
<li><p>판다스(pandas)는 데이터 분석 라이브러리이다.</p>
</li>
<li><p>데이터프레임(dataframe)은 판다스의 핵심 데이터 구조이다.</p>
</li>
<li><p>판다스 데이터 프레임을 만들기 위해 많이 사용하는 파일은 CSV 파일이다.</p>
</li>
<li><p>다음 주소와 read_csv()함수로 파일을 읽어낸다. :<a target="_blank" rel="noopener" href="https://bit.ly/perch_csv_data">https://bit.ly/perch_csv_data</a></p>
</li>
<li><p>read_csv() 함수로 데이터프레임을 만든 다음 to_numpy() 메서드를 사용해 넘파이 배열로 바꾼다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd   <span class="comment"># pd는 관례적으로 사용하는 판다스의 별칭이다.</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://bit.ly/perch_csv_data&#x27;</span>)</span><br><span class="line">perch_full = df.to_numpy()</span><br><span class="line"><span class="built_in">print</span>(perch_full)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 8.4   2.11  1.41]
 [13.7   3.53  2.  ]
 [15.    3.82  2.43]
 [16.2   4.59  2.63]
 [17.4   4.59  2.94]
 [18.    5.22  3.32]
 [18.7   5.2   3.12]
 [19.    5.64  3.05]
 [19.6   5.14  3.04]
 [20.    5.08  2.77]
 [21.    5.69  3.56]
 [21.    5.92  3.31]
 [21.    5.69  3.67]
 [21.3   6.38  3.53]
 [22.    6.11  3.41]
 [22.    5.64  3.52]
 [22.    6.11  3.52]
 [22.    5.88  3.52]
 [22.    5.52  4.  ]
 [22.5   5.86  3.62]
 [22.5   6.79  3.62]
 [22.7   5.95  3.63]
 [23.    5.22  3.63]
 [23.5   6.28  3.72]
 [24.    7.29  3.72]
 [24.    6.38  3.82]
 [24.6   6.73  4.17]
 [25.    6.44  3.68]
 [25.6   6.56  4.24]
 [26.5   7.17  4.14]
 [27.3   8.32  5.14]
 [27.5   7.17  4.34]
 [27.5   7.05  4.34]
 [27.5   7.28  4.57]
 [28.    7.82  4.2 ]
 [28.7   7.59  4.64]
 [30.    7.62  4.77]
 [32.8  10.03  6.02]
 [34.5  10.26  6.39]
 [35.   11.49  7.8 ]
 [36.5  10.88  6.86]
 [36.   10.61  6.74]
 [37.   10.84  6.26]
 [37.   10.57  6.37]
 [39.   11.14  7.49]
 [39.   11.14  6.  ]
 [39.   12.43  7.35]
 [40.   11.93  7.11]
 [40.   11.73  7.22]
 [40.   12.38  7.46]
 [40.   11.14  6.63]
 [42.   12.8   6.87]
 [43.   11.93  7.28]
 [43.   12.51  7.42]
 [43.5  12.6   8.14]
 [44.   12.49  7.6 ]]
</code></pre>
<ul>
<li>타깃 데이터는 이전과 동일한 방식으로 준비한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<ul>
<li>그 다음 perch_full과 perch_weight를 훈련 세트와 테스트 세트로 나눈다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split( </span><br><span class="line">    perch_full, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#train_input.shape, test_input.shape, train_target.shape, test_target.shape</span></span><br></pre></td></tr></table></figure>

<ul>
<li>이 데이터를 사용해 새로운 특성을 만든다.</li>
</ul>
<h3 id="사이킷런의-변환기"><a href="#사이킷런의-변환기" class="headerlink" title="사이킷런의 변환기"></a>사이킷런의 변환기</h3><ul>
<li><p>사이킷런은 특성을 만들거나 전처리하기 위한 다양한 클래스를 제공한다.</p>
</li>
<li><p>이런 클래스를 변환기(transformer)라고 부른다.</p>
</li>
<li><p>사이킷런의 모델 클래스에 일관된 fit(), score(), predict() 메서드가 있는 것처럼 변환기 클래스는 모두 fit(), transform()메서드를 제공한다</p>
</li>
<li><p>사용할 변환기는 PolynomialFeatures 클래스이다.</p>
</li>
<li><p>이 클래스는 sklearn.preprocessing패키지에 포함되어 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br></pre></td></tr></table></figure>

<ul>
<li>2개의 특성 2와 3으로 이루어진 샘플 하나를 적용해본다.</li>
<li>이 클래스의 객체를 만르고 fit(), transform() 메서드를 차례대로 호출한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit([[<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>, <span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[[1. 2. 3. 4. 6. 9.]]
</code></pre>
<ul>
<li><p>fit()</p>
<ul>
<li>새롭게 만들 특성 조합을 찾는다.</li>
</ul>
</li>
<li><p>transform()</p>
<ul>
<li>실제로 데이터를 변환한다.</li>
</ul>
</li>
<li><p>위 코드에서 fit()메서드에 입력데이터만 전달했다.</p>
</li>
<li><p>즉 여기에서는 2개의 특성을 가진 샘플 [2,3]이 6개의 특성을 가진 샘플 [1. 2. 3. 4. 6. 9.]로 바뀌었다.</p>
</li>
<li><p>PolynomialFeatures 클래스는 기본적으로 각 특성을 제곱한 항을 추가하고 특성끼리 서로 곱한 항을 추가한다.</p>
</li>
<li><p>2와 3을 각각 제곱한 4와 9가 추가되었고, 2와 3을 곱한 6이 추가된다. 1은 다음 식에 의해 추가된다.</p>
</li>
<li><p>무게 &#x3D; a x 길이 + b x 높이 + c x 두께 + d x 1</p>
</li>
<li><p>이렇게 놓고 보면 특성은 (길이, 높이, 두께, 1)이 된다.</p>
</li>
<li><p>하지만 사이킷런의 선형 모델은 자동으로 절편(계수)을 추가하므로 굳이 이렇게 특성을 만들 필요가 없다.</p>
</li>
<li><p>include_bias &#x3D; False로 지정하여 다시 특성을 변환한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit([[<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>, <span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[[2. 3. 4. 6. 9.]]
</code></pre>
<ul>
<li>절편을 위한 항이 제거되고 특성의 제곱과 특성끼리 곱한 항만 추가되었다.</li>
<li>이제 이 방식으로 train_input에 적용한다.</li>
<li>train_input을 변환한 데이터를 train_poly에 저장하고 이 배열의 크기를 확인해 보자.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 9)
</code></pre>
<ul>
<li>PolynomialFeaures 클래스는 9개의 특성이 어떻게 만들어졌는지 확인하는 아주 좋은 방법을 제공한다.</li>
<li>get_feature-names_out() 메서드를 호출하면 9개의 특성이 각각 어떤 입력의 조합으로 만들어졌는지 알려준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poly.get_feature_names_out()</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;x0&#39;, &#39;x1&#39;, &#39;x2&#39;, &#39;x0^2&#39;, &#39;x0 x1&#39;, &#39;x0 x2&#39;, &#39;x1^2&#39;, &#39;x1 x2&#39;,
       &#39;x2^2&#39;], dtype=object)
</code></pre>
<ul>
<li>x0은 첫 번째 특성을 의미하고 x0^2는 첫 번째 특성의 제곱, x0 x1은 첫 번째와 두 번째 특성의 곱을 타나내는 식이다.</li>
<li>이제 테스트 세트를 변환한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_poly = poly.transform(test_input)</span><br></pre></td></tr></table></figure>

<ul>
<li>이어서 변환된 특성을 사용하여 다중 회귀 모델을 훈련한다.</li>
</ul>
<h3 id="다중-회귀-모델-훈련하기"><a href="#다중-회귀-모델-훈련하기" class="headerlink" title="다중 회귀 모델 훈련하기"></a>다중 회귀 모델 훈련하기</h3><ul>
<li>사이킷런의 LinearRegression 클래스를 임포트하고 앞에서 만든 train_poly를 사용해 모델을 훈련시킨다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9903183436982124
</code></pre>
<ul>
<li>높은 점수가 나왔다.</li>
<li>농어의 길이뿐만 아니라 높이와 두께를 모두 사용했고 각 특성을 제곱하거나 서로 곱해서 다항 특성을 더 추가했다.</li>
<li>특성이 늘어나면 선형 회귀의 능력이 강해짐을 알 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9714559911594134
</code></pre>
<ul>
<li>테스트 셑트에 대한 점수는 높아지지 않았지만 농어의 길이만 사용했을 때 있던 과소적합 문제가 더 이상 나타나지 않게 되었다.</li>
<li>특성을 더 많이 추가하면 어떻게될까? 3제곱, 4제곱 항까지 넣는 것이다.</li>
<li>PolynomialFeaures 클래스의 degree 매개변수를 사용하여 필요한 고차항의 최대 차수를 지정할 수 있다.</li>
<li>5제곱까지 특성을 만들어 출력해본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(degree=<span class="number">5</span>, include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line">test_poly = poly.transform(test_input)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 55)
</code></pre>
<ul>
<li>만들어진 특성의 개수가 무려 55개나 된다.</li>
<li>train_poly 배열의 열의 개수가 특성의 개수이다.</li>
<li>이 데이터를 사용해 선형 회귀 모델을 다시 훈련한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9999999999991097
</code></pre>
<ul>
<li>거의 완벽한 점수다.</li>
<li>테스트 세트에 대한 점수는 어떨까?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>-144.40579242684848
</code></pre>
<ul>
<li><p>음수가 나왔다.</p>
</li>
<li><p>특성의 개수를 늘리면 선형 모델은 더 강력해진다.</p>
</li>
<li><p>하지만 이런 모델은 훈련 세트에 너무 과대적합되므로 테스트 세트에서는 형편없는 점수를 만든다.</p>
</li>
<li><p>이 문제를 해결하기 위해 2가지 방법이 있다.</p>
<ul>
<li>방법 1. 다시 특성을 줄인다.</li>
<li>방법 2. 규제를 사용한다.</li>
</ul>
</li>
</ul>
<h3 id="규제-regularization"><a href="#규제-regularization" class="headerlink" title="규제 (regularization)"></a>규제 (regularization)</h3><ul>
<li>규제는 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것을 말한다.</li>
<li>즉 모델이 훈련 세트에 과대적합되지 않도록 만드는 것이다.</li>
<li>회귀 모델의 경우 특성에 곱해지는 계수(또는 기울기)의 크기를 작게 만드는 일이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 규제하기 전에 먼저 정규화를 진행한다.</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler  <span class="comment"># 이 클래스는 변환기의 하나이다.</span></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_poly)</span><br><span class="line">train_scaled = ss.transform(train_poly)</span><br><span class="line">test_scaled = ss.transform(test_poly)</span><br></pre></td></tr></table></figure>

<ul>
<li>StandardScaler 클래스의 객체 ss를 초기화한 후 PolynomialFeatures 클래스로 만든 train_poly를 사용해 이 객체를 훈련한다.</li>
<li>반드시 훈련 세트로 학습한 변환기를 사용해 테스트 세트까지 변환해야 한다.</li>
<li>이제 표준점수로 변환한 train_scaled와 test_scaled가 준비되었다.</li>
</ul>
<h3 id="릿지-ridge-와-라쏘-lasso"><a href="#릿지-ridge-와-라쏘-lasso" class="headerlink" title="릿지(ridge)와 라쏘(lasso)"></a>릿지(ridge)와 라쏘(lasso)</h3><ul>
<li>선형 회귀 모델에 규제를 추가한 모델이다.</li>
<li>두 모델은 규제를 가하는 방법이 다르다.</li>
<li>릿지 <ul>
<li>계수를 제곱한 값을 기준으로 규제를 적용한다.</li>
</ul>
</li>
<li>라쏘<ul>
<li>계수의 절댓값을 기준으로 규제를 적용한다.</li>
</ul>
</li>
</ul>
<h3 id="릿지-회귀"><a href="#릿지-회귀" class="headerlink" title="릿지 회귀"></a>릿지 회귀</h3><ul>
<li>릿지와 라쏘 모두 sklearn.linear_model 패키지 안에 있다.</li>
<li>모델 객체를 만들고 fit() 메서드에서 훈련한 다음 score()메서드로 평가한다.</li>
<li>앞서 준비한 train_scaled 데이터로 릿지 모델을 훈련한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">ridge = Ridge()</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9896101671037343
</code></pre>
<ul>
<li>선형 회귀에 비해 낮아졌다.</li>
<li>이번에는 테스트 세트에 대한 점수를 확인한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9790693977615397
</code></pre>
<ul>
<li><p>확실히 과대적합도지 않아 테스트 세트에서도 좋은 성능을 내고 있다.</p>
</li>
<li><p>릿지와 라쏘 모델을 사용할 때 규제의 양을 임의로 조절할 수 있다.</p>
</li>
<li><p>모델 객체를 만들 때 alpha매개변수로 규제의 강도를 조절한다.</p>
</li>
<li><p>alpha 값이 크면 규제 강도가 세지므로 계수 값을 줄이고 더 과소적합되도록 유도한다.</p>
</li>
<li><p>aplha 값이 작으면 계수를 줄이는 역할이 줄어들고 선형 회귀 모델과 유사해지므로 과대적합될 가능성이 크다.</p>
</li>
<li><p>적절한 alpha값을 찾는 한 가지 방법은 alpha값에 R^2값의 그래프를 그려 보는 것이다.</p>
</li>
<li><p>훈련 세트와 테스트 세트의 점수가 가장 가까운 지점이 최적의 alpha 값이 된다.</p>
</li>
<li><p>alpha값을 바꿀 때마다 score() 메서드의 결과를 저장할 리스트를 만든다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br></pre></td></tr></table></figure>

<ul>
<li><p>다음은 alpha를 0.001에서 100까지 10배씩 늘려가며 릿지 회귀 모델을 훈련한 다음 훈련 세트와 테스트 세트의 점수를 리스트에 저장한다.</p>
</li>
<li><p>사람이 직버 지정해야 하는 매개변수 (하이퍼 파라미터)</p>
</li>
<li><p>다 돌려봐서 성능이 놓은 alpha 값 찾기</p>
</li>
<li><p>경우의 수 (15가지)</p>
<ul>
<li>A 조건 : 5가지</li>
<li>B 조건 : 3가지</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  <span class="comment"># 릿지 모델을 만든다.</span></span><br><span class="line">  ridge = Ridge(alpha=alpha)</span><br><span class="line">  <span class="comment"># 릿지 모델을 훈련한다.</span></span><br><span class="line">  ridge.fit(train_scaled, train_target)</span><br><span class="line">  <span class="comment"># 훈련 점수와 테스트 점수를 저장한다.</span></span><br><span class="line">  train_score.append(ridge.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<ul>
<li>이제 그래프를 그려본다.</li>
<li>alpha 값을 10배씩 늘렸기 때문에 그래프 일부가 너무 촘촘해진다.</li>
<li>alpha_list에 있는 6개의 값을 동일한 간격으로 나타내기 위해 로그 함수로 바꾸어 지수로 표현한다.<ul>
<li>0.001은 -3, 0.01은 -2가 되는 식이다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(np.log10(alpha_list), train_score)</span><br><span class="line">plt.plot(np.log10(alpha_list), test_score)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_57_0.png" alt="png"></p>
<ul>
<li><p>위는 훈련 세트 그래프, 아래는 테스트 세트 그래프이다.</p>
</li>
<li><p>이 그래프 왼쪽에서 두 세트의 점수 차이가 크다.</p>
</li>
<li><p>훈련 세트에만 잘 맞는 과대적합의 전형적인 모습니다.</p>
</li>
<li><p>반대로 오른쪽에서는 두 세트의 점수가 모두 낮아지는 과소적합이 나타난다.</p>
</li>
<li><p>적절한 alpha값은 두 그래프가 가장 가깝고 테스트 세트의 점수가 가장 높은 -1, 즉 10^-1 &#x3D; 0.1 이다.</p>
</li>
<li><p>alpha 값을 0.1로 하여 최종 모델을 훈련한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ridge = Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9903815817570366
0.9827976465386926
</code></pre>
<ul>
<li>이 모델은 훈련 세트와 테스트 세트의 점수가 비슷하게 모두 높고 과대적합과 과소적합 사이에서 균형을 맞추고 있다.</li>
<li>이번에는 라쏘 모델을 훈련해보자.</li>
</ul>
<h3 id="라쏘-회귀"><a href="#라쏘-회귀" class="headerlink" title="라쏘 회귀"></a>라쏘 회귀</h3><ul>
<li>라쏘 모델을 훈련하는 것은 릿지와 매우 비슷하다.</li>
<li>Ridge 클래스를 Lasso 클래스로 바꾸는 것이 전부이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">lasso = Lasso()</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.989789897208096
</code></pre>
<ul>
<li>라소도 과대적합을 잘 억제한 결과를 보여준다.</li>
<li>테스트 세트의 점수도 확인한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9800593698421883
</code></pre>
<ul>
<li>릿지만큼 좋은 점수가 나왔다.</li>
<li>앞에서와 같이 alpha값을 바꾸어 가며 훈련 세트와 테스트 세트에 대한 점수를 계산한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  <span class="comment"># 라쏘 모델을 만든다.</span></span><br><span class="line">  lasso = Lasso(alpha=alpha, max_iter = <span class="number">10000</span>)  <span class="comment"># 반복 횟수를 충분히 늘리기 위해 값을 지정.</span></span><br><span class="line">  <span class="comment"># 라쏘 모델을 훈련한다.</span></span><br><span class="line">  lasso.fit(train_scaled, train_target)</span><br><span class="line">  <span class="comment"># 훈련 점수와 테스트 점수를 저장한다.</span></span><br><span class="line">  train_score.append(lasso.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<ul>
<li>train_score와 test_score 리스트를 사용해 그래프를 그린다.</li>
<li>이 그래프도 x축은 로그 스케일로 바꿔 그린다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(np.log10(alpha_list), train_score)</span><br><span class="line">plt.plot(np.log10(alpha_list), test_score)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_69_0.png" alt="png"></p>
<ul>
<li>이 그래프도 왼쪽은 과대적합을 부여주고 있고, 오른쪽으로 갈수록 두 세트의 점수가 좁혀지고 있다.</li>
<li>라쏘 모델에서 최적의 alpha값은 1, 즉 10^1 &#x3D; 10이다.<ul>
<li>이 값으로 다시 모델을 훈련한다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lasso = Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.990137631128448
0.9819405116249363


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e+02, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<ul>
<li>모델이 잘 훈련되었다.</li>
<li>라쏘 모델은 계수 값을 아예 0으로 만들 수 있다.</li>
<li>라쏘 모델의 계수는 coef_ 속성에 저장되어 있다. 이 중에 0인 것을 헤아려본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(lasso.coef_ == <span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<pre><code>35
</code></pre>
<ul>
<li>많은 계수가 0이 되었다.</li>
<li>55개의 특성을 모델에 주입했지만 라소 모델이사용한 특성은 15개 밖에 되지 않는다.</li>
<li>이런 특징 때문에 라쏘 모델을 유용한 특성을 골라내는 용도로도 사용할 수 있다.</li>
</ul>
<h3 id="전체-소스-코드"><a href="#전체-소스-코드" class="headerlink" title="전체 소스 코드"></a>전체 소스 코드</h3><ul>
<li>다음 주소를 참고하라 : <a target="_blank" rel="noopener" href="https://bit.ly/hg-03-3">https://bit.ly/hg-03-3</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 특성 공학과 규제</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 준비</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://bit.ly/perch_csv_data&#x27;</span>)</span><br><span class="line">perch_full = df.to_numpy()</span><br><span class="line"><span class="built_in">print</span>(perch_full)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 사이킷런의 변환기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit([[<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>, <span class="number">3</span>]]))</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit([[<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>, <span class="number">3</span>]]))</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br><span class="line"></span><br><span class="line">poly.get_feature_names_out()</span><br><span class="line"></span><br><span class="line">test_poly = poly.transform(test_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 다중 회귀 모델 훈련하기</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures(degree=<span class="number">5</span>, include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line">test_poly = poly.transform(test_input)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br><span class="line"></span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 규제</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_poly)</span><br><span class="line">train_scaled = ss.transform(train_poly)</span><br><span class="line">test_scaled = ss.transform(test_poly)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 릿지 회귀</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"></span><br><span class="line">ridge = Ridge()</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">    <span class="comment"># 릿지 모델을 만듭니다</span></span><br><span class="line">    ridge = Ridge(alpha=alpha)</span><br><span class="line">    <span class="comment"># 릿지 모델을 훈련합니다</span></span><br><span class="line">    ridge.fit(train_scaled, train_target)</span><br><span class="line">    <span class="comment"># 훈련 점수와 테스트 점수를 저장합니다</span></span><br><span class="line">    train_score.append(ridge.score(train_scaled, train_target))</span><br><span class="line">    test_score.append(ridge.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">plt.plot(np.log10(alpha_list), train_score)</span><br><span class="line">plt.plot(np.log10(alpha_list), test_score)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">ridge = Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line">lasso = Lasso()</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">    <span class="comment"># 라쏘 모델을 만듭니다</span></span><br><span class="line">    lasso = Lasso(alpha=alpha, max_iter=<span class="number">10000</span>)</span><br><span class="line">    <span class="comment"># 라쏘 모델을 훈련합니다</span></span><br><span class="line">    lasso.fit(train_scaled, train_target)</span><br><span class="line">    <span class="comment"># 훈련 점수와 테스트 점수를 저장합니다</span></span><br><span class="line">    train_score.append(lasso.score(train_scaled, train_target))</span><br><span class="line">    test_score.append(lasso.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">plt.plot(np.log10(alpha_list), train_score)</span><br><span class="line">plt.plot(np.log10(alpha_list), test_score)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">lasso = Lasso(alpha=<span class="number">10</span>)</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(lasso.coef_ == <span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[[ 8.4   2.11  1.41]
 [13.7   3.53  2.  ]
 [15.    3.82  2.43]
 [16.2   4.59  2.63]
 [17.4   4.59  2.94]
 [18.    5.22  3.32]
 [18.7   5.2   3.12]
 [19.    5.64  3.05]
 [19.6   5.14  3.04]
 [20.    5.08  2.77]
 [21.    5.69  3.56]
 [21.    5.92  3.31]
 [21.    5.69  3.67]
 [21.3   6.38  3.53]
 [22.    6.11  3.41]
 [22.    5.64  3.52]
 [22.    6.11  3.52]
 [22.    5.88  3.52]
 [22.    5.52  4.  ]
 [22.5   5.86  3.62]
 [22.5   6.79  3.62]
 [22.7   5.95  3.63]
 [23.    5.22  3.63]
 [23.5   6.28  3.72]
 [24.    7.29  3.72]
 [24.    6.38  3.82]
 [24.6   6.73  4.17]
 [25.    6.44  3.68]
 [25.6   6.56  4.24]
 [26.5   7.17  4.14]
 [27.3   8.32  5.14]
 [27.5   7.17  4.34]
 [27.5   7.05  4.34]
 [27.5   7.28  4.57]
 [28.    7.82  4.2 ]
 [28.7   7.59  4.64]
 [30.    7.62  4.77]
 [32.8  10.03  6.02]
 [34.5  10.26  6.39]
 [35.   11.49  7.8 ]
 [36.5  10.88  6.86]
 [36.   10.61  6.74]
 [37.   10.84  6.26]
 [37.   10.57  6.37]
 [39.   11.14  7.49]
 [39.   11.14  6.  ]
 [39.   12.43  7.35]
 [40.   11.93  7.11]
 [40.   11.73  7.22]
 [40.   12.38  7.46]
 [40.   11.14  6.63]
 [42.   12.8   6.87]
 [43.   11.93  7.28]
 [43.   12.51  7.42]
 [43.5  12.6   8.14]
 [44.   12.49  7.6 ]]
[[1. 2. 3. 4. 6. 9.]]
[[2. 3. 4. 6. 9.]]
(42, 9)
0.9903183436982124
0.9714559911594134
(42, 55)
0.9999999999991097
-144.40579242684848
0.9896101671037343
0.9790693977615397
</code></pre>
<p><img src="/images/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_76_1.png" alt="png"></p>
<pre><code>0.9903815817570366
0.9827976465386926
0.989789897208096
0.9800593698421883


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<p><img src="/images/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_76_4.png" alt="png"></p>
<pre><code>0.9888067471131867
0.9824470598706695
40
</code></pre>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-30T00:00:00.000Z" title="2022. 3. 30. 오전 9:00:00">2022-03-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.197Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">12 minutes read (About 1861 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/30/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/">chapter3_2</a></h1><div class="content"><h3 id="데이터-준비하기"><a href="#데이터-준비하기" class="headerlink" title="데이터 준비하기"></a>데이터 준비하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련 세트와 테스트 세트로 나눈다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split( </span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<ul>
<li>훈련 세트와 테스트 세트를 2차원 배열로 변경</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = train_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h3 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># knn 클래스 불러오기</span></span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형학습</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테스트 점수 확인하자</span></span><br><span class="line"><span class="comment">#knr.score(test_input, test_target)</span></span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsRegressor(n_neighbors=3)
</code></pre>
<h3 id="예측"><a href="#예측" class="headerlink" title="예측"></a>예측</h3><ul>
<li>혼자 공부하는 머신러닝 + 딥러닝<ul>
<li>p132</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 어떤 숫자로 바꿔도 결과는 동일하다</span></span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))  </span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<h3 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 구하라!</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 구하라</span></span><br><span class="line"></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker = <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_11_0.png" alt="png"></p>
<ul>
<li>[과제] 위 시각화를 객체 지향으로 변경한다!</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 구하라!</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 구하라</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker = <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">ax.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 아래 코드를 참고함.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 객체 지향으로 변경</span></span><br><span class="line"><span class="string">fig, ax = plt.subplots()</span></span><br><span class="line"><span class="string">ax.scatter(perch_length, perch_weight)</span></span><br><span class="line"><span class="string">ax.set_xlabel(&quot;length&quot;)</span></span><br><span class="line"><span class="string">ax.set_xlabel(&quot;weight&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_13_0.png" alt="png"></p>
<pre><code>&#39;\nimport matplotlib.pyplot as plt\n\n# 객체 지향으로 변경\nfig, ax = plt.subplots()\nax.scatter(perch_length, perch_weight)\nax.set_xlabel(&quot;length&quot;)\nax.set_xlabel(&quot;weight&quot;)\n\nplt.show()\n&#39;
</code></pre>
<ul>
<li>머신러닝 모델은 주기적으로 훈련해야 한다. (135p)<ul>
<li>MLOps (Machine Learning &amp; Operations)</li>
<li>최근에 각광받는 데이터 관련 직업 필수 스킬!</li>
<li>입사와 함께 공부시작 (데이터 분석가, 머신러닝 엔지니어, 데이터 싸이언티스트 희망자)</li>
</ul>
</li>
</ul>
<h3 id="선형회귀-머신러닝"><a href="#선형회귀-머신러닝" class="headerlink" title="선형회귀 (머신러닝)"></a>선형회귀 (머신러닝)</h3><ul>
<li>평가지표 확신이 더 중요! R2 점수, MAE, MSE,…</li>
<li>5가지 가정들…</li>
<li>잔차의 정규성</li>
<li>등분산성, 다중공선성, etc…</li>
<li>종속변수 ~ 독립변수간의 “인간관계”를 찾는 과정…</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 선형 회귀 모델 훈련</span></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50 cm 농어 예측</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">200</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[7094.41034777]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker = <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.scatter(<span class="number">200</span>, <span class="number">7094</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_17_0.png" alt="png"></p>
<h3 id="회귀식을-찾기"><a href="#회귀식을-찾기" class="headerlink" title="회귀식을 찾기"></a>회귀식을 찾기</h3><ul>
<li>coef_  : 기울기</li>
<li>intercept_ : 상수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기울기,  상수</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[39.01714496] -709.0186449535477
</code></pre>
<ul>
<li>기울기 : 계수 &#x3D; 가중치(딥러닝)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 15~50 까지의 1차 방정식 그래프를 그린다.</span></span><br><span class="line">plt.plot([<span class="number">15</span>, <span class="number">50</span>], </span><br><span class="line">         [<span class="number">15</span> * lr.coef_ + lr.intercept_,</span><br><span class="line">          <span class="number">50</span> * lr.coef_ + lr.intercept_,</span><br><span class="line">          ])</span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1241.8</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_21_0.png" alt="png"></p>
<ul>
<li>모형 평가 (138p)<ul>
<li>과소 적합이 됨</li>
</ul>
</li>
</ul>
<h1 id="다항회귀의-필요성"><a href="#다항회귀의-필요성" class="headerlink" title="다항회귀의 필요성"></a>다항회귀의 필요성</h1><ul>
<li>치어를 생각해보자</li>
<li>치어가 1cm</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">1</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[-670.00149999]
</code></pre>
<ul>
<li>(140p) 1차 방정식을 2차방정식으로 만드는 과정이 나옴</li>
<li>넘파이 브로드캐스팅<ul>
<li>배열의 크기가 동일하면 상관 없음</li>
<li>배열의 크기가 다른데, 연산을 할 때, 브로드캐스팅 원리가 적용</li>
<li>브로드캐스팅 튜토리얼, 뭘 찾아서, 추가적 공부를 해야 함(분석가 지망, ai분야 지망)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_poly = np.column_stack((train_input ** <span class="number">2</span>, train_input))</span><br><span class="line">test_poly = np.column_stack((test_input ** <span class="number">2</span>, test_input))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 2) (14, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span> ** <span class="number">2</span>, <span class="number">50</span>]]))      </span><br></pre></td></tr></table></figure>

<pre><code>[1573.98423528]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기울기,  상수</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<ul>
<li><p>이 모델은 다음과 같은 그래프를 학습했다.</p>
<ul>
<li>무게 &#x3D; 1.01 x 길이^2 - 21.6 x 길이 + 116.05</li>
</ul>
</li>
<li><p>KNN의 문제점</p>
<ul>
<li>농어의 길이가 커져도 무게는 동일함 (현실성 제로)</li>
</ul>
</li>
<li><p>단순 선형회귀(1차 방정식)의 문제점</p>
<ul>
<li>치어(1cm)의 무게가 음수로 나옴 (현실성 제로)</li>
</ul>
</li>
<li><p>다항 회귀(2차 방정식)으로 변경</p>
<ul>
<li>현실성 있음</li>
</ul>
</li>
<li><p>이런 방정식을 다항싱(polynomial)이라 부르며 다항식을 사용한 선형 외귀를 다항 회귀(polynomial regression)이라 부른다.</p>
</li>
<li><p>이를 이용하여 이전과 동일하게 훈련 세트의 산점도에 그래프로 그려보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 구간별 직선을 그리기 위해 15 에서 49까지 정수 배열을 만든다.</span></span><br><span class="line">point = np.arange(<span class="number">15</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 그린다.</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 15에서 49까지 2차 방정식 그래프를 그린다.</span></span><br><span class="line">plt.plot(point, <span class="number">1.01</span>*point**<span class="number">2</span> - <span class="number">21.6</span>*point + <span class="number">116.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#50cm 농어 데이터</span></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1574</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_32_0.png" alt="png"></p>
<ul>
<li>앞선 단순 선형 회귀 모델보다 훨씬 나은 그래프가 그려졌다.</li>
<li>이제 훈련 세트와 테스트 세트의 R^2 점수를 평가한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9706807451768623
0.9775935108325122
</code></pre>
<ul>
<li>두 세트의 점수가 높아졌다. 좋은 결과다.</li>
<li>하지만 여전히 테스트 세트의 점수가 조금 더 높다.</li>
<li>과소적합이 아직 남아 있는 듯 하다. 3-3 에서 이를 해결해보자</li>
</ul>
<h3 id="전체-소스-코드"><a href="#전체-소스-코드" class="headerlink" title="전체 소스 코드"></a>전체 소스 코드</h3><ul>
<li>다음을 참고하라 : bit.ly&#x2F;hg-03-2</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트와 테스트 세트로 나눕니다</span></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># 훈련 세트와 테스트 세트를 2차원 배열로 바꿉니다</span></span><br><span class="line">train_input = train_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># k-최근접 이웃 회귀 모델을 훈련합니다</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 구합니다</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 그립니다</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 훈련 세트 중에서 이웃 샘플만 다시 그립니다</span></span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"><span class="comment"># 50cm 농어 데이터</span></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(train_target[indexes]))</span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">100</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 100cm 농어의 이웃을 구합니다</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">100</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 그립니다</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 훈련 세트 중에서 이웃 샘플만 다시 그립니다</span></span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"><span class="comment"># 100cm 농어 데이터</span></span><br><span class="line">plt.scatter(<span class="number">100</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 선형 회귀 모델 훈련</span></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어에 대한 예측</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 그립니다</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 15에서 50까지 1차 방정식 그래프를 그립니다</span></span><br><span class="line">plt.plot([<span class="number">15</span>, <span class="number">50</span>], [<span class="number">15</span>*lr.coef_+lr.intercept_, <span class="number">50</span>*lr.coef_+lr.intercept_])</span><br><span class="line"><span class="comment"># 50cm 농어 데이터</span></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1241.8</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_input, test_target))</span><br><span class="line"></span><br><span class="line">train_poly = np.column_stack((train_input ** <span class="number">2</span>, train_input))</span><br><span class="line">test_poly = np.column_stack((test_input ** <span class="number">2</span>, test_input))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>**<span class="number">2</span>, <span class="number">50</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 구간별 직선을 그리기 위해 15에서 49까지 정수 배열을 만듭니다</span></span><br><span class="line">point = np.arange(<span class="number">15</span>, <span class="number">50</span>)</span><br><span class="line"><span class="comment"># 훈련 세트의 산점도를 그립니다</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 15에서 49까지 2차 방정식 그래프를 그립니다</span></span><br><span class="line">plt.plot(point, <span class="number">1.01</span>*point**<span class="number">2</span> - <span class="number">21.6</span>*point + <span class="number">116.05</span>)</span><br><span class="line"><span class="comment"># 50cm 농어 데이터</span></span><br><span class="line">plt.scatter([<span class="number">50</span>], [<span class="number">1574</span>], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_37_1.png" alt="png"></p>
<pre><code>1033.3333333333333
[1033.33333333]
</code></pre>
<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_37_3.png" alt="png"></p>
<pre><code>[1241.83860323]
[39.01714496] -709.0186449535477
</code></pre>
<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_37_5.png" alt="png"></p>
<pre><code>0.939846333997604
0.8247503123313558
(42, 2) (14, 2)
[1573.98423528]
[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<p><img src="/images/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_37_7.png" alt="png"></p>
<pre><code>0.9706807451768623
0.9775935108325122
</code></pre>
<ul>
<li>Reference : 혼자 공부하는 머신러닝 + 딥러닝</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-29T00:00:00.000Z" title="2022. 3. 29. 오전 9:00:00">2022-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-09T10:58:13.253Z" title="2022. 4. 9. 오후 7:58:13">2022-04-09</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/">machine learning</a><span> / </span><a class="link-muted" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a></span><span class="level-item">5 minutes read (About 679 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/29/chapter3_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/">chapter3_1</a></h1><div class="content"><h1 id="데이터-준비"><a href="#데이터-준비" class="headerlink" title="데이터 준비"></a>데이터 준비</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<h3 id="k-최근점-이웃-회귀-Regression"><a href="#k-최근점-이웃-회귀-Regression" class="headerlink" title="k-최근점 이웃 회귀(Regression)"></a>k-최근점 이웃 회귀(Regression)</h3><ul>
<li>중요도 : 하 (그냥 넘어가세요!) <ul>
<li>실무에서 잘 안쓰이고, 시간은 한정되어 있기 때문</li>
</ul>
</li>
</ul>
<h3 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h3><ul>
<li>다음과 같이 fig, ax를 이용해 객체 지향으로 작성하라</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 객체 지향으로 변경</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(perch_length, perch_weight)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/chapter3_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/output_4_0.png" alt="png"></p>
<h3 id="훈련데이터-테스트데이터셋-분리"><a href="#훈련데이터-테스트데이터셋-분리" class="headerlink" title="훈련데이터 테스트데이터셋 분리"></a>훈련데이터 테스트데이터셋 분리</h3><ul>
<li>외워야 할 정도로 중요하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(  <span class="comment"># 자체적으로 셔플이 된다.</span></span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<ul>
<li>reshape() 사용하여 2차원 배열로 바꿈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = train_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h3 id="결정계수"><a href="#결정계수" class="headerlink" title="결정계수"></a>결정계수</h3><ul>
<li>모델이 얼마만큼 정확하냐?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># knn 클래스 불러오기</span></span><br><span class="line">knr = KNeighborsRegressor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형학습</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테스트 점수 확인하자</span></span><br><span class="line">knr.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>0.992809406101064
</code></pre>
<h3 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h3><ul>
<li>타깃과 예측의 절댓값 오차를 평균하여 반환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 데이터 만들기</span></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">test_prediction</span><br></pre></td></tr></table></figure>




<pre><code>array([  60. ,   79.6,  248. ,  122. ,  136. ,  847. ,  311.4,  183.4,
        847. ,  113. , 1010. ,   60. ,  248. ,  248. ])
</code></pre>
<ul>
<li>mae를 구한다.</li>
<li>mae &#x3D; mean_absolute_error<ul>
<li>평균적 오차를 구하는 것이다.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae)</span><br></pre></td></tr></table></figure>

<ul>
<li>평균적으로 19g정도 다르다.</li>
</ul>
<h3 id="과대적합-vs-과소적합"><a href="#과대적합-vs-과소적합" class="headerlink" title="과대적합 vs 과소적합"></a>과대적합 vs 과소적합</h3><ul>
<li>공통점은 머신러닝 모형이 실제 테스트 시 잘 예측을 못함!</li>
<li>과대적합 : 훈련데이터에는 예측 잘함 &#x2F; 테스트 데이터에서는 예측을 잘 못함<ul>
<li>처리하기 곤란</li>
</ul>
</li>
<li>과소적합 : 훈련데이터에서는 예측을 못하고, 테스트데이터에서는 예측을 잘 함 or 둘다 예측을 잘 못함.<ul>
<li>데이터의 양이 적거나, 모델을 너무 간단하게 만듬!</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련 데이터 점수 확인하자.</span></span><br><span class="line">knr.score(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>0.9698823289099254
</code></pre>
<ul>
<li>0.97 정도 나옴</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Defult 5를 3으로 변경</span></span><br><span class="line"><span class="comment"># 머신러닝 모형을 살짝 변경</span></span><br><span class="line">knr.n_neighbors = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델을 다시 훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9804899950518966
</code></pre>
<ul>
<li>훈련데이터로 검증 0.98</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9746459963987609
</code></pre>
<ul>
<li>mae 구하기<ul>
<li>평균적 오차 구하기</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae)</span><br></pre></td></tr></table></figure>

<pre><code>35.42380952380951
</code></pre>
<ul>
<li>평균적으로 35.4g 다름</li>
</ul>
<h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><ul>
<li><p>k 그룹을 5로 했을 때, R2 점수는 0.98, MAE는 19 였음</p>
</li>
<li><p>k 그룹을 3로 했을 때, R2 점수는 0.97, MAE는 35 였음</p>
</li>
<li><p>k 그룹을 7로 했을 때, R2 점수는 0.97, MAE는 32 였음</p>
</li>
<li><p>Reference : 혼자 공부하는 머신러닝 + 딥러닝</p>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/python/machine-learning/">Previous</a></div><div class="pagination-next"><a href="/categories/python/machine-learning/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/python/machine-learning/">1</a></li><li><a class="pagination-link is-current" href="/categories/python/machine-learning/page/2/">2</a></li><li><a class="pagination-link" href="/categories/python/machine-learning/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">125</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">34</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/JPA/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="level-start"><span class="level-item">생활코딩</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/%EA%B8%B0%EC%B4%88/"><span class="level-start"><span class="level-item">기초</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"><span class="level-start"><span class="level-item">분석 방법</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/SQL/PL-SQL/"><span class="level-start"><span class="level-item">PL/SQL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Vue-js/"><span class="level-start"><span class="level-item">Vue.js</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Vue-js/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/chatbot/"><span class="level-start"><span class="level-item">chatbot</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/chatbot/kakao-chatbot/"><span class="level-start"><span class="level-item">kakao_chatbot</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/frontEnd/"><span class="level-start"><span class="level-item">frontEnd</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/frontEnd/html-css/"><span class="level-start"><span class="level-item">html &amp; css</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/frontEnd/javascript/"><span class="level-start"><span class="level-item">javascript</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/git/github-blog/"><span class="level-start"><span class="level-item">github blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/"><span class="level-start"><span class="level-item">library</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/numpy/"><span class="level-start"><span class="level-item">numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pandas/"><span class="level-start"><span class="level-item">pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pyspark/"><span class="level-start"><span class="level-item">pyspark</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/visualization/"><span class="level-start"><span class="level-item">visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/machine-learning/"><span class="level-start"><span class="level-item">machine learning</span></span><span class="level-end"><span class="level-item tag">22</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">데이터 전처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"><span class="level-start"><span class="level-item">비지도학습</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"><span class="level-start"><span class="level-item">알고리즘</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"><span class="level-start"><span class="level-item">인공신경망</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"><span class="level-start"><span class="level-item">자료형, 반복문, 조건문</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"><span class="level-start"><span class="level-item">클래스</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"><span class="level-start"><span class="level-item">함수</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/NiFi/"><span class="level-start"><span class="level-item">NiFi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/airflow/"><span class="level-start"><span class="level-item">airflow</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/anaconda/"><span class="level-start"><span class="level-item">anaconda</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/crawling/"><span class="level-start"><span class="level-item">crawling</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/elasticsearch/"><span class="level-start"><span class="level-item">elasticsearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/wsl2/"><span class="level-start"><span class="level-item">wsl2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-22T00:00:00.000Z">2023-06-22</time></p><p class="title"><a href="/2023/06/22/jpa_relation_mapping/">JPA 연관 관계 매핑</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-15T00:00:00.000Z">2023-06-15</time></p><p class="title"><a href="/2023/06/15/jpa_mapping/">JPA 엔티티 매핑</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-12T00:00:00.000Z">2023-06-12</time></p><p class="title"><a href="/2023/06/12/jpa_em/">JPA 영속석 컨텍스트</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-07T00:00:00.000Z">2023-06-07</time></p><p class="title"><a href="/2023/06/07/jpa_crud/">JPA CRUD</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-30T00:00:00.000Z">2023-05-30</time></p><p class="title"><a href="/2023/05/30/jpa_setting/">JPA 환경 설정 &amp; 실행</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/HTML/"><span class="tag">HTML</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JPA/"><span class="tag">JPA</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JPA-%EA%B8%B0%EC%B4%88/"><span class="tag">JPA 기초</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NiFi/"><span class="tag">NiFi</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Notion/"><span class="tag">Notion</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PL-SQL/"><span class="tag">PL/SQL</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R-Markdown/"><span class="tag">R Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VScord/"><span class="tag">VScord</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue-js/"><span class="tag">Vue.js</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue-js-%EA%B8%B0%EC%B4%88/"><span class="tag">Vue.js 기초</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anaconda/"><span class="tag">anaconda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/chatbot/"><span class="tag">chatbot</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawling/"><span class="tag">crawling</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-blog/"><span class="tag">github blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/heroku/"><span class="tag">heroku</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/javascript/"><span class="tag">javascript</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kakao-chatbot/"><span class="tag">kakao_chatbot</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/oracle/"><span class="tag">oracle</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgreSQL/"><span class="tag">postgreSQL</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="tag">생활코딩</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>