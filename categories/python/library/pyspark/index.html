<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: pyspark - kmk3593 blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="kmk3593 blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="kmk3593 blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="kmk3593 blog"><meta property="og:url" content="https://kmk3593.github.io/"><meta property="og:site_name" content="kmk3593 blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kmk3593.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kmk3593.github.io"},"headline":"kmk3593 blog","image":["https://kmk3593.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"kmk3593 blog","logo":{"@type":"ImageObject","url":"https://kmk3593.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/python/">python</a></li><li><a href="/categories/python/library/">library</a></li><li class="is-active"><a href="#" aria-current="page">pyspark</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-01T00:00:00.000Z" title="2022. 5. 1. 오전 9:00:00">2022-05-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-03T23:41:30.416Z" title="2022. 5. 4. 오전 8:41:30">2022-05-04</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">7 minutes read (About 1109 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/01/Spark_ML/">Spark ML</a></h1><div class="content"><ul>
<li>Spark로 머신러닝을 사용해 본다.</li>
<li>실용성과 별개로 경험삼아 작성해보는 코드이다.</li>
<li>머신러닝(ML)은 Scikit-Learn을 중점적으로 공부해야 한다.</li>
<li>딥러닝(DL)은 Tensorflow, Pytorch에 포커스를 맞춰야 한다.</li>
</ul>
<p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터밀널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark_ml 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 폴더, 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ 폴더 생성 : chapter03_ml</p>
<p>→ <code>cd chapter03_ml</code></p>
<ul>
<li>슬랙에서 data.zip 을 다운로드</li>
<li>압축을 풀고  chapter03_ml 폴더에 복사하여 옮긴다.</li>
</ul>
<p>→ 파일 생성 : step01_regression.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.regression import DecisionTreeRegressor</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.ml.feature import VectorAssembler</span><br><span class="line"></span><br><span class="line"># 세션 할당</span><br><span class="line">spark = SparkSession.builder.appName(&quot;DecisionTree&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line"># StructType 이 과정 생략</span><br><span class="line">data = spark.read.option(&quot;header&quot;, &quot;true&quot;).option(&quot;inferSchema&quot;, &quot;true&quot;).csv(&quot;data/realestate.csv&quot;)</span><br><span class="line"></span><br><span class="line"># 데이터 프레임을 행렬로 변환</span><br><span class="line">assembler = VectorAssembler().setInputCols([&#x27;HouseAge&#x27;, &#x27;DistanceToMRT&#x27;, &#x27;NumberConvenienceStores&#x27;]).setOutputCol(&quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 타겟데이터 설정</span><br><span class="line">df = assembler.transform(data).select(&quot;PriceofUnitArea&quot;, &quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 데이터 분리</span><br><span class="line">trainTest = df.randomSplit([0.5, 0.5])</span><br><span class="line">trainingDF = trainTest[0]</span><br><span class="line">testDF = trainTest[1]</span><br><span class="line"></span><br><span class="line"># Decision Tree 클래스 정의</span><br><span class="line">dtr = DecisionTreeRegressor().setFeaturesCol(&quot;features&quot;).setLabelCol(&quot;PriceofUnitArea&quot;)</span><br><span class="line"></span><br><span class="line"># 모델 학습</span><br><span class="line">model = dtr.fit(trainingDF)</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line"># 모델 예측</span><br><span class="line">fullPredictions = model.transform(testDF).cache()</span><br><span class="line"></span><br><span class="line"># 예측값과 Label을 분리</span><br><span class="line">predictions = fullPredictions.select(&quot;prediction&quot;).rdd.map(lambda x: x[0])</span><br><span class="line"></span><br><span class="line"># 실제데이터</span><br><span class="line">labels = fullPredictions.select(&quot;PriceofUnitArea&quot;).rdd.map(lambda x: x[0])</span><br><span class="line"></span><br><span class="line"># zip</span><br><span class="line">preds_label = predictions.zip(labels).collect()</span><br><span class="line"></span><br><span class="line">for prediction in preds_label:</span><br><span class="line">    print(prediction)</span><br><span class="line"></span><br><span class="line"># print(data.show())</span><br><span class="line"></span><br><span class="line"># 세션 종료</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step01_regression.py</code></p>
<p>→ 다음과 같이 출력된다.</p>
<p><img src="/images/Spark_ML/Untitled.png" alt="Untitled"></p>
<p><strong>pyspark_ml 실습(2)</strong></p>
<p>→ 파일 생성 : step02_logistic_regression.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 세션 할당</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.ml.classification import LogisticRegression # 기억</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(&quot;AppName&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">training = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)</span><br><span class="line">print(&quot;hello&quot;)</span><br><span class="line"></span><br><span class="line"># 모델 만들기</span><br><span class="line"># Scikit-Learn 문법과 비슷</span><br><span class="line">mlr = LogisticRegression() # 기억</span><br><span class="line">mlr_model = mlr.fit(training) # 기억</span><br><span class="line"></span><br><span class="line"># 로지스틱 회귀, 선형 모델.. 기울기와 상수</span><br><span class="line">print(&quot;Coefficients: &quot; + str(mlr_model.coefficients))</span><br><span class="line">print(&quot;Intercept: &quot; + str(mlr_model.intercept))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step02_logistic_regression.py</code></p>
<p><strong>pyspark_ml 실습(3)</strong></p>
<ul>
<li>pyspark_pipeline</li>
</ul>
<p>→ 파일 생성 : step03_pipeline.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">from tokenize import Token</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.classification import LogisticRegression</span><br><span class="line">from pyspark.ml.feature import HashingTF, Tokenizer</span><br><span class="line"></span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 세션 할당</span><br><span class="line">spark = SparkSession.builder.appName(&quot;MLPipeline&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 가상의 데이터 만들기</span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (0, &quot;a b c d e spark&quot;, 1.0),</span><br><span class="line">    (1, &quot;b d&quot;, 0.0),</span><br><span class="line">    (2, &quot;spark f g h&quot;, 1.0),</span><br><span class="line">    (3, &quot;hadoop mapreduce&quot;, 0.0)</span><br><span class="line">], [&quot;id&quot;, &quot;text&quot;, &quot;label&quot;])</span><br><span class="line"></span><br><span class="line"># Feature Engineering</span><br><span class="line"># 요리 작업</span><br><span class="line"></span><br><span class="line"># 요리준비 1단계 : 텍스트를 단어로 분리</span><br><span class="line">tokenizer = Tokenizer(inputCol=&#x27;text&#x27;, outputCol=&#x27;words&#x27;)</span><br><span class="line"></span><br><span class="line"># 요리준비 2단계 : 변환된 텍스트를 숫자로 변환</span><br><span class="line">hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line"># 요리준비 3단계 : 모델을 가져옴</span><br><span class="line">lr = LogisticRegression(maxIter=5, regParam=0.01)</span><br><span class="line"></span><br><span class="line"># 요리 시작</span><br><span class="line">pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line"># 메인재료 투하</span><br><span class="line">model = pipeline.fit(training)</span><br><span class="line"></span><br><span class="line"># Prepare test documents, which are unlabeled (id, text) tuples.</span><br><span class="line">test = spark.createDataFrame([</span><br><span class="line">    (4, &quot;spark i j k&quot;),</span><br><span class="line">    (5, &quot;l m n&quot;),</span><br><span class="line">    (6, &quot;spark hadoop spark&quot;),</span><br><span class="line">    (7, &quot;apache hadoop&quot;)</span><br><span class="line">], [&quot;id&quot;, &quot;text&quot;])</span><br><span class="line"></span><br><span class="line"># 예측</span><br><span class="line">prediction = model.transform(test)</span><br><span class="line">selected = prediction.select(&quot;id&quot;, &quot;text&quot;, &quot;probability&quot;, &quot;prediction&quot;)</span><br><span class="line">for row in selected.collect():</span><br><span class="line">    row_id, text, prob, prediction = row # 튜플</span><br><span class="line">    print(</span><br><span class="line">        # 문자열 포맷팅</span><br><span class="line">        &quot;(%d, %s) -------&gt; probability=%s, prediction=%f&quot; % (row_id, text, str(prob), prediction)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"># training.show()</span><br><span class="line"></span><br><span class="line"># 세션 종료</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step03_pipeline.py</code></p>
<p><img src="/images/Spark_ML/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark_ml 실습(3)</strong></p>
<p>→ 파일 생성 : step03_randomforest.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">from cProfile import label</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 머신러닝 라이브러리</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.classification import RandomForestClassifier</span><br><span class="line">from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">spark = SparkSession.builder.appName(&quot;RandomForest&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line">data = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)</span><br><span class="line">print(type(data))</span><br><span class="line"></span><br><span class="line"># Feature Engineering</span><br><span class="line"># label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&#x27;label&#x27;, outputCol=&#x27;indexedLabel&#x27;).fit(data)</span><br><span class="line"></span><br><span class="line"># 범주형 데이터 체크, 인덱스화</span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&#x27;features&#x27;,</span><br><span class="line">                               outputCol=&#x27;IndexedFeatures&#x27;, maxCategories=4).fit(data)</span><br><span class="line"></span><br><span class="line"># 데이터 분리</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.7, 0.3])</span><br><span class="line"></span><br><span class="line"># 모델</span><br><span class="line">rf = RandomForestClassifier(labelCol=&#x27;indexedLabel&#x27;, # 종속변수</span><br><span class="line">                            featuresCol=&#x27;IndexedFeatures&#x27;, # 독립변수</span><br><span class="line">                            numTrees=10)</span><br><span class="line"></span><br><span class="line"># outputCol=&#x27;indexedLabel&#x27; --&gt; original label로 변환</span><br><span class="line">labelConvereter = IndexToString(inputCol=&#x27;prediction&#x27;,</span><br><span class="line">                                outputCol=&#x27;predictedLabel&#x27;, labels=labelIndexer.labels)</span><br><span class="line"></span><br><span class="line"># 파이프라인 구축</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConvereter])</span><br><span class="line"></span><br><span class="line"># 모델 학습</span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"># 모델 예측</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"># 행에 표시할 것 추출</span><br><span class="line">predictions.select(&quot;predictedLabel&quot;, &#x27;label&#x27;, &#x27;features&#x27;).show(5)</span><br><span class="line"></span><br><span class="line"># 모형 평가</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %f &quot; % (1.0 - accuracy))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step04_randomforest.py</code></p>
<p><img src="/images/Spark_ML/Untitled%202.png" alt="Untitled"></p>
<h3 id="팁"><a href="#팁" class="headerlink" title="팁"></a>팁</h3><p>venv 생성되어 있는 경로로 이동</p>
<p>→ pip install jupyterlab</p>
<p>→ jupyter lab</p>
<p>→ 주피터랩에서 블로그에 올릴 자료 작성 가능.</p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-28T00:00:00.000Z" title="2022. 4. 28. 오전 9:00:00">2022-04-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-01T01:16:28.899Z" title="2022. 5. 1. 오전 10:16:28">2022-05-01</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 768 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/28/pyspark_practice03/">pyspark 실습03</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터밀널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 폴더, 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ 폴더 생성 : chapter02_get_cleansing</p>
<ul>
<li>슬랙에서 data.zip 을 다운로드</li>
<li>압축을 풀고 chapter02_get_cleansing 파일에 복사하여 옮긴다.</li>
</ul>
<p>→ 파일 생성 : pipeline.py</p>
<p><img src="/images/pyspark_practice03/Untitled.png" alt="Untitled"></p>
<ul>
<li>코드를 작성해본다.</li>
</ul>
<p>→ 코드 작성</p>
<p><code>from pyspark.sql import SparkSession</code></p>
<p><code>from pyspark.sql.functions import *</code></p>
<p><code>print(&quot;Hello!&quot;)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter02_get_cleansing</code></p>
<p>→ 실행 : <code>python pipeline.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ pipeline.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.functions import *</span><br><span class="line">from pyspark.sql import functions as F</span><br><span class="line"></span><br><span class="line"># print(&quot;Hello!!&quot;)</span><br><span class="line"></span><br><span class="line"># 스파크 세션을 생성</span><br><span class="line">spark = SparkSession.builder.master(&quot;local[1]&quot;).\</span><br><span class="line">    appName(&quot;quickpipeline&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line"># 데이터 불러오기</span><br><span class="line">df = spark.read.csv(&quot;data\AA_DFW_2015_Departures_Short.csv.gz&quot;</span><br><span class="line">                    , header = True)</span><br><span class="line"></span><br><span class="line">print(&quot;file loaded&quot;)</span><br><span class="line"></span><br><span class="line">print(df.show())</span><br><span class="line"></span><br><span class="line"># remove duration = 0</span><br><span class="line">df = df.filter(df[3] &gt; 0)</span><br><span class="line"></span><br><span class="line"># ADD ID column</span><br><span class="line">df = df.withColumn(&#x27;id&#x27;, F.monotonically_increasing_id())</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">df.write.csv(&quot;data/output.csv&quot;, mode = &quot;overwrite&quot;)</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python pipeline.py</code></p>
<p>→ output.csv 가 생성되면 성공이다.</p>
<p><img src="/images/pyspark_practice03/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<ul>
<li>온도를 측정하는 코드를 작성해본다.</li>
<li>슬랙에서 다운로드<ul>
<li>1800.csv, book.txt, customer-orders.csv, fakefriends.csv</li>
</ul>
</li>
<li>chapter02_get_cleansing&#x2F;data 파일에 복사하여 옮긴다.</li>
</ul>
<p>파일 생성 : min_temp.py</p>
<p>→ 코드 작성</p>
<p><code>from pyspark import SparkConf, SparkContext</code></p>
<p><code>conf = SparkConf().setMaster(&#39;local&#39;).setAppName(&#39;MinTemperatures&#39;)</code></p>
<p><code>sc = SparkContext(conf = conf)</code></p>
<p><code>print(&quot;Hello&quot;)</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ min_temp.py를 다음과 같이 작성</p>
<p>from pyspark import SparkConf, SparkContext</p>
<p>conf &#x3D; SparkConf().setMaster(‘local’).setAppName(‘MinTemperatures’)</p>
<p>sc &#x3D; SparkContext(conf &#x3D; conf)</p>
<p>print(“Begins…”)</p>
<p>def parseLine(line):</p>
<p>fileds &#x3D; line.split(‘,’) # 문자열을 split</p>
<p>stationID &#x3D; fileds[0]</p>
<p>entryType &#x3D; fileds[2]</p>
<p>temperature &#x3D; float(fileds[3]) * 0.1 * (9.0 &#x2F; 5.0) + 32.0</p>
<p>return (stationID, entryType, temperature)</p>
<p>lines &#x3D; sc.textFile(‘data&#x2F;1800.csv’)</p>
<p>#print(lines)</p>
<p>parseLines &#x3D; lines.map(parseLine)</p>
<p>#print(parseLine)</p>
<p>minTemps &#x3D; parseLine.filter(lambda x : “TMIN” in x[1])</p>
<p>stationTemps &#x3D; minTemps.map(lambda x: (x[0], x[2]))</p>
<p>minTemps &#x3D; stationTemps.map(lambda x, y: min(x,y))</p>
<p>results &#x3D; minTemps.collect()</p>
<p>print(results)</p>
<p>→ 저장 후 실행</p>
<p>→ <code>python min_temp.py</code></p>
<p><strong>pyspark 실습(3)</strong></p>
<ul>
<li>나이를 출력하는 코드를 작성해보자</li>
</ul>
<p>파일 생성 : friends-by-age.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;FriendsByAge&quot;)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">def parseLine(line):</span><br><span class="line">    fields = line.split(&#x27;,&#x27;)</span><br><span class="line">    age = int(fields[2])</span><br><span class="line">    numFriends = int(fields[3])</span><br><span class="line">    return (age, numFriends)</span><br><span class="line"></span><br><span class="line">lines = sc.textFile(&quot;logs/fakefriends.csv&quot;)</span><br><span class="line">rdd = lines.map(parseLine)</span><br><span class="line">totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))</span><br><span class="line">averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])</span><br><span class="line">results = averagesByAge.collect()</span><br><span class="line">for result in results:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python friends-by-age.py</code></p>
<p><strong>pyspark 실습(4)</strong></p>
<p>파일 생성 : totalspent.py</p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 라이브러리 불러오기</span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"># 사용자 정의 함수</span><br><span class="line">def extractCusPrice(line):</span><br><span class="line">    fields = line.split(&quot;,&quot;)</span><br><span class="line">    return (int(fields[0]), float(fields[2]))</span><br><span class="line"></span><br><span class="line"># main 함수</span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    # 스파크 설정</span><br><span class="line">    conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&#x27;SpentbyCustomer&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    # 데이터 불러오기</span><br><span class="line">    input = sc.textFile(&quot;data/customer-orders.csv&quot;)</span><br><span class="line">    # print(&quot;is data?&quot;)</span><br><span class="line">    mappedInput = input.map(extractCusPrice)</span><br><span class="line">    totalByCustomer = mappedInput.reduceByKey(lambda x, y : x + y)</span><br><span class="line">		# 정렬</span><br><span class="line">    filpped = totalByCustomer.map(lambda x: (x[1], x[0]))</span><br><span class="line">    totalByCustomerStored = filpped.sortByKey()</span><br><span class="line"></span><br><span class="line">    results = totalByCustomer.collect()</span><br><span class="line">    for result in results:</span><br><span class="line">        print(result)</span><br><span class="line"></span><br><span class="line"># 실행 코드</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python totalspent.py</code></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-27T00:00:00.000Z" title="2022. 4. 27. 오전 9:00:00">2022-04-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-30T01:49:22.246Z" title="2022. 4. 30. 오전 10:49:22">2022-04-30</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">4 minutes read (About 632 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/27/pyspark_practice02/">pyspark 실습02</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>git bash로 VSCord에 들어가 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><strong>pyspark 실습(1)</strong></p>
<ul>
<li>가상환경 진입하고 파일 생성</li>
</ul>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step04_structype.py</p>
<p>키워드 : Struct Type</p>
<p>구글링 : Spark Struct Type, Spark Struct </p>
<p>참고 링크 :  </p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> Struct</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func </span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당 (필수)</span></span><br><span class="line"><span class="comment"># spark = SparkSession.builder.appName(&quot;&quot;)</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">toMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count().orderBy(func.desc(<span class="string">&#x27;count&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(movies_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 저장 후 실행</p>
<p>→ <code>python step04_structype.py</code></p>
<p>→ 다음 테이블이 출력되어야 한다.</p>
<p><img src="/images/pyspark_practice02/Untitled.png" alt="Untitled"></p>
<p><strong>pyspark 실습(2)</strong></p>
<p>→ chapter01_get_starged 폴더에서 파일 생성</p>
<p>→ 파일 생성 : step05_advancestructype.py</p>
<p>→ 코드 작성</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadMovieNames</span>():</span><br><span class="line">    movieNames = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(<span class="string">&quot;ml-100k/u.ITEM&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;ISO-8859-1&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            fields = line.split(<span class="string">&quot;|&quot;</span>)</span><br><span class="line">            movieNames[<span class="built_in">int</span>(fields[<span class="number">0</span>])] = fields[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> movieNames</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 할당</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이썬 딕셔너리 객체를 Spark 객체로 변환</span></span><br><span class="line">nameDict = spark.sparkContext.broadcast(loadMovieNames())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 스키마 작성 (u.logs 데이터)</span></span><br><span class="line">schema = StructType(</span><br><span class="line">    [</span><br><span class="line">        StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>)</span><br><span class="line">        , StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Schema is done&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">movies_df = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;ml-100k/u.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 내림차순으로 인기있는 영화 정렬</span></span><br><span class="line"><span class="comment"># movieID 그룹바이. count() orderby</span></span><br><span class="line">topMovieIds = movies_df.groupBy(<span class="string">&quot;movieID&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 딕셔너리</span></span><br><span class="line"><span class="comment"># key-value</span></span><br><span class="line"><span class="comment"># 키 값을 알면 value 자동으로 가져옴 (movieTitle)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lookupName</span>(<span class="params">movieID</span>):</span><br><span class="line">    <span class="keyword">return</span> nameDict.value[movieID]</span><br><span class="line"></span><br><span class="line">lookupNameUDF = func.udf(lookupName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MovieTitle 기존 topMovieIds 데이터에 추가</span></span><br><span class="line"><span class="comment"># 컬럼을 추가</span></span><br><span class="line">moviesWithNames = topMovieIds.withColumn(<span class="string">&quot;movieTitle&quot;</span>, lookupNameUDF(func.col(<span class="string">&quot;movieID&quot;</span>)))</span><br><span class="line"></span><br><span class="line">final_df = moviesWithNames.orderBy(func.desc(<span class="string">&quot;count&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_df.show(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 세션 종료</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ <code>python step05_advancestructype.py</code></p>
<p>→ 다음과 같이 출력된다.</p>
<p><img src="/images/pyspark_practice02/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>Reference : <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-26T00:00:00.000Z" title="2022. 4. 26. 오전 9:00:00">2022-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-29T12:29:53.952Z" title="2022. 4. 29. 오후 9:29:53">2022-04-29</time></span><span class="level-item"> minkuen </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/library/">library</a><span> / </span><a class="link-muted" href="/categories/python/library/pyspark/">pyspark</a></span><span class="level-item">5 minutes read (About 685 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/26/pyspark_practice01/">pyspark 실습01</a></h1><div class="content"><p><strong>사전준비</strong></p>
<ul>
<li>spark on windows 참고하여 세팅 </li>
<li>스파크를 설치한다.</li>
<li>만약, 파이썬이 처음이라면 **<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual">Anaconda</a>**를 설치한다.</li>
</ul>
<p><strong>pyspark 설치</strong></p>
<ul>
<li>git bash를 이용해 폴더를 생성하고 터미널을 연다.</li>
</ul>
<p>바탕화면 우클릭 : git bash here</p>
<p>→ <code>mkdir pyspk_project</code></p>
<p>→ <code>cd pyspk_project</code></p>
<p>→ <code>code .</code></p>
<p>→ git bash 터미널</p>
<p><img src="/images/pyspark_practice01/Untitled.png" alt="Untitled"></p>
<ul>
<li>가상환경 생성 후 pyspark 설치</li>
</ul>
<p>→ <code>virtualenv venv</code></p>
<p>→ <code>source venv/Scripts/activate</code></p>
<p>→ <code>pip install pyspark</code></p>
<p><img src="/images/pyspark_practice01/Untitled%201.png" alt="Untitled"></p>
<p><strong>pyspark 실습_1</strong></p>
<ul>
<li>폴더 파일 생성</li>
</ul>
<p>→ 폴더 생성 : chapter01_get_started</p>
<p>→ 파일 생성 : <code>step01_basic.py</code></p>
<p>→ 코드 작성</p>
<p><code>import pyspark</code></p>
<p><code>print(pyspark.__version__)</code></p>
<p>→ 저장</p>
<p>→ 경로 이동 : <code>cd chapter01_get_started</code></p>
<p>→ 실행 : <code>python step01_basic.py</code></p>
<p><img src="/images/pyspark_practice01/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>이어서 코드작성</li>
</ul>
<p>→ step01_basic.py를 다음과 같이 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import pyspark</span><br><span class="line">print(pyspark.__version__)</span><br><span class="line"></span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line"># 스파크 세션 초기화</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;SampleTutorial&#x27;).getOrCreate()</span><br><span class="line">rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])</span><br><span class="line"></span><br><span class="line">print(&quot;rdd Count:&quot;, rdd.count())</span><br></pre></td></tr></table></figure>

<p>→ 저장 후 실행</p>
<p>→ 주소창에 입력 :  <a target="_blank" rel="noopener" href="http://localhost:4040/">http://localhost:4040/</a></p>
<p>→ 다음 화면이 출력된다.</p>
<ul>
<li>교재 278p</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%203.png" alt="Untitled"></p>
<p><strong>pyspark 실습_2</strong></p>
<ul>
<li>슬랙에서 dataset.zip 을 다운로드</li>
<li>압축을 풀고 chapter01_get_started 파일에 복사하여 옮긴다.</li>
</ul>
<p><img src="/images/pyspark_practice01/Untitled%204.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step02_ratings.py</code></p>
<p>→ 코드 작성</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># SparkContext</span><br><span class="line"># RDD</span><br><span class="line"></span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line">import collections</span><br><span class="line"></span><br><span class="line">print(&quot;Hello&quot;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # MasterNode = local</span><br><span class="line">    # MapReduce</span><br><span class="line"></span><br><span class="line">    conf = SparkConf().setMaster(&#x27;local&#x27;).setAppName(&#x27;RatingsHistogram&#x27;)</span><br><span class="line">    sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line">    lines = sc.textFile(&quot;ml-100k/u.logs&quot;)</span><br><span class="line">    ratings = lines.map(lambda x: x.split()[2])</span><br><span class="line">    print(&quot;ratings: &quot;, ratings)</span><br><span class="line"></span><br><span class="line">    result = ratings.countByValue()</span><br><span class="line">    print(&quot;result:&quot;, result)</span><br><span class="line"></span><br><span class="line">    sortedResults = collections.OrderedDict(sorted(result.items()))</span><br><span class="line">    for key, value in sortedResults.items():</span><br><span class="line">        print(&quot;%s %i&quot; % (key, value))</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step02_ratings.py</code></p>
<p>→ 다음 결과가 출력된다.</p>
<p><img src="/images/pyspark_practice01/Untitled%205.png" alt="Untitled"></p>
<ul>
<li>VSCord에서 작업</li>
</ul>
<p>→ 파일 생성 : <code>step03_dataloading.py</code></p>
<p>→ 코드 작성</p>
<p>→ pip install pandas</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># Spark SQL 적용</span><br><span class="line"></span><br><span class="line"># Spark Session</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 스파크 세션 생성</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">my_spark = SparkSession.builder.getOrCreate()</span><br><span class="line">print(my_spark)</span><br><span class="line"></span><br><span class="line"># 테이블을 확인하는 코드</span><br><span class="line">print(my_spark.catalog.listDatabases())</span><br><span class="line"></span><br><span class="line"># show database</span><br><span class="line">my_spark.sql(&#x27;show databases&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 현재 DB 확인</span><br><span class="line">my_spark.catalog.currentDatabase()</span><br><span class="line">my_spark.stop()</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># CSV 파일 불러오기</span><br><span class="line">spark = SparkSession.builder.master(&#x27;local[1]&#x27;).appName(&#x27;DBTutorial&#x27;).getOrCreate()</span><br><span class="line">flights = spark.read.option(&#x27;header&#x27;, &#x27;true&#x27;).csv(&#x27;data/flight_small.csv&#x27;)</span><br><span class="line"># flights.show(4)</span><br><span class="line"></span><br><span class="line"># spark.catalog.currentDatabase()</span><br><span class="line"># flights 테이블을 default DB에 추가함</span><br><span class="line">flights.createOrReplaceTempView(&#x27;flights&#x27;)</span><br><span class="line"></span><br><span class="line"># print(spark.catalog.listTables(&#x27;default&#x27;))</span><br><span class="line"># spark.sql(&#x27;show tables from default&#x27;).show()</span><br><span class="line"></span><br><span class="line"># 쿼리 통해서 데이터 저장</span><br><span class="line">query = &quot;FROM Fligths SELECT * LIMIT 10&quot;</span><br><span class="line">query2 = &quot;SELECT * FROM flights 10&quot;</span><br><span class="line"></span><br><span class="line"># 스파크에 세션할당</span><br><span class="line">flights10 = spark.sql(query2)</span><br><span class="line">flights10.show()</span><br><span class="line"></span><br><span class="line"># Spark 데이터 프레임을 Pandas 데이터 프레임을 변환</span><br><span class="line">pd_flights10 = flights10.toPandas()</span><br><span class="line">print(pd_flights10.head())</span><br></pre></td></tr></table></figure>

<p>→ 저장</p>
<p>→ 실행 : <code>python step03_dataloading.py</code></p>
<ul>
<li>Reference<ul>
<li>실무 예제로 배우는 데이터</li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html">https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html</a></li>
</ul>
</li>
</ul>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">120</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">34</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/JPA/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/JavaScript/"><span class="level-start"><span class="level-item">JavaScript</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="level-start"><span class="level-item">생활코딩</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/%EA%B8%B0%EC%B4%88/"><span class="level-start"><span class="level-item">기초</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"><span class="level-start"><span class="level-item">분석 방법</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/SQL/PL-SQL/"><span class="level-start"><span class="level-item">PL/SQL</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/SQL/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Vue-js/"><span class="level-start"><span class="level-item">Vue.js</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Vue-js/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/chatbot/"><span class="level-start"><span class="level-item">chatbot</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/chatbot/kakao-chatbot/"><span class="level-start"><span class="level-item">kakao_chatbot</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/frontEnd/"><span class="level-start"><span class="level-item">frontEnd</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/frontEnd/html-css/"><span class="level-start"><span class="level-item">html &amp; css</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/frontEnd/javascript/"><span class="level-start"><span class="level-item">javascript</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/git/github-blog/"><span class="level-start"><span class="level-item">github blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/"><span class="level-start"><span class="level-item">library</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/library/numpy/"><span class="level-start"><span class="level-item">numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pandas/"><span class="level-start"><span class="level-item">pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/pyspark/"><span class="level-start"><span class="level-item">pyspark</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/python/library/visualization/"><span class="level-start"><span class="level-item">visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/machine-learning/"><span class="level-start"><span class="level-item">machine learning</span></span><span class="level-end"><span class="level-item tag">22</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">데이터 전처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"><span class="level-start"><span class="level-item">비지도학습</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"><span class="level-start"><span class="level-item">알고리즘</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"><span class="level-start"><span class="level-item">인공신경망</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">기초문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"><span class="level-start"><span class="level-item">자료형, 반복문, 조건문</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"><span class="level-start"><span class="level-item">클래스</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"><span class="level-start"><span class="level-item">함수</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/NiFi/"><span class="level-start"><span class="level-item">NiFi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/airflow/"><span class="level-start"><span class="level-item">airflow</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/anaconda/"><span class="level-start"><span class="level-item">anaconda</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/crawling/"><span class="level-start"><span class="level-item">crawling</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/elasticsearch/"><span class="level-start"><span class="level-item">elasticsearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/oracle/"><span class="level-start"><span class="level-item">oracle</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/postgreSQL/"><span class="level-start"><span class="level-item">postgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/wsl2/"><span class="level-start"><span class="level-item">wsl2</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-24T00:00:00.000Z">2023-05-24</time></p><p class="title"><a href="/2023/05/24/jpa_base/">JPA 개념</a></p><p class="categories"><a href="/categories/JPA/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-04T00:00:00.000Z">2023-05-04</time></p><p class="title"><a href="/2023/05/04/vue_cli_practice/">Vue Cli 실습</a></p><p class="categories"><a href="/categories/Vue-js/">Vue.js</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-03T00:00:00.000Z">2023-05-03</time></p><p class="title"><a href="/2023/05/03/vue_cli/">Vue Cli</a></p><p class="categories"><a href="/categories/Vue-js/">Vue.js</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-22T00:00:00.000Z">2023-04-22</time></p><p class="title"><a href="/2023/04/22/vue_router/">Vue 라우터</a></p><p class="categories"><a href="/categories/Vue-js/">Vue.js</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-21T00:00:00.000Z">2023-04-21</time></p><p class="title"><a href="/2023/04/21/vue_component/">Vue 컴포넌트</a></p><p class="categories"><a href="/categories/Vue-js/">Vue.js</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/HTML/"><span class="tag">HTML</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JPA/"><span class="tag">JPA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JPA-%EA%B8%B0%EC%B4%88/"><span class="tag">JPA 기초</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NiFi/"><span class="tag">NiFi</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Notion/"><span class="tag">Notion</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PL-SQL/"><span class="tag">PL/SQL</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R-Markdown/"><span class="tag">R Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VScord/"><span class="tag">VScord</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue-js/"><span class="tag">Vue.js</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue-js-%EA%B8%B0%EC%B4%88/"><span class="tag">Vue.js 기초</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anaconda/"><span class="tag">anaconda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/chatbot/"><span class="tag">chatbot</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawling/"><span class="tag">crawling</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-blog/"><span class="tag">github blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/heroku/"><span class="tag">heroku</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/javascript/"><span class="tag">javascript</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kakao-chatbot/"><span class="tag">kakao_chatbot</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/oracle/"><span class="tag">oracle</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgreSQL/"><span class="tag">postgreSQL</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"><span class="tag">생활코딩</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="kmk3593 blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>