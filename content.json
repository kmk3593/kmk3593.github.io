{"pages":[],"posts":[{"title":"chapter_8_1","text":"합성곱 신경망 코드보다는 용어 정리가 중요하다 더 나은 정확도를 위한 발전 과정 로지스틱 회귀 (일반 ML 모형) : 81% 인공신경망 (딥러닝 초기 모형) : 87% 합성곱 (Convolution, CNN) 합성곱 (CNN) 이미지의 특성을 뽑아내는 과정 합성곱에서는 뉴런이 입력층 위를 이동하면서 출력을 만든다. = 도장을 연상하라 합성곱 층의 뉴런에 있는 가중치 개수는 하이퍼 파라미터이다. 발전사 : alexnet -&gt; resnet -&gt; efficientnet 채널, 이미지의 너비, 크기 (파라미터 튜닝) Vision Transformer 비디오 객체인식(Object Detection) Yolo 논문 RNN / LSTM (자연어 처리) 구글 2017년 Transformer (논문) 필터 (filter) 합성곱에서의 뉴런 뉴런 개수를 이야기할 때 필터라 칭한다. 합성곱에서는 완전 연결 신경망과 달리 뉴런을 필터라 부른다. 혹은 커널(kernel)이라 부른다. 입력에 곱해지는 가중치를의미할 때 커널이라 부른다. 합성곱의 장점 기존 : 1차원 배열에서만 연산이 가능 2차원 배열에도 연산을 할 수 있도록 구현 입력이 2차원 배열이 되므로 필터도 2차원이다. 선형대수를 공부해야 하나요?? 1234from tensorflow import keraskeras.layers.Conv2D(10, # 필터(즉, 도장)의 개수 kernel_size=(3,3), # 필터에 사용할 커널의 크기 activation = 'relu') # 활성화 함수 지정 &lt;keras.layers.convolutional.Conv2D at 0x7f6c99df5c90&gt; 패딩 (padding) 입력 배열의 주위를 가상의 원소로 채우는 것. 실제 입력값이 아니기 때문에 패딩은 0으로 채운다. 실제 값은 0으로 채워져 있기에 계산에 영향을 미치지 않는다. 세임 패딩 (same padding) : 입력 주위에 0으로 패딩 하는 것 밸리드 패딩 (valid padding) : 패딩 없이 순수한 입력 배열에서만 합성곱하여 특성 맵을 마드는 것 패딩의 목적 배열의 크기를 조정하더라도 이미지 원 특성이 손실되는 것을 방지하는 것 스트라이드 (stride) 기존에 합성곱 연산은 좌우, 위아래로 한 칸씩 이동했다. 두 칸씩 건너뛸 수도 있다. 이런 이동의 크기를 ‘스트라이드’라고 한다. 두 칸씩 이동하면 특성 맵의 크기가 더 작아진다. 커널 도장을 찍는 횟수가 줄어들기 때문. 디폴트는 1칸 이동이다. 12345keras.layers.Conv2D(10, # 필터(즉, 도장)의 개수 kernel_size=(3,3), # 필터에 사용할 커널의 크기 activation='relu', # 활성화 함수 지정 padding = 'same', # 세임 패딩 strides = 1) # 1칸씩 이동 &lt;keras.layers.convolutional.Conv2D at 0x7f6c992ba8d0&gt; 풀링 (pooling) 값을 추출 100 x 100 이미지 –&gt; (수치로) 주요 이미지의 특성만 뽑은 후, 원 이미지와 같게 만듬 (50 x 50) 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. 특성맵의 크기를 줄이지는 않는다. 합성곱처럼 입력 위를 지나가면서 도장을 찍는다. 하지만, 풀링에는 가중치가 없다. 최대 풀링 (max pooling) 도장을 찍은 영역에서 가장 큰 값을 고른다. 평균 풀링 (average pooling) 도장을 찍은 영역에서 평균값을 계산한다. 특성 맵이 여러 개라면 동일한 작업을 반복한다. 즉, 10개의 특성 맵이 있다면 풀링을 거친 특성맵도 10개가 된다. 풀링 영역은 풀링의 크기만큼 이동한다. 즉, 겹치지 않고 이동한다. 풀링의 크기가 (2,2)이면 가로세로 두 칸씩 이동한다. 풀링은 가중치가 없고 풀링 크기와 스트라이드가 같다. 123keras.layers.MaxPooling2D(2, # 풀링의 크기. 대부분은 2로 둔다. strides=2, # 2칸씩 이동. 풀링의 크기와 같게 설정된다. padding='valid') # 풀링은 패딩을 하지 않으므로 'valid'로 지정. &lt;keras.layers.pooling.MaxPooling2D at 0x7f6c99253e90&gt; 기억할 점 풀링은 가로세로 방향으로만 진행한다. 특성 맵의 개수는 변하지 않고 그대로이다. 합성곱 신경망의 전체 구조 p437 1단계 : 이미지 데이터 입력 2단계 : 합성곱 층 (1) kernel_size + padding (2) 활성화 함수 적용 (3) 각각의 특성맵을 산출 3단계 : 풀링층 (1) Max Pooling : 최댓값 추출 (2) 최종 특성맵 위 과정을 계속 반복하는 것이 CNN 알고리즘 4단계 : 밀집층 (Fully Connected Layer) Chapter 7장 3차원 배열을 1차원으로 펼친다. (Flatten 클래스) 출력층의 입력이 된다. 5단계 : 분류 예측값을 산출 (Softmax 활성화 함수) 지정한 활성화 함수를 거쳐 최종 예측 확률이 된다. 주요 키워드 : 사전학습(Pretrained) / 전이학습 (Transfer Learning) / 파인 튜닝(Fine Tuning) 다른 사람이 작성한 학습 코드를 사용한다. 파인 튜닝 : 미세 조정하는 것이다. 캐글 경진대회에서 주로 사용. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/08/Chapter_8_1/"},{"title":"R 기초","text":"*** R 기초 강의 내용을 정리한 글입니다.==3.10================================================== R 설치, 초기설정, 기초. 구글 검색 : R English 버전으로 다운로드. 구글 검색 : Rstudio IDE 다운로드 - Desktop 버전. free 다운로드 *가능하면 관리자 권한으로 설치하라 [Rstudio] 새 스크립트] new file → Rscript 초기 설정] tools → gobal option → code → editing -&gt; soft-wrap R source files 체크→ saving → change → utf-8로 변경 글씨 조정 기능] tools → gobal option → appearance 코드 실행] ctrl + Enter 코드 저장] ctrl + s 프로젝트 생성] 우측 상단 : project : none ⇒ new project ⇒ new directory ⇒ new project ⇒ 파일이름 : temp 생성 스크립트 저장] 스크립트 생성 ⇒ ctrl + s ⇒ 이름 : ch01 생성 라이브러리 설치] 구글 검색 : Rtools → using rtools on window → 64bit 버전 다운로드 →관리자 권한으로 install 실행. → 에러 발생 시) 단체 채팅 방 링크로 들어가 4번 영상을 참고. → 에러 발생 시) 원 드라이브 비활성화 *경로에 한글이 있어도 에러. 라이브러리 사용] 스크립트에 다음 내용을 복사 붙여넣기 → 실행 → 저장 → 종료write('PATH=&quot;${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}&quot;', file = &quot;~/.Renviron&quot;, append = TRUE) → temp 파일 켜기 → 스크립트에 다음 내용을 복사 붙여넣기Sys.which(&quot;make&quot;) → 실행 → console 창에 sys.which(”make”) 가 출력되면 성공. → 다음 내용을 복사 붙여넣기install.packages(&quot;jsonlite&quot;, type = &quot;source&quot;) → 실행 → DONE (jsonlite) 출력 시 성공. → 다음 내용을 복사 붙여넣기install.packages(&quot;tidyverse&quot;) install.packages(”ggplot2”) → 실행 → 다운로드 완료 → 다음 내용을 복사 붙여넣고 각각 실행 library(ggplot2)library(tidyverse)iris &lt;- iris → console 창에 iris←iris 가 출력되면 성공.→ 다음 내용을 복사 붙여넣기 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) + geom_point() → 실행 → 우측의 plot에 그림이 출력되면 성공 [GitHub] gitHub 회원가입 구글 검색 : git → git download → window → 64bit 다운로드 시스템 환경 변수 편집 → 시스템 환경 변수 → 시스템 변수 : path → 편집 → cmd있는지 확인 다음 링크 → code → 복사 https://github.com/dschloe/R_edu 바탕화면 → 우클릭 → git bench here → git 창에 다음 내용 입력. → 바탕화면 : R_edu 파일 생성 시 성공 $ git clone https://github.com/dschloe/R_edu.git (cd Desktop에서 설치가 진행되어야 한다.) 바탕화면 → R_edu 파일 → R_edu 실행 [패키지] 여러 함수를 모아놓은 것 패키지 설치 : install.packages(”패키지 이름”) 패키지 구동 : library(패키지 이름) 다음 링크 → packeges → 원하는 것을 찾아 사용. The Comprehensive R Archive Network (r-project.org) 예시) ggplot2의 패키지 → packages에서 ctrl + F 로 검색. → 메뉴얼 읽고 사용. *ggplot2는 R참고서 201p에 기재되어있다. 사용 예시) The Comprehensive R Archive Network (r-project.org) → packages → Table of available packages, sorted by date of publication → (원하는 패키지를 ctrl + F로 찾아서 선택) ggplot2 → reference manual : ggplot2.pdf 를 클릭 → (index에서 원하는 함수를 선택해 이동) → Example 항목을 찾아서 복사 → 스크립트에 붙여넣기 → 스크립트 맨 위에 install.packagese(함수 이름) 작성 → 실행 → 사용 가능. 다음 명령을 스크립트에서 실행 library(ggplot2) install packages(”writexl”)library(writexl) library(ggplot2) // 다운 받은 것을 가져와서 사용한다는 의미 ggplot() *이후에 R 심화 과정을 원할 경우 참고 : 원서 https://r4ds.had.co.nz/ 그래프 시각화 지원 https://www.r-graph-gallery.com/ [그래프 시각화 지원 plot 사용 ] Basic ridgeline plot – the R Graph Gallery (r-graph-gallery.com) 위 링크의 코드 복사 → 스크립트에 붙여넣기 → 실행. [치트 시트] 자주 사용하는 것들을 모아놓은 것. Rstudio → help → cheat sheets → browser cheat sheets 또는 data visualization with ggplot2 위 과정대로 진행 시 cheat seet가 다운로드 됨. RStudio Cheatsheets - RStudio chapter 1. 기초 문법1 / 100 * 30 a &lt;- 1 / 100 * 30b &lt;- 1 / 1000 a &lt;- “A그룹” # (x) a &lt;- “A그룹”groupA &lt;- “A그룹”group_A &lt;- “A그룹”group.A &lt;- “A그룹” r_basics &lt;- 3r_basics 변수 유형 확인 예시class(r_basics)class(group_A) temp &lt;- TRUEclass(temp) [3장 데이터 타입] R을 이용한 공공데이터 분석 36p. chapter 2.벡터 만들기num_vector = c(1,2,3)print(num_vector)class(num_vector) char_vector = c(“A”,”B”,”C”)print(char_vector)class(char_vector) logical_vector = c(TRUE, FALSE, FALSE)print(logical_vector)class(logical_vector) (1) 예외temp = c(1, “1”, 2)print(temp)class(temp) // 모두 문자화 temp = c(1, FALSE, TRUE)print(temp)class(temp) // 모두 숫자화 temp = c(“A”,FALSE, TRUE)print(temp)class(temp) // 모두 문자화 ####(2) 범주형 변수 #####비서열 척도 = 명목형 척도location_vector = c(“서울”, “경기”,”대구”, “광주”)fct_vector = factor(location_vector)print(fct_vector)class(fct_vector) 결과) print(fct_vector)[1] 서울 경기 대구 광주Levels: 경기 광주 대구 서울class(fct_vector)[1] “factor” #서열 척도fct_vector2 = factor(location_vector,ordered=TRUE)print(fct_vector2)class(fct_vector2) 결과) print(fct_vector2)[1] 서울 경기 대구 광주Levels: 경기 &lt; 광주 &lt; 대구 &lt; 서울class(fct_vector2)[1] “ordered” “factor” ==3.11================================================== dplyr 함수 사용하기 &amp; 어떤 로컬에 있든 불러오기 &amp; 시각화 install.packages(“패키지명”)library(dplyr) # 데이터 가공 이름 &lt;- c(“evan”, “윤석열”, “이재명”)나이 &lt;- c(20, 30, 40)지각 &lt;- c(TRUE, FALSE, FALSE) students &lt;- data.frame(name = 이름,age = 나이,atte = 지각) str(students) #경로확인getwd() #파일저장 write.csv(x = students, file = “학생.csv”) #엑셀로 내보내기install.packages(”writexl”)library(writexl) write_xlsx(x=student, path= ”학생.xlsx”) #모두 지우기rm(list=ls()) #파일 불러오기getwd() students &lt;- read.csv(“학생.csv”) ****중요 위 파란 부분이 가장 오래 걸리는 부분이다. sql 문법과 유사하여, dplyr패키지를 배운 뒤, sql을 배우면 보다 빠르게 쿼리 작성에 능숙해질 수 있음 #dplyr 패키지 library(dplyr) iris ← iris str(iris) iris %&gt;% #~에서 # 150개, 5개의 변수 select(Sepal.Length, Sepal.width) %&gt;% # 150개, 2개 filter(Sepal.Length &gt; 6) %&gt;% # 61개, 2개의 변수 .. .. head(10) → iris2 # 10개, 2개의 변수 ?head() 구글 검색 : dplyr → 쿠라레? → 다음링크 → dplyr.pdf CRAN - Package dplyr (r-project.org) 로우데이터=가공되지 않은 데이터 dplyr = 데이터 가공 과제: 교재 98p에서부터 명령어 하나씩 써보기 과제: 하루에 코딩 5,6 시간 강사님이 카톡으로 전송한 data, solution 파일 다운로드 r_edu 파일로 실행 → 다음과 같은 경로로 폴더를 연다 → 1_2_dplyr 실행. 위 그림에서 ‘(톱니바퀴 모양) more’→ set as working directory # 경로 잡기 1_2_dplyr 파일에서 다음 내용을 실행 counties &lt;- readxl::read_xlsx(“counties.xslx”, sheet = 1). 만약 에러나오면 다음과 같이 data/ 를 추가하거나, read의 괄호안에서 Tab으로 찾아라. counties &lt;- readxl::read_xlsx(“data/counties.xslx”, sheet = 1) [restats 파일 부르기] 다음을 실행. getwd()stats &lt;- read.csv(“data/restats.csv””) # restats.csv [파일 미리보기] glimpse(counties) 실행 → 안되면, library(dplyr) 실행 후에 다시 실행. 강사님이 카톡으로 전송한 public dataset 파일 다음 경로에 다운로드 바탕화면 → solution → data → () 여기에 다운로드. 새스크립트 : dplyr_practice 만들고 1 or 2 선택해서 해보기 책 99p에 있는 코드부터 알아서 실행해보기. 구글 검색:r-4 data → 5 data transformation 참고해서 실행해보기 QnA) 교재 104p 참고 → :: 에 대한 질문. 불러올 때는 더블콜론(::)을 이용해서 불러오시오 install.packages(”hflights”) library(hflights) # 불러와서 씀 hflights = hflights::hflights # 임시로 잠깐 씀 둘다 비슷한 기능. [불러오는 법] 경로는 more → set as working directory 에서 잡고 위치는 read.csv(””) 에서 tab으로 찾아 들어가라. 불러오는 법 ex) more → set as working directory 다음 같은 형식으로 실행. getwd() student &lt;- read.csv(“source_2021/1_day_eda/data/student.csv”) mpg1 &lt;- read.csv(“source_2021/1_day_eda/data/public_dataset/mpg1.csv”) 강사님이랑 1_2_dplyr 스크립트의 내용을 따라감. glimpse , select, arrange, filter, mutate 등 배움. count, summarise 등 배움. summarise에 앞서 엑셀의 피벗테이블 개념 숙지. 피벗테이블 = 엑셀에서 시트의 일부분을 엮어 세팅하는 정보 테이블 다음을 참고. 엑셀 | 피벗 테이블(Pivot Table) 만드는 방법 – ㈜소프트이천 (soft2000.com) group by 사용 예시 counties %&gt;%select(state, population, private_work, public_work, self_employed) %&gt;%group_by(state) %&gt;%summarise(min_pop = min(population),max_pop = max(population),avg_pop = mean(population)) [시각화] 수많은 데이터를 분석해야 하지만 한 눈에 들어오도록 하는 것은 쉽지 않다. 방대한 데이터를 한 눈에 보이게 만드는 것이 시각화이다. 시각적 요소를 이용해 대량의 데이터를 강제로 인지시킨다고 한다. *참고) 구글검색 : inf learn → 시각화 구글검색 : dacon → 시각화 경진대회 &amp; 참가자 제출물 참고하기. 구직자를 위한 기업 트렌드 시각화 경진대회 - DACON 구글검색 : the R graph 갤러리, 유니콘 https://exts.ggplot2.tidyverse.org/gallery/ 깃허브 : 강사님 깃 https://github.com/IndrajeetPatil/ggstatsplot [시각화 코딩] 바탕화면 → R_edu → 금융데이터사이언스 스킬업.pdf → p51 참고 ggplot(data = data, aes(x = x축, y = y축)) + geon_poinrt() + ylim(3,6) 코딩 예시) library(ggplot2) iris &lt;- irisstr(iris) ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) + geom_abline() + 옵션 [시각화 저장] 위 코드 실행 → plot에 시각화 자료 출력. → export → save as image → directory → 바탕화면으로 설정 → save 팁 ?명령어 → 실행 → 해당 명령어의 메뉴얼이 출력된다. 과제 ==3.14================================================== 시각화. 나이팅게일 -간호사, 통계학자 -전쟁 중 사고 나서, 총이나 칼, 포탄 → 통념) 죽는 사람 많을 거라 생각.(현장 모르는 분) -위생&amp;부상 → 실제) 죽는 사람이 훨씬 많음(현장을 아는 분) -제안 : 위생 강화 &amp; 야전 병원을 좀 더 짓자 → 설득 : 그래프를 이용한 시각적 통계 시각화 표 : “금융데이터사이언스 스킬업.pdf” 53p 참고. [시각화 실습] 질병 관련 통계. temp 프로젝트 오픈. → 새 스크립트 → 0314.R 만들기. 바탕화면 → data → who_disease 불러와서 사용 . 데이터 불러오기library(dplyr)library(ggplot2)library(readxl) who_disease &lt;- read_xlsx(“who_disease.xlsx”) iris &lt;- irisglimpse(iris) 데이터 확인glimpse(who_disease) 산점도 그려보기(의미없음)ggplot(who_disease, aes(x=year,y=cases)) +geom_point() 투명도 주기ggplot(who_disease, aes(x=year,y=cases)) +geom_point(alpha=0.3) 투명도,색 주기ggplot(who_disease, aes(x=year,y=cases)) +geom_point(alpha=0.3, colour = “red”, size=10) 그룹화ggplot(who_disease, aes(x=year,y=cases,colour=region))+geom_point() 0314.R 에 다음 내용 복사 붙여 넣기. R_edu → … → solution → 1_3_ggplot 의 ( 64 line~끝 line ) 까지 긁어서 실습. install.packages(”waffle”) install.packages(“carData”) install.packages(“ggpol”) install.packages(“ggcorrplot”) install.packages(“mosaicData”) install.packages(“visreg”) install.packages(“gapminder”) install.packages(“ggpubr”) install.packages(“ggthemes”) install.packages(“nycflights13”) install.packages(“reshape”) #install.packages(“gcookbook”) install.packages(“ggthemes”) *팁 : 구글 검색 영어로 검색하라. how to code 또는 how to write로 시작하라. ex) how to write yaxis dollar sign ggplot2 [시각화 실습] R_edu → … → solution → 1_4_ggplot 실습. [옵션 이용하기] *367p 참고 *메뉴얼 참고 R Markdown: The Definitive Guide (bookdown.org) Rstudio → File 아래 (+)마크 클릭 → R Markdown → title, author 작성하고 OK → 생성됨 → 작명:report로 저장 → .rmd 확장자로 저장됨. → 톱니모양 옆에 ‘knit’ 클릭 → 관련 정보가 출력된다. R Markdown 언어 작성 → (+)마트 달린 ‘c’ 아이콘을 클릭 → R 선택 → R 작성 가능 창이 출력됨 → 입력 후 실행 → knit에 반영됨. 다음과 같은 식으로 report.Rmd에 적고 knit을 출력해보아라. 웹에서도 knit을 확인할 수 있다. knit은 desktop→data→report.html 클릭→ view in web *팁 아래의 R작성 가능 창에 install.packages를 올리지 말고 따로 install만 해놓면 library만 작성해도 잘 돌아간다. 4. 데이터 전처리1) 분석파일을 R로 불러오기123library(dplyr)library(ggplot2) 메뉴얼https://bookdown.org/yihui/rmarkdown/ 2) 시각화 코드 데이터를 불러와서 Sepal.Length, Sepal.Width 두 변수에 관한 산점도 시각화를 작성한다. 123ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) + geom_point() [배포] knit 출력 → 우측 상단의 ‘publish’ → Rpubs (무료버전) → publish →create an account → 내용을 임의로 작성하고 ‘continue’ → 주소를 복사해 카톡으로 전송 →본인 핸드폰으로 접속해본다. → 성공 시 knit 내용이 반영된 페이지에 접속됨. → 배포 : 페이지 게시 완료 [시각화 실습] R_edu → … → solution → 1_5_ggplot 실습. → 125 line ~ end of document 구글링 : ggplot extensions → 마음에 드는 테마를 적용 가능. → 테마 이름을 참고하여 다운로드 ex) install.packages(“ggthemes”) → 사용 예시를 보고 사용 ex) p + theme_stata() [시각화 실습] R_edu → … → solution → 1_6_ggplot 실습 → 폰트 적용 연습 [R 참고서적] 추가적인 공부를 원할 때 참고하라. -R data visualization -데이터 시각화 교과서 -R을 활용한 데이터 시각화 ==3.15================================================== 통계. [데이터 분석] -데이터수집 -데이터가공 -데이터시각화 -모델링 : 통계 모델링 / 머신러닝 모델링 / 딥러닝 모델링 -통계를 도대체 어디까지 알아야 하나? -선형대수를 얼마나 알아야 하나? -Top-Down방식 / Bottom-up방식 -모델링과 관련된 수식을 얼마나 알아야 하나? [진로와 관련] : 웹 개발자 → 라이브러리 자 갔다 쓰고, 배포 잘하면 끝. : 데이터 분석가 → 마케터(기획) / 여론조사 -기본적인 통계(고재 8장 통계 분석) -모수 검정 / 비모수 검정 —&gt; 빈도 주의 -베이지안 : 머신러닝 엔지니어 / 딥러닝 엔지니어 -통계 / 선형대수 필요 / 모델링 수식 굳이… -모형 만들고 배포를 잘해야 함(개발자) -포폴 : 머신러닝 논문 정리(최신) -라이브러리로 이미 만들어져 있음 -구글링 : paperswithcode → 딥러닝 관련내역 : 머신러닝 / 리서쳐 알고리즘 직접 구현 -최소 석사(관련 논문) -네이버,카카오AI -라이브러리를 직접 만드시는 분들 :Top-down 방식 -분석의 방향(수치 예측/분류 위주 예측) -그룹간의 비교/인과관계 -산업분야 [ 기초 통계 ] 참고temp → 2_day_stat_reggression → data → 기초 통계-평균,중간값,분산,표준편차.pdf deviation: 편차x1 : 개별 관찰값x : 평균 vlariance : 분산 (= 편차 제곱의 평균)x1: 개별 관찰값x : 평균 분산값이 크다 —&gt; 평균으로부터 멀어진 개별적인 데이터가 많다. = 흩어져있다. 분산값이 작다 —&gt; 평균주위에 개별적인 데이터가 많다. = 평균쪽에 몰려있다. 즉, 분산은 평균으로부터 떨어진 거리를 나타냄. 모집단과 분산 *참고 temp → 2_day_stat_reggression → data → 기초 통계-변동계수.pdf CV= 변동계수RSD= 상대 표준 편차평균 : u표준편차 : o install.packages(“tidyquant”) install.packages(“reshape2”) *참고 temp → 2_day_stat_reggression → data → 기초 통계-사분위수.pdf 이상치 판별: 중심에서 많이 떨어진 값을 의미 이상치 하한 Q1 - 1.5x(Q3-Q1) 이상치 상한 Q3 + 1.5x(Q3-Q1) [통계 실습] 슬랙 → #edu 채널 → 3/15에 게시된 ‘3교시 코드’ 참고 *참고 temp → 2_day_stat_reggression → data → 기초통계-z_score.pdf X = 원 데이터 M = 평균 SD = 표준편차 *참고 temp → 2_day_stat_reggression → data → 기초통계-z_test.pdf ❑ 가설검정(Hypothesis Testing) -평균에 대한 가설 검정-잘못된 가정: 대한민국 성인의 키는 크다-올바른 가정: 대한민국 성인의 평균 키는 170cm 이다 . ❑귀무가설 및 대립가설 o 귀무가설(H0)-내용: 대한민국 성인의 평균 키는 170cm이다.-통계적 표시법: H0: u = 170 o 대립가설(H1) 내용• 평균 키는 170이 아니다. = 제1형 = 양측검정• 평균 키는 170보다 작다. = 제2형 = 단측검정 = 좌측 검정• 평균 키는 170보다 크다. = 제3형 = 단측검정 = 우측 검정 ❑ 가설 선택의 기준 수립 1종 오류(type 1 error) → 제1종 오류는 우리가 모집단에 효과가 진짜로 존재한다고 믿지만 사실은 아무런 효과도 없는 것이다. 2종 오류(type 2 error) → 제1종 오류와는 반대이다. 즉, 모집단에 실제로 효과가 존재하지만 우리는 모집단에 아무 효과도 존재하지 않는다고 믿는 것이 제2종 오류이다. o 유의수준 제 1종 오류를 범할 확률의 최대 허용 한계 (유의수준 a) 표는 z_test.pdf 참고. [통계 실습] temp → 2_day_stat_reggression → source → 2_5_1_hypothesis_testing.R temp → 2_day_stat_reggression → source → 2_5_2_one_sample.R temp → 2_day_stat_reggression → source → 2_5_3_paired_t_test.R *참고 temp → 2_day_stat_reggression → data → 기초통계-??? 두 평균의 비교 (대응 표본 vs 독립표본) 단일 표본 T-Test 차이가 있는가? (모집단 vs 표본) 두개 표본 T-Test 대응표본 예시 : 신약 개발 시험 (사전 테스트 + 사후 테스트) 독립표본 예시 : 남자와 여자의 몸무게 비교 공통 사항 검정 정규성 검정 여부 확인 데이터 T-Test는 정규성 여부 확인을 전제로 만들어져서 단일 모집단 검정시에도 정규성 여부 조건을 확인해야 한다. ex) 레벨이 부족할 때 고레벨 전용 아이템을 사용 못하는 것과 같다. ==3.16================================================== R의 마지막 [전날 수업 내용 정리]기초통계의 핵심 : 평균편차 : 평균과 개별적인 데이터 사이의 거리분사(variance) : 편차의 제곱합의 데이터 객수만큼 나눔표준편차 : 분산에 루트 씌운다표준편차 + 평균 활용변동계수, z-score, 검정값, 표준오차모수 검정핵심: 두 그룹간의 평균의 차이를 검정두 그룹간의 차이가 유의미하냐? 우연히, 어쩌다가 한 번 일어난거냐!가정 : 데이터가 정규분표를 이룬다!평균 비교One Sample T Test : 모집단의 평균 ~ 샘플(표본)의 평균대응표본 : 사전 표본의 평균(정책, 신약 투여 등등 시간이 지난 후) 사후 표본의 평균독립표본 : A 그룹과 B그룹간의 평균 비교결국은 평균을 비교하는 것. 귀무가설 ~ 대립가설귀무가설 : 두 그룹가의 00평균의 차이가 없다!대립가설 : 두 그룹간의 평균의 차이는 존재하더라!t 통계량 / p-value 구글링 : 표준정규분포표 → 표를 보고 p-value값을 계산하면 된다 *팁 ‘우리 나라 석사 학위 논문’ 구글링 : RISS 하여 들어가서 찾아서 보면 된다. 논문은 별거 아니다. 다만, 데이터 수집하는 것이 가장 어렵다. [기초통계-분산분석]*참고 temp → 2_day_stat_reggression → data → 기초통계-분산분석.pdf 예를들어, 어느 학교의 3개의 반의 성적을 비교한다고 할 때, 3번을 비교해야한다. 분산분석: 두 개 이상 다수의 집단을 서로 평균에서 분산값을 비교하기 위한 가설검정 방법 F분표: 분산의 비교를 통해 얻어진 분표비율 계산식 -1학년 전체 학생 인원의 분산 : 300명 ( 분산=100) // 표본 내 분산 -각 반의 분산 // 표본 평균 간 분산 1반의 분산 90 2반의 분산 70 . . 가설수립-귀무가설 : 3학년 1,2,3반의 평균은 모두 같다. -대립가설: 적어도 1개반의 평균은 다르다. F통계량 공식-F = 검정통계량 -F통계량은 오차의 평균제곱합과 처리의 평균제곱합의 비인 MST/MSE -이를 나타내는 두 개의 자요도(k-1, n-k)를 모수로 하는 F-분포를 따르는 F 통계량 F = MST/MSE~F(k-1,m-k) -MSE(오차 평균 제곱합) : 처리’내’ 제곱합을 자유도로 나눈 값 -MST(처리 평균 제곱합) : 처리’간’ 제곱합을 자유도로 나눈 값 일원분산분석 모형검정통계량 구하기-분산 : 각 개별 자료값과 평균과의 차이 -총편차 : 개별자료와 전체 평균(y)과의 차 총 제곱합 (SST) = 오차제곱합(SSE) + 처리제곱합(SST) [통계 실습] temp → 0314 스크립트 생성 분산분석라이브러리 불러오기library(dplyr)library(ggplot2) 데이터 수집 및 가공my_data = PlantGrowthmy_data$group &lt;- ordered(my_data$group, levels=c(“ctrl”,”trt1”,”trt2”)) my_data %&gt;%group_by(group) %&gt;%summarise(count = n(),mean = mean(weight, na.rm= TRUE),sd = sd(weight, na.rm = TRUE)) ggplot(my_data, aes(x=group, y=weight))+geom_boxplot() one=way ANOVA 테스트오차제곱합(SSE)ctrl &lt;- my_data$weight[my_data$group==”ctrl”]trt1 &lt;- my_data$weight[my_data$group==”trt1”]trt2 &lt;- my_data$weight[my_data$group==”trt2”] ctrl_mean = mean(ctrl)trt1_mean = mean(trt1)trt2_mean = mean(trt2) 각 처리별 제곱합ctrl_sse = sum((ctrl-ctrl_mean)^2)trt1_sse = sum((trt1-trt1_mean)^2)trt2_sse = sum((trt2-trt2_mean)^2) 오차의 제곱합sse &lt;- ctrl_sse + trt1_sse + trt2_ssesse 오차의 자유도dfe &lt;- (length(ctrl)-1) + (length(trt1)-1) + (length(trt2)-1) 처리의 제곱합 구하기 (SST)total_mean = mean(my_data$weight)ctrl_sst = length(ctrl) * sum((ctrl_mean - total_mean) ^ 2)trt1_sst = length(trt1) * sum((trt1_mean - total_mean) ^ 2)trt2_sst = length(trt2) * sum((trt2_mean - total_mean) ^ 2) 처리 제곱합sst = ctrl_sst + trt1_sst + trt2_sst 처리 제곱합의 자유도dft = length(levels(my_data$group)) - 1 전체 제곱합과 분해된 제곱합의 합 구하기tsq = sum((my_data$weight - total_mean) ^ 2)ss = sst + sse #총 제곱합 all.equal(tsq, ss) # TRUE 검정 통계량mst = sst / dftmse = sse / dfe f.t = mst / msef.t alpha = 0.5tol &lt;- qf(1-alpha, 2, 27)tol p.value = 1-pf(f.t, 2, 27)p.value # 0.0159… 즉, 적어도 반 하나의 평균은 다르다.위의 모든 과정을 아래의 코드로 축약 가능res.aov &lt;- aov(weight ~ group, data =my_data)summary(res.aov) # p-value = 0.0159… 회귀식의 기본 공식*참고 바탕화면 → R-edu → 금융데이터사이언스 스킬업.pdf → 101p 참고 회귀 : 이전 데이터를 바탕으로 앞으로의 일을 예상하는 것 예시) 날씨 &amp; 온도 에 따른 아이스 아메리카노 판매량 온도, 강우, 위치 —&gt; 설명변수, 독립변수 판매량 —&gt; 종속변수, 반응변수 결과i = (model) + 오차i model = 최소제곱법 model = 기울기 * 예측변수의 점수 + 절편 # 절편 = 기본으로(최소한도) 팔리는 아아 판매량 결정 계수( R-squared) : 회귀모델의 추정된 회귀식이 관측된 데이터를 설명하고 있는 비율을 계수로 나타낸 것 : R 교재 186p 참고 팁구글링 : wikidocs → Must learning With R (개정판) = e-book → 통계 관련 내용 참고 Must Learning with R (개정판) - WikiDocs 스캔파일 → 앤디 필드의 유쾌한 R 통계학 → 머신러닝 있어서 어려움 &amp; 에러도 섞여있을 것. 유쾌한 알 통계학.pdf - OneDrive (live.com) 강의실 pc에 다운로드 완료 Reference : R을 이용한 공공데이터 분석","link":"/2022/03/21/R_start/"},{"title":"chapter1_3","text":"혼자 공부하는 머신 러닝 + 딥러닝생선 분류 문제 한빛 마켓에서 팔기 시작한 생선은 ‘도미’, 곤들매기’, ‘농어’, ‘강꼬치고기’, ‘로치’, ‘빙어’, ‘송어’이다. 이 생선들을 프로그램으로 분류한다고 가정해 보자. 어떻게 프로그램을 만들어야 할까. 도미 데이터 준비하기 우선 생선의 특징을 알기 쉽게 구분해보자. 예를들어 30cm이상인 생선은 도미라고 한다. 12#if fish_length &gt;= 30:# print(&quot;도미&quot;) 하지만 이는 절대적인 기준이 될 수 없다. 기준을 제대로 파악하기 위한 과정을 수행해보자. 데이터는 다음 링크를 참고하라.: https://gist.github.com/rickiepark/b37d04a95a42ef6757e4a99214d61697 다음 코드는 35마리의 도미의 길이와 생선의 무게에 대한 데이터이다. 123456bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] 위 리스트에서 첫 번째 도미의 길이는 25.4cm, 무게는 242.0g이다. 각 도미의 특징을 길이와 무게로 표현했음을 알 수 있다. 책에서는 이런 특징을 특성(feature)이라 부른다. 길이인 bream_length를 x축으로 삼는다. 무게인 bream_weight를 y축으로 한다. 이를 토대로 각 도미를 그래프에 점으로 표시해 보자. 이런 그래프를 산점도(scatter plot)라 부른다. 123456import matplotlib.pyplot as plt # matplotlib의 pyplot 함수를 plt로 줄여서 사용plt.scatter(bream_length, bream_weight)plt.xlabel('length') # x 축은 길이plt.ylabel('weight') # y 축은 무게plt.show() 도미 35마리를 2차원 그래프에 점으로 나타냈다. 생선의 길이가 길수록 무게가 많이 나간다고 생각하면 이 그래프는 매우 자연스럽다. 이렇게 산점도 그래프가 일직선에 가까운 형태로 나타나는 경우를 선형적(linear)이라고 한다. 빙어 데이터 준비하기 이번엔 빙어의 데이터를 준비해 보자. 데이터는 다음 링크를 참고하라 : https://gist.github.com/rickiepark/1e89fe2a9d4ad92bc9f073163c9a37a7 다음 코드는 14 마리의 빙어에 대한 데이터이다. 12smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 빙어는 도미에 비해 크기도 작고 무게도 가볍다. 빙어의 데이터도 산점도로 그려보자. 하는 김에 도미와 빙어의 산점도를 비교한다. 12345plt.scatter(bream_length, bream_weight)plt.scatter(smelt_length, smelt_weight)plt.xlabel('length')plt.ylabel('weight')plt.show() Matplotlib에 의해 두 산점도 색깔이 다르게 출력된다. 주황색 점이 빙어의 산점도이며 도미에 비해 길이도 무게도 작다. 또한 빙어는 도미와 달리 길이가 늘어나도 무게가 크게 늘지 않는다는 것을 알 수 있다. 첫 번째 머신러닝 프로그램 가장 간단하고 이해하기 쉬운 k-최근접 이웃(k-Nearest Neighbors) 알고리즘을 사용해 도미와 비엉 데이터를 구분해본다. 알고리즘 사용 이전에 앞서 준비했던 두 생선의 데이터를 합친다. 12length = bream_length + smelt_lengthweight = bream_weight + smelt_weight 책에서 사용하는 머신러닝 패키지는 사이컷런(scikit-learn)이다. 이 패키지를 이용하여 각 특성의 리스트를 세로 방향으로 늘어뜨린 2차원 리스트를 만들어야 한다. 이렇게 만들기 위해서 파이썬의 zip() 함수와 리스트 내포(list comprehension)구문을 사용한다. zip() 함수는 나열된 리스트 각각에서 하나씩 원소를 꺼내 반환한다. zip() 함수와 리스트 내포 구문을 사용해 length와 weight 리스트를 2차원 리스트로 만들어보자. 1fish_data = [[l, w] for l, w in zip(length, weight)] for문은 zip() 함수로 length와 weight 리스트에서 원소를 하나씩 꺼내어 l과 w에 할당한다. 그러면 [l, w] 가 하나의 원소로 구성된 리스트가 만들어진다. 1print(fish_data) [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] 2차원 리스트 첫 번째 생선의 길이 25.4cm와 무게 242.0g이 하나의 리스트를 구성하고 이런 리스트가 모여 전체 리스트를 만들었다. 이런 리스트를 2차원 리스트 혹은 리스트의 리스트라고 부른다. 생선 49개의 데이터가 준비되었다. 이제 마지막으로 준비할 데이터는 정답 데이터이다. 각 데이터가 실제로는 어떤 생선인지 정답지를 만드는 작업니다. 정답 리스트 머신러닝은 물론이고 컴퓨터 프로그램은 문자를 직접 이해하지 못한다. 대신 도미와 빙어를 숫자 1과 0으로 표현해보자 앞서 도미와 방어를 순서대로 나열했기에 정답 리스트는 1이 35번 등장하고 0이 14번 등장한다. 12fish_target = [1] * 35 + [0] * 14print(fish_target) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 이제 사이킷런 패키지에서 k-최근접 이웃 알고리즘을 구현한 클래스인 KNeighborsClassifier를 임포트한다. 1from sklearn.neighbors import KNeighborsClassifier 임포트한 KNeighborsClassfier 클래스의 객체를 먼저 만든다. 1kn = KNeighborsClassifier() 훈련 이 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시킨다. 이런 과정을 머신러닝에서는 훈련(training)이라 부른다. 사이킷런에서는 fit() 메서드가 이런 역할을 한다. 이 메서드에 fish_data 와 fish_target 을 순서대로 전달해보자. 1kn.fit(fish_data, fish_target) KNeighborsClassifier() 평가 fit() 메서드는 주어진 데이터로 알고리즘을 훈련한다. 이제 객체(또는 모델) kn이 얼마나 잘 훈련되었는지 평가해봐야 한다. 사이킷런에서 모델을 평가하는 메서드는 score()메서드이다. 이 메서드는 0에서 1 사이의 값을 반환한다. 1은 모든 데이터를 정확히 맞혔다는 것을 나타낸다. 예를 들어 0.5라면 절반만 맞혔다는 의미이다. 1kn.score(fish_data, fish_target) 1.0 정확도 1.0 이 출력되었다. 모든 fish_data의 답을 정확히 맞혔다는 뜻이 된다. 이러한 값을 정확도(accuracy)라고 부른다. k-최근접 이웃 알고리즘 앞에서 첫 번째 머신러닝 프로그램을 성공적으로 만들었다. 여기에서 사용한 알고리즘은 k-최근접 이웃이다. 이 알고리즘은 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용하다. 마치 근묵자흑과 같이 주위의 데이터로 현재 데이터를 판단하는 것이다. 예를 들어, 이전에 출력한 산점도에서 삼각형으로 표시된 새로운 데이터가 있다고 가정해 보자. 이 삼각형은 도미와 빙어 중 어디에 속할까? 이 삼각형이 도미의 데이터 부근에 위치해 있다면 도미라고 판단할 것이다. k-최급접 이웃 알고리즘도 마찬가지이다. 실제 코드로도 그런지 한 번 확인해 보자. 1kn.predict([[30, 600]]) # 2차원 리스트 array([1]) predict() 메서드 predict() 메서드는 새로운 데이터의 정답을 예측한다. 이 메서드도 앞서 fit() 메소드와 마찬가지로 2차원 리스트를 전달해야 한다. 그래서 삼각형 포인트를 리스트로 2번 감싼것이다. 반환되는 값은 1. 우리는 앞서 도미는 1, 빙어는 0으로 가정했다. 즉, 삼각형은 도미이다. k-최근접 이웃 알고리즘을 위해 준비해야 하는 것은 데이터를 모두 가지고 있는 것 뿐이다. 새로운 데이터에 대해 예측할 때는 가장 가까운 직선거리에 어떤 데이터가 있는지를 살피기만 하면 된다. 단점으로는 이런 특징 때문에 데이터가 아주 많은 경우 사용하기 어렵다는 점이 있다. 사이킷런의 KNeighborsClassifier 클래스도 마찬가지이다. 이 클래스는 _fit_X 속성에 우리가 전달한 fish_data를 모두 가지고 있다. 또 _y 속성에 fish_target을 가지고 있다. 1print(kn._fit_X) [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] 1print(kn._y) [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 실제로 k-최근접 이웃 알고리즘은 무언가 훈련되는 게 없는 셈이다. fit()메서드에 전달한 데이터를 모두 저장하고 있다가 새로운 데이터가 등장하면 가장 가까운 데이터를 참고하여 어떤 생선인지 구분한다. 그럼 가까운 몇 개의 데이터를 참고할까? 이는 정하기 나름이다. KNeighborsClassifier 클래스의 기본값은 5이다. 이 기준은 n_neighbors 매개변수로 바꿀 수 있다. 예를 들어, 다음 코드 실행 시 어떤 결과가 나올까? 1kn49 = KNeighborsClassifier(n_neighbors=49) # 참고 데이터를 49개로 한 kn49 모델 가장 가까운 데이터 49개를 사용하는 k-최근접 이웃 모델에 fish_data를 적용하면 fish_data에 있는 모든 생선을 사용하여 예측하게 된다. 다시 말하면 fish_data의 데이터 49개 중에 도미가 35개로 다수를 차지하므로 어떤 데이터를 넣어도 무조건 도미로 예측할 것이다. 12kn49.fit(fish_data, fish_target)kn49.score(fish_data, fish_target) 0.7142857142857143 fish_data에 있는 생선 중에 도미가 35개이고 빙어가 14개이다. kn49모델은 도미만 올바르게 맞히기 때운에 다음과 같이 정확도를 계산하면 score() 메서드와 같은 값을 얻을 수 있다. 1print(35/49) 0.7142857142857143 확실히 n_neighbors 매개변수를 49로 두는 것은 좋지 않다. 기본 값을 5로 하여 도미를 완벽하게 분류한 모델을 사용하기로 한다. 도미와 빙어 분류 (중간 정리) 지금까지 도미와 빙어를 구분하기 위해 첫 머신러닝 프로그램을 만들었다. 먼저 도미 35마리와 빙어 14마리의 길이와 무게를 측정해서 파이썬 리스트로 만든다. 그 다음 도미와 빙어 데이터를 합친 2차원 리스트를 준비했다. 사용한 머신러닝 알고리즘은 k-최근접 이웃 알고리즘이다. 사이킷런의 k-최근접 이웃 알고리즘은 주변에서 가장 가까운 5개의 데이터를 보고 다수결의 원칙에 따라 데이터를 예측한다. 이 모델은 준비된 데이터를 모두 맞혔다. 도미와 빙어를 분류하는 문제를 풀면서 KNeighborsClassifier 클래스의 fit(), score(), predict() 메서드를 사용해 보았다. 끝으로 k-최근접 이웃 알고리즘의 특징을 알아보았다. 전체 소스 코드123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 마켓과 머신러닝# 생선 분류 문제# 도미 데이터 준비하기bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0] bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]import matplotlib.pyplot as plt # matplotlib의 pyplot 함수를 plt로 줄여서 사용plt.scatter(bream_length, bream_weight)plt.xlabel('length') # x 축은 길이plt.ylabel('weight') # y 축은 무게plt.show()# 빙어 데이터 준비하기smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]plt.scatter(bream_length, bream_weight)plt.scatter(smelt_length, smelt_weight)plt.xlabel('length')plt.ylabel('weight')plt.show()# 첫 번째 머신러닝 프로그램length = bream_length + smelt_lengthweight = bream_weight + smelt_weightfish_data = [[l, w] for l, w in zip(length, weight)]print(fish_data)fish_target = [1] * 35 + [0] * 14print(fish_target)from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(fish_data, fish_target)kn.score(fish_data, fish_target)# k-최근접 이웃 알고리즘plt.scatter(bream_length, bream_weight)plt.scatter(smelt_length, smelt_weight)plt.scatter(30, 600, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()kn.predict([[30, 600]]) # 2차원 리스트print(kn._fit_X)print(kn._y)kn49 = KNeighborsClassifier(n_neighbors=49) # 참고 데이터를 49개로 한 kn49 모델kn49.fit(fish_data, fish_target)kn49.score(fish_data, fish_target)print(35/49) [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 0.7142857142857143 마무리키워드로 끝내는 핵심 포인트 특성 : 데이터를 표현하는 하나의 성질. 이 절에서 생선 데이터 각각을 길이와 무게 특성으로 나타냈다. 훈련 : 머신러닝 알고리즘이 데이터에서 규칙을 찾는 과정. 사이킷런에서는 fit() 메서드가 하는 역할이다. k-최근접 이웃 알고리즘 : 가장 간단한 머신러닝 알고리즘 중 하나. 사실 어떤 규칙을 찾기보다는 전체 데이터를 메모리에 가지고 있는 것이 전부이다. 모델 : 머신러닝 프로그램에서는 알고리즘이 구현된 객체를 모델이라 부른다. 종종 알고리즘 자체를 모델이라고 부르기도 한다. 정확도 : 정확한 답을 몇 개 맞혔는지를 백분율로 나타낸 값이다. 사이킷런에서는 0~1 사이의 값으로 출력된다. 정확도 = (정확히 맞힌 개수) / (전체 데이터 개수) 핵심 패키지와 함수 matplotlib scatter()는 산점도를 그리는 Matplotlib 함수이다. 처음 2개의 배개변수로 x축과 y축 값을 전달한다. 이 값은 파이썬 리스트 또는 넘파이 배열이다. c 매개변수로 색깔을 지정한다. scikit-learn KneighborsClassifier()는 k-최근접 이웃 분류 모델을 만드는 사이킷런 클래스이다. n_neighbors 매개변수로 이웃의 개수를 지정한다. 기본값은 5이다. p 매개변수로 거리를 재는 방법을 지정한다. 1일 경우 맨해튼 거리(https://bit.ly/man_distance)를 사용한다. 2일 경우 유클리디안 거리(https://bit.ly/euc_distance)를 사용한다. 기본 값은 2이다. fit()은 사이킷런 모델을 훈련할 때 사용하는 메서드이다. 처음 두 매개변수로 훈련에 사용할 특성과 정답 데이터를 전달한다. predict()는 사이킷런 모델을 훈련하고 예측할 때 사용하는 메서드이다. 특성 데이터 하나만 매개변수로 받는다. score()는 훈련된 사이킷런 모델의 성능을 측정한다. 처음 두 매개변수로 특성과 정답 데이터를 전달한다. 이 매서드는 먼저 predict() 메서드로 예측을 수행한 다음 분류 모델일 경우 정답과 비교해 맞게 예측한 개수의 비율을 반환한다. 확인 문제 데이터를 표현하는 하나의 성질로써, 예를 들어 국가 데이터의 경우 인구 수, GDP, 면적 등이 하나의 국가를 나타냅니다. 머신러닝에서 이런 성질을 무엇이라 부르나요? 특성 v 특질 개성 요소 가장 가까운 이웃을 참고하여 정답을 예측하는 알고리즘이 구현된 사이킷런 클래스는 무엇인가요? SGDClassifier LinearRegression RandomForestClassifier KNeighborsClassifier v 사이킷런 모델을 훈련할 때 사용하는 메서드는 어떤 것인가요? predict() fit() v score() transform() Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/03/27/chapter1_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"Scikitlearn_pipeline_tutorial","text":"데이터 누수 방지 위한 모델링 기법 : 파이프라인 구축 수능 시험 = 최종 테스트 데이터 모의고사 또는 과거 기출문제 = 검증데이터 교과서 문제지 = 훈련 데이터 머신러닝 엔지니어 : MLOps (선행되어야 하는 코드 조건, Pipeline 형태로 구축) 머신러닝 코드 자동화 가능! 운영 가능! 개발업계의 최상위 연봉자! 데이터 불러오기1234import pandas as pdimport numpy as npdata = pd.read_csv('https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv')data.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 731 entries, 0 to 730 Data columns (total 14 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 instant 731 non-null int64 1 dteday 731 non-null object 2 season 731 non-null int64 3 yr 731 non-null int64 4 mnth 731 non-null int64 5 holiday 731 non-null int64 6 weekday 731 non-null int64 7 workingday 731 non-null int64 8 weathersit 731 non-null int64 9 temp 731 non-null float64 10 atemp 731 non-null float64 11 hum 731 non-null float64 12 windspeed 731 non-null float64 13 rentals 731 non-null int64 dtypes: float64(4), int64(9), object(1) memory usage: 80.1+ KB 데이터 추출1234cols = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'rentals']data = data[cols]data.info()# data['mnth'].value_counts() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 731 entries, 0 to 730 Data columns (total 11 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 season 731 non-null int64 1 mnth 731 non-null int64 2 holiday 731 non-null int64 3 weekday 731 non-null int64 4 workingday 731 non-null int64 5 weathersit 731 non-null int64 6 temp 731 non-null float64 7 atemp 731 non-null float64 8 hum 731 non-null float64 9 windspeed 731 non-null float64 10 rentals 731 non-null int64 dtypes: float64(4), int64(7) memory usage: 62.9 KB Data Preprocessing 결측치 수동으로 채우거나 불필요한 변수를 제거하거나 이상치를 제거하거나 파생변수를 만들거나 등 기본 : 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 피처공학(원핫-인코딩) -&gt; 데이터셋 분리 -&gt; 모델링 코드 -&gt; 모델평가 파이프라인 : 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 데이터셋 분리 -&gt; 파이프라인 구축(피처공학, 모델링 코드) -&gt; 모델 평가 데이터 셋 분리12345from sklearn.model_selection import train_test_splitX = data.drop('rentals',axis=1)y = data['rentals']X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123) Feature Engineering 기존 : 개별적으로 코드 작성 현재 : Pipeline 코드로 추가할 것 Pipeline 구축1234567891011121314151617181920212223242526272829303132333435363738from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoderfrom sklearn.impute import SimpleImputerfrom sklearn.compose import ColumnTransformerfrom sklearn.pipeline import Pipeline# 데이터 타입 3가지# 수치형 데이터, 문자열 데이터# 문자열 데이터 : 범주형(명목형, 서열형 데이터로 구분됨)numeric_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='mean')) ,('scaler', StandardScaler())])ordinal_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='constant')) ,('ordEncoder', OrdinalEncoder())])onehot_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='constant')) ,('oheEncoder', OneHotEncoder()) ])# 수치형 데이터 및 Categorical 데이터 컬럼 분리numeric_features = ['temp', 'atemp', 'hum', 'windspeed']ordinal_features = ['holiday', 'weekday', 'workingday', 'weathersit']onehot_features = ['season', 'mnth']# numeric_features = data.select_dtypes(include=['int64', 'float64']).columns# categorical_features = data.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columnspreprocessor = ColumnTransformer( transformers=[ ('numeric', numeric_transformer, numeric_features) , ('ord_categorical', ordinal_transformer, ordinal_features) , ('ohe_categorical', onehot_transformer, onehot_features)]) 모델 적용 전처리가 끝났으니 모델을 적용한다. 123456789from sklearn.ensemble import RandomForestRegressorpipeline = Pipeline(steps = [ ('preprocessor', preprocessor) ,('regressor', RandomForestRegressor()) ])rf_model = pipeline.fit(X_train, y_train)print(rf_model) Pipeline(steps=[('preprocessor', ColumnTransformer(transformers=[('numeric', Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler())]), ['temp', 'atemp', 'hum', 'windspeed']), ('ord_categorical', Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')), ('ordEncoder', OrdinalEncoder())]), ['holiday', 'weekday', 'workingday', 'weathersit']), ('ohe_categorical', Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')), ('oheEncoder', OneHotEncoder())]), ['season', 'mnth'])])), ('regressor', RandomForestRegressor())]) 파이프라인끼리 연결시켜서 길게 늘이는 원리 데이터가 라인을 따라 흐르게 된다. 자동화 모델 평가123from sklearn.metrics import r2_scorepredictions = rf_model.predict(X_test)print (r2_score(y_test, predictions)) 0.7728368422640097 다중 모형 개발123456789101112131415161718from sklearn.ensemble import RandomForestRegressorfrom sklearn.tree import DecisionTreeRegressorregressors = [ RandomForestRegressor() ,DecisionTreeRegressor()]# regressors = [pipe_rf, pipe_dt]for regressor in regressors: pipeline = Pipeline(steps = [ ('preprocessor', preprocessor) ,('regressor',regressor) ]) model = pipeline.fit(X_train, y_train) predictions = model.predict(X_test) print(regressor) print(f'Model r2 score:{r2_score(predictions, y_test)}') RandomForestRegressor() Model r2 score:0.74544998600902 DecisionTreeRegressor() Model r2 score:0.6365934810580942 Reference Jay Hong, Data Leakage에 대한 개인적인 정리입니다, https://dacon.io/forum/403895 Alexis Cook &amp; Dan B, Data Leakage, https://www.kaggle.com/code/alexisbcook/data-leakage/tutorial","link":"/2022/04/09/ScikitLearn_pipeline_tutorial/"},{"title":"chapter3_1","text":"데이터 준비12345678910111213141516171819import numpy as npperch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) k-최근점 이웃 회귀(Regression) 중요도 : 하 (그냥 넘어가세요!) 실무에서 잘 안쓰이고, 시간은 한정되어 있기 때문 시각화 다음과 같이 fig, ax를 이용해 객체 지향으로 작성하라 123456789import matplotlib.pyplot as plt# 객체 지향으로 변경fig, ax = plt.subplots()ax.scatter(perch_length, perch_weight)ax.set_xlabel(&quot;length&quot;)ax.set_xlabel(&quot;weight&quot;)plt.show() 훈련데이터 테스트데이터셋 분리 외워야 할 정도로 중요하다. 123456from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( # 자체적으로 셔플이 된다. perch_length, perch_weight, random_state = 42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((42,), (14,), (42,), (14,)) reshape() 사용하여 2차원 배열로 바꿈 1234train_input = train_input.reshape(-1, 1)test_input = test_input.reshape(-1, 1)print(train_input.shape, test_input.shape) (42, 1) (14, 1) 결정계수 모델이 얼마만큼 정확하냐? 12345678910from sklearn.neighbors import KNeighborsRegressor# knn 클래스 불러오기knr = KNeighborsRegressor()# 모형학습knr.fit(train_input, train_target)# 테스트 점수 확인하자knr.score(test_input, test_target) 0.992809406101064 MAE 타깃과 예측의 절댓값 오차를 평균하여 반환 12345from sklearn.metrics import mean_absolute_error# 예측 데이터 만들기test_prediction = knr.predict(test_input)test_prediction array([ 60. , 79.6, 248. , 122. , 136. , 847. , 311.4, 183.4, 847. , 113. , 1010. , 60. , 248. , 248. ]) mae를 구한다. mae = mean_absolute_error 평균적 오차를 구하는 것이다. 12mae = mean_absolute_error(test_target, test_prediction)print(mae) 평균적으로 19g정도 다르다. 과대적합 vs 과소적합 공통점은 머신러닝 모형이 실제 테스트 시 잘 예측을 못함! 과대적합 : 훈련데이터에는 예측 잘함 / 테스트 데이터에서는 예측을 잘 못함 처리하기 곤란 과소적합 : 훈련데이터에서는 예측을 못하고, 테스트데이터에서는 예측을 잘 함 or 둘다 예측을 잘 못함. 데이터의 양이 적거나, 모델을 너무 간단하게 만듬! 12# 훈련 데이터 점수 확인하자.knr.score(train_input, train_target) 0.9698823289099254 0.97 정도 나옴 1234567# Defult 5를 3으로 변경# 머신러닝 모형을 살짝 변경knr.n_neighbors = 3# 모델을 다시 훈련knr.fit(train_input, train_target)print(knr.score(train_input, train_target)) 0.9804899950518966 훈련데이터로 검증 0.98 1print(knr.score(test_input, test_target)) 0.9746459963987609 mae 구하기 평균적 오차 구하기 123test_prediction = knr.predict(test_input)mae = mean_absolute_error(test_target, test_prediction)print(mae) 35.42380952380951 평균적으로 35.4g 다름 결론 k 그룹을 5로 했을 때, R2 점수는 0.98, MAE는 19 였음 k 그룹을 3로 했을 때, R2 점수는 0.97, MAE는 35 였음 k 그룹을 7로 했을 때, R2 점수는 0.97, MAE는 32 였음 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/03/29/chapter3_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter2","text":"지도학습과 비지도 학습 지도학습 : 경진대외 유형 입력과 타깃 : 독립변수(입력), 종속변수(타깃) 정답이 있는 문제 1 유형 : 타이타닉 생존자 분류 : survived (타깃) 2 유형 : 카페 예상매출액 : 숫자를 예측 특성(Feature) : 독립변수(엑셀의 컬럼) 비지도 학습 : 뉴스기사 종류를 분류 기사 1 : 사회, 의학, … 기사 2 : 사회, 경제, … 훈련 세트와 테스트 세트 12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 1234567fish_data = [[l,w] for l, w in zip(fish_length, fish_weight)]# fish_data# 1은 도미# 0는 빙어fish_target = [1]*35 + [0]*14#fish_target 머신러닝 모델 12from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier() 훈련세트와 테스트 세트로 분리1234567891011121314# 0부터 ~ 34인덱스까지 사용# 훈련데이터 독립변수train_input = fish_data[:35]# 훈련데이터 종속변수train_target = fish_target[:35]# 테스트데이터 독립변수test_input = fish_data[35:]# 테스트데이터 종속변수test_target = fish_target[35:]#train_input.shape, train_target.shape, test_input.shape, test_target.shape 12kn = kn.fit(train_input, train_target)kn.score(test_input, test_target) 0.0 1fish_data[:34] [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0]] 1fish_target[34:] [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 샘플링 편향넘파이 리스트로 연산은 지원이 잘 안 됨. 리스트를 넘파이 배열로 변환 123456import numpy as npinput_arr = np.array(fish_data)target_arr = np.array(fish_target)print(input_arr.shape, target_arr.shape) # shape 출력 (49, 2) (49,) suffle : 데이터를 섞어준다 실험 재현성 np.random.seed(42) 란? 뒤에 42는 무의미한 수치이다. 랜덤 시드이다. 어떤 특정한 시작 숫자를 정해 주면 컴퓨터가 정해진 알고리즘에 의해 마치 난수처럼 보이는 수열을 생성한다. 이런 시작 숫자를 시드(seed)라고 한다. 12345# 76p# 랜덤 시드np.random.seed(42)index = np.arange(49)index array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]) 셔플 123# 셔플 = 섞는다np.random.shuffle(index)print(index) [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] 훈련 데이터 및 테스트데이터 재 코딩 1234train_input = input_arr[index[:35]]train_target = target_arr[index[:35]]print(input_arr[13], train_input[0]) [ 32. 340.] [ 32. 340.] 12test_input = input_arr[index[35:]]test_target = target_arr[index[35:]] 1train_input.shape, train_target.shape, test_input.shape, test_target.shape ((35, 2), (35,), (14, 2), (14,)) 시각화 생략두 번째 머신러닝 프로그램12kn = kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 다음 두 코드의 결과가 같다. 예측 성공. 1kn.predict(test_input) array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) 1test_target array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) 02-2 데이터 전처리넘파이로 데이터 준비하기 다음 주소를 참고하라 : bit.ly/bream_smelt 12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 2차원 리스트를 작성해보자. 넘파이의 column_stack() 함수는 전달받은 리스트를 일렬로 세운 다음 차례대로 나란히 연결한다. 123import numpy as npnp.column_stack(([1,2,3], [4,5,6])) array([[1, 4], [2, 5], [3, 6]]) 이제 fish_length와 fish_weight를 합친다. 123fish_data = np.column_stack((fish_length, fish_weight))print(fish_data[:5]) [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ]] 동일한 방법으로 타깃 데이터도 만들어 보자. np.ones()와 np.zeros() 함수를 이용한다. 1print(np.ones(5)) [1. 1. 1. 1. 1.] np.concatenate() 함수를 사용하여 첫 번째 차원을 따라 배열을 연결해보자. 123fish_target = np.concatenate((np.ones(35), np.zeros(14)))print(fish_target) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 사이킷런으로 훈련 세트와 테스트 세트 나누기 train_test_split() 이 함수는 전달되는 리스트나 배열을 비율에 맞게 훈련 세트와 테스트 세트로 나누어 준다. 사용법 : 나누고 싶은 리스트나 배열을 원하는 만큼 전달하면 된다. 123from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, random_state=42) fish_data와 fish_target 2개의 배열을 전달했으므로 2개씩 나뉘어 총 4개의 배열이 반환된다. 차례대로 처음 2개는 입력 데이터(train_input, test_input), 나머지 2개는 타깃 데이터(train_target, test_target)이다. 랜덤 시드(random_state)는 42로 지정했다. 1print(train_input.shape, test_input.shape) (36, 2) (13, 2) 1print(train_target.shape, test_target.shape) (36,) (13,) 훈련 데이터와 테스트 데이터를 각각 36개와 13개로 나누었다. 입력 데이터는 2개의 열이 있는 2차원 배열이고 타깃 데이터는 1차원 배열이다. 도미와 빙어가 잘 섞였는지 확인해보자. 1print(test_target) [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 13개의 테스트 세트 중에 10개가 도미(1)이고, 3개가 빙어(0)이다. 빙어의 비율이 좀 모자란데, 이는 샘플링 편항때문이다. 이러한 문제를 train_test_split() 함수로 해결할 수 있다. stratify 매개변수에 타깃 데이터를 전달하면 클래스 비율에 맞게 데이터를 나누다. 훈련 데이터가 작거나 특정 클래스의 샘플 개수가 적을 때 특히 유용하다. 123train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify=fish_target, random_state=42)print(test_target) [0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.] 빙어가 하나 늘었다. 이전과 달리 비율이 좀 더 비슷해졌다. 데이터 준비가 완료되었다. 수상한 도미 한 마리 앞서 준비한 데이터로 k-최근접 이웃을 훈련해 보자. 12345from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 완벽한 결과이다. 테스트 세트의 도미와 빙어를 모두 올바르게 분류했다. 이 모델에 문제가 되었던 도미 데이터를 넣고 결과를 확인해본다. 1print(kn.predict([[25, 150]])) [0.] 도미 데이터인데 빙어로 나왔다. 산점도로 다시 확인해보자. 123456import matplotlib.pyplot as pltplt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^') # marker 매개변수는 모양을 지정한다. '^'는 삼각형.plt.xlabel('length')plt.ylabel('weight')plt.show() 새로운 샘플은 marker 매개변수를 이용하여 삼각형으로 표시했다. 샘플은 오른쪽의 도미와 가까운 위치에 있는데 어째서 빙어로 판단했을까? k-최근접 이웃은 주변의 샘플 중에서 다수인 클래스를 예측으로 사용한다. KNeighborsClassifier클래스는 주어진 샘플에서 가장 가까운 이웃을 찾아 주는 kneighbors() 메서드를 제공한다. 이 클래스의 이웃 개수인 n-neighbors의 기본값은 5이므로 5개의 이웃이 반환된다. 1distances, indexes = kn.kneighbors([[25, 150]]) indexes 배열을 사용해 훈련 데이터 중에서 이웃 샘플을 따로 구분해 그려본다. 12345plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^')plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D') # 'D' 는 마름모 모양으로 출력plt.xlabel('length')plt.ylabel('weight') Text(0, 0.5, 'weight') marker=’D’로 지정하면 산점도를 마름모로 그린다. 삼각형 샘플에 가장 가까운 5개의 샘플이 초록 다이아몬드로 표시되었다. 가장 가까운 이웃에 도미가 하나밖에 포함되지 않았다. 1print(train_input[indexes]) [[[ 25.4 242. ] [ 15. 19.9] [ 14.3 19.7] [ 13. 12.2] [ 12.2 12.2]]] 가장 가까운 생선 4개는 빙어(0)인 것 같다. 타깃 데이터로 확인하면 더 명확하다. 1print(train_target[indexes]) [[1. 0. 0. 0. 0.]] 해당 문제 해결의 실마리를 위해 distance배열을 출력해본다. 이 배열에는 이웃 샘플까지의 거리가 담겨 있다. 1print(distances) [[ 92.00086956 130.48375378 130.73859415 138.32150953 138.39320793]] 기준을 맞춰라 산점도를 다시 살펴본다. 삼각형 샘플과 근처 5개 샘플 사이의 거리가 이상하다. 가장 가까운 것과의 거리가 92이고, 그 나머지는 두 배 이상 멀어보이는데 수치는 그렇지 않다. 이는 x의 범위가 좁고 y축의 범위가 넓기에 그렇게 보이는 것이다. 명확하게 보기 위해 x축의 범위를 동일하게 맞춘다. xlim()함수를 사용하여 x축 범위를 지정한다. 1234567plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^')plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')plt.xlim((0, 1000)) # x축 지정plt.xlabel('length')plt.ylabel('weight')plt.show() 두 특성(길이와 무게)의 값이 놓인 범위가 매우 다르다. 이를 투 특성의 스케일(scale)이 다르다고 한다. 데이터 전처리 데이터를 표현하는 기준이 다르면 알고리즘이 올바르게 예측할 수 없다. 알고리즘이 거리 기반일 때 특히 그렇다. 여기에는 k-최근접 이웃도 포함된다. 이런 알고리즘들은 샘플 간의 거리에 영향을 많이 받으므로 제대로 사요하려면 특성값을 일정한 기준으로 맞춰 주어야 한다. 이런 작업을 데이터 전처리(data preprocessing)이라고 부른다. 표준 점수 가장 널리 사용하는 전처리 방법 중 하나는 표준점수(standatd score)이다. 표준점수는 각 특성값이 평균에서 표준편차의 몇 배만큼 떨어져 있는지를 나타낸다. 이를 통해 실제 특성값의 크기와 상광없이 동일한 조건으로 비교할 수 있다 12mean = np.mean(train_input, axis=0)std = np.std(train_input, axis=0) np.mean() 함수는 평균을 계산하고, np.std() 함수는 표준편차를 계산한다. axis=0으로 지정했으며, 이렇게 하면 행을 따라 각 열의 통계 값을 계산한다. 1print(mean, std) [ 27.29722222 454.09722222] [ 9.98244253 323.29893931] 각 특성마다 평균과 표준편차가 구해졌다. 이제 원본 데이터에서 평균을 빼고 표준편차로 나누어 표준점수로 변환한다. 1train_scaled = (train_input - mean) / std 브로드 캐스팅 (breadcastion) 이 식은 어떻게 계산될까? 넘파이는 train_input의 모든 행에서 mean에 있는 두 평균값을 뺀다. 그 다은 std에 있는 두 표준편차를 모든 행에 적용한다. 이런 넘파이 기능을 브로드캐스팅이라고 부른다. 전처리 데이터로 모델 훈련하기 앞에서 표준점수로 변환한 train_scaled를 만들었다. 다시 샘플을 산점도로 그려보자. 12345plt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(25, 150, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show() 우측 상단에 샘플 하나가 덩그러니 떨어져 있다. 훈련 세트를 mean(평균)으로 빼고 std(표준편차)로 나누어 주었기 때문에 값의 범위가 달라졌다. 동일한 기준으로 샘플을 변환하고 다시 산점도를 그려보자. 123456new = ([25, 150] - mean) / stdplt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show() 훈련 데이터의 두 특성이 비슷한 범위를 차지하고 있다. 이제 이 데이터셋으로 k-최근접 이웃 모델을 다시 훈련해 보자. 1kn.fit(train_scaled, train_target) KNeighborsClassifier() 테스트 세트의 스케일을 변환해 보자. 1test_scaled = (test_input - mean) / std 이제 모델을 평가한다. 1kn.score(test_scaled, test_target) 1.0 완벽하다. 모든 테스트 세트의 샘플을 완벽하게 분류했다. 앞서 훈련 세트의 평균고 표준편차로 변환한 김 팀장의 샘플 사용해 모델의 예측을 출력해보자. 1print(kn.predict([new])) [1.] 드디어 도미(1)로 예측했다. 확일시 길이가 25cm이고 무게가 150g인 생선은 도미일 것이다. 마지막으로 keighbors()함수로 이 샘플의 k-최근점 이웃을 구한 다음 산점도로 그려보자. 특성을 표준점수로 바꾸었기 때문에 알고리즘이 올바르게 거리를 측정했을 것이다. 1234567distances, indexes = kn.kneighbors([new])plt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker='^')plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')plt.xlabel('length')plt.ylabel('weight')plt.show() 삼각형 샘플에서 가장 가까운 샘플은 모두 도미이다. 따라서 이 수상한 샘플을 도미로 예측하는 것이 당연하다. 성공이다. 특성값의 스케일에 민감하지 않고 안정적인 예측을 할 수 있는 모델을 만들었다. 전체 소스 코드 다음 주소를 참고하라 : bit.ly/hg-02-2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]import numpy as npnp.column_stack(([1,2,3], [4,5,6]))fish_data = np.column_stack((fish_length, fish_weight))print(fish_data[:5])print(np.ones(5))fish_target = np.concatenate((np.ones(35), np.zeros(14)))print(fish_target)from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_data, fish_target, random_state=42)print(train_input.shape, test_input.shape)print(train_target.shape, test_target.shape)print(test_target)train_input, test_input, train_target, test_target = train_test_split( fish_data, fish_target, stratify=fish_target, random_state=42)print(test_target)from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(train_input, train_target)kn.score(test_input, test_target)print(kn.predict([[25, 150]]))import matplotlib.pyplot as pltplt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()distances, indexes = kn.kneighbors([[25, 150]])plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^')plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')plt.xlabel('length')plt.ylabel('weight')plt.show()print(train_input[indexes])print(train_target[indexes])print(distances)plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker='^')plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')plt.xlim((0, 1000))plt.xlabel('length')plt.ylabel('weight')plt.show()mean = np.mean(train_input, axis=0)std = np.std(train_input, axis=0)print(mean, std)train_scaled = (train_input - mean) / stdplt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(25, 150, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()new = ([25, 150] - mean) / stdplt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()kn.fit(train_scaled, train_target)test_scaled = (test_input - mean) / stdkn.score(test_scaled, test_target)print(kn.predict([new]))distances, indexes = kn.kneighbors([new])plt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker='^')plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')plt.xlabel('length')plt.ylabel('weight')plt.show() [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ]] [1. 1. 1. 1. 1.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (36, 2) (13, 2) (36,) (13,) [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.] [0.] [[[ 25.4 242. ] [ 15. 19.9] [ 14.3 19.7] [ 13. 12.2] [ 12.2 12.2]]] [[1. 0. 0. 0. 0.]] [[ 92.00086956 130.48375378 130.73859415 138.32150953 138.39320793]] [ 27.29722222 454.09722222] [ 9.98244253 323.29893931] [1.] Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/03/28/chapter2_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter3_2","text":"데이터 준비하기12345678910111213141516171819import numpy as npperch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) 훈련 세트와 테스트 세트로 나눈다. 1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state = 42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((42,), (14,), (42,), (14,)) 훈련 세트와 테스트 세트를 2차원 배열로 변경 1234train_input = train_input.reshape(-1, 1)test_input = test_input.reshape(-1, 1)print(train_input.shape, test_input.shape) (42, 1) (14, 1) 모델 만들기12345678910from sklearn.neighbors import KNeighborsRegressor# knn 클래스 불러오기knr = KNeighborsRegressor(n_neighbors=3)# 모형학습knr.fit(train_input, train_target)# 테스트 점수 확인하자#knr.score(test_input, test_target) KNeighborsRegressor(n_neighbors=3) 예측 혼자 공부하는 머신러닝 + 딥러닝 p132 12# 어떤 숫자로 바꿔도 결과는 동일하다print(knr.predict([[50]])) [1033.33333333] 시각화1234567891011import matplotlib.pyplot as plt# 50cm 농어의 이웃을 구하라!distances, indexes = knr.kneighbors([[50]])# 훈련 세트의 산점도를 구하라plt.scatter(train_input, train_target)plt.scatter(train_input[indexes], train_target[indexes], marker = 'D')plt.scatter(50, 1033, marker='^')plt.show() [과제] 위 시각화를 객체 지향으로 변경한다! 123456789101112131415161718192021222324import matplotlib.pyplot as plt# 50cm 농어의 이웃을 구하라!distances, indexes = knr.kneighbors([[50]])# 훈련 세트의 산점도를 구하라fig, ax = plt.subplots()ax.scatter(train_input, train_target)ax.scatter(train_input[indexes], train_target[indexes], marker = 'D')ax.scatter(50, 1033, marker='^')plt.show()# 아래 코드를 참고함.&quot;&quot;&quot; import matplotlib.pyplot as plt# 객체 지향으로 변경fig, ax = plt.subplots()ax.scatter(perch_length, perch_weight)ax.set_xlabel(&quot;length&quot;)ax.set_xlabel(&quot;weight&quot;)plt.show()&quot;&quot;&quot; '\\nimport matplotlib.pyplot as plt\\n\\n# 객체 지향으로 변경\\nfig, ax = plt.subplots()\\nax.scatter(perch_length, perch_weight)\\nax.set_xlabel(&quot;length&quot;)\\nax.set_xlabel(&quot;weight&quot;)\\n\\nplt.show()\\n' 머신러닝 모델은 주기적으로 훈련해야 한다. (135p) MLOps (Machine Learning &amp; Operations) 최근에 각광받는 데이터 관련 직업 필수 스킬! 입사와 함께 공부시작 (데이터 분석가, 머신러닝 엔지니어, 데이터 싸이언티스트 희망자) 선형회귀 (머신러닝) 평가지표 확신이 더 중요! R2 점수, MAE, MSE,… 5가지 가정들… 잔차의 정규성 등분산성, 다중공선성, etc… 종속변수 ~ 독립변수간의 “인간관계”를 찾는 과정… 123456789from sklearn.linear_model import LinearRegressionlr = LinearRegression()# 선형 회귀 모델 훈련lr.fit(train_input, train_target)# 50 cm 농어 예측print(lr.predict([[200]])) [7094.41034777] 1234plt.scatter(train_input, train_target)plt.scatter(train_input[indexes], train_target[indexes], marker = 'D')plt.scatter(200, 7094, marker='^')plt.show() 회귀식을 찾기 coef_ : 기울기 intercept_ : 상수 12# 기울기, 상수print(lr.coef_, lr.intercept_) [39.01714496] -709.0186449535477 기울기 : 계수 = 가중치(딥러닝) 123456789plt.scatter(train_input, train_target)# 15~50 까지의 1차 방정식 그래프를 그린다.plt.plot([15, 50], [15 * lr.coef_ + lr.intercept_, 50 * lr.coef_ + lr.intercept_, ])plt.scatter(50, 1241.8, marker='^')plt.show() 모형 평가 (138p) 과소 적합이 됨 다항회귀의 필요성 치어를 생각해보자 치어가 1cm 1print(lr.predict([[1]])) [-670.00149999] (140p) 1차 방정식을 2차방정식으로 만드는 과정이 나옴 넘파이 브로드캐스팅 배열의 크기가 동일하면 상관 없음 배열의 크기가 다른데, 연산을 할 때, 브로드캐스팅 원리가 적용 브로드캐스팅 튜토리얼, 뭘 찾아서, 추가적 공부를 해야 함(분석가 지망, ai분야 지망) 1234train_poly = np.column_stack((train_input ** 2, train_input))test_poly = np.column_stack((test_input ** 2, test_input))print(train_poly.shape, test_poly.shape) (42, 2) (14, 2) 12345lr = LinearRegression()lr.fit(train_poly, train_target)print(lr.predict([[50 ** 2, 50]])) [1573.98423528] 12# 기울기, 상수print(lr.coef_, lr.intercept_) [ 1.01433211 -21.55792498] 116.0502107827827 이 모델은 다음과 같은 그래프를 학습했다. 무게 = 1.01 x 길이^2 - 21.6 x 길이 + 116.05 KNN의 문제점 농어의 길이가 커져도 무게는 동일함 (현실성 제로) 단순 선형회귀(1차 방정식)의 문제점 치어(1cm)의 무게가 음수로 나옴 (현실성 제로) 다항 회귀(2차 방정식)으로 변경 현실성 있음 이런 방정식을 다항싱(polynomial)이라 부르며 다항식을 사용한 선형 외귀를 다항 회귀(polynomial regression)이라 부른다. 이를 이용하여 이전과 동일하게 훈련 세트의 산점도에 그래프로 그려보자. 1234567891011121314# 구간별 직선을 그리기 위해 15 에서 49까지 정수 배열을 만든다.point = np.arange(15, 50)# 훈련 세트의 산점도를 그린다.plt.scatter(train_input, train_target)# 15에서 49까지 2차 방정식 그래프를 그린다.plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)#50cm 농어 데이터plt.scatter(50, 1574, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show() 앞선 단순 선형 회귀 모델보다 훨씬 나은 그래프가 그려졌다. 이제 훈련 세트와 테스트 세트의 R^2 점수를 평가한다. 12print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target)) 0.9706807451768623 0.9775935108325122 두 세트의 점수가 높아졌다. 좋은 결과다. 하지만 여전히 테스트 세트의 점수가 조금 더 높다. 과소적합이 아직 남아 있는 듯 하다. 3-3 에서 이를 해결해보자 전체 소스 코드 다음을 참고하라 : bit.ly/hg-03-2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import numpy as npperch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] )from sklearn.model_selection import train_test_split# 훈련 세트와 테스트 세트로 나눕니다train_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state=42)# 훈련 세트와 테스트 세트를 2차원 배열로 바꿉니다train_input = train_input.reshape(-1, 1)test_input = test_input.reshape(-1, 1)from sklearn.neighbors import KNeighborsRegressorknr = KNeighborsRegressor(n_neighbors=3)# k-최근접 이웃 회귀 모델을 훈련합니다knr.fit(train_input, train_target)print(knr.predict([[50]]))import matplotlib.pyplot as plt# 50cm 농어의 이웃을 구합니다distances, indexes = knr.kneighbors([[50]])# 훈련 세트의 산점도를 그립니다plt.scatter(train_input, train_target)# 훈련 세트 중에서 이웃 샘플만 다시 그립니다plt.scatter(train_input[indexes], train_target[indexes], marker='D')# 50cm 농어 데이터plt.scatter(50, 1033, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()print(np.mean(train_target[indexes]))print(knr.predict([[100]]))# 100cm 농어의 이웃을 구합니다distances, indexes = knr.kneighbors([[100]])# 훈련 세트의 산점도를 그립니다\u001fplt.scatter(train_input, train_target)# 훈련 세트 중에서 이웃 샘플만 다시 그립니다\u001fplt.scatter(train_input[indexes], train_target[indexes], marker='D')# 100cm 농어 데이터plt.scatter(100, 1033, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()from sklearn.linear_model import LinearRegressionlr = LinearRegression()# 선형 회귀 모델 훈련lr.fit(train_input, train_target)# 50cm 농어에 대한 예측print(lr.predict([[50]]))print(lr.coef_, lr.intercept_)# 훈련 세트의 산점도를 그립니다\u001fplt.scatter(train_input, train_target)# 15에서 50까지 1차 방정식 그래프를 그립니다plt.plot([15, 50], [15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])# 50cm 농어 데이터plt.scatter(50, 1241.8, marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()print(lr.score(train_input, train_target))print(lr.score(test_input, test_target))train_poly = np.column_stack((train_input ** 2, train_input))test_poly = np.column_stack((test_input ** 2, test_input))print(train_poly.shape, test_poly.shape)lr = LinearRegression()lr.fit(train_poly, train_target)print(lr.predict([[50**2, 50]]))print(lr.coef_, lr.intercept_)# 구간별 직선을 그리기 위해 15에서 49까지 정수 배열을 만듭니다point = np.arange(15, 50)# 훈련 세트의 산점도를 그립니다plt.scatter(train_input, train_target)# 15에서 49까지 2차 방정식 그래프를 그립니다plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)# 50cm 농어 데이터plt.scatter([50], [1574], marker='^')plt.xlabel('length')plt.ylabel('weight')plt.show()print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target)) [1033.33333333] 1033.3333333333333 [1033.33333333] [1241.83860323] [39.01714496] -709.0186449535477 0.939846333997604 0.8247503123313558 (42, 2) (14, 2) [1573.98423528] [ 1.01433211 -21.55792498] 116.0502107827827 0.9706807451768623 0.9775935108325122 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/03/30/chapter3_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter3_3","text":"특성 공학과 규제 선형 회귀는 특성이 많을수록 효과가 좋아진다. 무게와 길이뿐만 아니라 높이와 두께도 활용해보자. 사이킷런의 PolynomialFeatures 클래스를 사용한다. 포인트 모델에 규제를 추가함 모형의 과대적합을 방지하기 위해! 훈련 데이터는 예측 성능이 좋고! 테스트 데이터는 예측성능이 떨어지는 현상 릿지, 라쏘 회귀 (중요도 하) 하이퍼 파라미터 (개념 이해 중요!) 머신러닝 모델이 학습할수 없고 사람이 알려줘야 하는 파라미터 (161p 참고) 실무에서는 그렇게 큰 의미가 없음 이유 : 가성비가 떨어짐 (작업시간 대비 성능 보장이 안 됨) 하이퍼 파라미터 기본 모델에서 과대적합이 발생함 모델의 성능을 높여주기 위해 여러 옵션을 선택 및 값 조정 문제 : 항상 선응이 보장이 안됨 모델마다 하이퍼 파라미터 새팅하는 방법이 다 다름 (종류가 제 각각) scikit-learn 라이브러리 내 모델의 갯수가 103개 어떤 모델은 하이퍼 파라미터 새팅 위해 필요한 매개 변수가 1개인 경우도 있음 어떤 모델은 하이퍼 파라미터의 매개변수가 80개가 넘어가는 것도 있음 하이퍼 파라미터 기존에 세팅되어 있는대로 사용 권유 (조건: 그 모델에 잘 모르면!!) 다중 회귀 (multiple regression) 여러 개의 특성을 사용한 선형 회귀를 다중 회귀라고 부른다. 특성 공학(feagure engineering) 기존의 각 특성을 서로 곱해서 또 다른 특성을 만들 수 있다. 예를 들어, ‘농어 길이 x 농어 높이’를 새로운 특성으로 삼을 수 있다. 이렇게 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업을 특성 공학이라고 부른다. 데이터 준비 이전과 달리 농어의 특성 3개를 사용한다. 판다스를 이용하여 간편하게 데이터를 입력한다. 판다스(pandas)는 데이터 분석 라이브러리이다. 데이터프레임(dataframe)은 판다스의 핵심 데이터 구조이다. 판다스 데이터 프레임을 만들기 위해 많이 사용하는 파일은 CSV 파일이다. 다음 주소와 read_csv()함수로 파일을 읽어낸다. :https://bit.ly/perch_csv_data read_csv() 함수로 데이터프레임을 만든 다음 to_numpy() 메서드를 사용해 넘파이 배열로 바꾼다. 1234import pandas as pd # pd는 관례적으로 사용하는 판다스의 별칭이다.df = pd.read_csv('https://bit.ly/perch_csv_data')perch_full = df.to_numpy()print(perch_full) [[ 8.4 2.11 1.41] [13.7 3.53 2. ] [15. 3.82 2.43] [16.2 4.59 2.63] [17.4 4.59 2.94] [18. 5.22 3.32] [18.7 5.2 3.12] [19. 5.64 3.05] [19.6 5.14 3.04] [20. 5.08 2.77] [21. 5.69 3.56] [21. 5.92 3.31] [21. 5.69 3.67] [21.3 6.38 3.53] [22. 6.11 3.41] [22. 5.64 3.52] [22. 6.11 3.52] [22. 5.88 3.52] [22. 5.52 4. ] [22.5 5.86 3.62] [22.5 6.79 3.62] [22.7 5.95 3.63] [23. 5.22 3.63] [23.5 6.28 3.72] [24. 7.29 3.72] [24. 6.38 3.82] [24.6 6.73 4.17] [25. 6.44 3.68] [25.6 6.56 4.24] [26.5 7.17 4.14] [27.3 8.32 5.14] [27.5 7.17 4.34] [27.5 7.05 4.34] [27.5 7.28 4.57] [28. 7.82 4.2 ] [28.7 7.59 4.64] [30. 7.62 4.77] [32.8 10.03 6.02] [34.5 10.26 6.39] [35. 11.49 7.8 ] [36.5 10.88 6.86] [36. 10.61 6.74] [37. 10.84 6.26] [37. 10.57 6.37] [39. 11.14 7.49] [39. 11.14 6. ] [39. 12.43 7.35] [40. 11.93 7.11] [40. 11.73 7.22] [40. 12.38 7.46] [40. 11.14 6.63] [42. 12.8 6.87] [43. 11.93 7.28] [43. 12.51 7.42] [43.5 12.6 8.14] [44. 12.49 7.6 ]] 타깃 데이터는 이전과 동일한 방식으로 준비한다. 1234567891011import numpy as npperch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) 그 다음 perch_full과 perch_weight를 훈련 세트와 테스트 세트로 나눈다. 1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_full, perch_weight, random_state = 42)#train_input.shape, test_input.shape, train_target.shape, test_target.shape 이 데이터를 사용해 새로운 특성을 만든다. 사이킷런의 변환기 사이킷런은 특성을 만들거나 전처리하기 위한 다양한 클래스를 제공한다. 이런 클래스를 변환기(transformer)라고 부른다. 사이킷런의 모델 클래스에 일관된 fit(), score(), predict() 메서드가 있는 것처럼 변환기 클래스는 모두 fit(), transform()메서드를 제공한다 사용할 변환기는 PolynomialFeatures 클래스이다. 이 클래스는 sklearn.preprocessing패키지에 포함되어 있다. 1from sklearn.preprocessing import PolynomialFeatures 2개의 특성 2와 3으로 이루어진 샘플 하나를 적용해본다. 이 클래스의 객체를 만르고 fit(), transform() 메서드를 차례대로 호출한다. 123poly = PolynomialFeatures()poly.fit([[2, 3]])print(poly.transform([[2, 3]])) [[1. 2. 3. 4. 6. 9.]] fit() 새롭게 만들 특성 조합을 찾는다. transform() 실제로 데이터를 변환한다. 위 코드에서 fit()메서드에 입력데이터만 전달했다. 즉 여기에서는 2개의 특성을 가진 샘플 [2,3]이 6개의 특성을 가진 샘플 [1. 2. 3. 4. 6. 9.]로 바뀌었다. PolynomialFeatures 클래스는 기본적으로 각 특성을 제곱한 항을 추가하고 특성끼리 서로 곱한 항을 추가한다. 2와 3을 각각 제곱한 4와 9가 추가되었고, 2와 3을 곱한 6이 추가된다. 1은 다음 식에 의해 추가된다. 무게 = a x 길이 + b x 높이 + c x 두께 + d x 1 이렇게 놓고 보면 특성은 (길이, 높이, 두께, 1)이 된다. 하지만 사이킷런의 선형 모델은 자동으로 절편(계수)을 추가하므로 굳이 이렇게 특성을 만들 필요가 없다. include_bias = False로 지정하여 다시 특성을 변환한다. 123poly = PolynomialFeatures(include_bias=False)poly.fit([[2, 3]])print(poly.transform([[2, 3]])) [[2. 3. 4. 6. 9.]] 절편을 위한 항이 제거되고 특성의 제곱과 특성끼리 곱한 항만 추가되었다. 이제 이 방식으로 train_input에 적용한다. train_input을 변환한 데이터를 train_poly에 저장하고 이 배열의 크기를 확인해 보자. 1234poly = PolynomialFeatures(include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)print(train_poly.shape) (42, 9) PolynomialFeaures 클래스는 9개의 특성이 어떻게 만들어졌는지 확인하는 아주 좋은 방법을 제공한다. get_feature-names_out() 메서드를 호출하면 9개의 특성이 각각 어떤 입력의 조합으로 만들어졌는지 알려준다. 1poly.get_feature_names_out() array(['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2'], dtype=object) x0은 첫 번째 특성을 의미하고 x0^2는 첫 번째 특성의 제곱, x0 x1은 첫 번째와 두 번째 특성의 곱을 타나내는 식이다. 이제 테스트 세트를 변환한다. 1test_poly = poly.transform(test_input) 이어서 변환된 특성을 사용하여 다중 회귀 모델을 훈련한다. 다중 회귀 모델 훈련하기 사이킷런의 LinearRegression 클래스를 임포트하고 앞에서 만든 train_poly를 사용해 모델을 훈련시킨다. 1234from sklearn.linear_model import LinearRegressionlr = LinearRegression()lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target)) 0.9903183436982124 높은 점수가 나왔다. 농어의 길이뿐만 아니라 높이와 두께를 모두 사용했고 각 특성을 제곱하거나 서로 곱해서 다항 특성을 더 추가했다. 특성이 늘어나면 선형 회귀의 능력이 강해짐을 알 수 있다. 1print(lr.score(test_poly, test_target)) 0.9714559911594134 테스트 셑트에 대한 점수는 높아지지 않았지만 농어의 길이만 사용했을 때 있던 과소적합 문제가 더 이상 나타나지 않게 되었다. 특성을 더 많이 추가하면 어떻게될까? 3제곱, 4제곱 항까지 넣는 것이다. PolynomialFeaures 클래스의 degree 매개변수를 사용하여 필요한 고차항의 최대 차수를 지정할 수 있다. 5제곱까지 특성을 만들어 출력해본다. 12345poly = PolynomialFeatures(degree=5, include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)test_poly = poly.transform(test_input)print(train_poly.shape) (42, 55) 만들어진 특성의 개수가 무려 55개나 된다. train_poly 배열의 열의 개수가 특성의 개수이다. 이 데이터를 사용해 선형 회귀 모델을 다시 훈련한다. 12lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target)) 0.9999999999991097 거의 완벽한 점수다. 테스트 세트에 대한 점수는 어떨까? 1print(lr.score(test_poly, test_target)) -144.40579242684848 음수가 나왔다. 특성의 개수를 늘리면 선형 모델은 더 강력해진다. 하지만 이런 모델은 훈련 세트에 너무 과대적합되므로 테스트 세트에서는 형편없는 점수를 만든다. 이 문제를 해결하기 위해 2가지 방법이 있다. 방법 1. 다시 특성을 줄인다. 방법 2. 규제를 사용한다. 규제 (regularization) 규제는 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것을 말한다. 즉 모델이 훈련 세트에 과대적합되지 않도록 만드는 것이다. 회귀 모델의 경우 특성에 곱해지는 계수(또는 기울기)의 크기를 작게 만드는 일이다. 123456# 규제하기 전에 먼저 정규화를 진행한다.from sklearn.preprocessing import StandardScaler # 이 클래스는 변환기의 하나이다.ss = StandardScaler()ss.fit(train_poly)train_scaled = ss.transform(train_poly)test_scaled = ss.transform(test_poly) StandardScaler 클래스의 객체 ss를 초기화한 후 PolynomialFeatures 클래스로 만든 train_poly를 사용해 이 객체를 훈련한다. 반드시 훈련 세트로 학습한 변환기를 사용해 테스트 세트까지 변환해야 한다. 이제 표준점수로 변환한 train_scaled와 test_scaled가 준비되었다. 릿지(ridge)와 라쏘(lasso) 선형 회귀 모델에 규제를 추가한 모델이다. 두 모델은 규제를 가하는 방법이 다르다. 릿지 계수를 제곱한 값을 기준으로 규제를 적용한다. 라쏘 계수의 절댓값을 기준으로 규제를 적용한다. 릿지 회귀 릿지와 라쏘 모두 sklearn.linear_model 패키지 안에 있다. 모델 객체를 만들고 fit() 메서드에서 훈련한 다음 score()메서드로 평가한다. 앞서 준비한 train_scaled 데이터로 릿지 모델을 훈련한다. 1234from sklearn.linear_model import Ridgeridge = Ridge()ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target)) 0.9896101671037343 선형 회귀에 비해 낮아졌다. 이번에는 테스트 세트에 대한 점수를 확인한다. 1print(ridge.score(test_scaled, test_target)) 0.9790693977615397 확실히 과대적합도지 않아 테스트 세트에서도 좋은 성능을 내고 있다. 릿지와 라쏘 모델을 사용할 때 규제의 양을 임의로 조절할 수 있다. 모델 객체를 만들 때 alpha매개변수로 규제의 강도를 조절한다. alpha 값이 크면 규제 강도가 세지므로 계수 값을 줄이고 더 과소적합되도록 유도한다. aplha 값이 작으면 계수를 줄이는 역할이 줄어들고 선형 회귀 모델과 유사해지므로 과대적합될 가능성이 크다. 적절한 alpha값을 찾는 한 가지 방법은 alpha값에 R^2값의 그래프를 그려 보는 것이다. 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점이 최적의 alpha 값이 된다. alpha값을 바꿀 때마다 score() 메서드의 결과를 저장할 리스트를 만든다. 123import matplotlib.pyplot as plttrain_score = []test_score = [] 다음은 alpha를 0.001에서 100까지 10배씩 늘려가며 릿지 회귀 모델을 훈련한 다음 훈련 세트와 테스트 세트의 점수를 리스트에 저장한다. 사람이 직버 지정해야 하는 매개변수 (하이퍼 파라미터) 다 돌려봐서 성능이 놓은 alpha 값 찾기 경우의 수 (15가지) A 조건 : 5가지 B 조건 : 3가지 123456789alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: # 릿지 모델을 만든다. ridge = Ridge(alpha=alpha) # 릿지 모델을 훈련한다. ridge.fit(train_scaled, train_target) # 훈련 점수와 테스트 점수를 저장한다. train_score.append(ridge.score(train_scaled, train_target)) test_score.append(ridge.score(test_scaled, test_target)) 이제 그래프를 그려본다. alpha 값을 10배씩 늘렸기 때문에 그래프 일부가 너무 촘촘해진다. alpha_list에 있는 6개의 값을 동일한 간격으로 나타내기 위해 로그 함수로 바꾸어 지수로 표현한다. 0.001은 -3, 0.01은 -2가 되는 식이다. 12345plt.plot(np.log10(alpha_list), train_score)plt.plot(np.log10(alpha_list), test_score)plt.xlabel('alpha')plt.ylabel('R^2')plt.show() 위는 훈련 세트 그래프, 아래는 테스트 세트 그래프이다. 이 그래프 왼쪽에서 두 세트의 점수 차이가 크다. 훈련 세트에만 잘 맞는 과대적합의 전형적인 모습니다. 반대로 오른쪽에서는 두 세트의 점수가 모두 낮아지는 과소적합이 나타난다. 적절한 alpha값은 두 그래프가 가장 가깝고 테스트 세트의 점수가 가장 높은 -1, 즉 10^-1 = 0.1 이다. alpha 값을 0.1로 하여 최종 모델을 훈련한다. 1234ridge = Ridge(alpha=0.1)ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target))print(ridge.score(test_scaled, test_target)) 0.9903815817570366 0.9827976465386926 이 모델은 훈련 세트와 테스트 세트의 점수가 비슷하게 모두 높고 과대적합과 과소적합 사이에서 균형을 맞추고 있다. 이번에는 라쏘 모델을 훈련해보자. 라쏘 회귀 라쏘 모델을 훈련하는 것은 릿지와 매우 비슷하다. Ridge 클래스를 Lasso 클래스로 바꾸는 것이 전부이다. 1234from sklearn.linear_model import Lassolasso = Lasso()lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target)) 0.989789897208096 라소도 과대적합을 잘 억제한 결과를 보여준다. 테스트 세트의 점수도 확인한다. 1print(lasso.score(test_scaled, test_target)) 0.9800593698421883 릿지만큼 좋은 점수가 나왔다. 앞에서와 같이 alpha값을 바꾸어 가며 훈련 세트와 테스트 세트에 대한 점수를 계산한다. 1234567891011train_score = []test_score = []alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: # 라쏘 모델을 만든다. lasso = Lasso(alpha=alpha, max_iter = 10000) # 반복 횟수를 충분히 늘리기 위해 값을 지정. # 라쏘 모델을 훈련한다. lasso.fit(train_scaled, train_target) # 훈련 점수와 테스트 점수를 저장한다. train_score.append(lasso.score(train_scaled, train_target)) test_score.append(lasso.score(test_scaled, test_target)) /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive train_score와 test_score 리스트를 사용해 그래프를 그린다. 이 그래프도 x축은 로그 스케일로 바꿔 그린다. 12345plt.plot(np.log10(alpha_list), train_score)plt.plot(np.log10(alpha_list), test_score)plt.xlabel('alpha')plt.ylabel('R^2')plt.show() 이 그래프도 왼쪽은 과대적합을 부여주고 있고, 오른쪽으로 갈수록 두 세트의 점수가 좁혀지고 있다. 라쏘 모델에서 최적의 alpha값은 1, 즉 10^1 = 10이다. 이 값으로 다시 모델을 훈련한다. 1234lasso = Lasso(alpha=0.1)lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target))print(lasso.score(test_scaled, test_target)) 0.990137631128448 0.9819405116249363 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e+02, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive 모델이 잘 훈련되었다. 라쏘 모델은 계수 값을 아예 0으로 만들 수 있다. 라쏘 모델의 계수는 coef_ 속성에 저장되어 있다. 이 중에 0인 것을 헤아려본다. 1print(np.sum(lasso.coef_ == 0)) 35 많은 계수가 0이 되었다. 55개의 특성을 모델에 주입했지만 라소 모델이사용한 특성은 15개 밖에 되지 않는다. 이런 특징 때문에 라쏘 모델을 유용한 특성을 골라내는 용도로도 사용할 수 있다. 전체 소스 코드 다음 주소를 참고하라 : https://bit.ly/hg-03-3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145# 특성 공학과 규제# 데이터 준비import pandas as pddf = pd.read_csv('https://bit.ly/perch_csv_data')perch_full = df.to_numpy()print(perch_full)import numpy as npperch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] )from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)# 사이킷런의 변환기from sklearn.preprocessing import PolynomialFeaturespoly = PolynomialFeatures()poly.fit([[2, 3]])print(poly.transform([[2, 3]]))poly = PolynomialFeatures(include_bias=False)poly.fit([[2, 3]])print(poly.transform([[2, 3]]))poly = PolynomialFeatures(include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)print(train_poly.shape)poly.get_feature_names_out()test_poly = poly.transform(test_input)# 다중 회귀 모델 훈련하기from sklearn.linear_model import LinearRegressionlr = LinearRegression()lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target))poly = PolynomialFeatures(degree=5, include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)test_poly = poly.transform(test_input)print(train_poly.shape)lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target))# 규제from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_poly)train_scaled = ss.transform(train_poly)test_scaled = ss.transform(test_poly)# 릿지 회귀from sklearn.linear_model import Ridgeridge = Ridge()ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target))print(ridge.score(test_scaled, test_target))import matplotlib.pyplot as plttrain_score = []test_score = []alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: # 릿지 모델을 만듭니다 ridge = Ridge(alpha=alpha) # 릿지 모델을 훈련합니다 ridge.fit(train_scaled, train_target) # 훈련 점수와 테스트 점수를 저장합니다 train_score.append(ridge.score(train_scaled, train_target)) test_score.append(ridge.score(test_scaled, test_target))plt.plot(np.log10(alpha_list), train_score)plt.plot(np.log10(alpha_list), test_score)plt.xlabel('alpha')plt.ylabel('R^2')plt.show()ridge = Ridge(alpha=0.1)ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target))print(ridge.score(test_scaled, test_target))from sklearn.linear_model import Lassolasso = Lasso()lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target))print(lasso.score(test_scaled, test_target))train_score = []test_score = []alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: # 라쏘 모델을 만듭니다 lasso = Lasso(alpha=alpha, max_iter=10000) # 라쏘 모델을 훈련합니다 lasso.fit(train_scaled, train_target) # 훈련 점수와 테스트 점수를 저장합니다 train_score.append(lasso.score(train_scaled, train_target)) test_score.append(lasso.score(test_scaled, test_target))plt.plot(np.log10(alpha_list), train_score)plt.plot(np.log10(alpha_list), test_score)plt.xlabel('alpha')plt.ylabel('R^2')plt.show()lasso = Lasso(alpha=10)lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target))print(lasso.score(test_scaled, test_target))print(np.sum(lasso.coef_ == 0)) [[ 8.4 2.11 1.41] [13.7 3.53 2. ] [15. 3.82 2.43] [16.2 4.59 2.63] [17.4 4.59 2.94] [18. 5.22 3.32] [18.7 5.2 3.12] [19. 5.64 3.05] [19.6 5.14 3.04] [20. 5.08 2.77] [21. 5.69 3.56] [21. 5.92 3.31] [21. 5.69 3.67] [21.3 6.38 3.53] [22. 6.11 3.41] [22. 5.64 3.52] [22. 6.11 3.52] [22. 5.88 3.52] [22. 5.52 4. ] [22.5 5.86 3.62] [22.5 6.79 3.62] [22.7 5.95 3.63] [23. 5.22 3.63] [23.5 6.28 3.72] [24. 7.29 3.72] [24. 6.38 3.82] [24.6 6.73 4.17] [25. 6.44 3.68] [25.6 6.56 4.24] [26.5 7.17 4.14] [27.3 8.32 5.14] [27.5 7.17 4.34] [27.5 7.05 4.34] [27.5 7.28 4.57] [28. 7.82 4.2 ] [28.7 7.59 4.64] [30. 7.62 4.77] [32.8 10.03 6.02] [34.5 10.26 6.39] [35. 11.49 7.8 ] [36.5 10.88 6.86] [36. 10.61 6.74] [37. 10.84 6.26] [37. 10.57 6.37] [39. 11.14 7.49] [39. 11.14 6. ] [39. 12.43 7.35] [40. 11.93 7.11] [40. 11.73 7.22] [40. 12.38 7.46] [40. 11.14 6.63] [42. 12.8 6.87] [43. 11.93 7.28] [43. 12.51 7.42] [43.5 12.6 8.14] [44. 12.49 7.6 ]] [[1. 2. 3. 4. 6. 9.]] [[2. 3. 4. 6. 9.]] (42, 9) 0.9903183436982124 0.9714559911594134 (42, 55) 0.9999999999991097 -144.40579242684848 0.9896101671037343 0.9790693977615397 0.9903815817570366 0.9827976465386926 0.989789897208096 0.9800593698421883 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive 0.9888067471131867 0.9824470598706695 40 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/03/31/chapter3_3_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter4_1","text":"로지스틱 회귀 대상이 어떤 타깃에 속할 확률을 구한다. 데이터 불러오기 컬럼 설명 177p 그림 1234import pandas as pdfish = pd.read_csv('https://bit.ly/fish_csv_data')fish.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Species Weight Length Diagonal Height Width 0 Bream 242.0 25.4 30.0 11.5200 4.0200 1 Bream 290.0 26.3 31.2 12.4800 4.3056 2 Bream 340.0 26.5 31.1 12.3778 4.6961 3 Bream 363.0 29.0 33.5 12.7300 4.4555 4 Bream 430.0 29.0 34.0 12.4440 5.1340 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-3c5195bb-ad65-485c-8b95-563887f303f2 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-3c5195bb-ad65-485c-8b95-563887f303f2'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; unique() 어떤 종류의 생선이 있는지 species 열에서 고유한 값을 추출한다. 1print(pd.unique(fish['Species'])) ['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt'] 데이터 변환 배열로 변환 12fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']] # Diagonal = 대각선fish_input.shape (159, 5) target 배열로 변환 종속변수 1fish_target = fish['Species'].to_numpy() 훈련 데이터와 테스트 데이터 이제 데이터를 훈련 세트와 테스트 세트로 나눈다. 외워야 할 정도로 중요. 자주 쓰다보면 외워진다. 1234from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state = 42) 표준화 전처리 이유가 중요하다 사이킷런의 StandardScaler 클래스를 사용해 훈련 세트와 테스트 세트를 표준화 전처리한다. 반드시 훈련 세트의 통계값으로 테스트 세트를 변환해야 한다. 123456from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) 12print(train_input[:5])print(train_scaled[:5]) Weight Length Diagonal Height Width 26 720.0 35.0 40.6 16.3618 6.0900 137 500.0 45.0 48.0 6.9600 4.8960 146 7.5 10.5 11.6 1.9720 1.1600 90 110.0 22.0 23.5 5.5225 3.9950 66 140.0 20.7 23.2 8.5376 3.2944 [[ 0.91965782 0.60943175 0.81041221 1.85194896 1.00075672] [ 0.30041219 1.54653445 1.45316551 -0.46981663 0.27291745] [-1.0858536 -1.68646987 -1.70848587 -1.70159849 -2.0044758 ] [-0.79734143 -0.60880176 -0.67486907 -0.82480589 -0.27631471] [-0.71289885 -0.73062511 -0.70092664 -0.0802298 -0.7033869 ]] k-최근접 이웃 분류기의 확률 예측 필요한 데이터를 모두 준비했다. 이제 k-최근접 이웃 분류기로 테스트 세트에 들어 있느 확률을 예측한다. 1234567from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier(n_neighbors=3) # 최근접 이웃 개수를 3으로 지정kn.fit(train_scaled, train_target)print(kn.score(train_scaled, train_target))print(kn.score(test_scaled, test_target)) 0.8907563025210085 0.85 182p 다중 분류( multi-class classification) 앞서 fish 데이터프레임에서 7종류의 생선이 있었다. fish[‘Species’]를 사용해 타깃 데이터를 만들었기에 두 세트의 타깃 데이터에도 7개의 생선 종류가 들어가 있다. 이렇게 타깃 데이터에 2개 이상의 클래스가 포함된 문제를 ‘다중 분류’라 부른다. 12345678910import numpy as np# predict_proba() 메서드로 클래스별 확률 값을 반환한다.proba = kn.predict_proba(test_scaled[:5])# round()함수. 소수점 네번째 자리로 반올림print(np.round(proba, decimals = 4))# 타깃값을 그대로 사이킷런 모델에 전달하면 순서가 알파벨 순으로 매겨진다.print(kn.classes_) [[0. 0. 1. 0. 0. 0. 0. ] [0. 0. 0. 0. 0. 1. 0. ] [0. 0. 0. 1. 0. 0. 0. ] [0. 0. 0.6667 0. 0.3333 0. 0. ] [0. 0. 0.6667 0. 0.3333 0. 0. ]] ['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish'] 위 코드의 결과는 어떤 물고기일지에 대한 확률이다. 예를 들어, 1번째 샘플은 100% 확률로 perch이다. 에를 들어, 4번째 샘플은 66% 확률로 perch이고, 33% 확률로 Roach이다. 로지스틱 회귀 중요도 : 최상 오늘 유튜브 영상 반드시 시청 개념 재복습 반드시 필요 Why? 로지스틱 회귀 기초 통계로도 활용 (의학통계) 머신러닝 부류모형의 기초 모형인데, 성능이 생각보다 나쁘지 않음 데이터셋, 수치 테이터 기반 딥러닝 : 초기모형에 해당됨. 이름은 회귀이지만 분류 모델이다. 선형 회귀와 동일하게 선형 방정식을 학습한다. 예를 들어 다음과 같다. z = a x (weight) + b x (length) + c x (Diagonal) + d x (Height) + e x (width) + f 여기에서 a, b, c, d, e는 가중치 혹은 계수이다. z 가 확률이 되려면 0~1 사이의 값이어야 한다. 이를 위해 사용하는 것이 시그모이드 함수( 또는 로지스틱 함수)이다. 1 / ( 1 + e^(-z) ) 이 식이 로지스틱 함수( 시그모이드 함수) 이다. 넘파이를 사용하여 z의 그래프를 그려보자. -5와 5 사이에서 0.1 간격으로 배열 z를 만든 다음 z 위치마다 로지스틱 함수를 계산한다. 함수 계산은 np.exp() 함수를 사용한다. 1234567891011import numpy as npimport matplotlib.pyplot as pltz = np.arange(-5, 5, 0.1)phi = 1 / (1 + np.exp(-z)) # exp는 거듭제곱, z는 범위 표시# print(z)# print(phi)plt.plot(z, phi) # 문서를 봐야 함plt.xlabel('z')plt.ylabel('phi')plt.show() 개발자 취업을 원한다면 공부 별도로 하지 않는다! 다만 알고리즘의 컨셉은 이해해야 한다. 얘기가 서로 통해야 하기 때문에 데이터 분석 관련 지망이라면 공부해야 한다. 로지스틱 회귀로 이진 분류 수행하기 사이킷런에는 로지스틱 회귀모델인 LogisticRegression 클래스가 준비되어 있다. 이진 분류이 경우 로지스틱 함수의 출력이 0.5보다 크면 양성 클래스 로지스틱 함수의 출력이 0.5보다 작으면 음성 클래스 불리언 인덱싱 (boolean indexing) 넘파일 배열은 True, False 값을 전달하여 행을 선택할 수 있다. 이를 불리언 인덱싱이라고 부른다. 12char_arr = np.array(['A', 'B', 'C', 'D', 'E'])print(char_arr[[True, False, True, False, False]]) ['A' 'C'] A 와 C만 True이므로 위 결과가 나온다. 이와 같은 방식으로 훈련 세트에서 도미(bream)와 빙어(smelt)의 행만 골라낸다. 비교 연산자를 사용하면 도미와 빙어의 행을 True로 만들 수 있다. 1234# OR 연산자(|) 를 사용하여 비교 결과를 합친다.bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')train_bream_smelt = train_scaled[bream_smelt_indexes]target_bream_smelt = train_target[bream_smelt_indexes] 위에서 bream_smelt_indexes 배열은 도미와 빙어일 경우만 True값이 들어간다. 이 배열을 사용해 train_scaled와 train_targt 배열에 불리언 인덱싱을 적용하여 도미와 빙어 데이터만 골라낼 수 있다. 186p 모형 만들고 예측하기! 이제 이 데이터로 로지스틱 회귀 모델을 훈련한다. 1234from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()# 독립변수 종속변수lr.fit(train_bream_smelt, target_bream_smelt) LogisticRegression() 훈련한 모델을 사용해 train_bream_smelt에 있는 처음 5개 샘플을 예측한다. 1234# 예측하기# 클래스로 분류# 확률값 -&gt; 0.5print(lr.predict(train_bream_smelt[:5])) ['Bream' 'Smelt' 'Bream' 'Bream' 'Bream'] 2 번째 샘플을 제외하고 모두 도미로 예측했다. 예측 확률은 predict_proba() 메서드에서 제공한다. 처음 5개 샘플의 예측 확률을 출력해 본다. 12print(lr.predict_proba(train_bream_smelt[:5])) # predict_proba에서 예측 확률 제공print(lr.classes_) [[0.99759855 0.00240145] [0.02735183 0.97264817] [0.99486072 0.00513928] [0.98584202 0.01415798] [0.99767269 0.00232731]] ['Bream' 'Smelt'] 위에서 첫번째 열이 음성 클래스(0)에 대한 확률이다. 위에서 두번째 열이 양성 클래스(1)에 대한 확률이다. bream이 음성이고, smelt가 양성 클래스이다. 이진 분류를 수행 완료했다. 이제 선형 회귀에서터럼 로지스틱 회귀가 학습한 계수를 확인한다. 방정식의 각 기울기와 상수를 구하는 코드 1print(lr.coef_, lr.intercept_) [[-0.4037798 -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132] 이 로지스틱 회귀 모델이 학습한 방정식은 다음과 같다. z = -0.404 x (weight) -0.576 x (length) -0.663 x (Diagonal) -1.103 x (Height) -0.732 x (width) -2.161 확실히 로지스틱 회귀는 선형 회귀와 비슷하다. LogistricRegression 모델로 z값을 계산해 보자. z식 z값을 출력하자. 12decisions = lr.decision_function(train_bream_smelt[:5])print(decisions) [-6.02927744 3.57123907 -5.26568906 -4.24321775 -6.0607117 ] 이 z값을 로지스틱 함수에 통과시키면 확률을 얻을 수 있다. expit() 함수를 이용해 편하게 계산 가능하다. 이 함수를 이용해 decisions 배열의 값을 확률로 변환한다. 12from scipy.special import expitprint(expit(decisions)) [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731] 양성 클래스에 대한 z값을 반환했다. 지금까지 이진 분류를 통해 2종류의 생선 샘플을 골라냈고 이를 이용해 로지스틱 회귀 모델을 훈련했다. 188p Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/02/chapter_4_1_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter4_2","text":"확률적 경사 하강법 1차 가장 큰 차이 (기존 ML모형) 샘플링 방식이 달라짐 샘플링을 좀 더 세분화함 2차 가장 큰 차이 오차를 보정 (200p~201p) 기울기 보정이다. 미분으로 기울기(경사)를 구한다. 기울기가 0에 가까워질 때까지 반복한다. 경사하강법이 쓰인 여러 알고리즘 (이미지, 텍스트) 딥러닝 기초 알고리즘 트리 알고리즘 + 경사하강법 융햡 = 부스팅 계열 : 대표 알고리즘 : LightGBM, Xgboost, Catboost : 1등으로 자주 쓰인 알고리즘 = lightGBM, Xgboost : 하이퍼 파라미터의 개수가 80개 넘음 머신러닝의 목적 : 오차를 줄이는 것 오차 = 손실(Cost) 손실 함수(loss function) 손실(Cost) = 오차 SGDClassifier 확률적 경사하강법 분류기 123import pandas as pd fish = pd.read_csv(&quot;https://bit.ly/fish_csv_data&quot;)fish.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 159 entries, 0 to 158 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Species 159 non-null object 1 Weight 159 non-null float64 2 Length 159 non-null float64 3 Diagonal 159 non-null float64 4 Height 159 non-null float64 5 Width 159 non-null float64 dtypes: float64(5), object(1) memory usage: 7.6+ KB 배열로 변환하는 코드 독립변수 = fish_input 종속변수 = fish_target 12fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']] # Diagonal = 대각선fish_target = fish['Species'].to_numpy() 훈련 데이터와 테스트 데이터 이제 데이터를 훈련 세트와 테스트 세트로 나눈다. 외워야 할 정도로 중요. 자주 쓰다보면 외워진다. 12345from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state = 42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((119, 5), (40, 5), (119,), (40,)) 표준화 처리 다시 한 번 강조하지만 꼭 훈련 세트에서 학습한 통계값으로 테스트 세트도 변환한다. 키워드 : Data Leakage 방지 데이터 분석 희망자! 필수 공부! 12345678from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)# ss 훈련데이터만 활용해서 학습(?)이 끝난 상태# 표준화 처리를 훈련데이터와 테스트데이터에 동시 적용train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) 모델 학습 2개의 매개 변수 지정 loss = “log” = 로지스틱 손실 함수로 지정 max_iter = 에포크 횟수 지정 1234567891011121314from sklearn.linear_model import SGDClassifier# 매개변수 지정# 하이퍼파라미터 설정## 매개변수 값을 dictionary 형태로 추가하는 코드 작성 가능## 강사는 입문자들에게는 비추천sc = SGDClassifier(loss = &quot;log&quot;, max_iter = 40, random_state=42)\\# 모형학습sc.fit(train_scaled, train_target)# 스코어 확인 (정확도)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.8571428571428571 0.8 에포크 최적의 기울기를 찾아야 한다. 적절한 에포크 숫자를 찾자 1234567891011121314import numpy as npsc = SGDClassifier(loss= &quot;log&quot;, random_state=42)train_score=[]test_score=[]classes = np.unique(train_target)for _ in range(0,300): sc.partial_fit(train_scaled, train_target, classes=classes) train_score.append(sc.score(train_scaled, train_target)) test_score.append(sc.score(test_scaled, test_target))# 정확도print(train_score[:5])print(test_score[:5]) [0.5294117647058824, 0.6218487394957983, 0.6386554621848739, 0.7310924369747899, 0.7226890756302521] [0.65, 0.55, 0.575, 0.7, 0.7] 모형 학습 시각화 12345678import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(train_score) # 푸른색ax.plot(test_score) # 주황색ax.set_xlabel(&quot;Epoch&quot;)ax.set_ylabel(&quot;Accuracy&quot;)plt.show() 위 결과 25쯤에서 과소적합. 위 결과 125쯤에서 과대적합. 이 모델의 경우 100번째 Epoch가 적절한 반복 횟수로 보인다. 그럼 SGDClassifier의 반복 횟루를 100에 맞추고 모델을 다시 훈련한다. 그리고 최종적으로 훈련 세트와 테스트 세트에서 점수를 출련한다. 12345sc = SGDClassifier(loss = 'log', max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.957983193277311 0.925 SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다. tol 매개변수에서 향상될 최솟값을 지정한다. 앞의 코드에서는 tol매개변수를 None으로 지정하여 자동으로 멈추지 않고 max_iter=100 만큼 무조건 반복하도록 했다. 결과적으로 점수가 높게 나왔다. 확률적 경사 하강법을 사용한 생선 분류 문제를 성공적으로 수행했다. loss 매개변수 SGDClassifier의 매개변수이다. loss 매개변수의 기본값은 ‘hinge’이다. ‘힌지 손실’은 ‘서포트 벡터 머신’ 이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수이다. 한 마디로 loss 매개변수는 여러 알고리즘에서 쓰이는 매개변수이다. loss 매개변수와 힌지 손실 예시 간단한 예로 힌지 손실을 사용해 같은 반복 횟수 동안 모델을 훈련해보자. 1234sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.9495798319327731 0.925 전체 소스 코드1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 확률적 경사 하강법# SGDClassifierimport pandas as pd fish = pd.read_csv(&quot;https://bit.ly/fish_csv_data&quot;)fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']] # Diagonal = 대각선fish_target = fish['Species'].to_numpy()from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state = 42)from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)# ss 훈련데이터만 활용해서 학습(?)이 끝난 상태# 표준화 처리를 훈련데이터와 테스트데이터에 동시 적용train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input)from sklearn.linear_model import SGDClassifier# 매개변수 지정# 하이퍼파라미터 설정## 매개변수 값을 dictionary 형태로 추가하는 코드 작성 가능## 강사는 입문자들에게는 비추천sc = SGDClassifier(loss = &quot;log&quot;, max_iter = 40, random_state=42)\\# 모형학습sc.fit(train_scaled, train_target)# 스코어 확인 (정확도)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target))sc = SGDClassifier(loss = 'log', max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target))sc.partial_fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target))# 에포크와 과대/과소적합import numpy as npsc = SGDClassifier(loss= &quot;log&quot;, random_state=42)train_score=[]test_score=[]classes = np.unique(train_target)for _ in range(0,300): sc.partial_fit(train_scaled, train_target, classes=classes) train_score.append(sc.score(train_scaled, train_target)) test_score.append(sc.score(test_scaled, test_target))# 정확도print(train_score[:5])print(test_score[:5])import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(train_score) # 푸른색ax.plot(test_score) # 주황색ax.set_xlabel(&quot;Epoch&quot;)ax.set_ylabel(&quot;Accuracy&quot;)plt.show()sc = SGDClassifier(loss = 'log', max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target))sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.8571428571428571 0.8 0.957983193277311 0.925 0.9411764705882353 0.925 [0.5294117647058824, 0.6218487394957983, 0.6386554621848739, 0.7310924369747899, 0.7226890756302521] [0.65, 0.55, 0.575, 0.7, 0.7] 0.957983193277311 0.925 0.9495798319327731 0.925 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/03/chapter_4_2_%EA%B9%80%EB%AF%BC%EA%B7%A0/"},{"title":"chapter_5_1","text":"결정 트리 결정 트리로 다음 문제를 해결해 보자 와인 캔에 인쇄된 알코올 도수, 당도, pH값으로 와인 종류를 구별해야 한다. 로지스틱 회귀로 와인 분류하기 우선 로지스틱 회귀로 문제 해결을 시도해본다. 데이터 불러오기 와인데이터 alcohol(알고올 도수), sugar(당도), pH(산도) 클래스 0 = 레드 와인 클래스 1 = 화이트 와인 123import pandas as pdwine = pd.read_csv('https://bit.ly/wine_csv_data')wine.head(5) # 데이터 잘 들어왔는지 확인 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol sugar pH class 0 9.4 1.9 3.51 0.0 1 9.8 2.6 3.20 0.0 2 9.8 2.3 3.26 0.0 3 9.8 1.9 3.16 0.0 4 9.4 1.9 3.51 0.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-ed50d596-f5ff-4ae2-a52f-cd3b0b3d75ad'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['/images/chapter_5_1/output_type'] = 'display_data'; await google.colab./images/chapter_5_1/output.render/images/chapter_5_1/output(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; info() 결측치 확인 / 변수 타입 1wine.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 6497 entries, 0 to 6496 Data columns (total 4 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 alcohol 6497 non-null float64 1 sugar 6497 non-null float64 2 pH 6497 non-null float64 3 class 6497 non-null float64 dtypes: float64(4) memory usage: 203.2 KB 12wine.describe()# 표준화가 안되어 있음을 알 수 있다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol sugar pH class count 6497.000000 6497.000000 6497.000000 6497.000000 mean 10.491801 5.443235 3.218501 0.753886 std 1.192712 4.757804 0.160787 0.430779 min 8.000000 0.600000 2.720000 0.000000 25% 9.500000 1.800000 3.110000 1.000000 50% 10.300000 3.000000 3.210000 1.000000 75% 11.300000 8.100000 3.320000 1.000000 max 14.900000 65.800000 4.010000 1.000000 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-decc42d0-d914-4603-8cd7-d87f4c9e480a button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-decc42d0-d914-4603-8cd7-d87f4c9e480a'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['/images/chapter_5_1/output_type'] = 'display_data'; await google.colab./images/chapter_5_1/output.render/images/chapter_5_1/output(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 표준화 작업 배열로 바꿔서 진행 12data = wine[['alcohol', 'sugar', 'pH']].to_numpy() # 참고할 데이터target = wine['class'].to_numpy() # class = 타깃값 = 어떤 와인인지 구분하는 것이 목표 훈련데이터와 테스트데이터로 분리 train_test_split() 함수는 설정값을 지정하지 않으면 25%를 테스트 세트로 지정한다. 이번엔 샘플 개수가 충분히 많으므로 20% 정도만 테스트 세트로 나눈다. test = 0.2 에는 이러한 의도가 담겨 있다. 123456from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42 # test_size=0.2 는 20%를 테스트 세트로 한다는 뜻.)print(train_input.shape, test_input.shape) (5197, 3) (1300, 3) 이제 표준화 진행하자 12345from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) 모델 만들기로지스틱 회귀 표준변환된 train_scaled와 test_scaled를 사용해 로지스틱 회귀 모델을 훈련한다. 123456from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()lr.fit(train_scaled, train_target)print(lr.score(train_scaled, train_target))print(lr.score(test_scaled, test_target))print(lr.coef_, lr.intercept_) 0.7808350971714451 0.7776923076923077 [[ 0.51270274 1.6733911 -0.68767781]] [1.81777902] 점수가 높게 나오지 않았다. 결정 트리를 이용하여 좀 더 쉽게 문제를 해결해보자 로지스틱 회귀 수식 의사결정트리의 기본 알고리즘을 활용해서, MS, 구글 등 이런 회사들이 신규 알고리즘을 만듬 XGBoost, lightGBM, CatBoost 캐글 정형데이터 lightGBM (지금 현재 실무에서 많이 쓰임) 4월 말까지는 코드에 집중. 대회 나감 PPT (알고리즘 소개) 결정 트리 (Decision Tree) 스무 고개와 같다. 질문을 하나씩 던져서 정답과 맞춰가는 것이다. 표준화된 훈련 세트를 이용하여 결정트리를 사용해 본다. 123456from sklearn.tree import DecisionTreeClassifierdt = DecisionTreeClassifier(random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target)) # 훈련 세트print(dt.score(test_scaled, test_target)) # 테스트 세트 0.996921300750433 0.8592307692307692 위 코드의 두 결과는 차이가 있다. 두 결과가 유사하게 나와야 한다. 앞으로 ‘가지치기’에서 차이를 좁히는 과정을 진행한다. 123456# 현재 트리의 형태를 출력해본다.import matplotlib.pyplot as pltfrom sklearn.tree import plot_treeplt.figure(figsize=(10,7))plot_tree(dt)plt.show() 과대적합이 나오는 이유 : 조건식을 걸기 때문 1234# plot_tree()함수에서 트리의 깊이를 제한하여 출력해 본다.plt.figure(figsize=(10,7))plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])plt.show() 불순도 : 운동회 ox 퀴즈에서 정답을 맞힌 사람만 살아남는 것과 같은 원리 가지치기 과대적합을 방지하기 위한 것 가지치기를 통해 두 결과가 유사하게 출력된다. 1234dt = DecisionTreeClassifier(max_depth = 3, random_state=42) # max_depth 매개변수 조절을 통해 가지치기 한다.dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target)) # 훈련 세트print(dt.score(test_scaled, test_target)) # 데이터 세트 0.8454877814123533 0.8415384615384616 훈련 세트와 테스트 성능이 유사하게 출력되었다. 이런 모델을 트리 그래프로 그린다면 훨씬 이해햐기 쉬울 것이다. 123plt.figure(figsize=(20,15))plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])plt.show() 훨씬 보기 좋게 출력되었다. 루트 노트 당도(sugar)를 기준으로 훈련세트를 나눈다. 깊이 1의 노드 모두 당도(sugar)를 기준으로 훈련 세트를 나눈다. 깊이 2의 노드 맨 왼쪽의 노드만 당도를 기준으로 나눈다. 왼쪽에서 두 번째 노드는 알고올 도수(alcohol)를 기준으로 나눈다. 오른쪽 두 노드는 pH를 기준으로 나눈다. 리프 노드 왼쪽에서 3번째에 있는 노드만 음성 클래스가 더 많다. 이 노드에 도착해야만 레드 와인으로 예측한다. 이 노드에 도달하려면 -0.802 &lt; sugar &lt; -0.239, alcohol &lt; -0.454 라는 조건을 만족해야 한다. 즉, -0.802 &lt; sugar &lt; -0.239, alcohol &lt; -0.454 이면 레드와인이다 그런데 -0.802라는 음수로 된 당도를 어떻게 설명해야할까? 좀 더 설명하기 쉽게 바꿔보자. 특성값의 스케일은 결정 트리 알고리즘에 아무런 영향을 미치지 않는다. 따라서 표준화 전처리를 할 필요가 없다. 전처리하기 전의 훈련 세트(train_input)와 테스트 세트(test_input)로 결정 트리 모델을 다시 훈련해 본다. 123456dt = DecisionTreeClassifier(max_depth=3, random_state=42)# 가지치기 때와 달리 train_scaled를 사용하지 않았다. 표준화 전처리 할 필요가 없기 때문인 듯.dt.fit(train_input, train_target)print(dt.score(train_input, train_target))print(dt.score(train_input, train_target)) 0.8454877814123533 0.8454877814123533 정확히 같은 결과가 나왔다. 트리도 그려보자. 123plt.figure(figsize=(20, 15))plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])plt.show() 같은 트리지만 특성값을 표준점수로 바꾸지 않았기에 이해하기 훨씬 쉽다. 적어도 당도를 음수로 표기하는 것보단 보기 좋다. 다음 조건을 만족하는 것이 레드 와인이다. (1.625 &lt; sugar &lt; 4.325) AND (alcohol &lt; 11.025) = 레드 와인 특성 중요도 결정 트리는 어떤 특성이 가장 유용한지 나타내는 특성 중요도를 계산해준다. 이 트리의 루트 노드와 깊이 1에서 sugar를 사용했기 때문에 아마 sugar가 가장 유용한 특성 중 하나일 것이다. 특성 중요도는 결정 트리 모델의 feature_importances_ 속성에 저장되어 있다. 1print(dt.feature_importances_) [0.12345626 0.86862934 0.0079144 ] alcohol ,sugar, ph 순서이기 때문에 두 번째인 sugar의 중요도가 가장 높은 것을 알 수 있다. 번외 123456789101112import graphvizfrom sklearn import tree# DOT datadot_data = tree.export_graphviz(dt, out_file=None, feature_names = ['alcohol', 'sugar', 'pH'], filled=True)# Draw graphgraph = graphviz.Source(dot_data, format=&quot;png&quot;) graphgraph.render(&quot;decision_tree_graphivz&quot;) 'decision_tree_graphivz.png' 123456789101112131415from matplotlib.colors import ListedColormap, to_rgbimport numpy as npplt.figure(figsize=(20, 15))artists = plot_tree(dt, filled = True, feature_names = ['alcohol', 'sugar', 'pH'])colors = ['blue', 'red']for artist, impurity, value in zip(artists, dt.tree_.impurity, dt.tree_.value): r, g, b = to_rgb(colors[np.argmax(value)]) f = impurity * 2 artist.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b)) artist.get_bbox_patch().set_edgecolor('black')plt.show() Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/04/chapter_5_1/"},{"title":"chapter_5_2","text":"교차 검증과 그리드 서치 키워드 : 하이퍼 파라미터 데이터가 작을 때, 주로 사용 하이퍼 파라미터 max_depth : 3, 정확도가 84% 결론 모르면 디폴트만 쓰자! 가성비 (시간 대비 성능 보장 안됨!) 검증 세트 테스트 세트(1회성) 훈련 데이터를 훈련 데이터 + 검증 데이터로 재 분할 현실 테스트 데이터가 별도로 존재하지 않음! 전체 데이터 = 훈련 (6) : 검증 (2) : 테스트 (2) 테스트 데이터는 모르는 데이터로 생각! 캐글 캐글에서는 훈련, 테스트 데이터가 제공된다. 훈련 데이터만 한 번 쪼개서 사용하면 된다. 참고 사이킷 런 : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html 구글링 : 그리드 탐색(서치) vs 랜덤 탐색(서치) 12345import pandas as pdwine = pd.read_csv(&quot;https://bit.ly/wine_csv_data&quot;)data = wine[['alcohol', 'sugar', 'pH']].to_numpy()target = wine['class'].to_numpy() 12345from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42) 123sub_input, val_input, sub_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42) 모델 만든 후 평가12345from sklearn.tree import DecisionTreeClassifierdt = DecisionTreeClassifier(random_state=42)dt.fit(sub_input, sub_target)print(dt.score(sub_input, sub_target))print(dt.score(val_input, val_target)) 0.9971133028626413 0.864423076923077 교차 검증 많이 하면 많이 할수록 좋다. 교차 검증의 목적 : 좋은 모델이 만들어진다! 좋은 모델 != 성능 좋은 모델 좋은 모델 = 과대 적합이 아닌 모델 = 모형의 오차가 적은 모델 = 안정적인 모델 교재 245p 모델 평가 1 : 90% 모델 평가 2 : 85% 모델 평가 3 : 80% 단점 : 시간이 오래 걸림 교차 검증 함수123from sklearn.model_selection import cross_validatescores = cross_validate(dt, train_input, train_target)print(scores) {'fit_time': array([0.01164412, 0.00772762, 0.00744891, 0.00796771, 0.00716805]), 'score_time': array([0.00128865, 0.00070405, 0.0007143 , 0.00097823, 0.00069904]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])} 최종점수 평균 구하기 12import numpy as npprint(np.mean(scores['test_score'])) 0.855300214703487 훈련 세트 섞은 후, 10-폴드 교차검증 12345from sklearn.model_selection import StratifiedKFoldsplitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state=42)scores = cross_validate(dt, train_input, train_target, cv = splitter)print(np.mean(scores['test_score'])) 0.8574181117533719 하이퍼 파라미터 튜닝 꼭 하고 싶다! 랜덤 서치 사용하자! 그리드 서치보다 편리하다 자동으로 잡아주는 라이브러리들이 등장하기 시작함 hyperopt 123456789%%timefrom sklearn.model_selection import GridSearchCVparams = { 'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],}# dt = DecisionTreeClassifier(random_state=42)gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)gs.fit(train_input, train_target) CPU times: user 83.8 ms, sys: 1.66 ms, total: 85.5 ms Wall time: 264 ms pamas에 2줄을 쓰면 시간이 2배 이상 더 걸린다. 12345678910%%timefrom sklearn.model_selection import GridSearchCVparams = { 'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005], 'max_depth' : [3, 4, 5, 6, 7]}# dt = DecisionTreeClassifier(random_state=42)gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)gs.fit(train_input, train_target) CPU times: user 191 ms, sys: 1.13 ms, total: 192 ms Wall time: 674 ms 123456789101112131415%%timefrom sklearn.model_selection import GridSearchCVparams = { 'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005], 'max_depth' : [3, 4, 5, 6, 7]}# dt = DecisionTreeClassifier(random_state=42)gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)gs.fit(train_input, train_target)dt = gs.best_estimator_print(dt)print(dt.score(train_input, train_target))print(gs.best_params_) DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005, random_state=42) 0.8830094285164518 {'max_depth': 7, 'min_impurity_decrease': 0.0005} CPU times: user 284 ms, sys: 38.7 ms, total: 323 ms Wall time: 2.15 s 이 부분에 의해 결과가 (5x5=)25개 출력된다. ‘min_impurity_decrease’ : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005] ‘max_depth’ : [3, 4, 5, 6, 7] 1print(gs.cv_results_['mean_test_score']) [0.84125583 0.84125583 0.84125583 0.84125583 0.84125583 0.85337806 0.85337806 0.85337806 0.85337806 0.85318557 0.85780355 0.85799604 0.85857352 0.85857352 0.85838102 0.85645721 0.85799678 0.85876675 0.85972866 0.86088306 0.85607093 0.85761031 0.85799511 0.85991893 0.86280466] 랜덤 서치 p252. 매개변수 값의목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있도록 확률 분포 객체를 전달. 123from scipy.stats import uniform, randintrgen = randint(0, 10)rgen.rvs(10) array([7, 9, 7, 4, 2, 0, 4, 8, 6, 3]) 1np.unique(rgen.rvs(1000), return_counts = True) (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([103, 90, 88, 110, 84, 115, 105, 102, 104, 99])) 254p 1234567891011from sklearn.model_selection import RandomizedSearchCVparams = { 'min_impurity_decrease' : uniform(0.0001, 0.001), 'max_depth' : randint(20,50)}gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter = 100, n_jobs = -1, random_state=42)gs.fit(train_input, train_target) RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_iter=100, n_jobs=-1, param_distributions={'max_depth': &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa6910bdd90&gt;, 'min_impurity_decrease': &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa6907f3810&gt;}, random_state=42) 위 parmas에 정의된 매개변수 범위에서 총 100번(n_iter 매개변수)을 샘플링하여 교차 검증을 수행하고 최적의 매개변수 조합을 찾는다. 앞서 그리드 서치보다 훨씬 교차 검증 수를 줄이면서 넓은 영역을 효과적으로 탐색할 수 있다. 결과를 확인해보자. 먼저 최적의 매개변수 조합을 출력한다. 1print(gs.best_params_) {'max_depth': 29, 'min_impurity_decrease': 0.000437615171403628} 최고의 교차 검증 점수도 확인한다. 1print(np.max(gs.cv_results_['mean_test_score'])) 0.8689635004071962 최적의 모델은 이미 전체 훈련 세트(train_input, train_target)로 훈련되어 best_estimator_속성에 저장되어 있다. 이 모델을 최종 모델로 결정하고 테스트 세트의 성능을 확인해 보자 12dt = gs.best_estimator_print(dt.score(test_input, test_target)) 0.8638461538461538 테스트 세트 점수는 검증 세트에 대한 점수보다 조금 작은 것이 일반적이다. 여기까지 두 서치를 사용해 본 결과, 랜덤 서치가 더 사용하기 용이하였다. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/04/chapter_5_2/"},{"title":"chapter_5_3","text":"트리의 앙상블 lightGBM 기억! GBM –&gt; XGBoost –&gt; LightGBM 참고 1. 모델개발속도가 빨라졌나? 참고 2. 모델의 성능이 좋아졌나? TabNet(2019) 딥러닝 컨셉! 랜덤 포레스트(Forest) 결정 트리를 랜덤하게 만들어 결정 트리의 숲을 만든다. 결정 트리 나무를 500개 심기 최종적인 결정은 투표 방식 나무-1 : 양성 나무_2 : 음성 나무_3 : 양성.. 나무-500 : 양성 데이터 불러오기 넘파이 배열로 변환 데이터 세트 나누기 12345678910111213import numpy as npimport pandas as pdfrom sklearn.model_selection import train_test_splitwine = pd.read_csv('https://bit.ly/wine_csv_data')data = wine[['alcohol', 'sugar', 'pH']].to_numpy()target = wine['class'].to_numpy()train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42) 267p cross_validate()함수 : 교차 검증 수행 RandomForestClassifier는 기본적으로 100개의 트리를 사용하므로 n_jops=-1로 지정하여 모든 CPU 코어를 사용한다. 1234567from sklearn.model_selection import cross_validatefrom sklearn.ensemble import RandomForestClassifierrf = RandomForestClassifier(n_jobs=-1, random_state=42) # n_jobs = -1은 pc의 모든 코어를 사용하겠다는 뜻scores = cross_validate(rf, train_input, train_target, return_train_score = True, n_jobs=-1)print(np.mean(scores['train_score']), np.mean(scores['test_score'])) 0.9973541965122431 0.8905151032797809 랜덤 포레스트는 결정 트리의 앙상블이기 때문에 DecisionTreeClassifier가 제공하는 매개변수를 모두 제공한다. 또한 결정 트리의 큰 장점 중 하나인 특성 중요도를 계산한다. 랜덤 포레스트 모델을 훈련 세트에 훈련한 후 특성 중요도를 출력해 본다. 12rf.fit(train_input, train_target)print(rf.feature_importances_) [0.23167441 0.50039841 0.26792718] 두 번째 특성인 sugar가 가장 중요도가 높다는 것을 알 수 있다. RandomForestClassifier는 자체적으로 모델을 평가하는 점수를 얻을 수도 있다. 이 점수를 얻으려면 RandomForestClassifier 클래스의 oob_score 매개변수를 True로 지정해야 한다. oob_score = True로 지정하고 모델을 훈련하여 OOB 점수를 출력해보자. 123rf = RandomForestClassifier(oob_score = True, n_jobs=-1, random_state=42)rf.fit(train_input, train_target)print(rf.oob_score_) 0.8934000384837406 교차 검즈에서 얻은 점수와 매우 비슷한 결과를 얻었다. 그래이디언트 부스팅 그 이전 트리의 오차를 보완하는 방식으로 사용 깊이가 얕은 트리를 사용. 학습률 매개변수로 속도를 조절. 단점 : 속도가 느림. 123456from sklearn.ensemble import GradientBoostingClassifiergb = GradientBoostingClassifier(random_state=42)scores = cross_validate(gb, train_input, train_target, return_train_score = True, n_jobs=-1)print(np.mean(scores['train_score']), np.mean(scores['test_score'])) 0.8881086892152563 0.8720430147331015 거의 과대적합이 되지 않았다. 그래디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강하다. 학습률을 증가시키고 트리의 개수를 늘리면 조금 더 성능이 향상될 수 있다. 12345gb = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.2, random_state = 42)scores = cross_validate(gb, train_input, train_target, return_train_score = True, n_jobs=-1)print(np.mean(scores['train_score']), np.mean(scores['test_score'])) 0.9464595437171814 0.8780082549788999 결정 트리 개수를 500개로 늘렸다. 5배로 늘렸지만 과대적합을 잘 억제하고 있다. 학습률 learning_rate의 기본값은 0.1이다. 그레이디언트 부스팅도 특성 중요도를 제공한다. 결과에서 볼 수 있듯이 그레이디언트 부스팅이 랜덤 포레스트보다 일부 특성(당도)에 더 집중한다. 12gb.fit(train_input, train_target)print(gb.feature_importances_) [0.15872278 0.68010884 0.16116839] 흐름 데이터 전처리 / 시각화 기본 모형으로 전체 흐름을 설계 여러 모형으로 비교 대조 교차 검증, 하이퍼 파라미터 성능 비교 … 1등 하는 그날까지 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/05/chapter_5_3/"},{"title":"chapter_6_2","text":"k-평균 각각의 픽셀값 (3차원 -&gt; 1차원 배열) 평균 구함 픽셀의 평균값은 활용해서 사과, 바나나, 파인애플에 근사한 이미지를 추출한 것 어떻게 평균값을 구할 수 있을까? k-평균 알고리즘 (k-Means) 알고리즘 평균값 = Cluster Center = Centroid 데이터 불러오기다음을 참고하라 : http://bit.ly/hg-06-2 1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-03-31 02:17:17-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10 Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 02:17:17-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 192.30.255.112 Connecting to github.com (github.com)|192.30.255.112|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 02:17:17-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: ‘fruits_300.npy’ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.05s 2022-03-31 02:17:17 (56.9 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128] 넘파이 파일을 불러옴 123456import numpy as npimport matplotlib.pyplot as pltfruits = np.load('fruits_300.npy')print(fruits.shape)print(fruits.ndim) (300, 100, 100) 3 3차원 (샘플개수, 너비, 높이) 2차원 (샘플개수, 너비 x 높이) 12fruits_2d = fruits.reshape(-1, 100*100)fruits_2d.shape (300, 10000) k-평균 알고리즘 활용 123from sklearn.cluster import KMeanskm = KMeans(n_clusters=3, random_state = 42)km.fit(fruits_2d) KMeans(n_clusters=3, random_state=42) 모형학습 후, labels 1print(km.labels_) [2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 직접 샘플의 개수 확인 1print(np.unique(km.labels_, return_counts=True)) (array([0, 1, 2], dtype=int32), array([111, 98, 91])) 12345678910111213141516import matplotlib.pyplot as pltdef draw_fruits(arr, ratio=1): n = len(arr) # n은 샘플 개수입니다 # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. rows = int(np.ceil(n/10)) # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다. cols = n if rows &lt; 2 else 10 fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False) for i in range(rows): for j in range(cols): if i*10 + j &lt; n: # n 개까지만 그립니다. axs[i, j].imshow(arr[i*10 + j], cmap='gray_r') axs[i, j].axis('off') plt.show() 1draw_fruits(fruits[km.labels_==0]) 클러스터 중심1draw_fruits(km.cluster_centers_.reshape(-1, 100, 100), ratio=3) 1print(km.transform(fruits_2d[100:101])) [[3393.8136117 8837.37750892 5267.70439881]] 1print(km.predict(fruits_2d[100:101])) [0] 1draw_fruits(fruits[100:101]) 최적의 k-평균 찾기1234567inertia = []for k in range(2, 7): km = KMeans(n_clusters = k, random_state=42) km.fit(fruits_2d) inertia.append(km.inertia_)plt.plot(range(2, 7), inertia)plt.show() 위 결과 최적의 k-평균은 3.0 정도 된다. chapter6. 비지도학습은 잘 안 쓰인다. 시각화 문법만 유의해서 살펴보자. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/06/chapter_6_2/"},{"title":"chapter_6_3","text":"주성분 분석 (PCA)PCA (주성분 분석) 차원축소의 개념 PCA 개념 과일 사진의 겨우, 10,000개의 픽셀 (높이 x 너비) 10,000개의 특성이 있는 셈(차원) 정형데이터에서도 활용 가능 문자열 데이터, 수치형 데이터 (연속형 데이터, 비연속형 데이터) 캐글 대회 : 수치형 컬럼 304개 연산은 RAM에서 처리 라면을 5개 끓여야 함 / 냄비 크기는 3개 용량 차원축소 = 일부 특성을 선택하여 데이터 크기를 줄임 머신러닝 측면 : 과대적합 방지 &amp; 성능 향상 데이터가 너무 많으니까 RAM에 부하가 걸린다. 따라서 데이터를 줄이고 과대적합을 방지하기 위한 것 양적 데이터 사이의 분산-공분산 관계를 이용해서 선형결합으로 표시되는 주성분을 찾음 2~3개의 주성분으로 전체 변동을 찾는 것이 PCA p326 그래프를 보면, 처음 10개의 주성분이 (10,000개의 픽셀) 굳이 10,000개의 픽셀을 전부 쓸 필요가 없다. 알고리즘 구성할 때, 필요한 데이터 픽셀 수, 300 x 10,000개 픽셀 원래는 300 x 10,000개 픽셀 필요 그런데, 300 x pc 10 주성분으로 줄임 기존 1시간 걸림 / 이제 10분 걸림 그럼에도 불구하고, 분류가 더 잘되더라. PCA 클래스데이터 불러오기1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-03-31 06:16:36-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10 Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 06:16:36-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 192.30.255.113 Connecting to github.com (github.com)|192.30.255.113|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 06:16:36-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: ‘fruits_300.npy’ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.04s 2022-03-31 06:16:36 (64.8 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128] 배열로 업로드 1234import numpy as npfruits = np.load(&quot;fruits_300.npy&quot;)fruits_2d = fruits.reshape(-1, 100*100)fruits_2d.shape (300, 10000) sklearn.decomposition 모듈 사이킷런은 이 모듈 아래 PCA 클래스로 주성분 분석 알고리즘을 제공한다. k-평균과 마찬가지로 비지도 학습이기 때문에 fit()메서드에 타깃값을 제공하지 않는다. 12345from sklearn.decomposition import PCApca = PCA(n_components = 50)# PCA 50개 성분으로 300 x 10000 픽셀값을 압축pca.fit(fruits_2d) PCA(n_components=50) PCA 클래스가 찾은 주성분은 components_ 속성에 저장되어 있다. 1print(pca.components_.shape) (50, 10000) 그래프 그리기 draw_fuits()함수를 사용해서 이 주성분을 그림으로 그려보자. 123456789101112131415161718import matplotlib.pyplot as pltdef draw_fruits(arr, ratio=1): n = len(arr) # n은 샘플 개수입니다 # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. rows = int(np.ceil(n/10)) # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다. cols = n if rows &lt; 2 else 10 fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False) for i in range(rows): for j in range(cols): if i*10 + j &lt; n: # n 개까지만 그립니다. axs[i, j].imshow(arr[i*10 + j], cmap='gray_r') axs[i, j].axis('off') plt.show()draw_fruits(pca.components_.reshape(-1, 100, 100)) 12fruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape) (300, 50) 데이터의 원래 크기 대비해서 1/200 줄임 용량이 줄었다는 것과 똑같음 원본 데이터 재구성 10,000개의 특성을 50개로 줄임 100% 재구성은 어렵지만, 그래도 쓸만하다. 12fruits_inverse = pca.inverse_transform(fruits_pca)print(fruits_inverse.shape) (300, 10000) 그래프 작성 10000개의 데이터가 복원되었다. 이 데이터를 100 x 100 크기로 바꾸어 100개씩 나누어 출력한다. 12fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)print(fruits_reconstruct.shape) (300, 100, 100) 1234# 압축을 풀고 사용하는 연쇄적인 과정for start in [0, 100, 200]: draw_fruits(fruits_reconstruct[start:start + 100]) print(&quot;\\n&quot;) 설명된 분산12plt.plot(pca.explained_variance_ratio_)plt.show() 처음 10개의 주성분이 대부분의 분산을 표현한다. 11개 주성분부터 ~50개까지는 잘 설명이 안됨 1print(np.sum(pca.explained_variance_ratio_)) 0.9215782334086065 다른 알고리즘과 함께 사용하기 3개의 과일 사진 분류 위해 로지스틱 회귀 123456from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()target = np.array([0]*100 + [1]*100 + [2]*100)print(target) [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] 교차검증 진행 1234from sklearn.model_selection import cross_validatescores = cross_validate(lr, fruits_2d, target)print(np.mean(scores['test_score']))print(np.mean(scores['fit_time'])) 0.9966666666666667 1.5795912265777587 PCA 수행 후, 학습 시간 비교 123scores = cross_validate(lr, fruits_pca, target)print(np.mean(scores['test_score']))print(np.mean(scores['fit_time'])) 1.0 0.12322616577148438 PCA 수행 후, fit_time이 짧게 단축되었다. 1.57 -&gt; 0.12 로 시간이 짧아졌다. 그러니 특성이 너무 많으면 PCA를 사용하자. 주 성분의 매개변수 개수 지정, 분산비율 지정 123pca = PCA(n_components = 0.5)pca.fit(fruits_2d)print(pca.n_components_) 2 주성분을 2개로 압축시킴. 12fruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape) (300, 2) 123scores = cross_validate(lr, fruits_pca, target)print(np.mean(scores['test_score']))print(np.mean(scores['fit_time'])) 0.9933333333333334 0.051814031600952146 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, 차원 축소된 데이터를 k-평균 알고리즘에 추가한다. 1234from sklearn.cluster import KMeanskm = KMeans(n_clusters=3, random_state=42)km.fit(fruits_pca)print(np.unique(km.labels_, return_counts = True)) (array([0, 1, 2], dtype=int32), array([110, 99, 91])) 123for label in range(0,3): draw_fruits(fruits[km.labels_ == label]) print(&quot;\\n&quot;) 시각화로 뿌려주기 12345for label in range(0,3): data = fruits_pca[km.labels_ == label] plt.scatter(data[:, 0], data[:, 1])plt.legend(['apple', 'banana', 'pineapple'])plt.show() Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/06/chapter_6_3/"},{"title":"chapter_6_1","text":"비지도 학습 vs 지도 학습 종속 변수가 있다 = 타겟이 있다 비지도 학습은 종속변수 및 타겟이 없다. 분류 다중분류 전제조건 : (다양한 유형) 데이터가 많아야 함 딥러닝과 연관이 됨(자연어 처리, 이미지) 데이터 불러오기 과일가게 문제 : 많은 과일 사진을 각 과일 별로 분류해야 한다. 다음을 참고하라 : http://bit.ly/hg-06-1 1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-03-31 03:09:03-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10 Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 03:09:03-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 140.82.121.4 Connecting to github.com (github.com)|140.82.121.4|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 03:09:03-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: ‘fruits_300.npy’ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.03s 2022-03-31 03:09:03 (107 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128] numpy 파일을 불러옴 123456import numpy as npimport matplotlib.pyplot as pltfruits = np.load('fruits_300.npy')print(fruits.shape) print(fruits.ndim) # 차원 수 확인 (300, 100, 100) 3 첫 번째 차원(300) = 샘플의 개수 두 번째 차원(100) = 이미지 높이 세 번째 차원(100) = 이미지 너비 이미지 크기 100 x 100 12# 첫 번째 행에 있는 픽셀 100개에 들어있는 값을 출력fruits[0, 0, :] array([ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 3, 1, 4, 1, 2, 5, 5, 5, 19, 148, 192, 117, 28, 1, 1, 2, 1, 4, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8) 이미지 시각화 흑백 사진을 담고 있다. 0~255까지의 정숫값을 가진다. 12plt.imshow(fruits[0], cmap='gray') # cmap 은 옵션plt.show() 1234plt.imshow(fruits[0], cmap='gray_r') # cmap 은 옵션plt.show()# 밝은 부분은 0에 가깝다# 어두운 부분은 255에 가깝다 여러 이미지 시각화 12345fig, axs = plt.subplots(1, 2)axs[0].imshow(fruits[100], cmap='gray_r')axs[1].imshow(fruits[200], cmap='gray_r')plt.show() 픽셀값 분석1234567apple = fruits[0:100].reshape(-1, 100 * 100) # 두 번째와 세 번째 차원 크기가 100이므로.pineapple = fruits[100:200].reshape(-1, 100 * 100)banana = fruits[200:300].reshape(-1, 100 * 100)print(apple.shape)print(pineapple.shape)print(banana.shape) (100, 10000) (100, 10000) (100, 10000) axis = 0 vs axis = 1 차이 확인 (p.293) 각 이미지에 대한 픽셀 평균값 비교 12# axis = 1 = 열print(apple.mean(axis = 1)) [ 88.3346 97.9249 87.3709 98.3703 92.8705 82.6439 94.4244 95.5999 90.681 81.6226 87.0578 95.0745 93.8416 87.017 97.5078 87.2019 88.9827 100.9158 92.7823 100.9184 104.9854 88.674 99.5643 97.2495 94.1179 92.1935 95.1671 93.3322 102.8967 94.6695 90.5285 89.0744 97.7641 97.2938 100.7564 90.5236 100.2542 85.8452 96.4615 97.1492 90.711 102.3193 87.1629 89.8751 86.7327 86.3991 95.2865 89.1709 96.8163 91.6604 96.1065 99.6829 94.9718 87.4812 89.2596 89.5268 93.799 97.3983 87.151 97.825 103.22 94.4239 83.6657 83.5159 102.8453 87.0379 91.2742 100.4848 93.8388 90.8568 97.4616 97.5022 82.446 87.1789 96.9206 90.3135 90.565 97.6538 98.0919 93.6252 87.3867 84.7073 89.1135 86.7646 88.7301 86.643 96.7323 97.2604 81.9424 87.1687 97.2066 83.4712 95.9781 91.8096 98.4086 100.7823 101.556 100.7027 91.6098 88.8976] 각 과일에 대한 히스토그램 작성 히스토그램은 값이 발생하는 빈도를 그래프로 표시한 것. 보통 x축은 값의 구간이고, y축은 발생 빈도이다. 1234567plt.hist(np.mean(apple, axis = 1), alpha = 0.8) # alpha 는 투명도 조절하는 매개변수plt.hist(np.mean(pineapple, axis = 1), alpha = 0.8)plt.hist(np.mean(banana, axis = 1), alpha = 0.8)plt.legend(['apple', 'pineapple', 'banana'])plt.xlabel('pixel average')plt.ylabel('prequency')plt.show() 위 결과에서 banana는 픽셀 평균값이 다른 두 과일과 확연히 다르다. banana는 픽셀 평균값으로 구분하기 쉽다. 이번에는 샘플의 평균값이 아니라 픽셀별 평균값을 비교해 본다. 즉, 전체 샘플에 대해 각 픽셀의 평균을 조사한다. axis=0으로 지정하여 픽셀의 평균을 계산하면 된다. 12345fig, axs = plt.subplots(1, 3, figsize=(20, 5))axs[0].bar(range(10000), np.mean(apple, axis=0))axs[1].bar(range(10000), np.mean(pineapple, axis=0))axs[2].bar(range(10000), np.mean(banana, axis=0))plt.show() 대표 이미지 123456789apple_mean = np.mean(apple, axis=0).reshape(100, 100)pineapple_mean = np.mean(pineapple, axis=0).reshape(100, 100)banana_mean = np.mean(banana, axis=0).reshape(100, 100)fig, axs = plt.subplots(1, 3, figsize=(20, 5))axs[0].imshow(apple_mean, cmap='gray_r')axs[1].imshow(pineapple_mean, cmap='gray_r')axs[2].imshow(banana_mean, cmap='gray_r')plt.show() 평균값과 가까운 사진 고르기123abs_diff = np.abs(fruits - apple_mean)abs_mean = np.mean(abs_diff, axis=(1,2))print(abs_mean.shape) (300,) 오차의 값이 가장 작은 순서대로 100개를 골라본다. 123apple_index = np.argsort(abs_mean)[:100]fig, axs = plt.subplots(10, 10, figsize=(10,10)) plt.show() 1234567apple_index = np.argsort(abs_mean)[:100]fig, axs = plt.subplots(10, 10, figsize=(10,10))for i in range(10): # 2중 for문 for j in range(10): axs[i, j].imshow(fruits[apple_index[i*10 + j]], cmap='gray_r') axs[i, j].axis('off')plt.show() Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/06/chapter_6_1/"},{"title":"chapter_7_1","text":"딥러닝인공신경망 1943년 즈음 등장 1차 융성기 ~ 1960 후반 로봇이 인간들과 함께 살 것이다 예언 XOR 문제 해결 못함 AI 연구 겨울 찾아옴 대안 : 최근접이웃, 결정트리, 서포트벡터머신 등 토론토 대학 AI 연구소 (역전파 알고리즘 개발) CNN 알고리즘 (1980년대 후반) -2차 융성시기 ~ 1990년대 후반 CNN, RNN 알고리즘 등장 연산 속도 문제/정확도 문제 산업계 즉시 활용 어려움 -3차 융성시기 2012 ~ 현재까지 GPU 세팅 (그래픽카드) 연산속도문제가 해결 세돌 vs 알파고 바둑 대회(2017년) 정부에서도 본격적으로 투자 교육쪽으로 먼저 투자 시작 대학교육 + 국비교육 데이터과학 2012년 CNN 알고리즘 논문 다수 출현 이미지 기본데이터셋 기존대비 성능이 좋아야 함 개존대비 연산속도가 좋아야 함 → 각자 딥러닝 관심 생김 → 공부하는 패턴 : 최운선순위는 가장 최근 나온 알고리즘 분야가 정말 많음 지도학습 : 분류/수치 예측(회귀)/비지도학습 엑셀데이터(정형데이터) 기초 통계가 중요(리포트 형태가 더 중요) 개발의 상대적 중요성 떨어짐(성과 측면) 딥러닝:비정형데이터 텍스트,음성,이미지,영상 주로 쓰이는 알고리즘 탐색 (최신 알고리즘) 계속 업그레이드 되고 있음 이세돌 vs 알파고 바둑 대회 (2017년) 데이터과학 지도 학습 vs 딥러닝 → 개발자라면 딥러닝 알고리즘을 가져다가 빠르게 개발하는 기술을 습득. 딥러닝 라이브러리 텐서플로 : https://www.tensorflow.org/ 2016년 텐서플로 1 버전 vs 텐서플로 2 버전 문법적으로 매우 다름 산업용 파이토치 : https://pytorch.org/ 연구용 12import tensorflowprint(tensorflow.__version__) 2.8.0 데이터 불러오기패션 MNIST 10종류의 패션 아이템으로 구성된 데이터셋 텐서프로를 사용해 이 데이터를 불러온다. 123from tensorflow import keras(train_input, train_target), (test_input, test_target)= keras.datasets.fashion_mnist.load_data() # load.data()함수는 훈련 데이터와 테스트 데이터를 나누어 반환한다. 데이터 확인 훈련 데이터 60,000개 이미지, 이미지 크기는 28x28 타깃은 60,000개 원소가 있는 1차원 배열 1print(train_input.shape, train_target.shape) (60000, 28, 28) (60000,) 테스트 세트 10,000개의 이미지로 이루어짐 1print(test_input.shape, test_target.shape) (10000, 28, 28) (10000,) 이미지 시각화 123456import matplotlib.pyplot as pltfig, axs = plt.subplots(1, 10, figsize=(10,10))for i in range(10): axs[i].imshow(train_input[i], cmap='gray_r') axs[i].axis('off')plt.show() 타겟 값 리스트 패션 MNIST의 타깃은 0~9까지의 숫자 레이블로 구성된다. 같은 숫자가 나온다면 타깃이 같은 두 샘플은 같은 종류의 옷이다. 1print([train_target[i] for i in range(10)]) [9, 0, 0, 3, 0, 2, 7, 2, 5, 5] 실제 타겟값의 값을 확인 각 라벨당 6000개의 이미지 존재 60,000개 즉, 각 의류마다 6,000개의 샘플이 들어있다. 12import numpy as npprint(np.unique(train_target, return_counts = True)) (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])) 로지스틱 회귀로 패션 아이템 분류하기 경사하강법 (기울기) 샘플이 60,000개나 되기에 샘플을 하나씩 꺼내서 모델을 훈련하는 게 더 효율적 해당 상황에 맞는 것이 강사하강법이다. 전제 조건 : 각 컬럼의 데이터셋 동일 (표준화) why 255? 각 픽셀의 값 0~255 사이의 정수값을 가진다. 255로 나누어 0~1 사이의 값으로 정규화 시킴 표준화는 아니지만 양수 값으로 이루어진 이미지를 전처리할 때 사용하는 방벙 12345train_scaled = train_input / 255.0# 경사하강법 사용을 위해 1차원 배열로 만들기train_scaled = train_scaled.reshape(-1, 28*28)print(train_scaled.shape) (60000, 784) 모델 만들기 비정형데이터에 선형모델 또는 비선형모델을 적용시키는 것이 합리적인가? 결론은 아니다! 다른 대안이 있는냐? 인공신경망! 정형데이터에 인공신경망 및 딥러닝 모델을 적용시키는 것이 합리적인가? 결론은 아니다! SGDClassifier 클래스와 cross_validate 함수로 이 데이터에서 교차 검증으로 성능을 확인한다. 1234567from sklearn.model_selection import cross_validatefrom sklearn.linear_model import SGDClassifiersc = SGDClassifier(loss='log', max_iter=5, random_state=42) # 반복 횟수를 5번으로 지정scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)print(np.mean(scores['test_score'])) 0.8195666666666668 로지스틱 회귀 공식을 그림으로 나타내면 인공신경망의 그림과 같다. 인동신경망을 만들어 패션 아이템 분류 문제의 성능을 높일 수 있는지 지켜보자. 참고 355~356p 인공신경망 : http://alexlenail.me/NN-SVG/index.html 입력층, 출력층, 뉴런(유닛)에 대해 숙지하자. 인공신경망 모델 적용 이미지 분류에는 인공 신경망이 적합하다. 12import tensorflow as tffrom tensorflow import keras 텐서플로 = 케라스 케라스 API를 사용해 패션 아이템을 분류하는 가장 간단한 인공 신경망을 만들어 보자. train_test_split() 1234from sklearn.model_selection import train_test_splittrain_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) test_size=0.2 훈련 세트에서 20%를 검증 세트로 덜어 내었다. 훈련 세트와 검증 세트의 크기를 알아보자. 1print(train_scaled.shape, train_target.shape) (48000, 784) (48000,) 1print(val_scaled.shape, val_target.shape) (12000, 784) (12000,) 60,000개 중에 12,000개가 검증 세트로 분리되었다. 먼저 훈련 세트로 모델을 만든다. 그 다음 검증 세트로 훈련한 모델을 평가해본다. 이미지 하나에 있는 픽셀은 784개. 뉴런은 10개. 이것을 모두 연결. 완전 연결층 = 밀집층 = 밀집하게 연결되어 있는 것 fully connected layer = dense layer 1print(train_target[:10]) [7 3 5 8 6 9 3 3 9 9] Dense 클래스를 통해 밀집층을 만들어보자 활성화 함수 softmax와 같이 뉴런의 선형 방정직 계산 결과에 적용되는 함수. 12# 매개변수의 의미는 차례대로 뉴런개수, 뉴런의 출력에 적용할 함수, 입력의 크기다.dense = keras.layers.Dense(10, activation = 'softmax', input_shape=(784, )) 방금 만든 밀집층을 가진 신경망 모델을 만들자. Sequential 클래스를 사용한다. 1model = keras.Sequential(dense) 인공 신경망으로 패션 아이템 분류하기 훈련하기 전의 설정 단계 1model.compile(loss = 'sparse_categorical_crossentropy', metrics = &quot;accuracy&quot;) 모델을 훈련한다. 반복할 에포크 횟수를 epochs 매개변수로 지정 1model.fit(train_scaled, train_target, epochs = 5) Epoch 1/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4782 - accuracy: 0.8383 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4574 - accuracy: 0.8484 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4450 - accuracy: 0.8525 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4372 - accuracy: 0.8549 Epoch 5/5 1500/1500 [==============================] - 2s 2ms/step - loss: 0.4318 - accuracy: 0.8575 &lt;keras.callbacks.History at 0x7fb1c0b7f450&gt; 갈수록 정확도가 증가함을 알 수 있다. 검증 세트(val_scaled, val_target)에서 모델의 성능을 확인한다. 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 1ms/step - loss: 0.4530 - accuracy: 0.8463 [0.4530307352542877, 0.8463333249092102] Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/07/chapter_7_1/"},{"title":"chapter_7_3","text":"7-3. 신경망 모델 훈련 케라스 API를 사용해 모델을 훈련하는데 필요한 다양한 도구들을 알아본다. 손실곡선 패션 MNIST 데이터셋을 적재하고 훈련 세트와 검증 세트로 나눈다. 12345678910from tensorflow import kerasfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) = \\ keras.datasets.fashion_mnist.load_data()train_scaled = train_input / 255.0train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 1s 0us/step 26435584/26421880 [==============================] - 1s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 16384/5148 [===============================================================================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step 4431872/4422102 [==============================] - 0s 0us/step 모델을 만든다. 사용자 정의함수를 작성함 if 구문을 제외하면 7-2의 코드와 동일하다. if 구문의 역할은 model_fn() 함수에 케라스 층을 추가하면 은닉층 뒤어 또 하나의 층을 추가하는 것이다. 모델 구조를 출력해본다. 12345678910def model_fn(a_layer=None): model = keras.Sequential() model.add(keras.layers.Flatten(input_shape=(28,28))) model.add(keras.layers.Dense(100, activation='relu')) if a_layer: model.add(a_layer) model.add(keras.layers.Dense(100, activation='softmax')) return modelmodel = model_fn()model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) /images/chapter_7_3/output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 dense (Dense) (None, 100) 78500 dense_1 (Dense) (None, 100) 10100 ================================================================= Total params: 88,600 Trainable params: 88,600 Non-trainable params: 0 _________________________________________________________________ 모델 정의 후, 학습 fit() 메서드의 결과를 history 변수에 담아본다. 12model.compile(loss='sparse_categorical_crossentropy', metrics = 'accuracy')history = model.fit(train_scaled, train_target, epochs = 5, verbose = 1) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.5574 - accuracy: 0.8081 Epoch 2/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3972 - accuracy: 0.8574 Epoch 3/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3572 - accuracy: 0.8710 Epoch 4/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3353 - accuracy: 0.8805 Epoch 5/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3187 - accuracy: 0.8855 history 객체 값은 무슨 값이 있냐? history 객체에는 훈련 측정값이 담겨 있는 history 딕셔너리가 들어 있다. dictionary 값으로 출력되기 때문에 다음과 같이 작성 1print(history.history.keys()) dict_keys(['loss', 'accuracy']) 결과 : 손실과 정확도가 포함되어 있다. 손실 곡선 history 속성에 포함된 손실과 정확도는 에포크마다 계산한 값이 순서대로 나열된 단순한 리스트이다. 멧플롯립으로 간단히 그릴 수 있다. 123456import matplotlib.pyplot as pltplt.plot(history.history['loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.show() 정확도 출력 이번에는 정확도를 출력해본다. 1234plt.plot(history.history['accuracy'])plt.xlabel('epoch')plt.ylabel('accuracy')plt.show() 확실히 에포크마다 손실이 감소하고 정확도가 향상됨을 알 수 있다. 계속 손실이 감소하는지 확인해보자. 에포크를 20으로 늘려서 모델을 훈련하고 손실을 그려본다. 12345678model = model_fn()model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')history = model.fit(train_scaled, train_target, epochs=20, verbose=0) # 수치 조정plt.plot(history.history['loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.show() 예상대로 손실이 잘 감소한다. 검증손실 다음과 같이 loss, accuracy, val_loss, val_accuracy 가 출력되도록 하는 것이 정석이다. 에포크마다 검증 손실을 계산하기 위해 케라스 모델의 fit()메서드에 검증 데이터를 전달할 수 있다. 12345model = model_fn()model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')history = model.fit(train_scaled, train_target, epochs=10, verbose=1, validation_data=(val_scaled, val_target)) Epoch 1/10 1500/1500 [==============================] - 9s 6ms/step - loss: 0.5619 - accuracy: 0.8060 - val_loss: 0.4507 - val_accuracy: 0.8375 Epoch 2/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3984 - accuracy: 0.8571 - val_loss: 0.3923 - val_accuracy: 0.8600 Epoch 3/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3603 - accuracy: 0.8704 - val_loss: 0.3582 - val_accuracy: 0.8761 Epoch 4/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3351 - accuracy: 0.8792 - val_loss: 0.3619 - val_accuracy: 0.8770 Epoch 5/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3207 - accuracy: 0.8860 - val_loss: 0.3707 - val_accuracy: 0.8754 Epoch 6/10 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3084 - accuracy: 0.8907 - val_loss: 0.3775 - val_accuracy: 0.8703 Epoch 7/10 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2998 - accuracy: 0.8948 - val_loss: 0.3707 - val_accuracy: 0.8787 Epoch 8/10 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2901 - accuracy: 0.8981 - val_loss: 0.3494 - val_accuracy: 0.8805 Epoch 9/10 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2815 - accuracy: 0.9015 - val_loss: 0.3691 - val_accuracy: 0.8823 Epoch 10/10 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2756 - accuracy: 0.9034 - val_loss: 0.4148 - val_accuracy: 0.8700 과대 / 과소적합 문제를 조사하기 위해 훈련 손실과 검증 손실을 한 그래프에 그려서 비교해본다. 123456plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() 검증 데이터 val이 갈수록 손실이 증가한다. 더 나은 그래프를 위해 조정해본다. 위 내용에서 optimizer = adam을 추가 123456789101112model = model_fn()model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics='accuracy') # adam 추가history = model.fit(train_scaled, train_target, epochs=10, verbose=1, validation_data=(val_scaled, val_target))plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() Epoch 1/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.5635 - accuracy: 0.8080 - val_loss: 0.5627 - val_accuracy: 0.7847 Epoch 2/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.4053 - accuracy: 0.8535 - val_loss: 0.3899 - val_accuracy: 0.8593 Epoch 3/10 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3595 - accuracy: 0.8705 - val_loss: 0.3780 - val_accuracy: 0.8627 Epoch 4/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3311 - accuracy: 0.8785 - val_loss: 0.3409 - val_accuracy: 0.8767 Epoch 5/10 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3130 - accuracy: 0.8855 - val_loss: 0.3361 - val_accuracy: 0.8784 Epoch 6/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.2950 - accuracy: 0.8899 - val_loss: 0.3473 - val_accuracy: 0.8775 Epoch 7/10 1500/1500 [==============================] - 5s 4ms/step - loss: 0.2818 - accuracy: 0.8961 - val_loss: 0.3380 - val_accuracy: 0.8781 Epoch 8/10 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2707 - accuracy: 0.9003 - val_loss: 0.3430 - val_accuracy: 0.8823 Epoch 9/10 1500/1500 [==============================] - 6s 4ms/step - loss: 0.2623 - accuracy: 0.9024 - val_loss: 0.3381 - val_accuracy: 0.8830 Epoch 10/10 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2520 - accuracy: 0.9064 - val_loss: 0.3427 - val_accuracy: 0.8813 val의 손실이 성공적으로 줄어들었다. 구글링 : image classification django -&gt; 개발자라면 공부해봐라 구글링 : image classification tensorflow -&gt; 이것도 드롭아웃 훈련 과정에서 층에 있는 일부 뉴런을 랜덤하게 꺼서(뉴런의 출력을 0으로 만들어) 과대적합을 막는다. 기본적으로는 모든 파라미터를 연산하는 것이 원칙 그런데, 일부 뉴런에서 출력이 없는 뉴런 발생 기존 일부 뉴런은 계산에서 제외 시킴 인공신경망(뇌과학) 값이 쏠림 현상 = 뇌에 피가 고인 현상= 뇌출혈 앞서 정의한 model_fn() 함수에 드롭아웃 객체를 전달하여 층을 추가해본다. 여기에서 30% 정도를 드롭아웃한다. 12model = model_fn(keras.layers.Dropout(0.3)) # 30% 드롭아웃model.summary() Model: &quot;sequential_4&quot; _________________________________________________________________ Layer (type) /images/chapter_7_3/output Shape Param # ================================================================= flatten_4 (Flatten) (None, 784) 0 dense_8 (Dense) (None, 100) 78500 dropout (Dropout) (None, 100) 0 dense_9 (Dense) (None, 100) 10100 ================================================================= Total params: 88,600 Trainable params: 88,600 Non-trainable params: 0 _________________________________________________________________ 결과. 은닉층 뒤에 추가된 드롭아웃 층(Dropout)은 훈련되는 모델 파라미터가 없다. 일부 뉴런의 출력을 0으로 만들지만 전체 출력 배열의 크기를 바꾸지는 않는다. 그래서 마음 편하게 검증 점수를 계산할 수 있다. 드롭아웃한 상태에서 이전과 마찬가지로 훈련 손실과 검증 손실의 그래프를 그려 비교해본다. 1234567891011model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics='accuracy') # adam 추가history = model.fit(train_scaled, train_target, epochs=20, verbose=0, # 수치 조정 validation_data=(val_scaled, val_target))plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() 과대적합이 확실히 줄었다. 다만, 20번의 에포크 동안 훈련했기에 결국 다소 과대적합이 되었다. 여기서 더 과대적합 하지 않게 하려면 에포크 횟수를 10으로 하고 다시 훈련하면 된다. 모델 저장과 복원 개발자 : 정확도는 중요하지 않음 딥러닝 모델 활용해서 웹앱을 개발 분석가 &amp; 머신러닝 엔지니어 : 캐글대회(정확도 검증 필수) 에포크 횟수를 10으로 하고 다시 훈련한다. 그리고 나중에 사용하려면 이 모델을 저장해야 한다. 12345model = model_fn(keras.layers.Dropout(0.3)) # 30% 드롭아웃model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics='accuracy') # adam 추가history = model.fit(train_scaled, train_target, epochs=20, verbose=0, # 수치 조정 validation_data=(val_scaled, val_target)) save_weights() 훈련된 모델의 파라미터를 저장한다. save() 모델 구조와 모델 파라미터를 함께 저장한다. 12model.save_weights('model-weights.h5')model.save('model-whole.h5') 두 가지 실험을 해본다. 첫 번째는 훈련을 하지 않은 새로운 모델을 만들고 model-weights.h5 파일에서 훈련된 모델 파라미터를 읽어서 사용한다. 두 번째는 아예 model-whole.h5 파일에서 새로운 모델을 만들어 바로 사용한다. 첫 번째 실험 모델 불러오기 12model = model_fn(keras.layers.Dropout(0.3))model.load_weights('model-weights.h5') 406p 10개 확률 중에 가장 큰 값의 인덱스를 골라 타깃 레이블과 비교하여 정확도를 계산해 본다. 1234import numpy as npval_labels = np.argmax(model.predict(val_scaled), axis=-1)print(np.mean(val_labels == val_target)) 0.8840833333333333 모델 전체를 파일에서 읽은 다음 검증 세트의 정확도를 출력해 본다. load_model()을 이용하여 파일을 읽으면 된다. 12model = keras.models.load_model('model-whole.h5')model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8841 [0.326292484998703, 0.8840833306312561] 같은 모델을 저장하고 다시 불렀기에 이전 코드와 동일한 정확도를 얻었다. 콜백 408p 지금까지 20번의 에포크 동안 모델을 훈련하여 검증 점수가 상승하는 지점을 확인했다. 이전처럼 모델을 두 번씩 훈련하지 않고 한 번에 끝내기 위해 콜백을 사용할 수 있다. 콜백 = 훈련 과정 중간에 어떤 작업을 수행할 수 있게 하는 객체이다. 12345678910model = model_fn(keras.layers.Dropout(0.3))model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb]) &lt;keras.callbacks.History at 0x7f3da939e310&gt; model_fn()함수로 모델을 만들고 compile()을 호출한다. 모델이 훈련한 후에 best-model.h5에 최상의 검증 점수를 낸 모델이 저장된다. 이 모델을 load_model()함수로 다시 읽어서 예측을 수행한다. 12model = keras.models.load_model('best-model.h5')model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8858 [0.31966158747673035, 0.8858333230018616] EarlyStopping 조기 종료 에포크를 많이 주면 줄수록 성능(가중치 업데이트 / 기울기가 계속 미분)이 좋아야 하는 것이 원리 에포크 100 / 50 에포크 시점과 90 에포크 시점 성능 차이 없음 즉, 계속 진행해도 좋아질지 안 좋아질지 모르기에 조기 종료하는 것. EarlyStopping 콜백을 ModelCheckpoint 콜백과 함께 사용하면 가장 낮은 검증 손실의 모델을 파일에 저장한다. 그리고 검증 손실이 다시 상승할 때 훈련을 중지할 수 있다. 훈련을 중지한 다음 현재 모델의 파라미터를 최상의 파라미터로 되돌린다. 두 콜백을 함께 사용해보자. 123456789101112model = model_fn(keras.layers.Dropout(0.3))model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, # patience는 몇 개의 콜백을 리스트로 전달할지 결정한다. restore_best_weights=True)history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) 몇 번째 훈련에서 중지되는지 다음 코드로 확인할 수 있다. 1print(early_stopping_cb.stopped_epoch) 10 epoch 값이 10에 다다랐을 때, ‘조기종료’한다. 123456plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() 이런 식으로 조기 종료 기법을 사용하면 안심하고 에포크 횟수를 크게 지정해도 괜찮다. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/07/chapter_7_3/"},{"title":"chapter_7_2","text":"심층 신경망 인공신경망에 층을 여러 개 추가하여 패션 MNIST 데이터셋을 분류한다. 동시에 케라스로 심층 신경망을 만들어본다. 368p 그림 참고 케라스로 API를 사용해 패션 MNIST 데이터셋을 불러온다. 123from tensorflow import keras(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 0s 0us/step 26435584/26421880 [==============================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 16384/5148 [===============================================================================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step 4431872/4422102 [==============================] - 0s 0us/step 이미지의 픽셀값을 0 ~ 255 범위에서 0 ~ 1로 변환 28x28 크기의 2차원 배열을 784 크기인 1차원 배열로 펼친다. train_test_split() 함수로 훈련 세트와 검증 세트로 나눈다. 1234567from sklearn.model_selection import train_test_splittrain_scaled = train_input / 255.0train_scaled = train_scaled.reshape(-1, 28*28)train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) 입력층과 출력층 사이에 밀집층을 만들 예정이다. 은닉층 : 입력층과 출력층 사이에 있는 모든 층 케라스의 Dense 클래스로 다음 내용을 만든다. sigmoid 활성화 함수를 사용한 은닉층 softmax 함수를 사용한 출력층 층을 추가하는 방법 Dense 클래스의 객체 dense1, 2를 만들어 Sequential 클래스에 전달한다. 12dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))dense2 = keras.layers.Dense(10, activation='softmax') dense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다. 활성화 함수를 ‘sigmoid’로 지정했고 매개변수로 입력의 크기를 (784,)로 지정했다. dense2는 출력층이다. 10개의 클래스를 분류하므로 10개의 뉴런을 두었고 활성화 함수는 softmax로 지정했다. 심층 신경망 컨셉만 이해하라! 직접 신경망 만들 일은 없고 가져다 쓰기만 하면 된다. 앞의 dense1과 dense2 객체를 Sequential 클래스에 추가하여 심층 신경망을 만들 예정이다. 12model = keras.Sequential([dense1, dense2])model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 100) 78500 dense_1 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 위와 같이 Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 층을 리스트로 만들어 전달해야 한다. model.summary()로 층에 대한 정보를 얻을 수 있다. 첫 줄에 모델의 이름이 나온다. 이 모델에 들어 있는 층이 순서대로 나열된다. 이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서로 나열된다. 층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 출력된다. name 매개변수로 이름을 지정하지 않으면 디폴트인 ‘dense’로 네이밍된다. 출력 크기는 (None,100)인데, 첫 번째 차원은 샘플 개수를 나타낸다. None인 이유는 어떤 배치 크기에도 잘 대응하기 위함이다. 두 번째 차원인 100은 뉴런 개수가 100이며, 따라서 100개의 출력이 나옴을 나타낸다. 층을 추가하는 다른 방법 Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만든다. 12345model = keras.Sequential([ keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'), # 층을 쌓아간다 keras.layers.Dense(10, activation='softmax', name='output') # 층을 쌓아간다], name='패션 MNIST 모델')model.summary() Model: &quot;패션 MNIST 모델&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= hidden (Dense) (None, 100) 78500 output (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 층을 추가하는 다른 방법 2 Sequential 클래스의 객체를 만들고 이 객체의 add() 메서드를 호출하여 층을 추가한다. 12345model = keras.Sequential()model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))) # 층을 쌓아간다model.add(keras.layers.Dense(10, activation='softmax')) # 층을 쌓아간다model.summary() Model: &quot;sequential_1&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_2 (Dense) (None, 100) 78500 dense_3 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 이제 모델을 훈련한다. 반복할 에포크 횟수를 epochs 매개변수로 지정 12model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 6s 3ms/step - loss: 0.5628 - accuracy: 0.8069 Epoch 2/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.4087 - accuracy: 0.8522 Epoch 3/5 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3747 - accuracy: 0.8645 Epoch 4/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3506 - accuracy: 0.8737 Epoch 5/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3344 - accuracy: 0.8784 &lt;keras.callbacks.History at 0x7f5bcb861b50&gt; 렐루 함수 층이 많은 신경망일수록 그 효과가 누적되어 학습이 어려워진다. 이를 개선하기 위한 활성화 함수이다. relu() 함수는 입력이 양수일 그냥 통과시키고, 입력이 음수라면 0으로 만든다. Flatten 클래스 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼친다. Flatten 클래스를 층처럼 입렬층과 은닉층 사잉에 추가하기 때문에 이를 층이라 부른다. 다음 코드처럼 입력층 바로 뒤에 추가한다. 123456model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28))) # 기존 코드 비교model.add(keras.layers.Dense(100, activation='relu')) # relu 로 변경model.add(keras.layers.Dense(10, activation='softmax'))model.summary() Model: &quot;sequential_2&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 dense_4 (Dense) (None, 100) 78500 dense_5 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 훈련 데이터를 다시 준비해서 모델을 훈련한다. 123456(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()train_scaled = train_input / 255.0train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) 모델을 컴파일하고 훈련한다. 12model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.5283 - accuracy: 0.8151 Epoch 2/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3926 - accuracy: 0.8602 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3562 - accuracy: 0.8713 Epoch 4/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3336 - accuracy: 0.8809 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3203 - accuracy: 0.8853 &lt;keras.callbacks.History at 0x7f5bcb762a10&gt; 시그모이드 함수를 사용했을 때와 비교하면 성능이 조금 향상되었다. 검증 세트에서의 성능도 확인하자. 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8717 [0.3712655007839203, 0.871749997138977] 검증 성능도 향상되었다. 123456(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()train_scaled = train_input / 255.0train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) 12model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3094 - accuracy: 0.8890 Epoch 2/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.2989 - accuracy: 0.8951 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.2902 - accuracy: 0.8974 Epoch 4/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.2825 - accuracy: 0.9018 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.9024 &lt;keras.callbacks.History at 0x7f5bcb835d10&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8792 [0.41104814410209656, 0.8791666626930237] 옵티마이저의 개념–&gt; Adam 사용하라–&gt; why Adam? 최고점을 찾기 위해서 스텝방향 &amp; 스템사이즈를 모두 고려한 옵티마이저 스텝방향 : GD, SGD, Momentum, NAG 스텝사이즈 : GD, SGD, Adagrad, RMSProp 하이퍼 파라미터는 사람이 지정해야 하는 파라미터 신경망에는 특히 하이퍼 파라미터가 많다. 은닉층의 뉴런 개수도 하이퍼 파라미터이다. compile() 에서는 케라스의 기본 하강법 알고리즘인 RMSprop을 사용했다. 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공한다. 이들을 ‘옵티마이저’라고 부른다. 옵티마이저 381p SGD 옵티마이저를 사용하려면 compile() 메서드의 optimizer 매개변수를 ‘sgd’로 지정 1model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy') ‘sgd’ 문자열은 이 클래스의 기본 설정 매개변수로 생성한 객체와 동일하다. 다음 코드는 위의 코드와 정확히 동일하다. 12sgd = keras.optimizers.SGD()model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy') 382p learning_rate = 0.1 만약 SGD 클래스의 학습률 기본값이 0.01일 때 이를 바꾸고 싶다면 다음와 같이 지정한다. 랜덤서치, 그리드서치 딥러닝에서도 하이퍼파라미터 튜닝 1sgd = keras.optimizers.SGD(learning_rate = 0.1) 기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공한다. SGD 클래서의 momentum 매개변수의 기본값은 0이다. 보통 0.9이상을 지정한다. 다음처럼 SGD 클래스의 nesterov 매개변수를 기본값 False 에서 True로 바꾸면 네스테로프 모멘텀 최적화를 사용한다. 테스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현한다. 대부분의 경우 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공한다. 1sgd = keras.optimizers.SGD(momentum = 0.9, nesterov = True) 적응적 학습률 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다. 이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높다. 이런 학습률을 적응적 학습률이라고 한다. Adagrad() 클래스 적응적 학습률을 사용하는 대표적인 옵티마이저이다. optimizer 매개변수에서 지정할 수 있다. optimizer 매개변수의 기본값이 바로 rmsprop이다. 12adagrad = keras.optimizers.Adagrad()model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy') RMSprop() 클래스 적응적 학습률을 사용하는 대표적인 옵티마이저이다. optimizer 매개변수에서 지정할 수 있다. optimizer 매개변수의 기본값이 바로 rmsprop이다. 12rmsprop = keras.optimizers.RMSprop()model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy') 다만, Adam을 사용하는 것이 더 좋다. Adam 모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다. 적응적 학습률을 사용하는 이 3개의 클래스는 learning_rate 매개변수의 기본값을 0.001로 두고 사용한다. Adam 클래스의 매개변수 기본값을 사용해 패션 MNIST 모델을 훈련해본다. 일단 모델을 다시 생성한다. 1234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28))) # 기존 코드 비교model.add(keras.layers.Dense(100, activation='relu')) # relu 로 변경model.add(keras.layers.Dense(10, activation='softmax')) compile() 메서드의 optimizer를 ‘adam’으로 설정하고 5번의 에포크 동안 훈련한다. 123model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')model.fit(train_scaled, train_target, epochs=5)model.evaluate(val_scaled, val_target) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.5293 - accuracy: 0.8155 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3980 - accuracy: 0.8571 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3542 - accuracy: 0.8713 Epoch 4/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3287 - accuracy: 0.8798 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8867 375/375 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8806 [0.32961416244506836, 0.8805833458900452] 결과를 보면 기본 RMSprop을 사용했을 때와 거의 같은 성능을 보인다. 검증 세트에서의 성능도 확인한다. 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8806 [0.32961416244506836, 0.8805833458900452] 환경마다 차이가 있을 수 있지만 여기서는 기본 RMSprop보다 조금 더 나은 성능을 보인다. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/07/chapter_7_2/"},{"title":"chapter_9_1","text":"순차 데이터와 순환 신경망통계 초급 레벨 : 기초통계 (t.test, 분산분석, 회귀분석 등) 중급 레벨 : 시계열 분석 / 베이지안 / 비모수검정 시계열 데이터 : 주식/ 날씨 / 매장 매출 R로 공부할 것 텍스트 텍스트 마이닝 (데이터 분석가) 대표 적으로 감정분석 (긍정 / 부정 분류) 문자열 : 인코딩하는 방법론이 존재 자연어 처리 (개발자에 해당) 챗봇 자동 번역 기본 딥러닝 알고리즘 / RNN &amp; LSTM 현실에서 쓸까? 안쓴다! 자료 딥러닝을 이용한 자연어 처리 입문 (텐서플로) : https://wikidocs.net/book/2155 Pytorch로 시작하는 딥러닝 입문 : https://wikidocs.net/32471 분야 선정 영상인식, 이미지 분류, 음성, 자연어 순환 신경망 이미지는 픽셀값이 어느정도 고정이 되어 있음 28x28로 정의 / 모든 데이터는 28x28 맞출 수 있음 텍스트 값이 고정이 불가함 494p I am a boy(1, 4, 3) I am a handsome boy(1, 4, 1, 2) Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/10/chapter_9_1/"},{"title":"chapter_8_1_2","text":"08-2. 합성곱 신경망을 이용한 이미지 분류패션 MNIST 데이터 불러오기 데이터 스케일을 0 ~ 255 사이 0 ~ 1 로 표준화 훈련 데이터 / 검증 데이터 분류 완전 연결 신경망 (Fully Connected Layer) –&gt; 2차원 배열 -&gt; 1차원 배열 (최종 분류값 도출)–&gt; 완전 연결 신경망과 달리, 합성곱에서는 2차원 이미지를 그대로 사용한다. 12345678910from tensorflow import kerasfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) = \\ keras.datasets.fashion_mnist.load_data()train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 0s 0us/step 26435584/26421880 [==============================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 16384/5148 [===============================================================================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step 4431872/4422102 [==============================] - 0s 0us/step 합성곱 신경망 만들기 446p 437p 그림을 코드로 구현하는 내용 1234567891011121314151617181920212223model = keras.Sequential()# 합성곱 층model.add(keras.layers.Conv2D(32, kernel_size=3, activation = 'relu', # Conv2D() 는 합성곱 층을 만든다. padding = 'same', input_shape = (28, 28, 1))) # 합성곱의 필터 32이므로 특성 맵의 깊이는 32 # 풀링층model.add(keras.layers.MaxPooling2D(2)) # (2,2) 풀링을 적용하여 합성곱 층의 특성 맵의 크기가 절반이 된다. # 합성곱 층model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation = 'relu', # 합성곱의 필터 64이므로 특성 맵의 깊이는 64 padding = 'same'))# 풀링층model.add(keras.layers.MaxPooling2D(2)) # (2,2) 풀링을 적용하여 합성곱 층의 특성 맵의 크기가 절반이 된다. # 완전연결층 (밀집층 = Fully Connected Layer)# Chapter 7장 내용model.add(keras.layers.Flatten())model.add(keras.layers.Dense(100, activation='relu')) # 은닉층model.add(keras.layers.Dropout(0.4)) # 드롭아웃 -&gt; 과대 적합 방지model.add(keras.layers.Dense(10, activation='softmax')) # 출력측model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) /images/chapter_8_1_2/output Shape Param # ================================================================= conv2d (Conv2D) (None, 28, 28, 32) 320 max_pooling2d (MaxPooling2D (None, 14, 14, 32) 0 ) conv2d_1 (Conv2D) (None, 14, 14, 64) 18496 max_pooling2d_1 (MaxPooling (None, 7, 7, 64) 0 2D) flatten (Flatten) (None, 3136) 0 dense (Dense) (None, 100) 313700 dropout (Dropout) (None, 100) 0 dense_1 (Dense) (None, 10) 1010 ================================================================= Total params: 333,526 Trainable params: 333,526 Non-trainable params: 0 _________________________________________________________________ 필터의 개수에 따라 특성 맵의 크기는 첫 번째 합성곱 층을 통과하면서 특성 맵의 크기가 32가 된다. 두 번째 합성곱에서 특성 맵의 크기가 64로 늘어난다. 반면 특성 맵의 가로세로 크기는 첫 번째 풀링 층에서 절반으로 줄어든다. 두 번째 풀링층에서 다시 절반으로 더 줄어든다. Flatten 클래스에서 (7,7,64) 크기의 특성 맵을 1차원 배열로 펼친다. (7,7,64) -&gt; (3136,) 모델 파라미터 개수 계산 첫 번째 합성곱 층 32개 필터, 커널 크기(3,3), 깊이1, 필터마다 하나의 절편 -&gt; 3x3x1x32 + 32 = 320개 두 번째 합성곱 층 64개 필터, 커널 크기(3,3), 깊이32, 필터마다 하나의 절편 -&gt; 3x3x32x64 + 64 = 18,496개 Flatten 즉, 은닉층 (3136,) 개의 1차원 배열, 100개의 뉴런 -&gt; 3136x100 + 100 = 313,700개 텐서플로 : https://www.tensorflow.org/hub 필요한 것을 찾아서 가져다 사용할 수 있다. 층의 구성을 그림으로 표현해 본다. keras.uitls 패키지의 plot_model() 함수 사용 1keras.utils.plot_model(model) 박스 안에서 왼쪽 : 층의 이름 오른쪽 : 클래스 inputLayer 클래스 케라스가 자동으로 추가해주는 입력층의 역할. Conv2D 클래스의 input_shape 매개변수를 사용. 층의 구성을 그림으로 표현해 본다. keras.uitls 패키지의 plot_model() 함수 사용 show_shapes 매개변수를 True로 설정하면 그림에 입력과 출력의 크기를 표시한다. 1keras.utils.plot_model(model, show_shapes = True) 지금까지 한 것은 모델 정의 모델 컴파일 후, 훈련 7장 내용 Adam 옵티마이저를 사용 조기 종료 기법을 구현 : ModelCheckpoint 콜백과 EarlyStopping 콜백을 함께 사용한다. 12345678910111213import tensorflow as tfmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)with tf.device('/device:GPU:0'): # GPU 잡는 법 history = model.fit(train_scaled, train_target, epochs=10, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/10 1500/1500 [==============================] - 59s 39ms/step - loss: 0.4968 - accuracy: 0.8231 - val_loss: 0.3245 - val_accuracy: 0.8799 Epoch 2/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.3304 - accuracy: 0.8809 - val_loss: 0.2726 - val_accuracy: 0.8967 Epoch 3/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.2833 - accuracy: 0.8987 - val_loss: 0.2461 - val_accuracy: 0.9072 Epoch 4/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.2534 - accuracy: 0.9069 - val_loss: 0.2360 - val_accuracy: 0.9119 Epoch 5/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.2311 - accuracy: 0.9165 - val_loss: 0.2258 - val_accuracy: 0.9170 Epoch 6/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.2104 - accuracy: 0.9224 - val_loss: 0.2346 - val_accuracy: 0.9157 Epoch 7/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.1916 - accuracy: 0.9275 - val_loss: 0.2132 - val_accuracy: 0.9234 Epoch 8/10 1500/1500 [==============================] - 55s 37ms/step - loss: 0.1757 - accuracy: 0.9343 - val_loss: 0.2152 - val_accuracy: 0.9220 Epoch 9/10 1500/1500 [==============================] - 56s 37ms/step - loss: 0.1619 - accuracy: 0.9393 - val_loss: 0.2172 - val_accuracy: 0.9247 훈련 세트의 정확도가 이전에 비해 증가했다. 손실 그래프를 그린다. 조기 종료가 잘 이루어졌는지 확인하자. 1234567import matplotlib.pyplot as pltplt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.xlabel('loss')plt.legend(['train', 'val'])plt.show() 그래프를 기반으로 9번째 에포크를 최적으로 생각할 수 잇다. 세트에 대한 성능을 평가해본다. 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 5s 14ms/step - loss: 0.2132 - accuracy: 0.9234 [0.21322399377822876, 0.9234166741371155] 좌측 파일 선택 -&gt; best-cnn-model.h5 다운로드 08-3. 합성곱 신경망 시각화 교재 465p 사전 학습 = 이전에 만든 모델이 어떤 가중치를 학습했는지 확인하기 위해 체크포인트 파일을 읽는다. model.layers 케라스 모델에 추가한 층을 출력한다. 1234567from tensorflow import keras# 사전학습 진행model2 = keras.models.load_model(&quot;best-cnn-model.h5&quot;)#keras.utils.plot_model(model2, show_shapes = True)model.layers [&lt;keras.layers.convolutional.Conv2D at 0x7fe1487e19d0&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7fe1d0495b50&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7fe148c92590&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7fe1487fa9d0&gt;, &lt;keras.layers.core.flatten.Flatten at 0x7fe1446bad10&gt;, &lt;keras.layers.core.dense.Dense at 0x7fe1446ba210&gt;, &lt;keras.layers.core.dropout.Dropout at 0x7fe14465cf50&gt;, &lt;keras.layers.core.dense.Dense at 0x7fe14465dcd0&gt;] 합성곱 층의 가중치를 확인 가능 우선 첫 번째 합성곱 층의 가중치를 조사한다. 12conv = model.layers[0]print(conv.weights[0].shape, conv.weights[1].shape) # 가중치, 절편 (3, 3, 1, 32) (32,) 12conv_weights = conv.weights[0].numpy()print(conv_weights.mean(), conv_weights.std()) # 가중치 배열의 평균, 표쥰편차 -0.038952995 0.26509935 이 가중치가 어떤 분표를 가졌는지 보기 쉽게 히스토그램으로 그린다. 1234plt.hist(conv_weights.reshape(-1, 1))plt.xlabel('weight')plt.ylabel('count')plt.show() 이 가중치가 어떤 의미인지 시각화 해보자. 468p 32개의 커널을 16개씩 2줄로 출력한다. 12345678ig, axs = plt.subplots(2, 16, figsize=(15,2))for i in range(2): for j in range(16): axs[i, j].imshow(conv_weights[:,:,0,i*16 + j], vmin=-0.5, vmax=0.5) # vmin, vmax는 맷플롯립의 컬러맵으로 표현할 범위를 지정 axs[i, j].axis('off')plt.show() 색이 밝은지 어두운지를 통해 가중치를 판단할 수 있다. 이번에는 훈련하지 않은 빈 합성곱 신경망을 만든다. 먼저 Conv2D 층을 하나 추가한다. 1234no_training_model = keras.Sequential()no_training_model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1))) 첫 번째 Conv2D층의 가중치를 no_training_conv 변수에 저장한다. 123no_training_conv = no_training_model.layers[0]print(no_training_conv.weights[0].shape) (3, 3, 1, 32) 가중치의 평균과 표준편차를 확인한다. 12no_training_weights = no_training_conv.weights[0].numpy()print(no_training_weights.mean(), no_training_weights.std()) 0.011464282 0.08503365 이 가중치 배열을 히스토그램으로 표현한다. 1234plt.hist(no_training_weights.reshape(-1, 1))plt.xlabel('weight')plt.ylabel('count')plt.show() 그래프가 이전과 확실히 다르다. 이 가중치 값을 맷플롯립의 imshow() 함수를 사용해 이전처럼 그림으로 출력한다. 12345678ig, axs = plt.subplots(2, 16, figsize=(15,2))for i in range(2): for j in range(16): axs[i, j].imshow(no_training_weights[:,:,0,i*16 + j], vmin=-0.5, vmax=0.5) # vmin, vmax는 맷플롯립의 컬러맵으로 표현할 범위를 지정 axs[i, j].axis('off')plt.show() 전체적으로 가중치가 밋밋하게 초기화되었다. 이 그림을 훈련이 끝난 이전 가중치와 비교해보자. 합성곱 신경망이 패현MNIST 데이터셋의 부류 정확도를 높이기 위해 유용한 패턴을 학습했다는 사실을 눈치챌 수 있다. 함수형 API 474p 특성 맵 시각화 케라스로 패현 MNIST 데이터셋을 읽은 후 훈련 세트에 있는 첫 번째 샘플을 그려본다. 12345print(model.input)conv_acti = keras.Model(model.input, model.layers[0]./images/chapter_8_1_2/output)(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()plt.imshow(train_input[0], cmap='gray_r')plt.show() KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=&quot;created by layer 'conv2d_input'&quot;) 앵클 부트다. 이 샘플을 conv_acti 모델에 주입하여 Conv2D 층이 만드는 특성 맵을 출력한다. 08-2장에서 했던 것처럼 전처리를 진행한다. feature_maps의 크기를 확인한다. 123inputs = train_input[0:1].reshape(-1, 28, 28, 1)/255.0feature_maps = conv_acti.predict(inputs)print(feature_maps.shape) (1, 28, 28, 32) same 패딩과 32개의 필터를 사용한 합성곱 층의 출력이므로 (28,28,32)이다. 샘플을 하나 입력했기에 1이다. 앞에서와 같이 맷플롯립의 imshow함수로 특성 맵을 그린다. 32개의 특성 맵을 4개의 행으로 나누어 그린다. 12345678fig, axs = plt.subplots(4, 8, figsize=(15,8))for i in range(4): for j in range(8): axs[i, j].imshow(feature_maps[0,:,:,i*8 + j]) axs[i, j].axis('off')plt.show() 두 번째 합성곱 층이 많든 특성 맵도 같은 방식으로 확인할 수 있다. 먼저 model 객체의 입력과 두 번째 합성곱 층인 model.layers[2]의 출력을 연결한 conv2_acti 모델을 만든다. 그 다음 첫 샘플을 conv2_acti 모델의 predict() 메서드에 전달한다. 첫 번째 풀링 층에서 가로세로 크기가 줄반으로 줄고, 두 번째 합성곱 층의 필터 개수는 64개이므로 (14,14,64) 가 된다. 64개의 특성 맵을 8개씩 나누어 imshow()함수로 그린다. 123456789101112conv2_acti = keras.Model(model.input, model.layers[2]./images/chapter_8_1_2/output)feature_maps = conv2_acti.predict(train_input[0:1].reshape(-1, 28, 28, 1)/255.0)print(feature_maps.shape)fig, axs = plt.subplots(8, 8, figsize=(12,12))for i in range(8): for j in range(8): axs[i, j].imshow(feature_maps[0,:,:,i*8 + j]) axs[i, j].axis('off')plt.show() (1, 14, 14, 64) 이번 특성 맵은 시각적으로 이해하기 어렵다. 두 번째 합성곱 층의 필터 크기는 (3,3,32)인데 (14,14,32)인 특성 맵에서 어떤 부위를 감지하는지 직관적으로 이해하기 어렵다. 478p 그림 참고 이런 현상은 합성곱 층을 많이 쌓을수록 심해진다. Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/08/chapter_8_1_2/"},{"title":"Github Blog","text":"깃허브 블로그-IT 프로그래밍 관련 —&gt; 소스 코드 / 결과 / 이미지 신입은 포폴 x 경력 이직 —&gt; 직장에서 했던 프로젝트 —&gt; 신기술을 써봤냐? 안 써봤냐? —&gt; 깃허브로 증명 가능 깃 설치 이후에 다음 내용 진행.구글링 : nodejs → LTS 버전 다운로드 → 경로 중 add path?에 놓는다. → ‘atuomatically install….’ 을 체크 → install → 바탕화면 —&gt; 우클릭 → git bash here → node -v 입력 후 enter → v16.14.1 출력되면 성공 *컴퓨터 내에서 검색 : 자격 증명 → 자격 증명 관리자 → window 자격 증명’ 확인하기 *다음 링크 참조 https://dschloe.github.io/settings/hexo_blog/ 바탕화면 우클릭 → git bash here → 다음을 복사 npm install -g hexo-cli → git bash here 에 Shift + insert 하여 붙여넣고 enter → (위 링크에 있는 몇몇 과정은 설명을 생략했다고 하심) → (~desktop 위치에서) hexo init myblog ### 다시 할 때는 여기부터 → 바탕화면에 myblog 폴더가 생성되면 성공 → myblog에 우클릭 후 ‘Open Folder as PyCharm Community…’ 클릭 → 파이참 하단에 Terminal 클릭 → 옆에 화살표 눌러서 gitbash 켜기 → hexo server 입력 → 링크 클릭 → 블로그 입장 성공 깃허브 → 로그인 → 우측상단 프로필 옆 클릭 → your repository → new → repository name에 myblog 입력 ( hexo init 명령에서 만든 폴더와 같아야 함 ) → create repository → 파이참으로 이동 →echo &quot;# myblog&quot; &gt;&gt; [README.md](http://README.md) →git init →git add README.md →git commit -m &quot;first commit&quot; → unable to auto-detect… 에러 발생 시 다음 입력 → git config –global user.email “alsrbs0219@gmail.com” → git config –global user.name “kmk3593” → 다시 git commit -m &quot;first commit&quot; → git branch -M main → git remote add origin https://github.com/kmk3593/myblog.git → git push -u origin main ##깃허브에서 복붙으로 편하게 진행 가능 git add 파일명# ⇒ 해당 파일명을 내가 올리겠다. git add .# ⇒ 모든 파일 올리겠다(띄어쓰기 주의) git commint -m “updated” git push # 최종 단계: 모든 파일을 깃허브(사이트)에 올려라 세팅 끝나면 다음 세 가지만 쓰면 된다. git add README.md # 단, README 는 그때 그때 다르게 쓴다. git commit -m &quot;first commit&quot; #단, first commit 은 그때 그때 다르게 쓴다. git push -u origin main ex) git add . git commit -m &quot;first commit&quot; git push hexo server → 링크타고 이동 → 파이참 왼쪽 목록에서 mblog → source → post → hello world 열기 → 내용 써보기 #첫번째글 안녕하세요 → 깃허브에서 source/_post를 클릭 → hello world .md 클릭 // 안녕하세요가 반영 안 되어있다. 반영해보자. →git add . (파이참에서 실행) git commit -m &quot;update&quot; git push → 이제 깃허브를 다시 확인 → ‘안녕하세요’가 적혀있다면 성공 → 다음을 입력하여 설치 (단, mblog 위치에서 해야 함 = cd mblog ) 123$ npm install$ npm install hexo-server --save$ npm install hexo-deployer-git --save → 파이참 왼쪽 목록에서 mblog → config.yml 열기 → #URL 부분에 [https://kmk3593.github.io](https://kmk3593.github.io) 입력 → config 맨 하단에 #Deployment 에서 다음과 같이 입력 1234deploy: type: git repo: https://github.com/kmk3593/kmk3593.github.io.git branch: main → kmk3593.github.io 복사해서 → 깃허브 your repository → new에서 repository name에 붙여넣기 → 생성 → 파이참에서 hexo generate → hexo deploy → INFO Deploy INFO : git 이 출력되면 배포 성공. # 오류나면 npm install 3개를 다시 진행 → 깃허브 새로고침 → 깃허브에서 active 상태될 때까지 기다린다. → ****kmk3593.github.io를 복사해서 주소창에 입력** → 배포가 완료됬음을 확인 할 수 있다. 파이참 → hexo new “MY New Post” # 새 파일 만들기 → hexo server # 반영됬는지 링크타고 확인하자. → hexo generate --deploy # 배포 한 줄로 하기 → 왠지 모르게 반영이 안된다. 일단 넘어가자. 테마 (이카루스)https://ppoffice.github.io/hexo-theme-icarus/uncategorized/getting-started-with-icarus/#install-npm 링크 들어가서 → 다음을 파이참에 붙여넣어 설치 → npm install -S hexo-theme-icarus → hexo config theme icarus → config.yml이 변경되었음을 알 수 있다. → hexo server → 만약 에러 나오면) npm install --save bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 → 만약 에러 나왔다면) 다시 hexo server → 나오는 링크타고 이동 → 제대로 페이지가 출력되면 성공 → hexo clean ( 청소하기 ) → hexo generate --deploy #배포 재시도 → 링크 들어가서 확인 재확인하기 파일 내용 막 써보고 → hexo server → 링크 들어가서 확인 → hexo generate --deploy → ****kmk3593.github.io 들어가서 확인** 주의사항 데이터셋 or 파일크기 —&gt; 50MB 이상은 깃허브에 올리면 안 됨 —&gt; 못 올리나요? 추가적인 설정이 필요. 깃허브 상에 파일 편집 금지!! →&gt; 아예 마우스로 건드리지 마시오 반영이 잘 안된다면구글링 : github status 확인 R MarkDown 올리기참고 : Hexo Blog 이미지 추가 - Data Science | DSChloe temp프로젝트 → R MakrDown → 저장 → knit 실행 → 저장한이름.html 생성됨 → 다음과 같이 작성 → knit 실행 → 저장한 이름.md 생성됨 → 다음과 같이 md 파일을 복사하여 다음 경로에 붙여넣기 → 파이참에 md 파일이 생성된다. → hexo server 하여 링크로 들어가 반영여부를 확인 → 다음 경로에 images파일을 만들고 다음과 같이 blog_files를 복사하여 그 안에 넣는다. → 파이참의 md파일에 /images/를 덧붙여서 다음과 같이 작성한다. *( ctrl+ R 로 하면 편리 ) → hexo server 하여 링크로 확인. → 이미지가 추가되었다면 성공. *’블로그 이름’폴더 → source → images 폴더 생성 → images안에 ‘블로그 이름’_files를 넣는게 핵심 [깃허브 블로그 실습] 이전에 과제로 작성한 R MarkDown파일인 stat_01을 깃허브에 올려보자. → 이미지가 없어서 그러지 images에 넣을 _files 폴더가 생성되지 않았다. → 배포까지 완료했다. → 성공 노션 올리기노션 → 올릴 페이지 선정 → 다음 그림과 같이 우측 상단의 ººº 을 선택 → 내보내기 → Markdown &amp; CSV 선택 → 내보내기 → 압축파일이 다운로드됨 → 압축해제 → 폴더 이름 재정의 → Markdown 올리기와 똑같이 파일을 source와 images에 복사 붙여넣기한다. → 파이참에 md파일이 생겼을 것이다. → 맨 위에 세팅 부분이 없을 건데, 다음과 같은 형식으로 작성해준다. → 이미지링크를 수정해야한다 → 링크 복사 → images에 있는 해당 폴더를 우클릭 → copy path/reference → Path From Repository Root → 다음과 같이 앞부분을 /images/파일명/ 으로 변경해야 한다. → hexo server 하여 반영되었는지 확인 → hexo generate --deploy 하여 배포 파이썬 올리기크롬 브라우저 → 구글 검색 : google colab → 파일 → 다운로드 → ipynb 다운로드 → 다운로드한 파일을 바탕화면으로 옮기고 colab_intro로 이름 변경 → anaconda navigator 관리자 권한으로 켜기 → JupyterLab → 이전에 다운받은 colab_intro 클릭 → file → Save and Export Notebook As → Markdown → 파일이 다운된다. → 바탕화면으로 옮기고 압축 해제 → markdown 때와 같이 폴더를 복사 붙여넣기 → 파이참에서 md 파일 확인 → 맨 위에 세팅 부분이 없을 건데, 다음과 같은 형식으로 작성해준다. → 이미지링크를 수정해야한다 → 링크 복사 → images에 있는 해당 폴더를 우클릭 → copy path/reference → Path From Repository Root → 다음과 같이 앞부분을 /images/경로/파일명/ 으로 변경해야 한다. → hexo server 하여 반영되었는지 확인 → hexo generate --deploy 하여 배포 태그 카테고리hexo 블로그를 꾸며보자!! 카테고리 작업을 해보자!! — SteemCoinPan -다음과 같이 tags와 categories를 써넣어라 구글링 : hexo multiple categories 팁-깃허브 프로젝트 주소 -깃허브 블로그 주소 이 2가지는 회사에 자기 PR 할 때는 발표자료에 적어야 한다. 그러니 반드시 배포까지 완료해야 한다.","link":"/2022/03/22/git_myblog/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 첫 번째 글입니다.안녕하세요.반갑습니다.","link":"/2022/03/21/hello-world/"},{"title":"chapter_9_2","text":"순환 신경망으로 IMDB 리뷰 분류 혹시, 자연어 처리, 감정분석 관심 있으면 강사님께 개인적으로 연락! 주제 : 긍정리뷰 부정리뷰 분류 501p 텍스트 자체가 신경망에 전달하지 않는다! (문자열 –&gt; 수식에 적용 X) 문자열을 수식으로 정하는 규칙이 매우 가변적임. (토근화, Tokenizing) He follows the cat. He loves the cat.10 11 12 13 10 14 12 13 고양이를 따라간다. He follows the cat.10 11 12 13 14 15 RNN, LSTM 알고리즘 영어권 사람들이 만들었어요. 자연어처리와 관련된 많은 알고리즘 영어권 사람들이 만듬 한글 != 영어 성과 내려면 제품(=돈) (네이버) 12from tensorflow.keras.datasets import imdb(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words = 500) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz 17465344/17464789 [==============================] - 0s 0us/step 17473536/17464789 [==============================] - 0s 0us/step 데이터 크기 확인 (1차원 배열) 텍스트의 길이가 다 다르기 때문에 1차원 배열로 정리 가능 1print(train_input.shape, test_input.shape) (25000,) (25000,) 문장의 길이가 다 다르다! 123print(len(train_input[0]))print(len(train_input[1]))print(len(train_input[2])) 218 189 141 Raw 데이터 전처리 -&gt; 토큰화 작업이 끝난 상황 (문자열 –&gt; 숫자로 바뀜) 1print(train_input[0]) [1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32] Target 데이터 출력 0은 부정리뷰 1은 긍정리뷰 1print(train_target[:20]) [1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1] 데이터셋 분리123456from sklearn.model_selection import train_test_split train_input, val_input, train_target, val_target = train_test_split( train_input, train_target, test_size = 0.2, random_state=42)train_input.shape, val_input.shape, train_target.shape, val_target.shape ((20000,), (5000,), (20000,), (5000,)) 데이터 시각화 각 리뷰의 평균단어의 갯수 12345import numpy as np#temp_list = [len(x) for x in train_input]# print(temp_list)lengths = np.array([len(x) for x in train_input])print(np.mean(lengths), np.median(lengths)) 239.00925 178.0 12345import matplotlib.pyplot as plt plt.hist(lengths)plt.xlabel('length')plt.ylabel('frequency')plt.show() 짧은 단어 100개만 사용 모든 길이를 100에 맞춘다. “패딩” 데이터의 갯수는 20000, 전체 길이는 100으로 맞춤 1234from tensorflow.keras.preprocessing.sequence import pad_sequences train_seq = pad_sequences(train_input, maxlen = 100)print(train_seq.shape) (20000, 100) 1print(train_seq[5]) [ 0 0 0 0 1 2 195 19 49 2 2 190 4 2 352 2 183 10 10 13 82 79 4 2 36 71 269 8 2 25 19 49 7 4 2 2 2 2 2 10 10 48 25 40 2 11 2 2 40 2 2 5 4 2 2 95 14 238 56 129 2 10 10 21 2 94 364 352 2 2 11 190 24 484 2 7 94 205 405 10 10 87 2 34 49 2 7 2 2 2 2 2 290 2 46 48 64 18 4 2] 12print(train_input[0][-10:])print(train_seq[0]) [6, 2, 46, 7, 14, 20, 10, 10, 470, 158] [ 10 4 20 9 2 364 352 5 45 6 2 2 33 269 8 2 142 2 5 2 17 73 17 204 5 2 19 55 2 2 92 66 104 14 20 93 76 2 151 33 4 58 12 188 2 151 12 215 69 224 142 73 237 6 2 7 2 2 188 2 103 14 31 10 10 451 7 2 5 2 80 91 2 30 2 34 14 20 151 50 26 131 49 2 84 46 50 37 80 79 6 2 46 7 14 20 10 10 470 158] 1val_seq = pad_sequences(val_input, maxlen = 100) 순환 신경망 만들기1234from tensorflow import kerasmodel = keras.Sequential()model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500)))model.add(keras.layers.Dense(1, activation='sigmoid')) 원핫 인코딩 적용 매칭이 성공하면 1을 출력 12train_oh = keras.utils.to_categorical(train_seq)print(train_oh.shape) (20000, 100, 500) 1print(train_oh[0][0][:12]) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] 1print(np.sum(train_oh[0][0])) 1.0 1이 출력되었으므로 성공 이제 검증데이터에 적용한다. 1val_oh = keras.utils.to_categorical(val_seq) 1model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= simple_rnn (SimpleRNN) (None, 8) 4072 dense (Dense) (None, 1) 9 ================================================================= Total params: 4,081 Trainable params: 4,081 Non-trainable params: 0 _________________________________________________________________ 1234567891011121314&quot;&quot;&quot;rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model.fit(train_oh, train_target, epochs=100, batch_size=64, validation_data=(val_oh, val_target), callbacks=[checkpoint_cb, early_stopping_cb])&quot;&quot;&quot; &quot;\\nrmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\\nmodel.compile(optimizer=rmsprop, loss='binary_crossentropy', \\n metrics=['accuracy'])\\n\\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5', \\n save_best_only=True)\\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\\n restore_best_weights=True)\\n\\nhistory = model.fit(train_oh, train_target, epochs=100, batch_size=64,\\n validation_data=(val_oh, val_target),\\n callbacks=[checkpoint_cb, early_stopping_cb])\\n&quot; 514p 문제점 발생: 토큰 1개를 500차원으로 늘림.. –&gt; 데이터 크기가 500배 커짐 1234567from tensorflow import kerasmodel2 = keras.Sequential()model2.add(keras.layers.Embedding(500, 16, input_length = 100))model2.add(keras.layers.SimpleRNN(8))model2.add(keras.layers.Dense(1, activation='sigmoid'))model2.summary() Model: &quot;sequential_1&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 100, 16) 8000 simple_rnn_1 (SimpleRNN) (None, 8) 200 dense_1 (Dense) (None, 1) 9 ================================================================= Total params: 8,209 Trainable params: 8,209 Non-trainable params: 0 _________________________________________________________________ 1234567891011121314'''rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model2.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model2.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) ''' &quot;\\nrmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\\nmodel2.compile(optimizer=rmsprop, loss='binary_crossentropy', \\n metrics=['accuracy'])\\n\\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', \\n save_best_only=True)\\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\\n restore_best_weights=True)\\n\\nhistory = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\\n validation_data=(val_seq, val_target),\\n callbacks=[checkpoint_cb, early_stopping_cb])\\n &quot; Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/11/chapter_9_2/"},{"title":"Java Script","text":"유튜브 영상인 ‘자바스크립트 입문’ 영상을 정리한 글입니다.JavaScript - 오리엔테이션 - YouTube *참고 - 생활코딩 링크 https://opentutorials.org/course/1 =1번 영상============================================ [프로그래밍이란 무엇인가] 자바스크립트 = 웹브라우저 제작 가능한 언어 탈웹브라우저의 흐름 → 자바스크립트를 웹서버에서 사용 웹서버를 동작하는 도구로서의 자바스크립트 = 서버 사이드 스크립트 node.js = 서버 사이드 스크립트의 대표적 기술. 자바스크립트는 웹브라우저에서 동작하지만 시간이 흘러 자바스크립트를 웹서버에서 동작하게 하는 기술이 등장. 이 기술의 예시로는 PHP, JAVA, PYTHON, Node.js 등이 있으며 이중에서도 각광받고 있는 기술이 Node.js 이다. 또 하나의 자바스크립트의 중요한 흐름은 탈웹. 웹 밖에서도 자바스크립트가 사용되기 시작. 이 예시로는 google apps script가 있다. 언어 = 의사소통을 위한 ‘약속’ 자바스크립트의 작동 환경 → 웹브라우저, nod.js, spreadSheet 웹브라우저에서 alert가 작동하고 node.js에서 write가 사용되며 spreadSheet 에서 msgBox가 이용됨. =2번 영상============================================ [언어의 실행방법과 실습환경에 대해서 알아본다] 기본 에디터를 사용하여 자바스크립트를 실행하는 법을 공부. 윈도우 기준 → 텍스트에디터 = 메모장 사용 링크를 타고 해당 내용을 복사 붙여넣기. ` alert('Hello world'); →>>>> 이 부분만 자바스크림트 / 나머진 html. ` +→ alert 명령어는 경고창 형태로 띄우는 기능. 다른 이름으로 저장하기 → sample.html → 파일형식:모든 파일 → 인코딩:UTF-8 https://opentutorials.org/module/532/4646 해당 링크를 참고하라. =3번 영상============================================ Chrome 크롬 브라우저 기준으로 설명. 개발자 도구를 킵니다 : 웹 브라우저 → 도구 → 개발자 도구 자바스크립트를 입력합니다 : 개발자 도구 → console → 자바스크립트 입력 더 자세한 정보는 해당 링크를 참고. https://opentutorials.org/course/580 ` console.log('Hello world'); →>>> 개발자 도구의 콘솔에 hello world 출력됨. ` 해당 내용으로 메모장을 수정하고 저장만 하면 적용됨. =4번 영상============================================ 도구의 선택. IDE = 통합 개발 환경 운영 체제에 맞는 IDE 를 사용해야 한다. 좋은 개발 도구를 사용하는 것은 좋은 코드를 작성하는 것만큼 중요. https://opentutorials.org/module/406/3595 =5번 영상============================================ 숫자와 문자 : 수의 표현 sublime Text를 설치. 파일 목록 표시 : view → show side view 사용할 파일 지정? : project → open project 입력할 창 생성 : 폴더에 우클릭 → new file 내용 입력 : 1. html 입력 후 Tab 키 = 기본적인 내용이 채워짐. 2. 빈 부분에 script 입력 후 Tab 키 = 추가로 내용이 채워짐. 3. 다음 캡처와 같이 정리하고 빈 칸에 원하는 내용 입력. 자바스크립트 입력 후 저장하면 적용된다. ex) alert(1); alert(1.1); alert(1.1+1.1); alert(2*8) 1 → 정수 1.1 → 실수 개발자 도구의 콘솔에서도 계산 가능. =6번 영상============================================ 수학 관련 명령어 수학 함수 Math 소개. Math.pow(3,2); →&gt;&gt;&gt; 3의 제곱은 9라는 내용. → 9 Math.round(10.6); →&gt;&gt;&gt; 10.6의 반올림 →11 Math.ceil(10.2); →&gt;&gt;&gt; 10.2의 올림. →11 Math.floor(10.2); →&gt;&gt;&gt; 10.2의 내림. → 10 Math.sqrt(9) →&gt;&gt;&gt; 9의 제곱근. →3 Math.random(); →&gt;&gt;&gt; 1보다 작은 랜덤 실수. 100 * Math.random(); →&gt;&gt;&gt; 100보다 작은 랜덤 실수. Math.round( 100 * Math.random() ); →&gt;&gt;&gt; 100 보다 작은 랜덤 정수 =7번 영상============================================ 따옴표 사용. 따옴표 = 지금부터 작성하는 것은 문자임 작은 따옴표로 열은 문장은 작은 따옴표로 닫아야 한다. 큰 따옴표로 열은 문장은 큰 따옴표로 닫아야 한다. *작은 따옴표 내에서 작은 따옴표 사용하기 ⇒ 역 슬래쉬 사용 ⇒ \\ (escape) *따옴표 내에 있다면 숫자라도 문자 취급 ⇒ ‘1’ 은 문자이다. 따라서 ‘1’+’1’ = ‘11’ 이다. *타입 구분법 ⇒ typeof ex) typeof 1, typeof ‘1’ =8번 영상============================================ 개행 사용법. 개행 = 줄바꿈이란 의미 ⇒ \\n 공백 생성법 ⇒ “ “ 와 + 를 사용. ex) “coding” + “ “ + “everyday ⇒ coding everyday 길이 측정법 ⇒ length 를 사용 ex) “coding everybody”.length = 16 *자바스크립트 명령어 모음. 다음 링크를 참고하라. https://opentutorials.org/course/50/37 문자 위치 출력 ⇒ indexOf 를 사용 ex) “code”.indexOf(”c”)=0, “code”.indexOf(”o”)=1, “code”.indexOf(”d”)=2, “code”.indexOf(”e”)=3 =9번 영상============================================ 변수. 변수 선언 예시 ⇒ var a = 1; 다음 같이 시행하면 경고창으로 10 이 출력된다. 다음과 같이 문자로도 사용 가능하다. =10번 영상=========================================== [변수의 효용] 변수의 값을 바꾸면 해당 변수가 들어간 모든 식에 반영이 된다. 이것은 매우 편리하고 실용적인 기능이다. 변수를 쓰는 이유 중 하나이다. 변수 사용 팁 ⇒ 여러 줄로 이루어진 식이 있다면 변할 수 있는 부분과 변하지 않는 부분으로 나누어라. 직접 사용해보면 알겠지만 유지보수에 좋은 형태이다. =11번 영상=========================================== [주석] 주석 ⇒ 코드의 실행에 관여하지 않는 설명문이다. ⇒ // 으로 사용가능. ⇒ ex) // 이 문장은 주석이다. ⇒ /* */ 으로도 사용 가능하다. 좋은 주석은 좋은 코드의 요인 중 하나이다. 미래의 타인이 되었을 자신을 위한 배려. =12번 영상=========================================== [줄바꿈과 여백] 세미 콜론 ⇒ ; ⇒ 줄이 끝났다는 표시이다. ex) var a = 1; alert(a); 이라 작성하면 서로 다른 줄로 인식도니다. 텝 ⇒ Tab ⇒ 들여쓰기가 된다. ⇒ 가독성을 높이기 위해 사용된다. 여러 줄을 드래그하고 텝하면 한 번에 들여쓰기가 적용된다. =13번 영상=========================================== [연산자] a=1 에서 =(equal) 은 대입 연산자이다. 다음 영상의 내용은 대입 연산자와 다른 개념인 비교 연산자이다. =14번 영상=========================================== [ == 과 === ] == (equal operator). → 동등 연산자. → 두 값을 비교하여 같다면 true, 틀리다면 false를 출력한다. → 문자도 비교 가능하다. ===( strict equal operator ) → 일치 연산자. → 값은 물론이고, 데이터의 타입까지 같아야 true를 출력한다. → == 라면 true를 출력할 것도 false를 출력하기도 한다. → 말 그대로 엄격한 동등 연산자이다. → 한 치의 오차도 용납하지 않아야 하는 중요한 코드에 사용한다. =15번 영상=========================================== ===(일치 연산자)를 사용하자. null = 값이 없다는 뜻. undefined = 값이 정의되지 않았다는 뜻. NaN = 숫자가 아니라는 뜻. alert( undefined == null) →&gt;&gt;&gt; true 가 경고창으로 출력된다. alert( undefined === null) →&gt;&gt;&gt; false 가 경고창으로 출력된다. [type 타입] boolean 의 예시 → true, false number 의 예시 → -1, 0, 1, 2 string 의 예시 → “a”, “b”, “c” null 의 예시 → null undefined의 예시 → undefined *주의 : alert( NaN === NaN ) 의 결과는 false. NaN 에만 해당함. 타입에 관한 자세한 정보는 다음을 참조하라. https://opentutorials.org/module/532/4722 https://dorey.github.io/JavaScript-Equality-Table/ =16번 영상=========================================== 부정과 부등호. ! = not = 부정을 의미한다. alert( 1!= 2) 의 결과는 true이다. 부등호. , =&gt;, &lt;, &lt;= =17번 영상=========================================== 조건문이란. 조건문은 if로 시작한다. **if**(**true**){ alert('result : true'); } if 옆의 괄호 부분에 true가 되어야만 중괄호 안쪽의 조건문이 실행된다. 다음을 참고하라. https://opentutorials.org/module/532/4724 =18번 영상=========================================== else, else if else를 통해 예외를 선택해 실행할 수 있다. **if**(**true**){ alert(1); } **else** { alert(2); } true일때는 if 부분을, false일때는 else 부분을 실행한다. else if는 조건문을 좀 더 풍부하게 사용할 수 있게 한다. **if**(**false**){ alert(1); } **else** **if**(**true**){ alert(2); } **else** **if**(**true**){ alert(3); } **else** { alert(4); } 처음으로 true가 나온 조건문만 실행한다. 위 코드의 결과는 2이다. =19번 영상=========================================== 조건문의 응용. prompt = 스캔문이다. 사용자가 입력하는 정보를 받는 명령어다. ex) alert( prompt(‘당신의 나이는?’)*2); 실행 시, 정보를 입력할 창이 나타난다. 사용자가 입력하는 값에 따라 출력되는 결과가 달라진다. ex) &lt;!DOCTYPE html&gt; &lt;**html**&gt; &lt;**head**&gt; &lt;**meta** charset=&quot;utf-8&quot;/&gt; &lt;/**head**&gt; &lt;**body**&gt; &lt;**script**&gt; id = prompt('아이디를 입력해주세요.') if(id=='egoing'){ alert('아이디가 일치 합니다.') } else { alert('아이디가 일치하지 않습니다.') } &lt;/**script**&gt; &lt;/**body**&gt; &lt;/**html**&gt; prompt의 입력창에서 입력하는 아이디가 정해진것과 같아야만 ‘아이디가 일치 합니다.’ 라는 문구가 출력됩니다. =20번 영상=========================================== 논리연산자. &amp; = 엔퍼센트. 라고 읽는다. &amp;&amp; = AND = 모두 true 일때만 조건문 실행. ex) **if**(**true** &amp;&amp; **true**){ alert(1); } || = or ex) 하나만 true 여도 조건문 실행. **if**(**true** || **true**){ alert(1); } =21번 영상=========================================== boolean의 대체재. 0 = false 0이 아닌 값 = true 다음을 참고하라. https://opentutorials.org/module/532/4724 =22번 영상=========================================== 반복문. 반복분 = loop = iterator https://opentutorials.org/module/532/4728 while 사용법. while (조건){ 반복해서 실행할 코드 } 조건이 true인한 계속해서 코드가 실행된다. false가 된다면 코드의 반복이 종료된다. [명령어] document.write = 문구 출력 = 개행 =23번 영상=========================================== 반복조건. 다음과 같이 조건을 설정. i가 0~9일 때는 반복이 실행되고 i 가 10이 되면 false가 되어 반복이 중지된다. 결과적으로 Coding everybody가 10번 출력된다. =24번 영상=========================================== for문. while보다 편리하다. 3가지 조건이 한 줄에 들어가기 때문. for는 다음과 같이 사용한다. for(초기화; 반복조건; 반복이 될 때마다 실행되는 코드){ 반복해서 실행될 코드 } ex) 이전 영상의 코드와 같은 결과를 낸다. i++ →&gt; 다음 라인부터 i=i+1 ++i →&gt; 현재 라인부터 i=i+1 =25번 영상=========================================== 반복문의 효용. 조건에 따라 무수한 반복조건을 실행 가능. =26번 영상=========================================== 반복문의 제어. break = 반복문을 종료. continue = 현재 반복을 중지하고 다시 반복을 실행. =27번 영상=========================================== 반복문의 중첩. 다음과 같이 반복문 안에 반복문을 사용. 결과적으로 Coding everybody 0 ~ Coding everybody 99가 출력된다. [디버그] 도구 → 개발자 도구 → Source → F5키. for가 있는 8번 라인을 클릭. breakpoints에 for의 정보가 표시된다. 이 상태에서 F5키를 입력 → Pause in debugger 뜨면서 회색 화면 출력됨. 코드 실행이 8번까지 와서 멈춘 것이다. 해당 상태에서 아래쪽의 코드제어 도구들을 사용 가능하다. 첫 번째 도구 = 코드 재실행. 두 번째 도구 = 세 번째 도구 = 다음 라인 실행 네 번째 도구 = 이전 라인 실행 코드제어 도구 옆 같에서 다음과 같이 표시 가능. 이 상태에서 벗어나기 = 8번 breakpoint를 클릭하고 첫 번째 도구를 누른다. =28번 영상=========================================== 함수. 재사용성이 높은 기능. 다음과 같이 사용한다. function 함수명( [인자...[,인자]] ){ 코드 **return** 반환값 } ex) numbering이란 함수를 정의. 변수와 달리 옆에 괄호가 있어야 한다. 그래야 변수가 아닌 함수로 인식된다. 자세한 내용은 다음을 참고. https://opentutorials.org/module/532/4729 =29번 영상=========================================== 함수의 효용. 한 번 정의한 함수는 재사용성, 유지보수의 용이성, 가독성이 띄어나다. =30번 영상=========================================== 입력과 출력. 출력 = return return = 출력과 동시에 함수를 종료시킨다. function get_member1(){ **return** 'egoing'; } function get_member2(){ **return** 'k8805'; } alert(get_member1()); alert(get_member2()); 출력 예시 = return에 의하여 alert가 egoing과 k8805를 출력된다. =31번 영상=========================================== 입력과 출력. 매개변수(parameter) = 입력받는 변수 인자(argument) = 함수로 유입되는 입력 값 입력 예시 = alert의 실행에서 함수의 괄호에 든 값이 변수 arg에 입력된다. =32번 영상=========================================== 다양한 정의 방법. 정의 방법 예시. 위 코드는 아래 코드와 같다고 볼 수 있다. [익명함수] 다음과 같이 함수 전체를 괄호로 덮는 것이다. 함수정의와 동시에 ;옆의 ()에 의해 함수 호출이 발동. 즉, 함수 정의와 함수 호출이 동시에 되어 일회성으로 사용되는 함수가 된다. =33번 영상=========================================== 배열의 문법. 배열(array) = 연관된 데이터를 모아 관리하기 위한 데이터 타입. = 변수가 하나의 데이터를 저장한다면 배열은 다수를 관리. ex) **var**member = ['egoing', 'k8805', 'sorialgi'] 위 코드의 member는 3개의 원소를 가진 배열이다. 배열에 담긴 원소는 0번, 1번, 2번….순서로 저장된다. 이 원소의 위치를 색인(index) 라고 한다. =34번 영상=========================================== 배열의 효용. 함수는 여러개의 입력이 가능한 것에 비해 출력은 하나만 가능하다. 그러나 배열을 이용해 return을 하면 여러 개의 출력이 가능해진다. ex) function get_members(){ **return** ['egoing', 'k8805', 'sorialgi']; } =35번 영상=========================================== 배열과 반복문의 조우. toUpperCase(); = 대문자로 바꿔주는 내장함수. = 다음과 같이 사용 가능하다. 위 함수를 이용한 예시이다. function get_members(){ **return** ['egoing', 'k8805', 'sorialgi']; } var members = get_members(); document.write(members[0]); document.write(members[1]); document.write(members[2]); 이 코드를 반복문을 통해 재구현하면 다음과 같다. 결과 : 배열의 원소들이 대문자로 출력된다. =36번 영상=========================================== 데이터의 추가. push() = 배열에 원소 추가. concat() = 배열에 복수의 원소 추가. ex) unshift() = 배열의 0번 자리에 원소 추가 ex) splice() = 배열의 중간에 추가 ex) splice(1,0,’d’) → 1번 자리에 원소를 0개 삭제하고 ‘d’를 추가 =37번 영상=========================================== 제거와 정렬. shift() = 배열의 0번 자리의 원소를 제거 ex) pop() = 배열의 끝의 원소를 제거 ex) sort() = 배열의 원소를 정렬 ex) reverse() = 배열의 원소를 거꾸로 정렬 ex) =38번 영상=========================================== 객체. 배열은 아이템에 대한 식별자로 숫자를 사용했다. 객체를 사용한다면 문자를 인덱스로 사용할 수 있다. 다음은 객체를 만드는 법이다. **var**grades = {'egoing': 10, 'k8805': 6, 'sorialgi': 80}; 위와 같이 인덱스와 값이 쌍을 이룬다. (key-value 쌍) 다음과 같이 객체를 만들 수도 있다. var grades = {}; grades['egoing'] = 10; grades['k8805'] = 6; grades['sorialgi'] = 80; 만들어진 객체는 다음과 같이 이용할 수 있다. [ ]를 사용하면 다음같이 사용 가능. =39번 영상=========================================== 객체와 반복문의 조우. 반복문에서 다음과 같이 사용. 참고로, 태크인 ~ 은 리스트를 뜻함. &lt;li&gt; ~ &lt;/li&gt; 는 document.write로 작성한 부분이라 한다. ( li = list 의 약자) for문에 의해 반복마다 변수 name에 배열 grades의 원소가 입력된다. 결과는 다음과 같다. 다음과 같은 활용도 가능하다. =40번 영상=========================================== 객체지향 프로그래밍. 배열 안에 함수를 정의하는 법. 결과는 ‘Hello world’ 또 다른 예시. 결과는 egoing 10 k8805 8 sorialgi 80 =41번 영상=========================================== 모듈. *모듈 부품. 작고 단순한 것에서 크고 복잡한 것으로 진화한다. 코드의 재활용성을 높이고, 유지보수를 쉽게 한다. *묘듈의 장점 자주 사용되는 코드를 별도의 파일로 만들어서 필요할 때마다 활용 가능. 코드 수정 시에 필요한 로직을 빠르게 찾을 수 있다. 필요한 로직만을 로드해서 메모리의 낭비를 줄일 수 있다. =42번 영상=========================================== 모듈화. main.html 파일 생성. https://opentutorials.org/module/532/4750 링크의 코드 복사 붙여넣기. src = “greeting.js” →&gt;&gt; 함수를 정의한 후에 호출하는 것과 같은 효과. greeting.js 파일 생성. 파일에 함수 부분의 코드를 작성. main.html의 함수 부분은 지운다. 두 파일을 작성 완료했으면 main에서 실행. ctrl + o 를 통해 main.html을 열고 코드를 실행한다. greeting.js이 호출되어 main에서 실행되는 결과가 나온다. =43번 영상=========================================== Node.js의 모듈화. 다른 환경에서의 모듈은 다루는 방법이 다름. 이 영상에선 오직 그것만 인지하면 됨. =44번 영상=========================================== 라이브러리란? [라이브러리] 모듈과 비슷한 개념. 자주 사용되는 로직을 재사용하기 편리하도록 정리한 코드들의 집합. 유명 라이브러리로는 jQuery 가 있다. =45번 영상=========================================== 라이브러리의 사용. jQuery 사용법. jQuery에서 파일을 다운로드 받는다. API documentation을 보고 사용법을 숙지한다. 두 가지를 이용하여 라이브러리를 사용. 실제 사용법. 구글에서 jquery를 검색. jquery에서 파일을 다운받는다. https://code.jquery.com/jquery-3.6.0.js 다운받으면 나타나는 페이지를 전체 복사(Ctrl+A) jquery.js파일을 생성하고 복사한 내용을 붙여넣기. script 부분에 src=”jquery.js”를 작성하여 실행하면 jquery를 사용할 수 있다. jquery 코드 작성 jquery의 코드는 $로 시작한다. 다음은 ~ 에 있는 empty를 바꾸는 실행문이다. excute라는 버튼을 생성. excute 버튼을 click시에 발동하는 함수 정의. 함수 내용은 li에 있는 텍스트를 coding everybody로 변경. 따라서 다음 결과가 나온다. 버튼을 누르면 다음과 같이 텍스트가 변경된다. =46번 영상=========================================== JavaScript-UI,API 그리고 문서 https://opentutorials.org/module/532/6533 =47번 영상=========================================== UI와 API. UI = User Interface API = Application Programming Interface UI는 코드를 모르는 사용자도 쉽게 다룰 수 있도록 해주는 편의성 중심 기술. 사용자의 의도를 손쉽게 pc에 전달하여 조작 난이도를 낮춰준다. internet explore 의 주소창에 다음 명령어를 입력. javascript.alert(“Hello world”); 경고창으로 Hello world가 출력된다. 이 경고창을 내가 만들었는지 시스템이 만들었는지는 애매하다. 하지만, 이 경고창의 ‘확인’에 커서를 갖다대면 색이 변하는 것이나 경고창이 뜨면서 나오는 경고음, 경고창의 위치 등은 확실하게 내가 만들었다고 할 수 없다. 이런 것들이 모두 API라고 할 수 있다. 물론 alert등의 명령어도 이에 포함된다. 정리하다면, 사용자는 UI를 통해 시스템을 사용하고 개발자는 UI와 API를 통해 시스템을 다룬다. =48번 영상=========================================== 문서 보는 법. 프로그래밍을 공부하기 위한 자료 - 레퍼런스, 튜토리얼 튜토리얼 = 언어의 문법을 설명. 레퍼런스 = 명령어의 사전. 자바스크립트 API는 크게 자바스크립트 자체의 API와 자바스크립트가 동작하는 호스트 환경의 API로 구분된다. 자바스크립트 API 문서 예시 ECMA script (표준문서) 자바스트립트 사전 : https://opentutorials.org/course/50 자바스크립트 레퍼런스 (MDN) jscript 레퍼런스 (MSDN) =49번 영상=========================================== 정규표현식. 정규표현식은 문자열에서 특정한 문자를 찾아내는 도구다. 더 자세한 내용을 알고 싶다면 다음을 참고. https://opentutorials.org/module/532/6580 https://opentutorials.org/course/909/5142 =50번 영상=========================================== 정규표현식 : 패턴만들기 정규표현식 사용은 두가지 단계로 이루어짐. [ 1단계 ] 컴파일 ⇒ 패턴을 찾는 것. var str = “a”; 즉, a 라는 텍스트를 찾아내는 정규표현식을 만들어보자. 방법 1) 정규표현식 리터럴 **var**pattern = /a/ 방법 2) 정규표현식 객체 생성자 var pattern = new RegExp('a'); [ 2단계 ] 실행 ⇒ 찾은 패턴을 구체화하는 것. =51번 영상=========================================== 정규표현식 : RegExp 객체의 정규 표현식 정규표현식을 컴파일해서 객체를 만들었다면 이제 문자열에서 원하는 문자를 찾아내야 한다. RegExp.exec() 다음과 같이 사용한다. 찾으려는 문자를 변수 pattern에 정의한 다음, exec() 의 괄호에 아무 문자열이나 채워넣는다. pattern.exec()를 실행하면 문자열중에서 pattern에 해당하는 문자를 찾아낸다. RegExp.test() 다음과 같이 사용한다. exec()와 같이 사용한다. 다만 결과는 boolean 값으로 출력된다. 찾는 문자가 있다면 true, 없다면 false. =52번 영상=========================================== 정규표현식 : String 객체의 정규 표현식 string.match() 다음과 같이 사용한다. exec()와 비슷하다. string.replace() 다음과 같이 사용한다. str에 입력된 문자열에서 replace()에 입력한 pattern을 찾은 후에 ( )안의 인자로 대체한다. =53번 영상=========================================== 정규표현식 : 옵션 /i ⇒ 소문자 대문자 모두 찾는 옵션. = a를 지정했음에도 “A”를 찾아 출력함. /g ⇒ 같은 문자가 여러 개 나와도 모두 찾는다. (글로벌) =54번 영상=========================================== 정규표현식 : 캡처 괄호안의 패턴은 마치 변수처럼 재사용할 수 있다. 이 때 기호 $를 사용하는데 아래 코드는 coding과 everybody의 순서를 역전시킨다. var pattern = /(\\w+)\\s(\\w+)/; var str = &quot;coding everybody&quot;; var result = str.replace(pattern, &quot;$2, $1&quot;); console.log(result); (\\w+)\\s(\\w+) ⇒ ‘문자+(공백)+문자’ 를 표현한 식이다. 이 식을 이용하여 다음 링크들을 살펴보자. https://regexper.com/ 정규표현식 시각화 페이지 입력한 식을 시각화하여 보여준다. https://regexr.com/ 정규표현식 빌더 텍스트박스에 식을 입력한다. 아래의 박스에 여러 단어를 입력한다. 텍스트박스의 식과 일치하는 아래 박스의 단어는 파랗게 빛난다. =55번 영상=========================================== 정규표현식 : 치환 다음 코드는 본문 중의 URL을 링크 html 태그로 교체한다. var urlPattern = /\\b(?:https?):\\/\\/[a-z0-9-+&amp;@#\\/%?=~_|!:,.;]*/gim; var content = '생활코딩 : [http://opentutorials.org/course/1](http://opentutorials.org/course/1) 입니다. 네이버 : [http://naver.com](http://naver.com/) 입니다. '; var result = content.replace(urlPattern, **function**(url){ **return** '&lt;a href=&quot;'+url+'&quot;&gt;'+url+'&lt;/a&gt;'; }); console.log(result); =56번 영상=========================================== 유효범위 : 전역변수화 지역변수 https://opentutorials.org/module/532/6495 유효범위(Scope)는 변수의 수명을 위미. var vscope = 'global'; function fscope(){ var vsope = 'local'; alert(vscope); } fscope(); 함수 내에 선언된 vscope에 의해 local이 출력된다. 만약, 함수 내의 vscope이 없다면 함수 밖의 global이 출력된다. 함수 내에서 var로 변수 정의한 것은 ‘로컬(지역)변수’가 된다. 만약, var을 붙이지 않는다면 전역변수가 된다. 따라서, 위 코드에서 함수 내의 vscope=’local’에 의해 맽 윗줄의 var vscope 의 내용물은 ‘global’에서 ‘local’이 된다. 단, 같은 함수 내에 이미 같은 변수가 지역변수로 존재한다면 var이 안 붙어있어도 지역변수로 취급된다. =57번 영상=========================================== 유효범위 : 유효범위와 효용 아래 두개의 예제는 변수 i를 지역변수로 사용했을 때와 전역변수로 사용했을 때의 차이점을 보여준다. 전역변수는 각기 다른 로직에서 사용하는 같은 이름의 변수값을 변경시켜서 의도하지 않은 문제를 발생시킨다. function a (){ **var** i = 0; } **for**(**var** i = 0; i &lt; 5; i++){ a(); document.write(i); } 결과 : 01234 function a (){ i = 0; } **for**(i = 0; i &lt; 5; i++){ a(); document.write(i); } 결과 : 무한반복 =58번 영상=========================================== 유효범위 : 전역변수를 사용하는 법 불가피하게 전역변수를 사용해야 하는 경우는 하나의 객체를 전역변수로 만들고 객체의 속성으로 변수를 관리하는 방법을 사용한다. 다음은 전역변수 하나를 선언하고 나머지 변수는 전역변수의 소속변수로 둔 것이다. 따라서 다른 코드의 이름이 같은 변수와 충돌할 가능성을 줄일 수 있다. var MYAPP = {} MYAPP.calculator = { 'left' : **null**, 'right' : **null** } MYAPP.coordinate = { 'left' : **null**, 'right' : **null** } MYAPP.calculator.left = 10; MYAPP.calculator.right = 20; function sum(){ **return** MYAPP.calculator.left + MYAPP.calculator.right; } document.write(sum()); 결과 : 10+20=30 =59번 영상=========================================== 유효범위 : 유효범위의 대상 자바스크립트는 함수에 대한 유효범위만을 제공한다. 많은 언어들이 블록(대체로 {,})에 대한 유효범위를 제공하는 것과 다른 점이다. 아래 예제의 결과는 coding everybody이다. **for**(**var** i = 0; i &lt; 1; i++){ **var** name = 'coding everybody'; } alert(name); 자바에서는 아래의 코드는 허용되지 않는다. name은 지역변수로 for 문 안에서 선언 되었는데 이를 for문 밖에서 호출하고 있기 때문이다 **for**(int i = 0; i &lt; 10; i++){ String name = &quot;egoing&quot;; } System.out.println(name); =60번 영상=========================================== 유효범위 : 정적 유효 범위 자바스크립트는 함수가 선언된 시점에서의 유효범위를 갖는다. 이러한 유효범위의 방식을 정적 유효범위(static scoping), 혹은 렉시컬(lexical scoping)이라고 한다. var i = 5; function a(){ **var** i = 10; b(); } function b(){ document.write(i); } a(); 결과 : 5 [정적 유효범위 개념] 사용될 때가 아니라, 정의될 때를 기준으로 하기 때문에 결과는 5이다. =61번 영상=========================================== 값으로서의 함수와 콜백 : 함수의 용도1 https://opentutorials.org/module/532/6508 JavaScript에서는 함수도 객체다. 다시 말해서 일종의 값이다. 거의 모든 언어가 함수를 가지고 있다. JavaScript의 함수가 다른 언어의 함수와 다른 점은 함수 자체 값이 될 수 있다는 점이다. **function**a(){} 위 코드에서 함수 a는 변수 a에 담겨진 값이다. 또한 함수는 객체의 값으로 포함될 수 있다. 이렇게 객체의 속성 값으로 담겨진 함수를 메소드(method)라고 부른다. a = { b:**function**(){ } }; 위 코드에서 a안에 담긴 b라는 속성(property)이 있다고 볼 수 있으며, 중괄호 안의 함수 function은 메소드(method)이다. 객체 내에서 정의된 함수는 메소드이므로 a 라는 객체 안에서 정의된 함수 function은 메소드이다. 함수는 값이기 때문에 다른 함수의 인자로 전달 될수도 있다. 다음과 같이 사용 가능. function cal(func, num){ **return** func(num) } function increase(num){ **return** num+1 } function decrease(num){ **return** num-1 } alert(cal(increase, 1)); alert(cal(decrease, 1)); =62번 영상=========================================== 값으로서의 함수와 콜백 : 함수의 용도2 함수는 함수의 리턴 값으로도 사용할 수 있다. function cal(mode){ **var** funcs = { 'plus' : **function**(left, right){**return** left + right}, 'minus' : **function**(left, right){**return** left - right} } **return** funcs[mode]; } alert(cal('plus')(2,1)); alert(cal('minus')(2,1)); 결과 : 3, 1 배열의 값으로도 사용할 수 있다. var process = [ **function**(input){ **return** input + 10;}, **function**(input){ **return** input * input;}, **function**(input){ **return** input / 2;} ]; var input = 1; **for**(**var** i = 0; i &lt; process.length; i++){ input = process[i](input); } alert(input); for문에 의해 배열에 담긴 함수가 차례로 호출. input=1 → input+10=11 → input*input=121 → input/2=60.5 결과 : 60.5 =63번 영상=========================================== 값으로서 함수와 콜백 : 콜백 sort() 는 내장 메소드이다. 위 코드를 실행하면 sort()에 따라 배열이 정렬된다. 하지만 우리가 원하는 배열이 되지 않는다. sort()는 앞에 온 문자로 순서를 판단하는 듯 하다. 크기 순서로 배열하려면 array()를 사용해야 한다. 자바스크립트 사전에서 array의 원리를 파악하고 코딩한 결과이다. 결과로 배열이 제대로 정렬되어 출력된다. 값으로 전달된 함수는 호출될 수 있기 때문에 이를 이용하면 함수의 동작을 완전히 바꿀 수 있다. 이것을 ‘콜백’이라고 하며, 이것이 가능한 것은 자바스크립트에서 함수가 값으로 취급되기 때문이다. =64번 영상=========================================== 값으로서 함수와 콜백 : 비동기 콜백 콜백은 ‘비동기처리’에서도 유용하게 사용된다. 시간이 오래걸리는 작업이 있을 때 이 작업이 완료된 후에 처리해야 할 일을 콜백으로 지정하면 해당 작업이 끝났을 때 미리 등록한 작업을 실행하도록 할 수 있다. to-do와 비슷하다. 동기화는 비동기화의 반대되는 개념이다. 비동기 처리의 예시로는 Ajax가 있다. Ajax = asynchronous java script and XML ( 비동기 ) =65번 영상=========================================== 클로저 : 외부함수와 내부함수 https://opentutorials.org/module/532/6544 클로저(closure)는 내부함수가 외부함수의 맥락(context)에 접근할 수 있는 것을 가르킨다. function outter(){ **function** inner(){ **var** title = 'coding everybody'; alert(title); } inner(); } outter(); 위 코드에서 inner()는 내부함수, outer()는 외부함수이다. 내부함수는 외부함수의 지역변수에 접근할 수 있다. function outter(){ **var** title = 'coding everybody'; **function** inner(){ alert(title); } inner(); } outter(); 결과 : coding everybody 이 결과는 inner() 외부함수의 지역변수인 var title에 접근할 수 있음을 알려준다. =66번 영상=========================================== 클로저 : 클로저란 클로저(closure)는 내부함수와 밀접한 관계를 가지고 있는 주제다. 내부함수는 외부함수의 지역변수에 접근 할 수 있는데 외부함수의 실행이 끝나서 외부함수가 소멸된 이후에도 내부함수가 외부함수의 변수에 접근 할 수 있다. 이러한 메커니즘을 클로저라고 한다. function outter(){ **var** title = 'coding everybody'; **return** **function**(){ alert(title); } } inner = outter(); inner(); 결과 : coding everybody =67번 영상=========================================== 클로저 : private variable 다음은 클로저를 이용해 영화의 제목을 저장하고 있는 객체를 정의하고 있다. function factory_movie(title){ **return** { get_title : **function** (){ **return** title; }, set_title : **function**(_title){ title = _title } } } ghost = factory_movie('Ghost in the shell'); matrix = factory_movie('Matrix'); alert(ghost.get_title()); → Ghost in the shell alert(matrix.get_title()); → Matrix ghost.set_title('공각기동대'); alert(ghost.get_title()); → 공각기동대 alert(matrix.get_title()); → Matrix 각각 자신이 실행된 시점에서의 title값에 접근한다. private variable = 비밀변수. private variable의 개념으로 title이란 변수를 안전하게 저장한 것이다. =68번 영상=========================================== 클로저 : 클로저의 응용 클로저 사용 시 주의점. var arr = [] **for**(**var** i = 0; i &lt; 5; i++){ arr[i] = **function**(){ **return** i; } } **for**(**var** index **in** arr) { console.log(arr[index]()); } 결과 : 5 5 5 5 5 설명이 이해가 되지 않았다. 다시 보자. =69번 영상=========================================== arguments : arguments란? arguments는 배열과 유사하지만, 배열은 아니다. 실제로는 arguments 객체의 인스턴스다. function sum(){ **var** i, _sum = 0; **for**(i = 0; i &lt; arguments.length; i++){ document.write(i+' : '+arguments[i]+'&lt;br /&gt;'); _sum += arguments[i]; } **return** _sum; } document.write('result : ' + sum(1,2,3,4)); arguments의 자체적인 기능으로 인해 sum() 안에 몇 개의 인자가 담겨있는지 파악이 가능하다. 그렇기에 위 코드 실행 시, argument.length = 4 가 된다. =70번 영상=========================================== arguments : function length 매개변수와 관련된 두가지 수가 있다. 하나는 함수.length, 다른 하나는 arguments.length이다. arguments.length는 함수로 전달된 실제 인자의 수를 의미하고, 함수.length는 함수에 정의된 인자의 수를 의미한다. function zero(){ console.log( 'zero.length', zero.length, 'arguments', arguments.length ); } function one(arg1){ console.log( 'one.length', one.length, 'arguments', arguments.length ); } function two(arg1, arg2){ console.log( 'two.length', two.length, 'arguments', arguments.length ); } zero(); // zero.length 0 arguments 0 one('val1', 'val2'); // one.length 1 arguments 2 two('val1'); // two.length 2 arguments 1 =71번 영상=========================================== 함수의 호출 : apply 소개 https://opentutorials.org/module/532/6550 함수를 호출하는 가장 기본적인 방법이다 function func(){ } func(); 함수 func는 Function이라는 객체의 인스턴스다. 따라서 func는 객체 Function이 가지고 있는 메소드들을 상속하고 있다. 해당 영상에서 이야기하려는 메소드는 Function.apply과 Function.call이다 function sum(arg1, arg2){ **return** arg1+arg2; } alert(sum.apply(**null**, [1,2])) → 3 함수 sum은 Function 객체의 인스턴스다. 그렇기 때문에 객체 Function 의 메소드 apply를 호출 할 수 있다. apply 메소드는 두개의 인자를 가질 수 있는데, 첫번째 인자는 함수(sum)가 실행될 맥락이다. 두번째 인자는 배열인데, 이 배열의 담겨있는 원소가 함수(sum)의 인자로 순차적으로 대입된다. =72번 영상=========================================== 함수의 호출 : apply의 사용 this는 호출할 때 결정된다. o1 = {val1:1, val2:2, val3:3} o2 = {v1:10, v2:50, v3:100, v4:25} function sum(){ **var** _sum = 0; **for**(name **in** **this**){ → 코드 실행 시, var this = o1 이 된다. _sum += **this**[name]; } **return** _sum; } alert(sum.apply(o1)) // 6 alert(sum.apply(o2)) // 185 =73번 영상=========================================== 객체지향프로그래밍 : 오리엔테이션 https://opentutorials.org/module/532/6553 객체지향 프로그래밍(Object-Oriented Programming) 객체는 틀이다. 붕어빵을 만드는 틀과 같이 정해진 형태가 있으며, 틀에서 만들어진 붕어빵과 같이 객체 역시 자신과 같은 형태를 계속해서 찍어낼 수 있다. =74번 영상=========================================== 객체지향프로그래밍 : 추상화 좋은 객체를 만들기 위해서는 설계가 중요하다. 좋은 설계는 현실을 잘 반영해야 한다. 현실은 복잡하지만 그 복잡함 전체가 필요한 것은 아니다. 지하철 노선도를 떠올리면 간단하다. 노선도마냥 알기 쉽게하는 과정을 ‘추상화(abstract)’라고 한다. =75번 영상=========================================== 객체지향프로그래밍 : 부품화 객체 지향은 ‘부품화’의 정점이라고 할 수 있다. 배운 것 중에서 부품화의 특성을 보여줄 수 있는 기능을 생각해보자. 메소드는 부품화의 예라고 할 수 있다. 메소드를 사용하는 기본 취지는 연관되어 있는 로직들을 결합해서 메소드라는 완제품을 만드는 것이다. 그리고 이 메소드들을 부품으로 해서 하나의 완제품인 독립된 프로그램을 만드는 것이다. 메소드를 사용하면 코드의 양을 극적으로 줄일 수 있고, 메소드 별로 기능이 분류되어 있기 때문에 필요한 코드를 찾기도 쉽고 문제의 진단도 빨라진다. =76번 영상=========================================== 생성자와 new : 소개 https://opentutorials.org/module/532/6570 자바스크립트 = prototype-based programming. 자바스크립트의 객체 지향 사용법을 알아보자. 다른 언어와 사용법이 다르다고 하니 주의. =77번 영상=========================================== 생성자와 new : 객체생성 객체란 서로 연관된 변수와 함수를 그룹핑한 그릇이라고 할 수 있다. 객체 내의 변수를 프로퍼티(property) 함수를 메소드(method)라고 부른다. 객체를 만들어보자. var person = {} person.name = 'egoing'; person.introduce = **function**(){ **return** 'My name is '+**this**.name; } document.write(person.introduce()); → My name is egoing 이런 형태로 코드를 작성하다 보면 중복이 발생할 수 있다. 그것을 막기 위해서 생성자를 사용해야 한다. =78번 영상=========================================== 생성자와 new : 생성자와 new 생성자(constructor)는 객체를 만드는 역할을 하는 함수다. 자바스크립트에서 함수는 재사용 가능한 로직의 묶음이 아니라 객체를 만드는 창조자라고 할 수 있다. 생성자는 new를 사용한다. function Person(){} var p = new Person(); p.name = 'egoing'; p.introduce = **function**(){ **return** 'My name is '+this.name; } document.write(p.introduce()); 자바스크립트에서 생성자는 소속이 없다. 생성자는 함수일 뿐이다. 자바스크립트에선 클래스라는 것이 없다. 다음은 생성자를 이용해 재사용성이 높은 코드를 작성한 것이다. function Person(name){ **this**.name = name; **this**.introduce = **function**(){ **return** 'My name is '+**this**.name; } } var p1 = **new** Person('egoing'); document.write(p1.introduce()+&quot;&lt;br /&gt;&quot;); var p2 = **new** Person('leezche'); document.write(p2.introduce()); 생성자 내에서 이 객체의 프로퍼티를 정의하고 있다. 이러한 작업을 초기화(initalize)라고 한다. 이를 통해서 코드의 재사용성이 대폭 높아졌다. 코드를 통해서 알 수 있듯이 생성자 함수는 일반함수와 구분하기 위해서 첫글자를 대문자로 표시한다. =79번 영상=========================================== 전역객체 https://opentutorials.org/module/532/6577 전역객체(Global object)는 특수한 객체다. 모든 객체는 이 전역객체의 프로퍼티다. window는 전역 객체이다. window.func()와 func()는 같은 명령이며 window는 생략하여 사용이 가능하다. 우리는 우리도 모르게 window를 사용하고 있었다. =80번 영상=========================================== this : 함수와 this https://opentutorials.org/module/532/6571 this는 함수 내에서 함수 호출 맥락(context)를 의미한다. 맥락이라는 것은 상황에 따라서 달라진다는 의미이다. 즉 함수를 어떻게 호출하느냐에 따라서 this가 가리키는 대상이 달라진다는 뜻이다. this는 전역객체인 window와 같다. function func(){ **if**(window === **this**){ document.write(&quot;window === this&quot;); } } func(); →&gt;&gt; window === this =81번 영상=========================================== this : 메소드와 this 객체의 소속인 메소드의 this는 그 객체를 가르킨다. var o = { func : **function**(){ **if**(o === **this**){ document.write(&quot;o === this&quot;); } } } o.func(); →&gt;&gt; o === this =82번 영상=========================================== this : 생성자와 this 아래 코드는 함수를 호출했을 때와 new를 이용해서 생성자를 호출했을 때의 차이를 보여준다. var funcThis = **null**; function Func(){ funcThis = **this**; } var o1 = Func(); **if**(funcThis === window){ document.write('window &lt;br /&gt;'); →&gt;&gt; window } var o2 = **new** Func(); **if**(funcThis === o2){ document.write('o2 &lt;br /&gt;'); →&gt;&gt; o2 } =83번 영상=========================================== this : 객체로서 함수 함수가 객체인 것에 대한 설명. =84번 영상=========================================== this : apply와 this 함수의 메소드인 apply, call을 이용하면 this의 값을 제어할 수 있다. var o = {} var p = {} function func(){ **switch**(**this**){ **case** o: document.write('o&lt;br /&gt;'); **break**; **case** p: document.write('p&lt;br /&gt;'); **break**; **case** window: document.write('window&lt;br /&gt;'); **break**; } } func(); →&gt;&gt; window func.apply(o); →&gt;&gt; o func.apply(p); →&gt;&gt; p =85번 영상=========================================== 상속 : 상속이란? https://opentutorials.org/module/532/6572 객체는 연관된 로직들로 이루어진 작은 프로그램이라고 할 수 있다. 상속은 객체의 로직을 그대로 물려 받는 또 다른 객체를 만들 수 있는 기능을 의미한다. 단순히 물려받는 것이라면 의미가 없을 것이다. 기존의 로직을 수정하고 변경해서 파생된 새로운 객체를 만들 수 있게 해준다. =86번 영상=========================================== 상속 : 상속의 사용방법 function Person(name){ // 생성자 **this**.name = name; } Person.prototype.name=**null**; Person.prototype.introduce = **function**(){ **return** 'My name is '+**this**.name; } function Programmer(name){ // 객체화 **this**.name = name; } Programmer.prototype = **new** Person(); // 상속 var p1 = **new** Programmer('egoing'); document.write(p1.introduce()+&quot;&lt;br /&gt;&quot;); // 상속으로 introduce 사용 가능 =87번 영상=========================================== 상속 : 기능의 추가 다음 코드에서 Programmer는 Person의 기능을 가지고 있으면서 Person이 가지고 있지 않은 기능인 메소드 coding을 가지고 있다. function Person(name){ **this**.name = name; } Person.prototype.name=**null**; Person.prototype.introduce = **function**(){ **return** 'My name is '+**this**.name; } function Programmer(name){ **this**.name = name; } Programmer.prototype = **new** Person(); Programmer.prototype.coding = **function**(){ **return** &quot;hello world&quot;; } var p1 = **new** Programmer('egoing'); document.write(p1.introduce()+&quot;&lt;br /&gt;&quot;); // my name is egoing document.write(p1.coding()+&quot;&lt;br /&gt;&quot;); // hello world =88번 영상=========================================== prototype : prototype이란? https://opentutorials.org/module/532/6573 prototype = 상속의 구체적인 수단이다. prototype은 말 그대로 객체의 원형이라고 할 수 있다. 함수는 객체다. 그러므로 생성자로 사용될 함수도 객체다. 객체는 프로퍼티를 가질 수 있는데 prototype이라는 프로퍼티는 그 용도가 약속되어 있는 특수한 프로퍼티다. prototype에 저장된 속성들은 생성자를 통해서 객체가 만들어질 때 그 객체에 연결된다. function Ultra(){} Ultra.prototype.ultraProp = **true**; function Super(){} Super.prototype = **new** Ultra(); function Sub(){} Sub.prototype = **new** Super(); var o = **new** Sub(); console.log(o.ultraProp); // true =89번 영상=========================================== prototype : prototype chain 위 코드에서 생성자 Sub를 통해서 만들어진 객체 o가 Ultra의 프로퍼티 ultraProp에 접근 가능한 것은 prototype 체인으로 Sub와 Ultra가 연결되어 있기 때문이다. 내부적으로는 아래와 같은 일이 일어난다. 객체 o에서 ultraProp를 찾는다. 없다면 Sub.prototype.ultraProp를 찾는다. 없다면 Super.prototype.ultraProp를 찾는다. 없다면 Ultra.prototype.ultraProp를 찾는다. prototype는 객체와 객체를 연결하는 체인의 역할을 하는 것이다. 이러한 관계를 prototype chain이라고 한다. =90번 영상=========================================== 표준 내장 객체의 확장 : 표준 내장 객체란? https://opentutorials.org/module/532/6475 표준 내장 객체(Standard Built-in Object)는 자바스크립트가 기본적으로 가지고 있는 객체들을 의미한다. 내장 객체가 중요한 이유는 프로그래밍을 하는데 기본적으로 필요한 도구들이기 때문에다. 자바스크립트는 아래와 같은 내장 객체를 가지고 있다. Object Function Array String Boolean Number Math Date RegExp =91번 영상=========================================== 표준 내장 객체의 확장 : 배열의 확장1 배열을 확장해보자. 아래 코드는 배열에서 특정한 값을 랜덤하게 추출하는 코드다. var arr = **new** Array('seoul','new york','ladarkh','pusan', 'Tsukuba'); function getRandomValueFromArray(haystack){ **var** index = Math.floor(haystack.length*Math.random());// 스택길이x난수 **return** haystack[index]; } console.log(getRandomValueFromArray(arr)); // 배열 중 랜덤으로 하나 출력 =92번 영상=========================================== 표준 내장 객체의 확장 : 배열의 확장2 prototype을 사용해 위와 같은 것을 구현. 가독성이 더 좋아졌다. Array.prototype.rand = **function**(){ **var** index = Math.floor(**this**.length*Math.random()); **return** **this**[index]; } var arr = **new** Array('seoul','new york','ladarkh','pusan', 'Tsukuba'); console.log(arr.rand()); // 배열 중 랜덤으로 하나 출력 =93번 영상=========================================== Object : Object란? https://opentutorials.org/module/532/6578 Object 객체는 객체의 가장 기본적인 형태를 가지고 있는 객체이다. 다시 말해서 아무것도 상속받지 않는 순수한 객체다. 자바스크립트에서는 값을 저장하는 기본적인 단위로 Object를 사용한다. **var**grades = {'egoing': 10, 'k8805': 6, 'sorialgi': 80}; 동시에 자바스크립트의 모든 객체는 Object 객체를 상속 받는데, 그런 이유로 모든 객체는 Object 객체의 프로퍼티를 가지고 있다. =94번 영상=========================================== Object : Object API object 객체의 메뉴얼 읽는 법. 다음 페이지에서 원하는 객체를 찾아 읽고 사용. https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference ex) 메뉴얼 예시 Object.key() 페이지. https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/keys Object.prototype.toString() 페이지 https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/toString p.s) specification 란에서 버전 확인 가능. 명시된 버전에서만 객체 사용 가능. =95번 영상=========================================== Object : Object 확장 object, prototype 으로 배열에 포함된 문자 찾기 기능 제작. Object.prototype.contain = **function**(neddle) {//needle:바늘찾기로 작명 **for**(**var** name **in** **this**){ **if**(**this**[name] === neddle){ **return** **true**; } } **return** **false**; } var o = {'name':'egoing', 'city':'seoul'} console.log(o.contain('egoing')); // true var a = ['egoing','leezche','grapittie']; console.log(a.contain('leezche')); // true =96번 영상=========================================== Object : Object 확장의 위험 위 코드와 같은 확장은 위험하다. 모든 코드에 영향을 주기 때믄이다. 따라서 해당사용법에는 주의를 기울여야 한다. **for**(var name **in** o){ console.log(name); } // name contain 객체가 기본적으로 가지고 있을 것으로 예상하고 있는 객체 외에 다른 객체를 가지고 있는 것은 개발자들에게 혼란을 준다. 이 문제를 회피하기 위해서는 프로퍼티의 해당 객체의 소속인지를 체크해볼 수 있는 hasOwnProperty를 사용하면 된다. **for**(**var** name **in** o){ **if**(o.hasOwnProperty(name)) console.log(name); } hasOwnProperty는 인자로 전달된 속성의 이름이 객체의 속성인지 여부를 판단한다. 만약 prototype으로 상속 받은 객체라면 false가 된다 . =97번 영상=========================================== 데이터 타입 : 원시 데이터 타입과 객체 https://opentutorials.org/module/532/6579 데이터 타입이란 데이터의 형태를 의미한다. 데이터 타입은 크게 두가지로 구분할 수 있다. 객체와 객체가 아닌 것. 객체 데이터 타입 vs 원시 데이터 타입(primitive) 객체가 아닌 것 = 원시 데이터 타입 숫자 문자열 불리언(true/false) null undefined =98번 영상=========================================== 데이터 타입 : 래퍼 객체 래퍼 객체. var str = 'coding'; console.log(str.length); // 6 console.log(str.charAt(0)); // &quot;C&quot; 문자열은 분명히 프로퍼티와 메소드가 있다. 그렇다면 객체다. 그런데 왜 문자열이 객체가 아니라고 할까? 그것은 내부적으로 문자열이 원시 데이터 타입이고 문자열과 관련된 어떤 작업을 하려고 할 때 자바스크립트는 임시로 문자열 객체를 만들고 사용이 끝나면 제거하기 때문이다. var str = 'coding'; str.prop = 'everybody'; console.log(str.prop); // undefined tr.prop를 하는 순간에 자바스크립트 내부적으로 String 객체가 만들어진다. prop 프로퍼티는 이 객체에 저장되고 이 객체는 곧 제거 된다. 그렇기 때문에 prop라는 속성이 저장된 객체는 존재하지 않게된다. 이러한 특징은 일반적인 객체의 동작 방법과는 다르다. 하지만 문자열과 관련해서 필요한 기능성을 객체지향적으로 제공해야 하는 필요 또한 있기 때문에 원시 데이터 형을 객체처럼 다룰 수 있도록 하기 위한 객체를 자바스크립트는 제공하고 있는데 그것이 레퍼객체(wrapper object)다. =99번 영상=========================================== 참조 : 복제란? https://opentutorials.org/module/532/6507 전자화된 시스템의 가장 중요한 특징은 복제다. 현실의 사물과 다르게 전자화된 시스템 위의 데이터를 복제 하는데는 비용이 거의 들지 않는다. 이 특징이 소프트웨어를 기존의 산업과 구분하는 가장 큰 특징일 것이다. 프로그래밍에서 복제가 무엇인가를 살펴보자. var a = 1; var b = a; b = 2; console.log(a); // 1 =100번 영상=========================================== 참조 : 참조 그런데 자연의 산물이 아니라 거대한 약속의 집합인 소프트웨어의 세계에서 당연한 것은 없다. 이것이 당연하지 않은 이유는 다음 예제를 통해서 좀 더 분명하게 드러난다. var a = {'id':1}; var b = a; b.id = 2; console.log(a.id); // 2 변수 b에 담긴 객체의 id 값을 2로 변경했을 뿐인데 a.id의 값도 2가 되었다. 이것은 변수 b와 변수 a에 담긴 객체가 서로 같다는 것을 의미하다. 이것은 참조(reference)로 인한 결과이다. 비유하자면 복제는 파일을 복사하는 것이고 참조는 심볼릭 링크(symbolic link) 혹은 바로가기(윈도우)를 만드는 것과 비슷하다. 원본 파일에 대해서 심볼릭 링크를 만들면 원본이 수정되면 심볼릭 링크에도 그 내용이 실시간으로 반영되는 것과 같은 효과다. 다시 말해서 원본을 복제한 것이 아니라 원본 파일을 참조(reference)하고 있는 것이다. 덕분에 저장 장치의 용량을 절약할 수 있고, 원본 파일을 사용하고 있는 모든 복제본이 동일한 내용을 유지할 수 있게 된다. a = 1; a = {'id':1}; 전자는 데이터형이 숫자이고 후자는 객체다. 숫자는 원시 데이터형(기본 데이터형, Primitive Data Types)이다. 자바스크립트에서는 원시 데이터형을 제외한 모든 데이터 타입은 객체이다. 객체를 다른 말로는 참조 데이터 형(참조 자료형)이라고도 부른다. 기본 데이터형은 위와 같이 복제 되지만 참조 데이터형은 참조된다. 모든 객체는 참조 데이터형이다. =101번 영상=========================================== 참조 : 함수와 참조 일종의 변수할당이라고 할 수 있는 메소드의 매개변수는 어떻게 동작하는가를 살펴보자. 다음은 원시 데이터 타입을 인자로 넘겼을 때의 동작 모습이다. var a = 1; function func(b){ b = 2; } func(a); console.log(a); // 1 다음은 참조 데이터 타입을 인자로 넘겼을 때 동작하는 장면이다. var a = {'id':1}; function func(b){ b = {'id':2}; } func(a); console.log(a.id); // 1 함수 func의 파라미터 b로 전달된 값은 객체 a이다. (b = a) b를 새로운 객체로 대체하는 것은 (b = {‘id’:2}) b가 가르키는 객체를 변경하는 것이기 때문에 객체 a에 영향을 주지 않는다. 하지만 다음은 다르다. var a = {'id':1}; function func(b){ b.id = 2; } func(a); console.log(a.id); // 2 파라미터 b는 객체 a의 레퍼런스다. 이 값의 속성을 바꾸면 그 속성이 소속된 객체를 대상으로 수정작업을 한 것이 되기 때문에 b의 변경은 a에도 영향을 미치게 된다. 시간나면 다음 영상을 참조하라. 코드와 오픈소스 : https://opentutorials.org/course/1189/6340 =102번 영상=========================================== 수업을 마치며. 1.코드는 양면테이프와 같다. 부품과 부품을 이어붙여 편의성을 도모할 수 있다. 하지만 이제는 테이프에서 벗어나 부품 그 자체에도 주의를 기울여야 한다. 2.문법을 많이 알아둬야 한다. 다른 사람의 코드를 이해하기 쉬워지고 실력향상에 도움이 된다. 3.가장 본질적인 언어 하나를 붙잡고 결과물을 만들어라. 본질적인 언어란 단순히 절차에 따라 사건이 일어나게 하는 것이다. 끝.","link":"/2022/03/21/java_Script/"},{"title":"pandas_tutorial_02","text":"라이브러리 불러오기 12import pandas as pdprint(pd.__version__) 1.3.5 구글 드라이브 연동 구글 드라이브 → colab notebook → 새 폴더 생성 : data → 슬랙에서 다운 받은 lemonade.csv 파일을 올린다 -&gt; 다음 코드를 실행 12from google.colab import drivedrive.mount('/content/drive') Mounted at /content/drive Mounted at ..drive 가 출력되었으므로 성공 현재 좌측에 폴더 그림 -&gt; drive -&gt; mydrive -&gt; Colab Notebooks -&gt; data -&gt; supermarket_sales.csv를 찾아서 우클릭 -&gt; 경로 복사 -&gt; 다음 코드에 붙여넣어 사용 123DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/data/supermarket_sales.csv'sales = pd.read_csv(DATA_PATH)sales .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Invoice ID Branch City Customer type Gender Product line Unit price Quantity Date Time Payment 0 750-67-8428 A Yangon Member Female Health and beauty 74.69 7 1/5/2019 13:08 Ewallet 1 226-31-3081 C Naypyitaw Normal Female Electronic accessories 15.28 5 3/8/2019 10:29 Cash 2 631-41-3108 A Yangon Normal Male Home and lifestyle 46.33 7 3/3/2019 13:23 Credit card 3 123-19-1176 A Yangon Member Male Health and beauty 58.22 8 1/27/2019 20:33 Ewallet 4 373-73-7910 A Yangon Normal Male Sports and travel 86.31 7 2/8/2019 10:37 Ewallet ... ... ... ... ... ... ... ... ... ... ... ... 995 233-67-5758 C Naypyitaw Normal Male Health and beauty 40.35 1 1/29/2019 13:46 Ewallet 996 303-96-2227 B Mandalay Normal Female Home and lifestyle 97.38 10 3/2/2019 17:16 Ewallet 997 727-02-1313 A Yangon Member Male Food and beverages 31.84 1 2/9/2019 13:22 Cash 998 347-56-2442 A Yangon Normal Male Home and lifestyle 65.82 1 2/22/2019 15:33 Cash 999 849-09-3807 A Yangon Member Female Fashion accessories 88.34 7 2/18/2019 13:28 Cash 1000 rows × 11 columns &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-8a1e46d8-83ea-49d2-a98d-cf274f10b34d button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-8a1e46d8-83ea-49d2-a98d-cf274f10b34d'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1sales.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1000 entries, 0 to 999 Data columns (total 11 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Invoice ID 1000 non-null object 1 Branch 1000 non-null object 2 City 1000 non-null object 3 Customer type 1000 non-null object 4 Gender 1000 non-null object 5 Product line 1000 non-null object 6 Unit price 1000 non-null float64 7 Quantity 1000 non-null int64 8 Date 1000 non-null object 9 Time 1000 non-null object 10 Payment 1000 non-null object dtypes: float64(1), int64(1), object(9) memory usage: 86.1+ KB Group by (동의어) 집계함수를 배운다. 12# 여러가지 시도해보면서 정보를 파악해보자sales['Invoice ID'].value_counts() 750-67-8428 1 642-61-4706 1 816-72-8853 1 491-38-3499 1 322-02-2271 1 .. 633-09-3463 1 374-17-3652 1 378-07-7001 1 433-75-6987 1 849-09-3807 1 Name: Invoice ID, Length: 1000, dtype: int64 12# 여러가지 시도해보면서 정보를 파악해보자sales.groupby('Customer type')['Quantity'].sum() Customer type Member 2785 Normal 2725 Name: Quantity, dtype: int64 1sales.groupby(['Customer type', 'Branch', 'Payment'])['Quantity'].sum() Customer type Branch Payment Member A Cash 308 Credit card 282 Ewallet 374 B Cash 284 Credit card 371 Ewallet 269 C Cash 293 Credit card 349 Ewallet 255 Normal A Cash 264 Credit card 298 Ewallet 333 B Cash 344 Credit card 228 Ewallet 324 C Cash 403 Credit card 194 Ewallet 337 Name: Quantity, dtype: int64 data type은 Series 이다. 1print(type(sales.groupby(['Customer type', 'Branch', 'Payment'])['Quantity'].sum())) &lt;class 'pandas.core.series.Series'&gt; 검색 키워드를 잘 선택하는게 중요하다. 1sales.groupby(['Customer type', 'Branch', 'Payment'])['Quantity'].agg(['sum', 'mean']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sum mean Customer type Branch Payment Member A Cash 308 5.500000 Credit card 282 5.755102 Ewallet 374 6.032258 B Cash 284 5.358491 Credit card 371 5.888889 Ewallet 269 5.489796 C Cash 293 4.966102 Credit card 349 5.816667 Ewallet 255 5.100000 Normal A Cash 264 4.888889 Credit card 298 5.418182 Ewallet 333 5.203125 B Cash 344 6.035088 Credit card 228 4.956522 Ewallet 324 5.062500 C Cash 403 6.200000 Credit card 194 5.105263 Ewallet 337 6.017857 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-9f19e00c-ea81-404c-b289-c9ddb325aeaa button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-9f19e00c-ea81-404c-b289-c9ddb325aeaa'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1print(type(sales.groupby(['Customer type', 'Branch', 'Payment'])['Quantity'].agg(['sum', 'mean']))) &lt;class 'pandas.core.frame.DataFrame'&gt; 1sales.groupby(['Customer type', 'Branch', 'Payment'], as_index=False)['Quantity'].agg(['sum', 'mean']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sum mean Customer type Branch Payment Member A Cash 308 5.500000 Credit card 282 5.755102 Ewallet 374 6.032258 B Cash 284 5.358491 Credit card 371 5.888889 Ewallet 269 5.489796 C Cash 293 4.966102 Credit card 349 5.816667 Ewallet 255 5.100000 Normal A Cash 264 4.888889 Credit card 298 5.418182 Ewallet 333 5.203125 B Cash 344 6.035088 Credit card 228 4.956522 Ewallet 324 5.062500 C Cash 403 6.200000 Credit card 194 5.105263 Ewallet 337 6.017857 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-f56f9b0d-43e2-4ba0-8abf-56fa96c5d20f button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-f56f9b0d-43e2-4ba0-8abf-56fa96c5d20f'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 결측치 다루기 결측치 데이터 생성 임의로 여러가지 생성해보자 (숙달 과정) 1234567891011import pandas as pdimport numpy as npdict_01 = { 'Score_A' : [80, 90, np.nan, 80], 'Score_B' : [30, 45, np.nan, np.nan], 'Score_C' : [np.nan, 50, 80, 90],}df = pd.DataFrame(dict_01)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_A Score_B Score_C 0 80.0 30.0 NaN 1 90.0 45.0 50.0 2 NaN NaN 80.0 3 80.0 NaN 90.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-6c9ddc3e-23cb-46c2-bcca-8e0adaab788b button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-6c9ddc3e-23cb-46c2-bcca-8e0adaab788b'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; True = 숫자 1로 인식 False = 숫자 0으로 인식 결측치 (Nan) 개수 세기 1df.isnull().sum() Score_A 1 Score_B 2 Score_C 1 dtype: int64 결측치를 다른 것으로 채우기 1df.fillna(&quot;0&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_A Score_B Score_C 0 80.0 30.0 0 1 90.0 45.0 50.0 2 0 0 80.0 3 80.0 0 90.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-ce166771-c2da-430d-aa22-8b7cac811d94 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-ce166771-c2da-430d-aa22-8b7cac811d94'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 12# 바로 윗칸의 데이터로 채우기df.fillna(method=&quot;pad&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_A Score_B Score_C 0 80.0 30.0 NaN 1 90.0 45.0 50.0 2 90.0 45.0 80.0 3 80.0 45.0 90.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-14c34a17-7745-4466-a779-62f00b5030de button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-14c34a17-7745-4466-a779-62f00b5030de'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1234567dict_01 = { &quot;성별&quot; : [&quot;남자&quot;, &quot;여자&quot;, np.nan, &quot;남자&quot;], &quot;Salary&quot; : [30, 45, 90, 70],}df = pd.DataFrame(dict_01)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 성별 Salary 0 남자 30 1 여자 45 2 NaN 90 3 남자 70 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-54d9e838-5824-4cb9-9f0f-8291411d9270 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-54d9e838-5824-4cb9-9f0f-8291411d9270'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1df['성별'].fillna(&quot;성별 없음&quot;) 0 남자 1 여자 2 성별 없음 3 남자 Name: 성별, dtype: object 결측치 –&gt; 문자열 타입이랑 / 숫자 타입이랑 접근 방법이 다름–&gt; 문자열(빈도 –&gt; 가장 많이 나타나는 문자열 넣어주기!, 최빈값)–&gt; 숫자열(평균, 최대, 최소, 중간, 기타 등등..) 123456789101112import pandas as pdimport numpy as npdict_01 = { 'Score_A' : [80, 90, np.nan, 80], 'Score_B' : [30, 45, np.nan, np.nan], 'Score_C' : [np.nan, 50, 80, 90], 'Score_D' : [50, 30, 80, 60],}df = pd.DataFrame(dict_01)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_A Score_B Score_C Score_D 0 80.0 30.0 NaN 50 1 90.0 45.0 50.0 30 2 NaN NaN 80.0 80 3 80.0 NaN 90.0 60 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-a1c2a0ad-c902-4c13-8d35-ae4931ac7c3d button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-a1c2a0ad-c902-4c13-8d35-ae4931ac7c3d'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 결측치가 있을 때 열을 지운다. axis = 1 -&gt; columns 1df.dropna(axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_D 0 50 1 30 2 80 3 60 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-a9658aae-24a1-43bd-a6fe-73b30c752e90 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-a9658aae-24a1-43bd-a6fe-73b30c752e90'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 결측치가 있을 때 행을 지운다. axis = 0 -&gt; index 1df.dropna(axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Score_A Score_B Score_C Score_D 1 90.0 45.0 50.0 30 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-1359a925-a759-4d30-9b57-10abcaf3af1a button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-1359a925-a759-4d30-9b57-10abcaf3af1a'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 이상치1sales .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Invoice ID Branch City Customer type Gender Product line Unit price Quantity Date Time Payment 0 750-67-8428 A Yangon Member Female Health and beauty 74.69 7 1/5/2019 13:08 Ewallet 1 226-31-3081 C Naypyitaw Normal Female Electronic accessories 15.28 5 3/8/2019 10:29 Cash 2 631-41-3108 A Yangon Normal Male Home and lifestyle 46.33 7 3/3/2019 13:23 Credit card 3 123-19-1176 A Yangon Member Male Health and beauty 58.22 8 1/27/2019 20:33 Ewallet 4 373-73-7910 A Yangon Normal Male Sports and travel 86.31 7 2/8/2019 10:37 Ewallet ... ... ... ... ... ... ... ... ... ... ... ... 995 233-67-5758 C Naypyitaw Normal Male Health and beauty 40.35 1 1/29/2019 13:46 Ewallet 996 303-96-2227 B Mandalay Normal Female Home and lifestyle 97.38 10 3/2/2019 17:16 Ewallet 997 727-02-1313 A Yangon Member Male Food and beverages 31.84 1 2/9/2019 13:22 Cash 998 347-56-2442 A Yangon Normal Male Home and lifestyle 65.82 1 2/22/2019 15:33 Cash 999 849-09-3807 A Yangon Member Female Fashion accessories 88.34 7 2/18/2019 13:28 Cash 1000 rows × 11 columns &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-04da7866-a736-4456-8d77-a7760df771c5 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-04da7866-a736-4456-8d77-a7760df771c5'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 일반적인 통계적 공식 IQR - 박스플롯 - 사분위수 Q0(0), Q1(25%), Q2(50%), Q3(75%), Q4(100%) 이상치의 하한 경계값 : Q1 - 1.5 * (Q3-Q1) 이상치의 상한 경계값 : Q3 + 1.5 * (Q3-Q1) 도메인 (각 비즈니스 영역, 미래 일자리) 에서 바라보는 이상치 기준 (관습) 1sales[['Unit price']]. describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unit price count 1000.000000 mean 55.672130 std 26.494628 min 10.080000 25% 32.875000 50% 55.230000 75% 77.935000 max 99.960000 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-6bdae016-4a2d-4f55-9e51-5f68e6af7217 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-6bdae016-4a2d-4f55-9e51-5f68e6af7217'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 이상치의 하한 경계값 : Q1 - 1.5 * (Q3-Q1) 이런 공식은 통계적으로 타당하지만 그 외에도 이상치인지 판단할 방법이 있다. 12345678Q1 = sales['Unit price'].quantile(0.25)Q3 = sales['Unit price'].quantile(0.75)# Q1보다 낮은 값을 이상치로 간주outliers_q1 = (sales['Unit price'] &lt; Q1)# Q1보다 높은 값을 이상치로 간주outliers_q3 = (sales['Unit price'] &gt; Q3) 이 코드는 특히 중요하다 1print(sales['Unit price'][~(outliers_q1 | outliers_q3)]) 0 74.69 2 46.33 3 58.22 6 68.84 7 73.56 ... 991 76.60 992 58.03 994 60.95 995 40.35 998 65.82 Name: Unit price, Length: 500, dtype: float64","link":"/2022/03/24/pandas_tutorial_02/"},{"title":"파이썬_기초문법_1","text":"Hello world1print(&quot;Hello, World&quot;) Hello, World 주석 처리 코드 작업 시, 특정 코드에 대해 설명 사용자 정의 함수 작성 시, 클래스 작성시.. (도움말 작성..) 123456# 한 줄 주석 처리'''여러 줄 주석 처리 시'''print( &quot;Hello, World!&quot;) Hello, World! 변수 (Scalar) 객체(Object)로 구현이 됨 하나의 자료형(Type)을 가진다. 클래스로 정의가 됨. 다양한 함수들이 존재 함. int init 정수를 표현하는데 사용함. 123456789#데이터 전처리..#데이터 전처리를 잘해야! 분석도 잘함. 예측 모형도 잘 만듬.#데이터 전처리를 잘하기 위해서는, 기초문법이 중요함.num_int = 1num_int2 = 3print(num_int)print(num_int2)print(type(num_int)) 1 3 &lt;class 'int'&gt; float 실수를 표현하는데 사용한다. 123num_float = 0.2print(num_float)print(type(num_float)) 0.2 &lt;class 'float'&gt; 12## bool- True와 False로 나타내는 Boolean 값을 표현하는데 사용한다. 123bool_true = Trueprint(bool_true)print(type(bool_true)) True &lt;class 'bool'&gt; None Null을 나타내는 자료형으로 None이라는 한 가지 값만 가집니다. 123none_x = Noneprint(none_x)print(type(none_x)) None &lt;class 'NoneType'&gt; 사칙연산 정수형 사칙 연산 123456789a = 10b = 5print('a + b = ', a+b)print('a - b = ', a-b)print('a * b = ', a*b)print('a / b = ', a/b)print('a // b = ', a//b)print('a % b = ', a%b)print('a ** b = ', a**b) a + b = 15 a - b = 5 a * b = 50 a / b = 2.0 a // b = 2 a % b = 0 a ** b = 100000 실수형 사칙연산123456789a = 10.0b = 5.0print('a + b = ', a+b)print('a - b = ', a-b)print('a * b = ', a*b)print('a / b = ', a/b)print('a // b = ', a//b)print('a % b = ', a%b)print('a ** b = ', a**b) a + b = 15.0 a - b = 5.0 a * b = 50.0 a / b = 2.0 a // b = 2.0 a % b = 0.0 a ** b = 100000.0 논리형 연산자 Bool 형은 True와 False 값으로 정의 AND / OR 123456789101112x = 5 &gt; 4 # Truey = 3 &gt; 4 # Falseprint(x and x)print(x and y)print(y and x)print(y and y)print(&quot;-----&quot;)print(x or x)print(x or y)print(y or x)print(y or y) 비교 연산자 부등호를 의미합니다. 비교 연산자를 True와 False값을 도출 논리 &amp; 비교 연산자 응용12var = input(&quot;입력해주세요....&quot;)print(type(var)) # 숫자를 입력해도 str로 판단 입력해주세요....1 &lt;class 'str'&gt; 형변환을 해준다. 문자열, 정수, 실수 등등등 12var = int(&quot;1&quot;) # 형변환print(type(var)) &lt;class 'int'&gt; 12var = int(input(&quot;숫자를 입력하여 주세요 : &quot;)) # 형변환print(type(var)) 숫자를 입력하여 주세요 : 1 &lt;class 'int'&gt; 123456789num1 = int(input(&quot;숫자를 입력하여 주세요... : &quot;)) # 10num2 = int(input(&quot;숫자를 입력하여 주세요... : &quot;)) # 3num3 = int(input(&quot;숫자를 입력하여 주세요... : &quot;)) # 5num4 = int(input(&quot;숫자를 입력하여 주세요... : &quot;)) # 7var1 = num1 &gt;= num2 # Truevar2 = num3 &lt; num4 # Trueprint(var1 and var2)print(var1 or var2) 숫자를 입력하여 주세요... : 10 숫자를 입력하여 주세요... : 3 숫자를 입력하여 주세요... : 5 숫자를 입력하여 주세요... : 7 True True 변수 ( Non Scalar) 문자열을 입력 12print(&quot;'Hello, world'&quot;)print('&quot;Hello, world&quot;') 'Hello, world' &quot;Hello, world&quot; String 연산자 덧셈 연산자를 써보자. 1234str1 = &quot;Hello &quot;str2 = &quot;World! &quot;str3 = &quot;\\n&quot;print(str1 + str2) Hello World! 곱셈 연산자를 사용해본다. 12greeting = str1 + str2 + str3print(greeting * 3) Hello World! Hello World! Hello World! indexing 문자열 인덱싱은 각각의 문자열 안에서 범위를 지정하여 특정 문자를 추출한다. 12greeting = &quot;Hello kaggle!&quot;print(greeting[6]) k 슬라이싱 범위를 지정하고 데이터를 가져온다. 1234567greetingprint(greeting[:]) print(greeting[6:]) print(greeting[:6]) # 시작 인덱스 ~ 끝 인덱스-1 만큼 출력하므로 Helloprint(greeting[3:9])print(greeting[0:9:2]) # 3번째 index는 몇번 건너띄는 것인지 표시 Hello kaggle! kaggle! Hello lo kag Hlokg 리스트 시퀀스 데이터 타입 데이터에 순서가 존재하냐! 슬라이실이 가능해야 함. 대관호 ([‘값1’, ‘값2’, ‘값3’]) 1234567891011a = [] # 빈 리스트a_func = list() # 빈 리스트 생성b = [1] # 숫자가 요소가 될 수 있다.c = ['apple'] # 문자열도 요소가 될 수 있다.d = [1, 2, ['apple']] # 리스트 안에 또 다른 리스트 요소를 넣을 수 있다.print(a)print(a_func)print(b)print(c)print(d) [] [] [1] ['apple'] [1, 2, ['apple']] 리스트 슬라이싱1234567a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]# print(a)print(a[0])print(a[6:])print(a[:5])print(a[3:5])print(a[1:9:2]) 1 [7, 8, 9, 10] [1, 2, 3, 4, 5] [4, 5] [2, 4, 6, 8] 123456a = [[&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;], 1]print(a[0])print(a[0][2])print(a[0][0][4])print(a[0][0][-1])print(a[0][2][2]) ['apple', 'banana', 'cherry'] cherry e e e 123a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]print(a[::-1]) # 역순print(a[::2]) [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] [1, 3, 5, 7, 9] 123456## 리스트 연산자a = [&quot;john&quot;, &quot;evan&quot;]b = [&quot;alice&quot;, &quot;eva&quot;]c = a + bprint(c) ['john', 'evan', 'alice', 'eva'] 1234c = a * 3d = b * 0print(&quot;a * 3 = &quot;, c)print(&quot;b * 0 = &quot;, d) a * 3 = ['john', 'evan', 'john', 'evan', 'john', 'evan'] b * 0 = [] 리스트 수정 및 삭제123a = [0, 1, 2]a[1] = &quot;b&quot;print(a) [0, 'b', 2] 리스트 값 추가하기123456789a = [100, 200, 300]a.append(400)print(a)a.append([500, 600])print(a) a.extend([500, 600]) # extend는 []없이 추가한다.print(a) [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] [100, 200, 300, 400, [500, 600], 500, 600] 1234a = [0, 1, 2]# a.insert(인덱스번호, 넣고자하는 값)a.insert(1,100)print(a) [0, 100, 1, 2] 리스트 값 삭제하기12345a = [4, 3, 2, 1, &quot;A&quot;]a.remove(1) # 리스트 안에 있는 값을 삭제print(a)a.remove(&quot;A&quot;)print(a) [4, 3, 2, 'A'] [4, 3, 2] 1234567a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]del a[1] # 인덱스 번호print(a)del a[1:5]print(a) [1, 3, 4, 5, 6, 7, 8, 9, 10] [1, 7, 8, 9, 10] 1234b = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]x = b.pop() # 맨 끝자리 하나를 가져온다.print(x)print(b) d ['a', 'b', 'c'] 그 외 메서드12345a = [0, 1, 2, 3]print(a)a.clear()print(a) [0, 1, 2, 3] [] 123a = [&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;]print(a.index(&quot;a&quot;)) # 해당 문자가 여럿 있을 경우, 처음 하나만 출력print(a.index(&quot;b&quot;)) 0 2 123456789a = [1, 4, 5, 2, 3]b = [1, 4, 5, 2, 3]a.sort()print(&quot;sort() : &quot;, a)# 내림차순 b.sort(reverse=True)print(&quot;sort(reverse=True) : &quot;, b) sort() : [1, 2, 3, 4, 5] sort(reverse=True) : [5, 4, 3, 2, 1] 튜플 List와 비슷하다. 슬라이싱, 인덱싱 등등 (vs 리스트) : 튜플은 수정 삭제가 안된다. 123456tuple1 = (0) # 끝에 코마(,)를 붙이지 않을 때tuple2 = (0, ) # 끝에 코마 붙일 때tuple3 = 0, 1, 2print(type(tuple1))print(type(tuple2))print(type(tuple3)) &lt;class 'int'&gt; &lt;class 'tuple'&gt; &lt;class 'tuple'&gt; 12345678a = (0, 1, 2, 3, 'a')print(type(a))print(a)b[1]=&quot;b&quot;a= tuple(b)print(a) &lt;class 'tuple'&gt; (0, 1, 2, 3, 'a') (5, 'b', 3, 2, 1) 튜플 인덱싱 및 슬라이싱 하기1234a = (0, 1, 2, 3, 'a')print(a[1])print(a[2])print(a[4]) 1 2 a 더하기 곱셈 연산자 사용123456t1 = (1, 2, 3)t2 = (4, 5, 6)print(t1 + t2)print(t1 * 3)print(t1 * 0) (1, 2, 3, 4, 5, 6) (1, 2, 3, 1, 2, 3, 1, 2, 3) () 딕셔너리 key &amp; value 값으로 나뉨. 12345678dict_01 = {'teacher' : 'evan', 'class' : 601, 'students' : 24, '학생이름' : ['A', 'Z']}dict_01print(dict_01['teacher'])print(dict_01['class'])print(dict_01['학생이름']) evan 601 ['A', 'Z'] 123print(dict_01.keys())print(list(dict_01.keys())) dict_keys(['teacher', 'class', 'students', '학생이름']) ['teacher', 'class', 'students', '학생이름'] 1print(dict_01.values()) dict_values(['evan', 601, 24, ['A', 'Z']]) 1dict_01.items() dict_items([('teacher', 'evan'), ('class', 601), ('students', 24), ('학생이름', ['A', 'Z'])]) 1234print(dict_01.get(&quot;teacher&quot;)) # get 메소드print(dict_01.get(&quot;선생님&quot;, &quot;값 없음&quot;))print(dict_01.get(&quot;class&quot;))print(dict_01.get(&quot;students&quot;)) evan 값 없음 601 24 조건문 &amp; 반복분 일상에서 조건문 언제쓸까요? 1234567# 날씨가 맑다 --&gt; 우산을 안 책겨간다# 날씨가 흐리다 -&gt; 우산을 챙긴다weather = &quot;맑음&quot;if weather == &quot;비&quot;: print(&quot;우산을 가져간다&quot;)else : print(&quot;우산을 가져가지 않는다&quot;) 우산을 가져가지 않는다 123456789# 등급표 만들기# 60점 이상 합격 / 불합격# 숫자는 아무거나 써도 상관없음grade = 70if grade &gt; 60 : print(&quot;합격입니다.&quot;)else : print(&quot;불합격입니다.&quot;) 합격입니다. 12345grade = int(input(&quot;숫자를 입력하여 주세요... : &quot;))if grade &gt; 60 : print(&quot;합격입니다.&quot;)else : print(&quot;불합격입니다.&quot;) 숫자를 입력하여 주세요... : 10 불합격입니다. 12345678910# 90점 이상은 A등급# 80점 이상은 B등급# 나머지는 F등급grade = int(input(&quot;숫자를 입력하여 주세요... : &quot;))if grade &gt;= 90 : print(&quot;A 등급입니다.&quot;)elif grade &gt;= 80 : print(&quot;B 등급입니다.&quot;)else : print(&quot;F 등급입니다.&quot;) 숫자를 입력하여 주세요... : 85 B 등급입니다. 반복문for문123# 안녕하세요! 5번 반복하라for i in range(5) : print(i+1, &quot;안녕하세요&quot;) 1 안녕하세요 2 안녕하세요 3 안녕하세요 4 안녕하세요 5 안녕하세요 12345678910count = range(5)print(count)for n in count: print(str(n+1) + &quot;번째&quot;) if(n+1) == 3: print(&quot;그만합니다&quot;) break print(&quot;축구 슈팅&quot;) range(0, 5) 1번째 축구 슈팅 2번째 축구 슈팅 3번째 그만합니다 123456a = &quot;hello&quot;for x in a : if x in a : if x == &quot;l&quot; : break print(x) h e while문반복해서 문장을 수행해야 할 경우 while문을 사용한다. 1234567#열 번 찍어 안 넘어가는 나무 없다&quot;treehit = 0while treehit &lt; 10: treehit = treehit + 1 print(&quot;나무를 %d번 찍었습니다.&quot; % treehit) if treehit == 10: print(&quot;나무가 넘어갑니다.&quot;) 나무를 1번 찍었습니다. 나무를 2번 찍었습니다. 나무를 3번 찍었습니다. 나무를 4번 찍었습니다. 나무를 5번 찍었습니다. 나무를 6번 찍었습니다. 나무를 7번 찍었습니다. 나무를 8번 찍었습니다. 나무를 9번 찍었습니다. 나무를 10번 찍었습니다. 나무 넘어갑니다. 1234567# while문 만들기prompt = &quot;&quot;&quot;1.Add2.Del3.List4.QuitEnter number: &quot;&quot;&quot; 1234number = 0while number != 4: print(prompt) number = int(input()) 1.Add 2.Del 3.List 4.Quit Enter number: 4 12345678910# 커피 자판기 이야기coffee = 10money = 300while money : print(&quot;돈을 받았으니 커피를 줍니다.&quot;) coffee = coffee - 1 print(&quot;남은 커피의 양은 %d개입니다.&quot; % coffee) if coffee == 0: print(&quot;커피가 다 떨어졌습니다. 판매를 중지합니다.&quot;) break while문의 맨 처음으로 돌아가기 (continue)123456a = 0while a &lt; 10 : a = a + 1 if a % 2 == 0 : continue print(a) 1 3 5 7 9 무한 루프12while True : print(&quot;Ctrl+C를 눌러야 while문을 빠져나갈 수 있습니다.&quot;) 문자열 포매팅 문자열 안의 특정한 값을 바꿔야 할 경우가 있을 때 이것을 가능하게 해주는 것이 바로 문자열 포매팅 기법이다. 숫자는 %d, 문자는 %s 12# 숫자 바로 대입 &quot;I eat %d apple.&quot; % 3 'I eat 3 apple.' 12# 문자열 바로 대입&quot;I eat %s apples.&quot; % &quot;five&quot; 'I eat five apples.' 123# 숫자 값을 나타내는 변수로 대입number = 3&quot;I eat %d apples.&quot; % number 'I eat 3 apples.' 1234# 2개 이상의 값 넣기number = 10day = &quot;three&quot;&quot;I ate %d apples. so I was sick for %s day&quot; % (number, day) 'I ate 10 apples. so I was sick for three day' 12&quot;I have %s apples&quot; % 3&quot;rate is %s &quot; % 3.234 'rate is 3.234 ' format 함수를 사용한 포매팅 문자열의 format 함수를 사용하면 좀 더 발전된 스타일로 문자열 포맷을 지정할 수 있다. 12# 숫자 바로 대입하기&quot;I eat {0} apples&quot;.format(3) 'I eat 3 apples' 12# 문자 바로 대입하기&quot;I eat {0} apples&quot;.format(&quot;five&quot;) 'I eat five apples' 123# 숫자 값을 가진 변수로 대입하기number = 3&quot;I eat {0} apples&quot;.format(number) 'I eat 3 apples' 1234# 2개 이상의 값 넣기number = 10day = &quot;three&quot;&quot;I ate {0} apples. so I was sick for {1} days. &quot;.format(number, day) 'I ate 10 apples. so I was sick for three days. ' 12# 이름으로 넣기&quot;I ate {number} apples. so I was sick for {day} days.&quot;.format(number=10, day=3) 'I ate 10 apples. so I was sick for 3 days.' 12# 인덱스와 이름을 혼용해서 넣기&quot;I ate {0} apples. so I was sick for {day} days.&quot;.format(10, day=3) 'I ate 10 apples. so I was sick for 3 days.' 12# 왼쪽 정렬&quot;{0:&lt;10}&quot;.format(&quot;hi&quot;) # 왼쪽으로 정렬하고 총 자릿수를 10으로 설정. 'hi ' 12# 오른쪽 정렬&quot;{0:&gt;10}&quot;.format(&quot;hi&quot;) # 오른쪽으로 정렬하고 총 자릿수를 10으로 설정. ' hi' 12# 가운데 정렬&quot;{0:^10}&quot;.format(&quot;hi&quot;) ' hi ' 123# 공백 채우기&quot;{0:=^10}&quot;.format(&quot;hi&quot;)&quot;{0:!&lt;10}&quot;.format(&quot;hi&quot;) 'hi!!!!!!!!' 123# 소수점 표현하기y = 3.42134234&quot;{0:0.4f}&quot;.format(y) # 소수점을 4자리까지만 표현 '3.4213' 12# 정렬과 소수점 표현 &quot;{0:10.4f}&quot;.format(y) ' 3.4213' 12# { 또는 } 문자 표현하기&quot;{{ and }}&quot;.format() '{ and }' f 문자열 포매팅 파이썬 3.6 버전부터는 f 문자열 포매팅 기능을 사용할 수 있다. f 문자열 포매팅은 표현식을 지원한다. 표현식이란 문자열 안에서 변수와 +, -와 같은 수식을 함께 사용하는 것을 말한다. 123name = '홍길동'age = 30f'나의 이름은 {name}입니다. 나이는 {age}입니다.' '나의 이름은 홍길동입니다. 나이는 30입니다.' 12age = 30f'나는 내년이면 {age+1}살이 된다.' '나는 내년이면 31살이 된다.' 123# f 문자열 포매팅에서의 딕셔너리d = {'name':'홍길동', 'age':30}f'나의 이름은 {d[&quot;name&quot;]}입니다. 나이는 {d[&quot;age&quot;]}입니다.' '나의 이름은 홍길동입니다. 나이는 30입니다.' 1234# f 문자열에서 정렬f'{&quot;hi&quot;:&lt;10}'f'{&quot;hi&quot;:&gt;10}'f'{&quot;hi&quot;:^10}' ' hi ' 123# f 문자열에서 공백채우기f'{&quot;hi&quot;:=^10}'f'{&quot;hi&quot;:!&lt;10}' 'hi!!!!!!!!' 1234# f 문자열에서 소수점표현y = 3.42134234f'{y:0.4f}'f'{y:10.4f}' ' 3.4213' 12# f 문자열에서 { } 문자를 표시f'{{ and }}' '{ and }' 문자열 관련 함수들 문자열 자료형은 자체적으로 함수를 가지고 있다. 이들 함수를 다른 말로 문자열 내장 함수라 한다. 이 내장 함수를 사용하려면 문자열 변수 이름 뒤에 ‘.’를 붙인 다음에 함수 이름을 써주면 된다. 123# 문자 개수 세기 (count)a = &quot;hobby&quot;a.count('b') 2 1234# 위치 알려주기1 (find)a = &quot;Python is the best choice&quot;a.find('b')a.find('k') # 찾는 문자가 없다면 -1을 반환. -1 123# 위치 알려주기2 (index)a = &quot;Life is too short&quot;a.index('t') 8 문자열 삽입(join)1&quot;,&quot;.join('abcd') 'a,b,c,d' 123# 대문자를 소문자로 바꾸기a = &quot;HI&quot;a.lower() 'hi' 123# 왼쪽 공백 지우기a = &quot; hi &quot;a.lstrip() 'hi ' 123# 오른쪽 공백 지우기(rstrip)a = &quot; hi &quot;a.rstrip() ' hi' 123# 양쪽 공백 지우기(strip)a = &quot; hi &quot;a.strip() 'hi' 문자열 바꾸기(replace)12a = &quot;Life is too short&quot;a.replace(&quot;Life&quot;, &quot;your leg&quot;) 'your leg is too short' 문자열 나누기(split)12345a = &quot;Life is too short&quot;a.split()b = &quot;a:b:c:d&quot;b.split(':') ['a', 'b', 'c', 'd'] 1# 2장 연습문제 파이썬 프로그래밍의 기초, 자료형 123456789# Q1 홍길동 씨의 과목별 점수는 다음과 같다. 홍길동 씨의 평균 점수를 구해 보자.from IPython.core.display import Mathkor = 80en = 75math = 55mean = (kor + en + math) / 3print(mean) 70.0 1234567# Q2 자연수 13이 홀수인지 짝수인지 판별할 수 있는 방법에 대해 말해 보자..from IPython.core.display import Mathif 13 % 2 == 1 : print(&quot;13은 홀수이다&quot;)else : print(&quot;13은 짝수이다&quot;) 13은 홀수이다 12345678# Q3 자연수 13이 홀수인지 짝수인지 판별할 수 있는 방법에 대해 말해 보자..num = &quot;881120-1068234&quot;num1 = num[:6]num2 = num[7:]print(num1) print(num2) 881120 1068234 1234#Q4 주민등록번호에서 성별을 나타내는 숫자를 출력해 보자.pin = &quot;881120-1068234&quot;print(pin[7]) 1 123456#Q5 다음과 같은 문자열 a:b:c:d가 있다.# 문자열의 replace 함수를 사용하여 a#b#c#d로 바꿔서 출력해 보자.a = &quot;a:b:c:d&quot;a.replace(&quot;:&quot;, &quot;#&quot;)print(a) a:b:c:d 1234#Q6 [1, 3, 5, 4, 2] 리스트를 [5, 4, 3, 2, 1]로 만들어 보자.a = [1,3,5,4,2]a.sort(reverse=True)print(a) [5, 4, 3, 2, 1] 1234#Q7 ['Life', 'is', 'too', 'short'] 리스트를 Life is too short 문자열로 만들어 출력해 보자.a = ['Life', 'is', 'too', 'short']print(a[0] + &quot; &quot; + a[1] + &quot; &quot; + a[2] + &quot; &quot; + a[3]) Life is too short 12345#Q8 (1,2,3) 튜플에 값 4를 추가하여 (1,2,3,4)를 만들어 출력해 보자.t1 = (1, 2, 3)t2 = (4, )t1 + t2 (1, 2, 3, 4) Q9 다음과 같은 딕셔너리 a가 있다. a = dict()a{}다음 중 오류가 발생하는 경우를 고르고, 그 이유를 설명해 보자.1.a[‘name’] = ‘python’2.a[(‘a’,)] = ‘python’3.a[[1]] = ‘python’4.a[250] = ‘python’ 123456789#Q9 1번과 3번에서 오류가 발생합니다.# 1번은 invalid syntax 오류# 3번은 unhashable type: 'list' 오류a = dict()a# a['name' = 'python']a[('a',)] = 'python'# a[[1]] = 'python'a[250] = 'python' 12345#Q10 딕셔너리 a에서 'B'에 해당되는 값을 추출해 보자.dict_00 = {'A':90, 'B':80, 'C':70}d = dict_00.pop('B')print(dict_00)print(d) {'A': 90, 'C': 70} 80 123456#Q11 a 리스트에서 중복 숫자를 제거해 보자.# 다시 풀어보자a = [1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5]aset = set(a)b = list(aset)print(b) [1, 2, 3, 4, 5] Q12 파이썬은 다음처럼 동일한 값에 여러 개의 변수를 선언할 수 있다. 다음과 같이 a, b 변수를 선언한 후 a의 두 번째 요솟값을 변경하면 b 값은 어떻게 될까? 그리고 이런 결과가 오는 이유에 대해 설명해 보자.a = b = [1, 2, 3]a[1] = 4print(b) 12345#Q12 a = b = [1,2,3]a[1] = 4print(b)# a=b 라고 설정했기 때문에 다음 결과가 나옵니다. [1, 4, 3] 3장 연습문제12345678#Q1 다음 코드의 결괏값은?a = &quot;Life is too short, you need python&quot;if &quot;wife&quot; in a : print(&quot;wife&quot;)elif &quot;python&quot; in a and &quot;you&quot; not in a : print(&quot;python&quot;)elif &quot;shirt&quot; not in a : print(&quot;shirt&quot;)elif &quot;need&quot; in a : print(&quot;need&quot;)else: print(&quot;none&quot;) shirt 123456789#Q2 while문을 사용해 1부터 1000까지의 자연수 중 3의 배수의 합을 구해 보자.count = 1sum = 0while count &lt; 1000 : count = count + 1 if count % 3 == 0 : sum = sum + countprint(sum) 166833 12345#Q3 while문을 사용하여 다음과 같이 별(*)을 표시하는 프로그램을 작성해 보자.count = 0while count &lt; 5: count = count + 1 print(&quot;*&quot; * count) * ** *** **** ***** 123#Q4 for문을 사용해 1부터 100까지의 숫자를 출력해 보자.for num in range(100): print(num+1) 12345678910#Q5 A 학급에 총 10명의 학생이 있다. 이 학생들의 중간고사 점수는 다음과 같다.#[70, 60, 55, 75, 95, 90, 80, 80, 85, 100]#for문을 사용하여 A 학급의 평균 점수를 구해 보자.sum = 0a_class = [70, 60, 55, 75, 95, 90, 80, 80, 85, 100]for num in a_class : sum = sum + nummean = sum / len(a_class)print(mean) 79.0 12345678910111213#Q6 리스트 중에서 홀수에만 2를 곱하여 저장하는 다음 코드가 있다. numbers = [1, 2, 3, 4, 5]result = []for n in numbers: if n % 2 == 1: result.append(n*2) # 위 코드를 리스트 내포(list comprehension)를 사용하여 표현해 보자.# 다시 풀어보자numbers = [1, 2, 3, 4, 5]result = [n*2 for n in numbers if n%2==1]print(result) [2, 6, 10]","link":"/2022/03/22/python_01/"},{"title":"파이썬_기초문법_2","text":"기초 문법 리뷰1234567891011# 리스트book_list = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;]# append, extend, insert, remove, pop, etc# 튜플book_tuple = (&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)# 수정 삭제가 불가능하다# 딕셔너리book_dictionary = {&quot;책 제목&quot; : [&quot;A&quot;, &quot;B&quot;], &quot;출판년도&quot; : [2011, 2002]}# keys(), values(), items(), get() 조건문 &amp; 반복문123456if True: print(&quot;코드 실행&quot;)elif True: print(&quot;코드 실행&quot;)else: print(&quot;코드 실행&quot;) 12for idx in range(3): print(idx+1, &quot;안녕하세요&quot;) 1 안녕하세요 2 안녕하세요 3 안녕하세요 123book_list = [&quot;프로그래밍 R&quot;, &quot;혼자 공부하는 머신러닝&quot;]for book in book_list: print(book) 프로그래밍 R 혼자 공부하는 머신러닝 123strings01 = &quot;Hello world&quot;for char in strings01: print(char) 123num_tuple = (1, 2, 3, 4)for num in num_tuple: print(num) 1 2 3 4 1234num_dict = {&quot;A&quot; : 1, &quot;B&quot; : 2}for num in num_dict: print(num) print(num_dict[num]) A 1 B 2 반복문의 필요성123456789101112131415161718product_name = [&quot;요구르트&quot;, &quot;우유&quot;, &quot;과자&quot;]prices = [1000, 1500, 2000]quantities = [5, 3, 4]name = product_name[0]sales = prices[0] * quantities[0]print(name + &quot;의 매출액은 &quot; + str(sales) + &quot;원이다.&quot;)name = product_name[1]sales = prices[1] * quantities[1]print(name + &quot;의 매출액은 &quot; + str(sales) + &quot;원이다.&quot;)# 위 코드의 반복문 코드 작성 필요 절감for num in range(len(product_name)): name = product_name[num] sales = prices[num] * quantities[num] print(name + &quot;의 매출액은 &quot; + str(sales) + &quot;원이다.&quot;) 요구르트의 매출액은 5000원이다. 우유의 매출액은 4500원이다. 요구르트의 매출액은 5000원이다. 우유의 매출액은 4500원이다. 과자의 매출액은 8000원이다. while 조건식이 들어간 반복문(vs for-loop 범위!!!) 123456count = 1while count &lt; 5: count = count + 1 print(&quot;안녕하세요..&quot;)print(&quot;5 초과했군요..&quot;) 안녕하세요.. 안녕하세요.. 안녕하세요.. 안녕하세요.. 5 초과했군요.. 1234567count = 3while count &gt; 0: print(&quot;안녕하세요..&quot;) count = count - 1 print(count)print(&quot;0 미만이군요..&quot;) 안녕하세요.. 2 안녕하세요.. 1 안녕하세요.. 0 0 미만이군요.. 개발자를 지향한다! while 공부 좀 더 비중 있게 다루는 걸 추천 데이터 분석 for-loop 공부를 좀 더 비중있게 하는 것 추천 사용자 정의 함수 (User-Defined Function) why? 클래스(Class)를 왜 쓸까? 코드의 반복성을 줄이기 위해서 사용! len() –&gt; 누군가가 만들었고, 우리는 그걸 그냥 쓰는 것 리스트의 길이 구할 때 사용 리스트 전체 길이를 구하겠다!? –&gt; 1회성? 나만 쓰는가? no 12345def 함수명(): #코드 실행 return 값함수명() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768def add(a, b): &quot;&quot;&quot;정수 2개를 입력받아 더하는 함수입니다. Args: a(int) : 계산할 정수 b(int) : 계산할 정수 c(int) : 계산 결과 Returns: int &quot;&quot;&quot; c = a + b return cadd(1,2)def minus(a,b): &quot;&quot;&quot;정수 2개를 입력받아 빼는 함수입니다. Args: a(int) : 계산할 정수 b(int) : 계산할 정수 c(int) : 계산 결과 Returns: int &quot;&quot;&quot; c = a - b return cminus(10, 5)def multiple(a,b): &quot;&quot;&quot;정수 2개를 입력받아 곱하는 함수입니다. Args: a(int) : 계산할 정수 b(int) : 계산할 정수 c(int) : 계산 결과 Returns: int &quot;&quot;&quot; c = a * b return cmultiple(10,5)def divide(a,b): &quot;&quot;&quot;정수 2개를 입력받아 나누는 함수입니다. Args: a(int) : 계산할 정수 b(int) : 계산할 정수 c(float) : 계산 결과 Returns: float &quot;&quot;&quot; c = a / b return cdivide(10,5)if __name__ == &quot;__main__&quot;: print(&quot;add(10,5) = &quot;, add(10,5) ) print(&quot;minus(10,5) = &quot;, minus(10,5) ) print(&quot;multiple(10,5) = &quot;, multiple(10,5) ) print(&quot;divide(10,5) = &quot;, divide(10,5) ) add(10,5) = 15 minus(10,5) = 5 multiple(10,5) = 50 divide(10,5) = 2.0 123456789101112131415def minus(a,b): &quot;&quot;&quot;정수 2개를 입력받아 빼는 함수입니다. Args: a(int) : 계산할 정수 b(int) : 계산할 정수 c(int) : 계산 결과 Returns: int &quot;&quot;&quot; c = a - b return cminus(10, 5) jupyter notebook, ipynb 파일명 .py로 저장(PyCharm..) 1!which pyhon basic.py로 저장할 때, 예시 12345678910111213141516171819202122# /usr/local/bin/python# -*- coding: utf-8 -*- def temp(content, letter): &quot;&quot;&quot;content 안에 있는 문자를 세는 함수입니다. Args: content(str) : 탐색 문자열 letter(str) : 찾을 문자열 Returns: int &quot;&quot;&quot; print(&quot;함수 테스트&quot;) cnt = len([char for char in content if char == letter]) return cntif __name__ == &quot;__main__&quot;: help(temp) docstring = temp.__doc__ print(docstring) Help on function temp in module __main__: temp(content, letter) content 안에 있는 문자를 세는 함수입니다. Args: content(str) : 탐색 문자열 letter(str) : 찾을 문자열 Returns: int content 안에 있는 문자를 세는 함수입니다. Args: content(str) : 탐색 문자열 letter(str) : 찾을 문자열 Returns: int help() 위 코드에서 help()는 본인이 작성한 주석을 바탕으로 문서화한다. 리스트 컴프리헨션 for-loop 반복문을 한 줄로 처리 리스트 안에 반복문을 작성할 수 있다 12345678910111213my_list = [[10], [20,30]]print(my_list)flattened_list = []for value_list in my_list: print(value_list) for value in value_list: print(value) flattened_list.append(value)print(flattened_list)# 결괏값 : return[10 ,20, 30] [[10], [20, 30]] [10] 10 [20, 30] 20 30 [10, 20, 30] 123my_list = [[10], [20, 30]]flattened_list = [value for value_list in my_list for value in value_list] # 리스트 컴프리헨션print(flattened_list) [10, 20, 30] 1234letters = []for char in &quot;helloworld&quot;: letters.append(char)print(letters) ['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd'] 12letters2 = [char for char in &quot;helloworld&quot;] # 리스트 컴프리헨션print(letters) ['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd'] 123456789value_list = [1, 2, 3, 4, 5, 6]print(&quot;avg: &quot;, sum(value_list) / len(value_list))# 중간값midpoint = int(len(value_list) / 2)#len(value_list) % 2 == 0;print((value_list[midpoint -1 ] + value_list[midpoint]) / 2)print(value_list[midpoint]) avg: 3.5 3.5 4 1234567891011121314151617181920212223242526# 사용자 정의함수의 문서화def mean_and_median(value_list): &quot;&quot;&quot; 숫자 리스트의 요소들의 평균과 중간값을 구하는 코드를 작성해라 Args: value_list (iterable of int / float) : A list of int numbers Returns: tuple(float, float) &quot;&quot;&quot; #평균 mean = sum(value_list) / len(value_list) #중간값 midpoint = int(len(value_list) / 2) if len(value_list) % 2 == 0: median = (value_list[midpoint - 1] + value_list[midpoint]) / 2 else: median = value_list[midpoint] return mean, medianif __name__ == &quot;__main__&quot;: value_list = [1, 1, 2, 2, 3, 4, 5] avg, median = mean_and_median(value_list) print(&quot;avg : &quot;, avg) print(&quot;median&quot;, median) avg : 2.5714285714285716 median 2 데코레이터, 변수명 immutable or mutable, context manager는jump to python 페이지에 없기에 따로 찾아 공부해야 한다. 함수 실습여러 개의 입력값을 받는 함수1234567# 여러 개의 입력값을 받는 함수 만들기def add_many(*args): result = 0 for i in args: result = result + i return result 1234567# 위 함수를 이용해보자result = add_many(1,2,3)print(result)#위 함수는 매개변수가 몇 개든 작동한다.result = add_many(1,2,3,4,5,6,7,8,9,10)print(result) 6 55 1234567891011# 여러 개의 입력값을 받는 함수 만들기2def add_mul(choice, *args): if choice == &quot;add&quot;: result=0 for i in args: result = result + i elif choice == &quot;mul&quot;: result = 1 for i in args: result = result * i return result 123456# 위 함수를 이용해보자result = add_mul('add', 1, 2, 3, 4, 5)print(result)result = add_mul('mul', 1, 2, 3, 4, 5)print(result) 15 120 키워드 파라미터 kwargs 키워드 파라미터를 사용할 때는 매개변수 앞에 별 두 개(**)를 붙인다. 12345678910# 매개변수 kwargs를 출력하는 함수이다.def print_kwargs(**kwargs): print(kwargs)# 위 함수를 사용해보자print_kwargs(a=1)print_kwargs(name='foo', age=3){'age': 3, 'name': 'foo'}# **을 붙이면 매개변수 kwargs는 딕셔너리가 되고 모든 key=value 형태의 결괏값이 그 딕셔너리에 저장된다. {'a': 1} {'name': 'foo', 'age': 3} {'age': 3, 'name': 'foo'} 매개변수에 초깃값 미리 설정하기1234567891011def say_myself(name, old, man=True): # boolean 값을 이용하여 설정 print(&quot;나의 이름은 %s 입니다.&quot; % name) print(&quot;나이는 %d살입니다.&quot; % old) if man : print(&quot;남자입니다.&quot;) # True else : print(&quot;여자입니다.&quot;) # Falsesay_myself(&quot;박응용&quot;, 27)say_myself(&quot;박응용&quot;, 27, True)say_myself(&quot;박응용&quot;, 27, False) 나의 이름은 박응용 입니다. 나이는 27살입니다. 남자입니다. 나의 이름은 박응용 입니다. 나이는 27살입니다. 남자입니다. 나의 이름은 박응용 입니다. 나이는 27살입니다. 여자입니다. 함수 안에서 선언한 변수의 효력 범위123456789a = 1def vartest(a): a = a +1vartest(a)print(a)# 결과 = 1# 즉 함수 안에서 사용하는 매개변수는 함수 밖의 변수 이름과는 전혀 상관이 없다는 뜻이다. 1 함수 안에서 함수 밖의 변수를 변경하는 방법 return 사용하기 global 사용하기 12345678# return 사용하기a = 1def vartest(a): a = a + 1 return a # return으로 값 반환 a = vartest(a)print(a) 2 12345678# global 사용하기a = 1def vartest(): global a a = a + 1vartest() #효과는 있지만, 가급적 사용하지 말자.print(a) 2 lambda 함수를 생성할 때 사용하는 예약어로 def와 동일한 역할을 한다. 보통 함수를 한줄로 간결하게 만들 때 사용 123add = lambda a, b : a+bresult = add(3,4)print(result) 7 사용자 입력과 출력사용자 입력 input 사용 123456number1 = input(&quot;숫자를 입력하세요... : &quot;)print(number1) # 문자열 취급이므로 주의number2 = int(input(&quot;숫자를 입력하세요... : &quot;))print(number2) # int로 형변환하여 정수 취급됨. 숫자를 입력하세요... : 1 1 숫자를 입력하세요... : 4 4 print 자세히 알기123# 큰따옴표로 둘러싸인 문자열은 + 연산과 동일하다print(&quot;life&quot; &quot;is&quot; &quot;too short&quot;)print(&quot;life&quot; + &quot;is&quot; + &quot;too short&quot;) lifeistoo short lifeistoo short 12# 문자열 띄어쓰기는 콤마로 한다print(&quot;life&quot;, &quot;is&quot;, &quot;too short&quot;) life is too short 1234# 한 줄에 결괏값 출력하기for i in range(10): print(i, end=' ') # 매개변수 end를 사용하여 끝 문자를 지정 0 1 2 3 4 5 6 7 8 9 파일 생성하기 파일 열기 모드에는 다음과 같은 것이 있다. r : 읽기모드 - 파일을 읽기만 할 때 사용 w : 쓰기모드 - 파일에 내용을 쓸 때 사용 a : 추가모드 - 파일의 마지막에 새로운 내용을 추가 시킬 때 사용 12f = open(&quot;새파일.txt&quot;, 'w')f.close() 123# 만약 새파일.txt 파일을 C:/doit 디렉터리에 생성하고 싶다면 다음과 같이 작성f = open(&quot;C:/doit/새파일.txt&quot;, 'w')f.close() 123456# 파일을 쓰기 모드로 열어 출력값 적기f = open(&quot;C:/doit/새파일.txt&quot;, 'w')for i in range(1, 11): data = &quot;%d번째 줄입니다.\\n&quot; % i f.write(data)f.close() 123456# 파일에 새로운 내용 추가하기f = open(&quot;C:/doit/새파일.txt&quot;,'a')for i in range(11, 20): data = &quot;%d번째 줄입니다.\\n&quot; % i f.write(data)f.close() 4장 연습문제12345678910# Q1 주어진 자연수가 홀수인지 짝수인지 판별해 주는 함수(is_odd)를 작성해 보자.def is_odd(n): if n%2 ==0 : print(&quot;짝수입니다...&quot;) else : print(&quot;홀수입니다...&quot;)num = int(input(&quot;자연수를 입력하세요...: &quot;))is_odd(num) 자연수를 입력하세요...: 3 홀수입니다... 1234567891011# Q2 입력으로 들어오는 모든 수의 평균 값을 계산해 주는 함수를 작성해 보자. # (단 입력으로 들어오는 수의 개수는 정해져 있지 않다.)def cal_median(*args): result = 0 for i in args: result = result + i return result / len(args)result = cal_median(1,2,3,4,5,6,7,8,9,10)print(result) 5.5 123456789# Q3 다음은 두 개의 숫자를 입력받아 더하여 돌려주는 프로그램이다.# 3과 6을 입력했을 때 9가 아닌 36이라는 결괏값을 돌려주었다. 이 프로그램의 오류를 수정해 보자.input1 = int(input(&quot;첫번째 숫자를 입력하세요:&quot;))input2 = int(input(&quot;두번째 숫자를 입력하세요:&quot;))# int를 통한 형변환을 시행.total = input1 + input2print(&quot;두 수의 합은 %s 입니다&quot; % total) 첫번째 숫자를 입력하세요:1 두번째 숫자를 입력하세요:4 두 수의 합은 5 입니다 123456# Q4 다음 중 출력 결과가 다른 것 한 개를 골라 보자.print(&quot;you&quot; &quot;need&quot; &quot;python&quot;)print(&quot;you&quot;+&quot;need&quot;+&quot;python&quot;)print(&quot;you&quot;, &quot;need&quot;, &quot;python&quot;) # 콤마를 이요한 띄어쓰기를 사용함print(&quot;&quot;.join([&quot;you&quot;, &quot;need&quot;, &quot;python&quot;])) youneedpython youneedpython you need python youneedpython 12345678910# Q5 다음은 &quot;test.txt&quot;라는 파일에 &quot;Life is too short&quot; 문자열을 저장한 후 다시 그 파일을 읽어서 출력하는 프로그램이다. # 예상한 값을 출력할 수 있도록 프로그램을 수정해 보자.f1 = open(&quot;test.txt&quot;, 'w')f1.write(&quot;Life is too short&quot;)f1.close() # 열린 파일 객체를 닫는다.f2 = open(&quot;test.txt&quot;, 'r')print(f2.read())f2. close() # close를 추가함. Life is too short 123456789# Q6 사용자의 입력을 파일(test.txt)에 저장하는 프로그램을 작성해 보자. #(단 프로그램을 다시 실행하더라도 기존에 작성한 내용을 유지하고 새로 입력한 내용을 추가해야 한다.)# 다시 풀어보자user_input = input(&quot;저장할 내용을 입력하세요:&quot;)f = open('test.txt', 'a') # 내용을 추가하기 위해서 'a'를 사용f.write(user_input)f.write(&quot;\\n&quot;) # 입력된 내용을 줄 단위로 구분하기 위한 개행 문자 사용f.close() 저장할 내용을 입력하세요:hihi 1234567891011# Q7 다음과 같은 내용을 지닌 파일 test.txt가 있다. 이 파일의 내용 중 &quot;java&quot;라는 문자열을 &quot;python&quot;으로 바꾸어서 저장해 보자.# 다시 풀어보자f = open('test.txt', 'r')body = f.read()f.close()body = body.replace('java', 'python')f = open('test.txt', 'w')f.write(body)f.close()","link":"/2022/03/22/python_02/"},{"title":"파이썬_기초문법_3","text":"클래스를 만드는 목적! 코드의 간결화! 코드를 재사용! 여러 라이브러리 –&gt; 클래스로 구현이 됨 list 클래스, str 클래스 객체로 사용 변수명으로 정의! 여러 클래스들이 모여서 하나의 라이브러리가 됨. 장고 / 웹개발 / 머신러닝 / 시각화 / 데이터 전처리 1234567891011121314151617class Person: # 클래스 이름 첫문자는 대문자로 설정 #class attribute country = &quot;korean&quot; #instance attribute def __init__(self, name, age): # def __init__(self, ) 는 디폴트로 정해진 부분이다 self.name = name self.age = ageif __name__ == &quot;__main__&quot;: kim = Person(&quot;Kim&quot;, 100) Lee = Person(&quot;lee&quot;, 100) # access class attribute print(&quot;kim은 {}&quot;.format(kim.__class__.country)) print(&quot;Lee는 {}&quot;.format(Lee.__class__.country)) kim은 korean Lee은 korean instance 메서드 생성 list.append(), list.extend() 12345678910111213141516171819202122232425class Person: country = &quot;korean&quot; def __init__(self, name, age): self.name = name self.age = age # instance method 정의 def singing(self, songtitle, sales): return &quot;{}판매량 {}된 {}을 노래합니다.&quot;.format(self.name, sales, songtitle)if __name__ == &quot;__main__&quot;: kim = Person(&quot;Kim&quot;, 100) Lee = Person(&quot;lee&quot;, 100) # access class attribute print(&quot;kim은 {}&quot;.format(kim.country)) print(&quot;Lee는 {}&quot;.format(Lee.__class__.country)) # call instance method print(kim.singing(&quot;A&quot;, 10)) print(Lee.singing(&quot;B&quot;, 200)) kim은 korean Lee는 korean Kim판매량 10된 A을 노래합니다. lee판매량 200된 B을 노래합니다. 123name = &quot;lee&quot;songtitle = &quot;B&quot;print(&quot;{} {}을 노래합니다.&quot;.format(name, songtitle)) lee B을 노래합니다. 클래스 상속 부모님 유산… 부모님 집 (냉장고, 세탁기, TV, etc) 사용은 같이 함 본인, 돈을 모음 개인 노트북 구매 ( 여러분 각자 방에 비치 ) 노트분은 본인 것이지만 추가 가전 제품을 구매해서 확장! 123456class Parent: passclass Child(Parent): passif __name__ == &quot;__main__&quot;: kim_child = Child() 123456789101112131415161718192021222324252627282930313233343536class Parent: # instance attribute def __init__(self, name, age): self.name = name self.age = age def whoAmI(self): print(&quot;I am Parent!!&quot;) def singing(self, songtitle): return &quot;{}된 {}을 노래합니다.&quot;.format(self.name, songtitle) def dancing(self): return &quot;{} 현재 춤을 춥니다.&quot;.format(self.name)class Child(Parent): # 상속 def __init__(self, name, age): #super() function # 상속 기능 super().__init__(name, age) print(&quot;Child Class is ON&quot;) def whoAmI(self): print(&quot;I am child&quot;) def studying(self): print(&quot;I am Fast Runner&quot;)if __name__ == &quot;__main__&quot;: child_kim = Child(&quot;kim&quot;, 15) parent_kim = Parent(&quot;kim&quot;, 45) print(child_kim.dancing()) print(child_kim.singing(&quot;연애&quot;)) # print(child_kim.studying()) child_kim.whoAmI() parent_kim.whoAmI() Child Class is ON kim 현재 춤을 춥니다. kim된 연애을 노래합니다. I am Fast Runner None I am child I am Parent!! 12345678910111213141516171819202122232425class TV: #init constructor ( 생성자 ) def __init__(self): self.__maxprice = 500 # 클래스 내부에서 쓸 수 있게끔 private variable def sell(self): print(&quot;selling Price : {}&quot;.format(self.__maxprice)) def setMaxPrice(self, price): self.__maxprice = priceif __name__ == &quot;__main__&quot;: tv = TV() tv.sell() # change price # 안 바뀌는 코드의 예시 tv.__maxprice = 1000 tv.sell() # setMaxPrice # 값을 바꿀 수 있다?? 외부의 입력값을 업데이트 할 수 있다. tv.setMaxPrice(1000) tv.sell() selling Price : 500 selling Price : 500 selling Price : 1000 자식 클래스가 많이 있는 라이브러리는 사용자가 스기 까다로울 것 같은데, 많이 써주는 이유는 자식클래스 이름마다 의미를 주려고 그런건가요? 특수 목적을 해결하기 위해서 라이브러리를 만듦 초기 버전은 3개 클래스 정도 만들면 해결이 되겠지? 버그 나오고, 이슈 터지고 –&gt; 개발자들이 해결 2개 더 만들고 다시 배포 클래스 내부에 조건문 init contsructor에 조건문을 써보자! 123456789101112131415161718192021222324252627282930313233class Employee: #init constructor #name, salary def __init__(self, name, salary = 0): self.name = name #조건문 추가 if salary &gt; 0: self.salary = salary else: self.salary = 0 print(&quot;급여는 0원이 될 수 없습니다. 다시 입력해십시오!!&quot;) def update_salary(self, amount): self.salary += amount def weekly_salary(self): return self.salary / 7if __name__ == &quot;__main__&quot;: emp01 = Employee(&quot;Evan&quot;, -5000) print(emp01.name) print(emp01.salary) emp01.salary = emp01.salary + 1500 print(emp01.salary) emp01.update_salary(3000) print(emp01.salary) week_salary = emp01.weekly_salary() print(week_salary) 급여는 0원이 될 수 없습니다. 다시 입력해십시오!! Evan 0 1500 4500 642.8571428571429 클래스 Doctring 문서화 문서화의 일반적인 과정 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class Person: &quot;&quot;&quot; 사람을 표현하는 클래스 ... Attributes ---------- name : str name of the person age : int age of the person ... ... Methods ---------- info(additional=&quot;&quot;): prints the person's name and age &quot;&quot;&quot; def __init__(self, name, age): &quot;&quot;&quot; Constructs all the neccessary attributes for the person object Parameters ---------- name : str name of the person age : int age of the person &quot;&quot;&quot; self.name = name self.age = age def info(self, additional=None): &quot;&quot;&quot; 귀찮음... Parameters ---------- additional : str, optional more info to be displayed (Default is None) Returns ------- None &quot;&quot;&quot; print(f'My name is {self.name}. i am {self.age} years old.' + additional) if __name__ == &quot;__main__&quot;: person = Person(&quot;Evan&quot;, age = 20) person.info(&quot;나의 직장은 00이야&quot;) help(Person) My name is Evan. i am 20 years old.나의 직장은 00이야 Help on class Person in module __main__: class Person(builtins.object) | Person(name, age) | | 사람을 표현하는 클래스 | ... | | Attributes | ---------- | name : str | name of the person | | age : int | age of the person | ... | ... | | Methods | ---------- | | info(additional=&quot;&quot;): | prints the person's name and age | | Methods defined here: | | __init__(self, name, age) | Constructs all the neccessary attributes for the person object | | Parameters | ---------- | name : str | name of the person | | age : int | age of the person | | info(self, additional=None) | 귀찮음... | | Parameters | ---------- | additional : str, optional | more info to be displayed (Default is None) | | Returns | ------- | None | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) | | ---------------------------------------------------------------------- | Data and other attributes defined here: | | person = &lt;__main__.Person object&gt; 클래스 실습1234567891011121314151617181920# 더하기, 빼기 기능이 있는 클래스class Calculator: def __init__(self): self.result = 0 def add(self,num): self.result += num return self.result def sub(self,num): self.result -= num return self.resultcal1 = Calculator()cal2 = Calculator()print(cal1.add(3))print(cal1.add(4))print(cal2.add(3))print(cal2.add(7)) 3 7 3 10 12345678910111213# 4칙연산 기능이 달린 클래스 정의# 일단 더하기만 구현class FourCal: def setdata(self, first, second): self.first = first self.second = second def add(self): result = self.first + self.second return resulta = FourCal()a.setdata(4,2)a.add() 6 123456789101112131415161718192021222324# 4칙연산 기능이 달린 클래스 정의class FourCal: def setdata(self, first, second): self.first = first self.second = second def add(self): result = self.first + self.second return result def mul(self): result = self.first * self.second return result def sub(self): result = self.first - self.second return result def div(self): result = self.first / self.second return resulta = FourCal()a.setdata(4,2)print(a.mul())print(a.sub())print(a.div()) 8 2 2.0 생성자 위 함수의 setdata는 생성자의 역할을 한다. setdata를 생성자 __init__으로 바꿔도 정상 작동한다. 12345678910111213141516171819202122# setdata를 생성자 __init__으로 변경class FourCal: def __init__(self, first, second): self.first = first self.second = second def add(self): result = self.first + self.second return result def mul(self): result = self.first * self.second return result def sub(self): result = self.first - self.second return result def div(self): result = self.first / self.second return resulta = FourCal(4, 2) # 이전과 달리 매개변수도 작성해야 작동.print(a.mul())print(a.sub())print(a.div()) 8 2 2.0 클래스의 상속 FourCal 클래스는 만들어 놓았으므로 FourCal 클래스를 상속하는 MoreFourCal 클래스는 다음과 같이 간단하게 만들 수 있다. 123456# 상속class MoreFourCal(FourCal): passa = MoreFourCal(4,2)a.add() 6","link":"/2022/03/23/python_03/"},{"title":"pandas_tutorial_01","text":"데이터 전처리 데이터 전처리의 기본 garbage Data —[ Great Model ]—&gt; Garbage Results 데이터 전처리의 주요 과정 데이터 전처리 수행 프로세스***(중요)*** 1.중복값 제거 및 결측치 처리 -&gt; 2.이상치 처리 -&gt; 3.Feature Engineering 주요 목적 : 더 나은 분석 결과 도출 및 모형 성능 개선 실현 pandas 기본자료형 숫자, 문자 모두 들어간다. 중복이 불가능하다. 판다스라이브러리 불러오기12import pandas as pdprint(pd.__version__) 1.3.5 테스트12345temp_dic = {&quot;col1&quot;: [1,2,3], &quot;col2&quot;: [3, 4, 5]}df = pd.DataFrame(temp_dic) # DataFrame() 사용df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 0 1 3 1 2 4 2 3 5 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-5f12a67d-363f-495e-a8d6-e15402e0c5d6 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-5f12a67d-363f-495e-a8d6-e15402e0c5d6'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1print(type(df)) &lt;class 'pandas.core.frame.DataFrame'&gt; 1234temp_dic = {'a':1, 'b':2, 'c':3}ser = pd.Series(temp_dic) # Series() 사용print(ser)print(type(ser)) a 1 b 2 c 3 dtype: int64 &lt;class 'pandas.core.series.Series'&gt; 구글 드라이브 연동 구글 드라이브 → colab notebook → 새 폴더 생성 : data → 슬랙에서 다운 받은 lemonade.csv 파일을 올린다 -&gt; 다음 코드를 실행 12from google.colab import drivedrive.mount('/content/drive') Mounted at /content/drive Mounted at ..drive 가 출력되었으므로 성공 현재 좌측에 폴더 그림 -&gt; drive -&gt; mydrive -&gt; Colab Notebooks -&gt; data -&gt; Lemonade2016.csv를 찾아서 우클릭 -&gt; 경로 복사 -&gt; 다음 코드에 붙여넣어 사용 123DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/data/Lemonade2016.csv'juice = pd.read_csv(DATA_PATH)juice .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 5 7/6/2016 Beach 103 69 82 90.0 0.25 6 7/6/2016 Beach 103 69 82 90.0 0.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 8 NaN Beach 123 86 82 113.0 0.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 11 7/11/2016 Beach 162 120 83 135.0 0.25 12 7/12/2016 Beach 130 95 84 99.0 0.25 13 7/13/2016 Beach 109 75 77 99.0 0.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 16 7/16/2016 Beach 81 50 74 90.0 0.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 18 7/18/2016 Park 131 92 81 122.0 0.50 19 7/19/2016 Park 122 85 78 113.0 0.50 20 7/20/2016 Park 71 42 70 NaN 0.50 21 7/21/2016 Park 83 50 77 90.0 0.50 22 7/22/2016 Park 112 75 80 108.0 0.50 23 7/23/2016 Park 120 82 81 117.0 0.50 24 7/24/2016 Park 121 82 82 117.0 0.50 25 7/25/2016 Park 156 113 84 135.0 0.50 26 7/26/2016 Park 176 129 83 158.0 0.35 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-e4ed5b94-20e7-42ba-9f65-459f54e1728a button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-e4ed5b94-20e7-42ba-9f65-459f54e1728a'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 데이터를 불러왔다. 첫번째 파악해야 하는 것! 데이터 구조를 파악해보자 1juice.info() # 데이터 구조 파악 &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB 1juice.head() # 상위의 데이터를 여러개 불러온다. 디폴트 값이 5개. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-c3238942-1033-4010-80b8-10e94c66dc23 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-c3238942-1033-4010-80b8-10e94c66dc23'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1juice.tail() # 하위의 데이터를 여러개 불러온다. 디폴트 값이 5개 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-cc60af2a-dd96-48c1-9398-546b4a947c77 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-cc60af2a-dd96-48c1-9398-546b4a947c77'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Describe() 함수 기술통계량 확인해주는 함수 1juice.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Lemon Orange Temperature Leaflets Price count 32.000000 32.000000 32.000000 31.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354687 std 25.823357 21.863211 4.067847 20.117718 0.113137 min 71.000000 42.000000 70.000000 68.000000 0.250000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 max 176.000000 129.000000 84.000000 158.000000 0.500000 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-bfd69db7-f9d2-49ea-84ed-2989ca9e02a8 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-bfd69db7-f9d2-49ea-84ed-2989ca9e02a8'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1type(juice.describe()) # Describe함수 결과물의 타입은 DataFrame 이다. pandas.core.frame.DataFrame value_counts() 12print(juice['Location'].value_counts())print(type(juice['Location'].value_counts())) Beach 17 Park 15 Name: Location, dtype: int64 &lt;class 'pandas.core.series.Series'&gt; 데이터 다뤄보기 행과 열을 핸들링 해보자. 12juice['Sold'] = 0 # sold 열 추가.print(juice.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 12juice['Sold'] = juice['Lemon'] + juice['Orange'] # Sold에 값 설정print(juice.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 매출액 = 가격 x 판매량 Revenue 로 만들어보자 12juice['Revenue'] = juice['Sold'] * juice['Price']print(juice.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 Revenue 0 41.00 1 41.25 2 46.75 drop(axis = 0|1) axis는 ‘축’을 의미한다. 한 축을 따라서 연산이 된다. axis를 0으로 설정 시, 행(=index)방향으로 drop() 실행 axis를 1로 설정 시, 열방향으로 drop 수행함. 12juice_column_drop = juice.drop('Sold', axis = 1)print(juice_column_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 12juice_row_drop = juice.drop(0, axis = 0)print(juice_row_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 Revenue 1 41.25 2 46.75 3 58.25 데이터 인덱싱1juice[0:5] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-bfa3fabe-e933-4527-879f-12c188c0b8bd button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-bfa3fabe-e933-4527-879f-12c188c0b8bd'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; boolean 값을 활용한 데이터 추출123# location이 Beach인 경우# juice['Location'].value_counts()juice[juice['Location'] == &quot;Beach&quot;] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-f23f5092-ba57-4126-bdd5-ecc3581c90cd button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-f23f5092-ba57-4126-bdd5-ecc3581c90cd'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 123# location이 Beach인 경우# juice['Location'].value_counts()juice[juice['Leaflets'] &gt;= 100] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-080b31c4-9d87-4d46-a98d-5d6eec44b68f button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-080b31c4-9d87-4d46-a98d-5d6eec44b68f'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; iloc vs loc 차이를 확인한다! 123juice.head(3)# index 번호는 다음 실행 결과에서# 0 1 2 3 4 5 6 7 8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-dadb1a11-c681-42a1-9b8b-85510d760ea0 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-dadb1a11-c681-42a1-9b8b-85510d760ea0'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; %%time 실행 시간 측정 코드의 효율을 살펴보자 123%%timejuice.iloc[0:3, 0:2] # 인덱스 기반 CPU times: user 2.14 ms, sys: 0 ns, total: 2.14 ms Wall time: 3.19 ms .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-dfd7fd78-f2b8-491f-a422-bd0e37bc0297 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-dfd7fd78-f2b8-491f-a422-bd0e37bc0297'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; loc -&gt; 라벨 기반 123%%timejuice.loc[0:2, ['Date', 'Location']] # 라벨 기반이라 0:2로 실행 시, 3개 생성된다 CPU times: user 1.64 ms, sys: 0 ns, total: 1.64 ms Wall time: 1.62 ms .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-f63e27df-425e-4e52-acd7-6c213c3c886a button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-f63e27df-425e-4e52-acd7-6c213c3c886a'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 123# juice[juice['Leaflets'] &gt;= 100, 컬럼명 별도 추출]juice.loc[juice['Leaflets'] &gt;= 100, ['Date', 'Location']] # 컬럼은 컬럼별로 추출 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location 2 7/3/2016 Park 4 7/5/2016 Beach 7 7/7/2016 Beach 8 NaN Beach 9 7/9/2016 Beach 10 7/10/2016 Beach 11 7/11/2016 Beach 14 7/14/2016 Beach 15 7/15/2016 Beach 17 7/17/2016 Beach 18 7/18/2016 Park 19 7/19/2016 Park 22 7/22/2016 Park 23 7/23/2016 Park 24 7/24/2016 Park 25 7/25/2016 Park 26 7/26/2016 Park &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-80c7ea4c-f3b6-416c-90a6-935ca4d10c87 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-80c7ea4c-f3b6-416c-90a6-935ca4d10c87'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1juice.iloc[juice['Leaflets'] &gt;= 100, 0:2] 정렬 sort_values() 12# 매출액 순서로 정렬juice.sort_values(by=['Revenue'], ascending=False).head(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-d4ef77c6-8bab-4eae-9f75-40bfaf70f3b7 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-d4ef77c6-8bab-4eae-9f75-40bfaf70f3b7'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 123456# 2개 이상 기준으로 할 경우, 그룹화하여 정렬됨juice.sort_values(by=['Price', 'Temperature'], ascending=False) #이것도 가능#juice.sort_values(by=['Price', 'Temperature'], ascending=[False, True]) -&gt; Price는 내림차순, Temparature는 오름차순#juice.sort_values(by=['Price', 'Temperature'], ascending=[False, True]).rest_index(drop=True) -&gt; index 번호도 재정렬 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-14051fd5-627b-4ebe-ab05-3415f55cc7f3 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-14051fd5-627b-4ebe-ab05-3415f55cc7f3'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Group by R dplyr groupby() %&gt;% summarize() -&gt; 데이터 요약 -&gt; 엑셀로 피벗 테이블 12# Location 항목을 카운트juice.groupby(by = 'Location').count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Lemon Orange Temperature Leaflets Price Sold Revenue Location Beach 16 17 17 17 17 17 17 17 Park 15 15 15 15 14 15 15 15 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-26afeca1-6bb7-494f-ba2d-92aab015b058 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-26afeca1-6bb7-494f-ba2d-92aab015b058'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1234# 집계 함수import numpy as npjuice.groupby(['Location'])['Revenue'].agg([max, min, sum, np.mean]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } max min sum mean Location Beach 95.5 43.0 1002.8 58.988235 Park 134.5 41.0 1178.2 78.546667 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-650575f1-c764-4097-b860-3fa1b26021c5 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-650575f1-c764-4097-b860-3fa1b26021c5'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1234# 집계 함수import numpy as npjuice.groupby(['Location'])['Revenue', 'Lemon'].agg([max, min, sum, np.mean]) /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead. after removing the cwd from sys.path. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Revenue Lemon max min sum mean max min sum mean Location Beach 95.5 43.0 1002.8 58.988235 162 76 2020 118.823529 Park 134.5 41.0 1178.2 78.546667 176 71 1697 113.133333 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-7a3b6989-de2d-4a76-8bd8-66538dc5863c button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-7a3b6989-de2d-4a76-8bd8-66538dc5863c'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt;","link":"/2022/03/23/pandas_tutorial_01/"},{"title":"python_numpy_01","text":"라이브러리 여러가지 라이브러리를 사용해보자 NumpyQ : what is numpy? A : 배열 연산이다. Q : why numpy? A : 두개의 리스트 연산 시도 → Type Error → Numpy 도입 12345# 다음 코드는 사용 시 error가 나온다.A = [1, 2, 3]B = [4, 5, 6]A / B ** 2 123456789# numpy 사용 시 정상적으로 작동한다.import numpy as npA = [1, 2, 3]B = [4 ,5, 6]np_A = np.array(A)np_B = np.array(B)np_A / np_B ** 2 array([0.0625 , 0.08 , 0.08333333]) Reshape사용 예시 (2,3) 배열 -&gt; np.reshape(3,2) -&gt; (3,2)배열 사용 예시 np.reshape(-1, 2)에서 -1의 의미: 특정 차원에서 열은 2로 고정된 상태에서 행은 사이즈에 맞도록 자동으로 정렬해준다는 뜻 123456import numpy as nptemp_arr = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])temp_arrnew_arr = temp_arr.reshape(2, -1)new_arr array([[ 1, 2, 3, 4, 5, 6, 7, 8], [ 9, 10, 11, 12, 13, 14, 15, 16]]) 123# -1을 이용한 자동 정렬new_arr = temp_arr.reshape(4, -1)new_arr array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]]) 조언 머신러닝 / 딥러닝 수학을 잘 하는 사람 vs 수학을 처음 하는 사람 머신러닝 / 딥러닝 (인간이 만든 수식!) 개념을 이해하고, 수식으로 이해하고, 코드로 그 수식을 구현해야 머신러닝과 딥러닝을 쓰기 위해서는 수학자만 해야되냐!? 결론은 아닙니다! 머신러닝 / 딥러닝의 주 목적이 인간 생활의 보편적인 무제 해결을 위해 나온 것 프레임워크로 형태로 내놨어요 (개념을 이해하고 있자!) 개념만 문자열 타입으로 매개변수를 잘 조정만 하면 모델 만들어짐! 성과를 내야 하는데 (개발자는 배포를 잘해야 함!) 이미지 인식 모델을 만듬 / (쓸데가 없음…) / 안드로이드 앱 / 웹앱에 탑재할줄만 알아도 기획 (어떤 문데를 풀까?) AutoML 코드를 4 ~ 5줄 치면 머신러닝 모델이 만들어짐! 하지만 이공계 출신이라면 수식도 나름대로 정리해 볼 것 라이브러리 설치 방법 (vs R) 1234567891011121314# R install.packages(&quot;패키지명&quot;)# 파이썬 라이브러리 설치 코드에서 실행 (X)# 터미널에서 설치# 방법1. conda 설치# --&gt; 아나콘다 설치 후, conda 설치 (데이터 과학)# conda 라이브러리 관리 (버전 업데이트가 조금 느림)# 방법2. pip 설치# --&gt; 아나콘다 설치 안 함 / 파이썬만 설치# git bash 열고, pip install numpy#pip install numpy# google colab에선 기본적 환경이 갖추어져 있음. Numpy 라이브 불러오기 123# 다음과 같이 np 라고 줄여서 출력한다.import numpy as npprint(np.__version__) 1.21.5 배열로 변환 1부터 10까지의 리스트를 만든다. Numpy 배열로 변환해서 저장한다. 1234temp = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]arr = np.array(temp)print(arr)print(temp) [ 1 2 3 4 5 6 7 8 9 10] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 12print(type(arr))print(type(temp)) &lt;class 'numpy.ndarray'&gt; &lt;class 'list'&gt; Numpy를 사용하여 기초 통계 함수를 사용한다. 1234print(np.mean(arr))print(np.sum(arr))print(np.median(arr))print(np.std(arr)) 5.5 55 5.5 2.8722813232690143 사칙연산12345math_scores = [90,80, 88]english_scores = [80, 70, 90]total_scores = math_scores + english_scorestotal_scores [90, 80, 88, 80, 70, 90] 12345678math_scores = [90,80, 88]english_scores = [80, 70, 90]math_arr = np.array(math_scores)english_arr = np.array(english_scores)total_scores = math_arr + english_arrtotal_scores array([170, 150, 178]) 1np.min(total_scores) 150 1np.max(total_scores) 178 123456789101112math_scores = [2, 3, 4]english_scores = [1, 2, 3]math_arr = np.array(math_scores)english_arr = np.array(english_scores)#사칙연산print(&quot;덧셈 : &quot;, np.add(math_arr, english_arr))print(&quot;뺄셈 : &quot;, np.subtract(math_arr, english_arr))print(&quot;곱셈 : &quot;, np.multiply(math_arr, english_arr))print(&quot;나눗셈 : &quot;, np.divide(math_arr, english_arr))print(&quot;거듭제곱 : &quot;, np.power(math_arr, english_arr)) 덧셈 : [3 5 7] 뺄셈 : [1 1 1] 곱셈 : [ 2 6 12] 나눗셈 : [2. 1.5 1.33333333] 거듭제곱 : [ 2 9 64] 배열의 생성 0차원부터 3차원까지 생성하는 방법 1234temp_arr = np.array(20)print(temp_arr)print(type(temp_arr))print(temp_arr.shape) 20 &lt;class 'numpy.ndarray'&gt; () 123456# 1차원 배열temp_arr = np.array([1,2,3])print(temp_arr)print(type(temp_arr))print(temp_arr.shape) # 배열의 형태 확인용print(temp_arr.ndim) # ndim은 차원 확인용 [1 2 3] &lt;class 'numpy.ndarray'&gt; (3,) 1 123456# 2차원 배열temp_arr = np.array([[1,2,3], [4, 5, 6]])print(temp_arr)print(type(temp_arr))print(temp_arr.shape)print(temp_arr.ndim) # ndim 은 차원 확인 [[1 2 3] [4 5 6]] &lt;class 'numpy.ndarray'&gt; (2, 3) 2 123456# 3차원 배열temp_arr = np.array([[[1,2,3], [4, 5, 6]], [[1,2,3], [4, 5, 6]]])print(temp_arr)print(type(temp_arr))print(temp_arr.shape)print(temp_arr.ndim) # ndim 은 차원 확인 [[[1 2 3] [4 5 6]] [[1 2 3] [4 5 6]]] &lt;class 'numpy.ndarray'&gt; (2, 2, 3) 3 12345temp_arr = np.array([1, 2, 3, 4], ndmin = 2) # 차원을 변경 가능print(temp_arr)print(type(temp_arr))print(temp_arr.shape)print(temp_arr.ndim) [[1 2 3 4]] &lt;class 'numpy.ndarray'&gt; (1, 4) 2 소수점 정렬12temp_arr = np.trunc([-1.23, 1.23])temp_arr array([-1., 1.]) 12temp_arr = np.fix([-1.23, 1.23])temp_arr array([-1., 1.]) 123# 반올림temp_arr = np.around([-1.63789, 1.23784], 4) # 소수점 아래 4번째자리로 반올림 한다는 표현temp_arr array([-1.6379, 1.2378]) 123# 올림temp_arr = np.floor([-1.63789, 1.23784])temp_arr array([-2., 1.]) 123# 내림temp_arr = np.ceil([-1.63789, 1.23784])temp_arr array([-1., 2.]) shape 높이 * 세로 * 가로 순인건가요? axis 축 설정 배열을 사용하는 다양한 방법들123# np.arange(5) -&gt; 0 부터 시작하는 5개의 배열 생성temp_arr = np.arange(5)temp_arr array([0, 1, 2, 3, 4]) 123# np.arange(1, 11, 3) -&gt; 1 부터 11까지 3만큼 차이나게 배열 생성temp_arr = np.arange(1, 11, 3)temp_arr array([ 1, 4, 7, 10]) 1234567# np.zeros -&gt; 0으로 채운 배열 만들기zero_arr = np.zeros((2,3))print(zero_arr)print(type(zero_arr))print(zero_arr.shape)print(zero_arr.ndim)print(zero_arr.dtype) # dype = data type [[0. 0. 0.] [0. 0. 0.]] &lt;class 'numpy.ndarray'&gt; (2, 3) 2 float64 1234567# np.ones -&gt; 1로 채운 배열 만들기temp_arr = np.ones((4,5), dtype=&quot;int32&quot;) print(temp_arr)print(type(temp_arr))print(temp_arr.shape)print(temp_arr.ndim)print(temp_arr.dtype) [[1 1 1 1 1] [1 1 1 1 1] [1 1 1 1 1] [1 1 1 1 1]] &lt;class 'numpy.ndarray'&gt; (4, 5) 2 int32 123456temp_arr = np.ones((2,6), dtype=&quot;int32&quot;) print(temp_arr)print(type(temp_arr))print(temp_arr.shape)print(temp_arr.ndim)print(temp_arr.dtype) [[1 1 1 1 1 1] [1 1 1 1 1 1]] &lt;class 'numpy.ndarray'&gt; (2, 6) 2 int32 12345678# reshape() 사용하여 배열 변환하기 temp_arr = np.ones((12,12), dtype=&quot;int32&quot;) temp_res_arr = temp_arr.reshape(4, -1) # -1 은 자동정령print(temp_res_arr)print(type(temp_res_arr))print(temp_res_arr.shape)print(temp_res_arr.ndim)print(temp_res_arr.dtype) [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]] &lt;class 'numpy.ndarray'&gt; (4, 36) 2 int32 numpy 조건식 where(a, b, c) 사용법 a조건 True면 b로 변환, False이면 c로 변환 12temp_arr = np.arange(10)temp_arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 12345# 5보다 작은 값은 원래값으로 변환# 5보다 큰 값은 원래 값 * 10np.where(temp_arr &lt;5, temp_arr, temp_arr * 10)# where(a, b, c) a조건 True면 b로 변환, False이면 c로 변환 array([ 0, 1, 2, 3, 4, 50, 60, 70, 80, 90]) 12345# 0~100 까지의 배열 만들고, 50보다 작은 값은 곱하기 10, 나머지는 그냥 원래 값으로 반환temp_arr = np.arange(101)temp_arrnp.where(temp_arr &lt;50, temp_arr * 10, temp_arr) array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]) 두가지 조건식을 사용해야 할 경우 np.select 사용법은 다음 코드를 참고 1234567temp_arr = np.arange(10)temp_arr# 5보다 큰 값은 곱하기 2, 2보다 작은 값은 더하기 100condlist = [temp_arr &gt; 5, temp_arr &lt;2] # 조건식choielist = [temp_arr *2, temp_arr + 100] # 같은 위치의 조건 만족 시, 설정한 대로 변환np.select(condlist, choielist, default = temp_arr) array([100, 101, 2, 3, 4, 5, 12, 14, 16, 18]) 브로드캐스팅 서로 다른 크기의 배열을 계산할 때 참고해야하는 내용이다.","link":"/2022/03/23/python_numpy_01/"},{"title":"R 통계분석","text":"***해당 글은 “R을 이용한 공공데이터 분석”책의 8장을 정리한 글입니다.[ 1. 분석 방법 ]기술 통계 평균, 최솟값, 최댓값, 중앙값과 같이 데이터의 특징을 알려주는 값 기술통계는 Descriptive statistic 추론 통계 변수 간의 관계를 파악하고, 변수간의 인과관계 또는 새로운 사실을 밝혀냄 평균 차이 검정, 교차 분석, 상관관계분석, 회귀분석 평균차이 검정 집단별로 평균의 차이가 실제로 있는가 검정 독립표본 T검정 교차분석 범주형 변수로 구성된 집단들의 관련성을 검정하는 통계 분석 교차분석은 카이제곱(x^2)검정, 카이스퀘어검정, 독립성 검정이라고도 함 상관관계분석 상관관계분석은 변수 간의 상관관계(correlation)를 알아보는 것 변수간의 연관성 한 변수가 변화하면 다른 변수도 변화하는 관계 방향은 한 변수가 변화할 때 다른 변수가 같은 방향으로 변화하는지, 반대 방향으로 변화하는지를 의미 변화의 강도와 방향을 나나나는 계수가 상관계수(r) 상관계수는 -1~1 사이에 있으며, 수치가 클수록 영향을 주는 강도가 크다 ‘+’는 ‘정의 관계’, ‘-‘는 ‘부의 관계’ 또는 ‘역의 관계’에 있는 것을 의미 상관관계 : -1 &lt;= r &lt;= 1 회귀분석 상관관계로는 변수들의 관계를 알 수 있지만, 인과관계는 알 수 없음 인과관계는 원인과 결과의 관계. 한 변수가 다른 변수에 영향을 주는 것 영향을 주는 변수는 독립변수(independent variable)이고,영향을 받는 변수는 종속변수(dependent variable)이다 독립변수와 종속변수 간의 인과관계를 분석하는 통계적 방법을회귀분석(regression analysis)이라고 한다 “월급이 증가하면 외식횟수가 늘어날 것”이라고 가정하면, 월급은 독립변수이고 외식횟수는 종속변수이다 월급의 증감이 외식횟수에 미치는 영향을 확률적으로 분석하는 것이 회귀분석 회귀분석에서 독립변수가 1개이면 단순회귀분석, 2개 이상이면 다중회귀분석이라고 함 다중회귀분석은 종속 변수는 1개이며 독립변수가 복수인 경우 복수의 독립변수들이 종속변수에 영향을 주는 정도를 분석하는 것 [ 2. 통계 검정 ]가설 가설(hypothesis)은 어떤 현상을 설명하기 위해 가정하는 명제 증명되지 않은 추정 가설에는 귀무가설과 대립가설이 있다 귀무가설은 설정한 가설이 맞을 확률이 극히 적어서 처음부터 기각될 것으로 예상되는 가설 대립가설은 귀무가설이 기각될 경우 받아들여지는 가설이며, 연구자가 검정하고자 하는 가설 통계 검정은 통계적인 방법을 이용해서 대립가설이 맞는가를 검정하는 것 두 집단의 평균 차이가 있는가를 알아보려 할 때, 귀무가설은 ‘평균 차이가 없다’이며, 대립 가설은 ‘평균 차이가 있다’이다. 유의수준 가설검정의 결과는 유의수준에 의하여 결정 유의수준(significance level)은 귀무가설이 맞는데도 대립가설을 체택할 확률 즉 오류를 범할 확률. 차이가 없는 데도 있다고 할 확률이다 통계 분석에서는 p-value(p값)f로 제시 p값이 0.01이라면 오류를 범할 확률이 1%라는 의미 현실적으로 오류는 존재할 수 밖에 없기에, ‘허용할 수 있는 오류 범위’를 설정 유의수준 5%는 오류를 5%까지 허용하겠다는 의미 허용하는 유의수준의 범위와 정확성은 반대의 개념 유의수준의 범위가 넓으면 연구 결과를 얻기가 쉽지만 결과의 정확성이 떨어진다 통계분석을 하면 결과물에는 유의수준(p-value)이 적혀있다 통계 분석 결과를 해석할 때는 먼저 유의수준이 0.05 이내인가를 보고, 결과가 통계적으로 유의미한지를 판단해야 한다 유의수준이 0.05 이상인데도 결과가 유의미하다고 해석하면 매우 심각한 오류. 유의수준의 반대 개념은 신뢰수준(confidence level). 신뢰할 수 있는 범위를 의미. 유의수준 5% 이내라고 하면 신뢰수준은 95% 척도 척도(scale)는 측정도구이며, 수치로 표시된다 척도에는 명목척도, 서열척도, 등간척도, 비율척도 등 네 종류가 있다 명목척도 : 측정대상의 특성이나 범주를 구분하는 수치. 운동선수의 번호를 생각하면 파악하기 쉽다. 번호는 특정 선수를 의미. 성을 분류할 때 통상 남자를 1번, 여자를 2번으로 분류하는 것과 같이 결혼유무, 종교, 인종, 지역, 계절 등을 표시할 때도 이용된다. 산술연산을 할 수 없다. 서열척도 : 계급, 사회계층, 자격등급 등과 같이 측정대상의 등급순위를 나타내는 척도. 척도 간의 거리나 간격은 나타내지 않는다. 산술연산을 할 수 없다. 등간척도 : 측정대상을 일정한 간격으로 구분한 척도이다. 서열뿐만 아니라 거리와 간격도 표시한다. 온도, 학력, 시험점수 등. 덧셈과 뺄셈이 가능. 비율척도 : 측정대상을 비율로 나타낼 수 있는 척도. 연령, 무게 등. 모든 수로 측정할 수 있어 4칙 연산이 가능. [ 3. 통계 분석 사례 ]두 집단의 평균 차이 검정 남녀 등 두 집단의 평균 차이를 분석할 때는 독립표본 t검정을 한다 R에서는 내장된 t.test()함수로 한다 독립변수는 명목척도이며, 종속변수는 등간척도 또는 비율척도이어야 한다. t.test()함수 사용 방식은 2가지방법1. t.test(data=데이터세트,종속변수(비교값) ~ 독립변수(비교대상))방법2. t.test(데이터세트$종속변수(비교값) ~ 데이터세트$독립변수(비교대상)) 예제파일인 mpg1.csv의 trans변수에는 기어변속방법으로 auto(자동식)와 manual(수동식)등 두 방식이 있다.두 방식에 cty 평균에 통계적으로 유의미한 차이가 있는지 알아보자.cty는 도시에서 1갤런당 달리는 거리.독립변수는 trans이며, 종속변수는 cty이다.가설은 다음과 같이 설정한다. 귀무가설(H0) : auto와 manual의 cty평균은 차이가 없다. 대립가설(H1) : auto와 manual의 cty평균은 차이가 있다. 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)t.test(data=mpg1, cty~trans) #t.test(mpg1$cty~mpg1$tran)도 같음 1234567891011## ## Welch Two Sample t-test## ## data: cty by trans## t = -4.5375, df = 132.32, p-value = 1.263e-05## alternative hypothesis: true difference in means between group auto and group manual is not equal to 0## 95 percent confidence interval:## -3.887311 -1.527033## sample estimates:## mean in group auto mean in group manual ## 15.96815 18.67532 결과를 보면 p-value=1.263e-05 임을 알 수 있으며 이 값은 1.263/100000 &lt; 0.05 이다.유의수준이 0.05보다 적기 때문에 유의수준 허용조건(p&lt;.05)을 총종한다.결과의 ‘alternative hypothesis : true difference in means is not equal to 0’는‘대립가설 : 평균 차이가 있다’ 라는 의미. 교차분석 교차분석은 범주형 변수들이 관계가 있다는 것을 입증하는 것 평균의 차이가 아니라, 비율에 차이가 있는지를 검정 교차분석 검정은 R의 chisq.test() 함수 사용 mpg1.csv를 mpg1로 불러온다. mpg1에 있는 trans(기어 변속방식)변수의 범주에 따라 drv(구동방식)범주의 비율에 차이가 있는가를 알아본다. 연구가설은 다음과 같이 설정. 귀무가설(H0) : trans에 따라 drv의 차이가 없다. 대립가설(H1) : trans에 따라 drv의 차이가 있다. 우선 table() 함수와 prop.table()함수로 교차분석을 해서 trans에 따른 drv의 빈도와 비율을 알아본다. 123mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;, stringsAsFactors = F)table(mpg1$trans, mpg1$drv) # trans와 drv의 교차분석 1234## ## 4 f r## auto 75 65 17## manual 28 41 8 1prop.table(table(mpg1$trans, mpg1$drv),1) # auto와 manual의 drv 비율 분석 1234## ## 4 f r## auto 0.4777070 0.4140127 0.1082803## manual 0.3636364 0.5324675 0.1038961 auto에서는 4륜구동(4)인 47.8%로 가장 많고, manual에서는 전륜구동(f)이 53.2%이 가장 많아서trans에 따라 drv에 차이가 있는 것 같다. 이에 대해 정말 그런지, 통계적으로 분석하는 것이 교차분석이다. 방법 1 1chisq.test(mpg1$trans, mpg1$drv) 12345## ## Pearson's Chi-squared test## ## data: mpg1$trans and mpg1$drv## X-squared = 3.1368, df = 2, p-value = 0.2084 방법 2 1chisq.test(table(mpg1$trans, mpg1$drv)) 12345## ## Pearson's Chi-squared test## ## data: table(mpg1$trans, mpg1$drv)## X-squared = 3.1368, df = 2, p-value = 0.2084 방법 3 1summary(table(mpg1$trans, mpg1$drv)) 1234## Number of cases in table: 234 ## Number of factors: 2 ## Test for independence of all factors:## Chisq = 3.1368, df = 2, p-value = 0.2084 방법 1의 결과를 보면 유의수준(p-value)이 0.2084 &gt; 0.5 이다. 대립가설을 기각하지 못하므로trans에 따라 drv에 차이가 있다고 할 수 없다. 다른 방법에서도 같은 결과. 상관관계분석 상관관계분석은 R에 내장되어 있는 cor.test()함수로 한다 1#cor.test(데이터세트$비교변수1, 데이터세트$비교변수2) mpgl에는 cty와 hwy가 있다 cty는 도시에서 1갤런당 달리는 거리 hwy는 고속도로에서 1갤런당 달리는 거리 cty가 길면 hwy도 길 것이라 생각할 수 있다. 이 가설을 검정해본다.검정하려는 가설은 cty와 hwy는 서로 상관관계가 있다는 것이기 때문에 이것이 대립가설.귀무가설은 상관관계가 없다는 것이다. 귀무가설(H0) : cty와 hwy는 상관관계가 없다. 대립가설(H1) : cty와 hwy는 상관관계가 있다. 123mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;, stringsAsFactors = F)cor.test(mpg1$cty, mpg1$hwy) #상관관계분석 1234567891011## ## Pearson's product-moment correlation## ## data: mpg1$cty and mpg1$hwy## t = 49.585, df = 232, p-value &lt; 2.2e-16## alternative hypothesis: true correlation is not equal to 0## 95 percent confidence interval:## 0.9433129 0.9657663## sample estimates:## cor ## 0.9559159 결과를 보면 ‘p-value &lt; 2.2e-15’이다. 유의수준이 2.2/10^16보다 작다.유의수준(p&lt;.05)안에 있다. 이 검정의 결과로 귀무가설을 기각하고 대립가설을 채택할 수 있다.대립가설은 “상관관계는 0이 아니다(alternative hypothesis: true correlation is not equal to 0)” 결과의 sample estimates: 부분을 보면 상관관계는 0.9959159. 1에 가까우므로 매우 높다.결과는 “cty와 hwy는 유의미하게 매우 높은 상관관계(r=.96)에 있다(p&gt;.05)” 회귀분석단순회귀분석 단순회귀분석은 독립변수가 1개, 종속변수가 1개일때 한다 회귀분석의 변수는 독립변수와 종속변수가 모두 등간척도 또는 비율척도이어야 한다 회귀분석은 R의 lm() 함수로 한다 1234#다음 3가지 중 어느 것을 써도 된다.#방법1 lm(data=데이터세트, 종속변수~독립변수)#방법2 lm(종속변수~독립변수, data=데이터세트)#방법3 lm(데이터세트$종속변수~데이터세트$독립변수) R에 있는 mtcars 데이터로 분석한다. R에서 help(mtcars)를 하면 mtcars에 관한 정보를 알 수 있다.어느 한 미국 잡지에 실렸던 데이터이며, 11개 변수에서 32개 자동차의 정보를 담고 있다.11개의 변수 가운데 disp(배기량)가 mpg(1갤런당 주행 마일)에 미치는 여향을 분석해본다.str(mtcars)로 mtcars에 있는 변수들을 보면, disp와 mpg는 모두 실수형(num)변수이어서 회귀분석이 가능하다. 귀무가설(H0) : disp는 mpg에 영향을 주지 않는다. 귀무가설(H1) : disp는 mpg에 영향을 준다. 1lm(data=mtcars, mpg~disp) 1234567## ## Call:## lm(formula = mpg ~ disp, data = mtcars)## ## Coefficients:## (Intercept) disp ## 29.59985 -0.04122 1#lm(mpg~disp, data=mtcars), lm(mtcars$mpg~mtcars$disp)의 결과도 같다. 결과의 Coefficients 부분을 보면 disp의 계수(Coefficients)는 -0.04122이며, 절편은 29.59985이다.단순회귀분석은 1차 함수를 구하는 것과 같다.이 회귀분석에서 구해진 식은 mpg는 0.04122씩 감소한다.이제 유의수준을 알아봐야 한다. lm()의 결과를 summary()함수에 넣으면 상세한 결과를 확인 가능. 123RA &lt;- lm(data=mtcars, mpg~disp) #회귀분석 결과를 RA에 넣기summary(RA) # 상세한 분석 결과 출력 123456789101112131415161718## ## Call:## lm(formula = mpg ~ disp, data = mtcars)## ## Residuals:## Min 1Q Median 3Q Max ## -4.8922 -2.2022 -0.9631 1.6272 7.2305 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 29.599855 1.229720 24.070 &lt; 2e-16 ***## disp -0.041215 0.004712 -8.747 9.38e-10 ***## ---## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1## ## Residual standard error: 3.251 on 30 degrees of freedom## Multiple R-squared: 0.7183, Adjusted R-squared: 0.709 ## F-statistic: 76.51 on 1 and 30 DF, p-value: 9.38e-10 결과의 맨 밑줄을 확인하면 통계분석을 한 회귀모형이 적합한가를 순석하는 값이 있다. p-value가 .05보다 작으면 회귀모형이 적합하다고 해석한다. p-value가 .05보다 크면 회귀모형에 문자가 있는 것이므로 회귀분석 자체가 성립하지 않는다. 이 분석에서는 p-value가 9.38e-10이므로 회귀모형이 적합하다. 다중회귀분석 다중회귀분석은 종속변수에 영향을 주는 독립변수가 복수일 때 분석하는 방식이다. 여러 독립변수들은 서로 영향을 주면서 종속변수에 영향을 주기 때문에한 독립변수가 종속변수에 미치는 영향력은 단순회귀분석을 했을 때와 다중회귀 분석을 했을 때에 달라진다. 다중회귀분석에서는 단순회귀분석의 독립변수들을 ‘+’기호로 연결한다. 123#방법1 lm(data=데이터세트, 종속변수~독립변수1+독립변수2+...)#방법2 lm(종속변수~독립변수1+독립변수2+..., data=데이터세트)#방법3 lm(데이터세트$종속변수~데이터세트$독립변수1+데이터세트$독립변수2+...) mtcars 데이터로 실습한다. mpg에는 disp(배기량)이외에도 hp(마력)와 wt(중량)가 영향을 미칠 수 있다.세 독립변수가 mpg에 어떤 영향을 주는지 알아본다. 1lm(data=mtcars, mpg~disp+hp+wt) 1234567## ## Call:## lm(formula = mpg ~ disp + hp + wt, data = mtcars)## ## Coefficients:## (Intercept) disp hp wt ## 37.105505 -0.000937 -0.031157 -3.800891 12#lm(mpg~disp+hp+wt, data=mtcars),#lm(mtcars$mpg~mtcars$disp+mtcars$hp+mtcars$wt)의 결과도 같다. 결과의 Coefficients 부분을 보면 세 독립변수의 회귀계수가 있다.다중회귀식은 mpg = 37.105505 - 0.000937 x disp - 0.0311157 x hp - 0.3800891 x wt이다.그러나 세 독립변수의 회귀계수에 대한 유의수준이 없어서 회귀계수가 유의미한지 알 수 없다.summary()함수로 유의수준을 비롯한 상세 결과를 알아본다. 123RA &lt;- lm(data=mtcars, mpg~disp+hp+wt) #회귀분석 결과를 RA 녛기summary(RA) 1234567891011121314151617181920## ## Call:## lm(formula = mpg ~ disp + hp + wt, data = mtcars)## ## Residuals:## Min 1Q Median 3Q Max ## -3.891 -1.640 -0.172 1.061 5.861 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.105505 2.110815 17.579 &lt; 2e-16 ***## disp -0.000937 0.010350 -0.091 0.92851 ## hp -0.031157 0.011436 -2.724 0.01097 * ## wt -3.800891 1.066191 -3.565 0.00133 ** ## ---## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1## ## Residual standard error: 2.639 on 28 degrees of freedom## Multiple R-squared: 0.8268, Adjusted R-squared: 0.8083 ## F-statistic: 44.57 on 3 and 28 DF, p-value: 8.65e-11 결과의 맨 밑줄을 확인하면 p값은 86e-11로 유의수준 .001보다 작아 회귀모형은 적합하다 Coefficients 부분을 보면 각각의 유의수준은 disp는 (p&gt;.05), hp는 (p&lt;.05), wt는 (p&lt;.01)이다 disp는 mpg에 영향을 주지 않고, hp와 wt만 영향을 준다 결과의 Adjusted R-squared 는 0.8083으로 높아서 회귀모델의 설명력이 높다 위 내용들을 토대로 다음과 같이 적는다 “회귀모형은 유의수준 p&lt;.001에서 적합하며, 회귀식의 수정된 결정계수(R^2)는 .81이다.3개 독립변수가 연비에 미치는 회귀계수(베타)는 hp가 -0.03(p&lt;.05), wt가 -3.80(p&lt;.01), disp는 없다.wt의 영향력이 가장 컸다.” Reference : R을 이용한 공공데이터 분석 End of Document","link":"/2022/03/21/stat_01/"},{"title":"visualization_tutorial_01","text":"데이터 시각화데이터 시각화의 기본 조건 목적에 맞는 선정 선형 그래프, 막대 그래프, 산점도, 박스플롯 etc 환경에 맞는 도구 선택 코드 기반(R, Python) 프로그램 기반 (시각화 툴) Powr BI, Tableau, Excel 문맥(도메인)에 맞는 색과 도형 사용 회사 로고 색깔 색상의 일반적인 통념 빨간색(경고), 초록색(안전) 코드 기반의 장점 재현성 (함수화) 여러 그래프 동시 작성 가능 기존 코드 Ctrl + C/V 데이터 크기 제한 없음 (RAM 조건 충족 시) Matplotlib 사용시 주의점 객체 지향 API 문법을 사용하라 숙달 시 다른 곳에도 사용 가능하다. pyplot API 문법 사용은 자제하라. 숙달해도 다른 문법과 차이가 있어서 쓸 데가 없다. 참고 데이터 분석 강의안_220307.pdf 63페이지. ‘시각화’ Matplotlib : https://matplotlib.org/stable/api/ticker_api.html seaborn : https://seaborn.pydata.org/ 국새 파이썬 시각화 TOP 블로그 Pega Devlog (jehyunlee.github.io) 이 분 블로그는 정독할 필요가 있으니, 즐겨찾기 해두자. 라이브러리 불러오기1234import matplotlibimport seaborn as snsprint(matplotlib.__version__)print(sns.__version__) 3.2.2 0.11.2 시각화 그려보기12345678910111213141516import matplotlib.pyplot as pltdates = [ '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', '2021-01-09', '2021-01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]# 앞으로 본인이 아래와 같이 코드를 작성해야 한다. 디폴트이므로 쓰고 보자.fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(10,6))ax.plot(dates, min_temperature, label = &quot;Min Temp.&quot;)ax.plot(dates, max_temperature, label = &quot;Max Temp.&quot;)ax.legend()plt.show() 주섹 데이터 다운로드 받기1!pip install yfinance --upgrade --no-cache-dir Collecting yfinance Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB) Requirement already satisfied: pandas&gt;=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5) Requirement already satisfied: numpy&gt;=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5) Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10) Collecting lxml&gt;=4.5.1 Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB) \u001b[K |████████████████████████████████| 6.4 MB 9.7 MB/s \u001b[?25hCollecting requests&gt;=2.26 Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB) \u001b[K |████████████████████████████████| 63 kB 41.2 MB/s \u001b[?25hRequirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2.8.2) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24.0-&gt;yfinance) (1.15.0) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2021.10.8) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (1.24.3) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.0.12) Installing collected packages: requests, lxml, yfinance Attempting uninstall: requests Found existing installation: requests 2.23.0 Uninstalling requests-2.23.0: Successfully uninstalled requests-2.23.0 Attempting uninstall: lxml Found existing installation: lxml 4.2.6 Uninstalling lxml-4.2.6: Successfully uninstalled lxml-4.2.6 \u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70 12345import yfinance as yfdata = yf.download(&quot;AAPL&quot;, start=&quot;2019-08-01&quot;, end=&quot;2020-08-01&quot;)ts = data['Open']print(ts.head())print(type(ts)) # Series 타입니다. [*********************100%***********************] 1 of 1 completed Date 2019-08-01 53.474998 2019-08-02 51.382500 2019-08-05 49.497501 2019-08-06 49.077499 2019-08-07 48.852501 Name: Open, dtype: float64 &lt;class 'pandas.core.series.Series'&gt; pyplot 형태1234567import matplotlib.pyplot as pltplt.plot(ts)plt.title(&quot;&quot;)plt.title(&quot;Stock Market of APL&quot;)plt.xlabel(&quot;Date&quot;)plt.ylabel(&quot;Open Pric&quot;)plt.show() 객체지향으로 그리기 fix 는 테두리 나머지는 ax가 표현 12345678import matplotlib.pyplot as pltfix, ax = plt.subplots()ax.plot(ts)#ax.title(&quot;Stock Market of APL&quot;)#ax.xlabel(&quot;Date&quot;)#ax.ylabel(&quot;Open Pric&quot;)plt.show() 막대 그래프1234567891011121314151617181920212223import matplotlib.pyplot as pltimport numpy as npimport calendarmonth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450]fix, ax = plt.subplots(figsize = (10, 6))barplots = ax.bar(month_list, sold_list) # bar() 로 막대 그래프 생성print(&quot;barplots : &quot;, barplots)for plot in barplots: print(plot) #print(plot.get_height()) #print(plot.get_x()) #print(plot.get_y()) #print(plot.get_width()) height = plot.get_height() ax.text(plot.get_x() + plot.get_width()/2., height, height, ha = 'center', va = 'bottom') plt.xticks(month_list, calendar.month_name[1:13], rotation = 90)plt.show() barplots : &lt;BarContainer object of 12 artists&gt; Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) 1### 산점도 12345678910111213import seaborn as snstips = sns.load_dataset(&quot;tips&quot;) # 영수증 데이터이다.# print(tips.info())x = tips['total_bill']y = tips['tip']# 산점도flg, ax = plt.subplots(figsize=(10, 6))ax.scatter(x,y)ax.set_xlabel('Total Bill')ax.set_ylabel('Tip')plt.show &lt;function matplotlib.pyplot.show&gt; 123456789101112131415label, data = tips.groupby('sex')# print(label)# print(data)tips['sex_color'] = tips['sex'].map({'Male': '#2521F6', 'Female': '#EB4036'})#print(tips.head())fix, ax = plt.subplots(figsize=(10,6))for label, data in tips.groupby('sex'): ax.scatter(data['total_bill'], data['tip'], label=label, color=data['sex_color'],alpha=0.5) ax.set_xlabel('Total Bill') ax.set_ylabel('Tip')ax.legend() # 범례plt.show() Seaborn 다음 코드는 위와 같은 결과가 나온다. 하지만 더 간단하다. 123456789import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)# print(tips.info())fig, ax =plt.subplots(figsize=(10,6))sns.scatterplot(x='total_bill', y = 'tip', hue='sex', data = tips)plt.show() 12345678910# 두 개의 그래프를 동시에 표현fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax=ax[1], fit_reg = True)ax[1].set_title(&quot;with linear regression line&quot;)sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax=ax[0], fit_reg = False)ax[0].set_title(&quot;without linear regression line&quot;)plt.show() 막대 그래프 그리기 seaborn 방식12sns.countplot(x=&quot;day&quot;, data=tips)plt.show() 123print(tips['day'].value_counts().index)print(tips['day'].value_counts().values)print(tips['day'].value_counts(ascending=True)) CategoricalIndex(['Sat', 'Sun', 'Thur', 'Fri'], categories=['Thur', 'Fri', 'Sat', 'Sun'], ordered=False, dtype='category') [87 76 62 19] Fri 19 Thur 62 Sun 76 Sat 87 Name: day, dtype: int64 12345678910flg, ax = plt.subplots()ax = sns.countplot(x=&quot;day&quot;, data=tips, order = tips['day'].value_counts().index)for plot in ax.patches: # matplotlib 와 같은 역할을 수행한다. print(plot) height = plot.get_height() ax.text(plot.get_x() + plot.get_width()/2., height, height, ha = 'center', va = 'bottom') ax.set_ylim(-5, 100)plt.show() Rectangle(xy=(-0.4, 0), width=0.8, height=87, angle=0) Rectangle(xy=(0.6, 0), width=0.8, height=76, angle=0) Rectangle(xy=(1.6, 0), width=0.8, height=62, angle=0) Rectangle(xy=(2.6, 0), width=0.8, height=19, angle=0) 어려운 시각화 그래프123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import matplotlib.pyplot as pltimport seaborn as snsimport numpy as npfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)def major_formatter(x, pos): return &quot;%.2f$&quot; % xformatter = FuncFormatter(major_formatter)tips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))ax0 = sns.barplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, ci=None, color='lightgray', alpha=0.85, zorder=2, # alpha는 투명도 ax = ax[0])# groupbygroup_mean = tips.groupby(['day'])['total_bill'].agg('mean')#print(group_mean)h_day = group_mean.sort_values(ascending=False).index[0] # sun 표시#print(h_day)h_mean = group_mean.sort_values(ascending=False).values[0] print(h_mean)# text 추가for plot in ax0.patches: height = np.round(plot.get_height(), 2) # print(height) # Default fontweight = &quot;normal&quot; color = &quot;k&quot; if h_mean == height: fontweight = &quot;bold&quot; color = &quot;darkred&quot; plot.set_facecolor(color) plot.set_edgecolor(&quot;black&quot;) ax0.text(plot.get_x() + plot.get_width()/2., height + 1, height, ha = 'center', size=12, fontweight = fontweight, color = color)# 축 수정ax0.set_ylim(-3, 30)ax0.set_title(&quot;Bar Graph&quot;, size = 16)# 테두리(spines) 삭제ax0.spines['top'].set_visible(False)ax0.spines['left'].set_position((&quot;outward&quot;, 20))ax0.spines['left'].set_visible(False)ax0.spines['right'].set_visible(False)ax0.yaxis.set_major_locator(MultipleLocator(10))ax0.yaxis.set_major_formatter(formatter)ax0.yaxis.set_minor_locator(MultipleLocator(5))ax0.set_ylabel(&quot;Avg. Total Bill($)&quot;, fontsize=14)ax0.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color = &quot;lightgray&quot;)ax0.grid(axis=&quot;y&quot;, which=&quot;major&quot;, ls = &quot;:&quot;)for xtick in ax0.get_xticklabels(): print(xtick) if xtick.get_text() == h_day: xtick.set_color(&quot;darkred&quot;) xtick.set_fontweight(&quot;demibold&quot;)ax0.set_xticklabels(['Thursday', 'Friday', 'Saturday', 'Sunday'], size = 12)plt.show() 21.41 Text(0, 0, 'Thur') Text(0, 0, 'Fri') Text(0, 0, 'Sat') Text(0, 0, 'Sun')","link":"/2022/03/26/visualization_tutorial_01/"},{"title":"pandas_10minutes","text":"Pandas 10분 완성https://dataitgirls2.github.io/10minutes2pandas/ 1234# 라이브러리 불러오기import pandas as pdimport numpy as npimport matplotlib.pyplot as plt 1.Object Creation (객체 생성) Pandas는 값을 가지고 있는 리스트를 통해 Series를 만들고, 정수로 만들어진 인덱스를 기본값으로 불러온다. 123# Series를 이용한 객체 생성s = pd.Series([1,3,5,np.nan,6,8])s 0 1.0 1 3.0 2 5.0 3 NaN 4 6.0 5 8.0 dtype: float64 datetime 인덱스와 레이블이 있는 열을 가지고 있는 numpy 배열을 전달하여 데이터프레임을 만든다. 123# date_range()를 이용해 20130101을 포함한 연속적인 6일의 데이터를 넣는다.dates = pd.date_range('20130101', periods = 6)dates DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D') 123# 데이터 프레임 생성df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 -0.214371 -0.489334 0.807876 -2.328570 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 2013-01-04 -2.044753 -0.853425 1.582471 -0.756233 2013-01-05 0.394973 -0.526762 0.393856 1.550660 2013-01-06 -1.665879 0.184903 1.905710 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-98ec8384-9a3f-4ee3-9d62-d8f6d1821857 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-98ec8384-9a3f-4ee3-9d62-d8f6d1821857'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Series와 같은 것으로 변환될 수 있는 객체들의 dict로 구성된 데이터프레임을 만든다. 12345678df2 = pd.DataFrame({'A' : 1., 'B' : pd.Timestamp('20130102'), 'C' : pd.Series(1, index=list(range(4)), dtype='float32'), 'D' : np.array([3] * 4,dtype = 'int32'), 'E' : pd.Categorical([&quot;test&quot;, &quot;train&quot;, &quot;test&quot;, &quot;train&quot;]), 'F' : 'foo'})df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-32a9a2b4-301b-48af-8afa-569444b4838a button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-32a9a2b4-301b-48af-8afa-569444b4838a'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 데이터프레임 결과물의 열은 다양한 데이터 타입 (dtypes) 으로 구성 1df2.dtypes A float64 B datetime64[ns] C float32 D int32 E category F object dtype: object 2.Viewing Data (데이터 확인하기) 데이터프레임의 가장 윗 줄과 마지막 줄을 확인하고 싶을 때에 사용하는 방법은 다음과 같다. 12df.tail(3) # 끝에서부터 3줄을 출력df.tail() # 끝에서부터 5줄을 출력. 디폴트값이 5이다 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 2013-01-04 -2.044753 -0.853425 1.582471 -0.756233 2013-01-05 0.394973 -0.526762 0.393856 1.550660 2013-01-06 -1.665879 0.184903 1.905710 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-b90adfec-6c56-41b4-a15c-699d26a51033 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-b90adfec-6c56-41b4-a15c-699d26a51033'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1df.head() # 처음 5줄을 출력. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 -0.214371 -0.489334 0.807876 -2.328570 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 2013-01-04 -2.044753 -0.853425 1.582471 -0.756233 2013-01-05 0.394973 -0.526762 0.393856 1.550660 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-1d5aaccf-3123-46cc-a71a-b7f235656a2f button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-1d5aaccf-3123-46cc-a71a-b7f235656a2f'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 인덱스(index), 열(column) 그리고 numpy 데이터에 대한 세부 정보를 표시 1df.index DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D') 1df.columns Index(['A', 'B', 'C', 'D'], dtype='object') 1df.values array([[-0.21437119, -0.48933404, 0.80787593, -2.32856993], [-0.01876194, -0.43804563, 0.59387975, 0.67184854], [-0.59620717, 0.08161493, 0.18211706, -2.06300731], [-2.0447528 , -0.85342539, 1.58247067, -0.75623263], [ 0.39497306, -0.52676189, 0.39385602, 1.55066002], [-1.66587853, 0.18490331, 1.9057098 , 2.34549952]]) describe()는 데이터의 대략적인 통계적 정보 요약을 보여준다. 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D count 6.000000 6.000000 6.000000 6.000000 mean -0.690833 -0.340175 0.910985 -0.096634 std 0.964410 0.395899 0.685599 1.926208 min -2.044753 -0.853425 0.182117 -2.328570 25% -1.398461 -0.517405 0.443862 -1.736314 50% -0.405289 -0.463690 0.700878 -0.042192 75% -0.067664 -0.048300 1.388822 1.330957 max 0.394973 0.184903 1.905710 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-bc50d2c1-8824-4181-b8ce-c7aecf4a30e1 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-bc50d2c1-8824-4181-b8ce-c7aecf4a30e1'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 데이터를 전치한다. 즉, 두 축을 서로 바꾼다 1df.T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06 A -0.214371 -0.018762 -0.596207 -2.044753 0.394973 -1.665879 B -0.489334 -0.438046 0.081615 -0.853425 -0.526762 0.184903 C 0.807876 0.593880 0.182117 1.582471 0.393856 1.905710 D -2.328570 0.671849 -2.063007 -0.756233 1.550660 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-cfc48a53-c108-4b41-bf62-f85fc6923d20 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-cfc48a53-c108-4b41-bf62-f85fc6923d20'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 축 별로 정렬한다. 12df.sort_index(axis=1, ascending=False)# axis=1 일때, 열방향으로 실행한다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } D C B A 2013-01-01 -2.328570 0.807876 -0.489334 -0.214371 2013-01-02 0.671849 0.593880 -0.438046 -0.018762 2013-01-03 -2.063007 0.182117 0.081615 -0.596207 2013-01-04 -0.756233 1.582471 -0.853425 -2.044753 2013-01-05 1.550660 0.393856 -0.526762 0.394973 2013-01-06 2.345500 1.905710 0.184903 -1.665879 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-2b34e281-4cce-48fe-b140-c57dc7828ca4 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-2b34e281-4cce-48fe-b140-c57dc7828ca4'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 값 별로 정렬한다. 1df.sort_values(by='B') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-04 -2.044753 -0.853425 1.582471 -0.756233 2013-01-05 0.394973 -0.526762 0.393856 1.550660 2013-01-01 -0.214371 -0.489334 0.807876 -2.328570 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 2013-01-06 -1.665879 0.184903 1.905710 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-30e7da7b-4a36-43a6-b2c3-a5a382f252de button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-30e7da7b-4a36-43a6-b2c3-a5a382f252de'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 3.Selection (선택) 주석 (Note) : 선택과 설정을 위한 Python / Numpy의 표준화된 표현들이 직관적이며, 코드 작성을 위한 양방향 작업에 유용하지만 우리는 Pandas에 최적화된 데이터 접근 방법인 .at, .iat, .loc 및 .iloc 을 추천. Getting (데이터 얻기) df.A 와 동일한 Series를 생성하는 단일 열을 선택 1df['A'] 2013-01-01 -0.214371 2013-01-02 -0.018762 2013-01-03 -0.596207 2013-01-04 -2.044753 2013-01-05 0.394973 2013-01-06 -1.665879 Freq: D, Name: A, dtype: float64 행을 분할하는 [ ]를 통해 선택한다. 1df[0:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.654753 -0.366034 -1.440226 -1.043957 2013-01-02 1.589167 0.321939 1.393342 0.898153 2013-01-03 0.270879 0.107423 -2.032053 1.861947 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-42a08968-1f35-45a3-bca9-318f73f513c6 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-42a08968-1f35-45a3-bca9-318f73f513c6'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1df['20130102':'20130104'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 2013-01-04 -2.044753 -0.853425 1.582471 -0.756233 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-ebb43e9b-1f8f-4438-93a1-e004bc46108e button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-ebb43e9b-1f8f-4438-93a1-e004bc46108e'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Selection by Label (Label을 통한 선택) 라벨을 사용하여 횡단면을 얻는다. 1df.loc[dates[0]] A -0.214371 B -0.489334 C 0.807876 D -2.328570 Name: 2013-01-01 00:00:00, dtype: float64 라벨을 사용하여 여러 축의 데이터를 획득한다. 1df.loc[:,['A','B']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-01 -0.214371 -0.489334 2013-01-02 -0.018762 -0.438046 2013-01-03 -0.596207 0.081615 2013-01-04 -2.044753 -0.853425 2013-01-05 0.394973 -0.526762 2013-01-06 -1.665879 0.184903 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-0d130634-6f70-4a3b-a931-3907cbf47eb6 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-0d130634-6f70-4a3b-a931-3907cbf47eb6'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 양쪽 종단점을 포함한 라벨 슬라이싱을 표시. 1df.loc['20130102':'20130104', ['A','B']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-02 -0.018762 -0.438046 2013-01-03 -0.596207 0.081615 2013-01-04 -2.044753 -0.853425 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-80998ed9-78c8-48ef-84e6-b2e58d3420c3 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-80998ed9-78c8-48ef-84e6-b2e58d3420c3'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 반환되는 객체의 차원를 줄인다. 1df.loc['20130102',['A','B']] A -0.018762 B -0.438046 Name: 2013-01-02 00:00:00, dtype: float64 스칼라 값을 얻는다. 1df.loc[dates[0], 'A'] -0.21437119207750993 스칼라 값을 더 빠르게 구하는 방법 (앞선 메소드와 동일하다) 1df.at[dates[0], 'A'] -0.21437119207750993 Selection by Position(위치로 선택하기) 넘겨받은 정수의 위치를 기준으로 선택. 1df.iloc[3] A -2.044753 B -0.853425 C 1.582471 D -0.756233 Name: 2013-01-04 00:00:00, dtype: float64 정수로 표기된 슬라이스들을 통해, numpy / python과 유사하게 작동. 1df.iloc[3:5, 0:2] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-04 -2.044753 -0.853425 2013-01-05 0.394973 -0.526762 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-a6c9e7cd-47c2-42bc-8726-b9b8dbf72bb9 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-a6c9e7cd-47c2-42bc-8726-b9b8dbf72bb9'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 정수로 표기된 위치값의 리스트를 통하여 numpy / python 의 스타일과 유사해진다. 1df.iloc[[1, 2, 4], [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A C 2013-01-02 -0.018762 0.593880 2013-01-03 -0.596207 0.182117 2013-01-05 0.394973 0.393856 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-1d8279d9-f642-48e7-8d6a-5006bade95b3 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-1d8279d9-f642-48e7-8d6a-5006bade95b3'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 다음은 명시적으로 행을 나누고자 하는 경우이다 즉, 한쪽을 공백으로 둘 경우 1df.iloc[1:3, : ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-02 -0.018762 -0.438046 0.593880 0.671849 2013-01-03 -0.596207 0.081615 0.182117 -2.063007 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-f8cec5e2-bbc6-4151-9e24-a55e5e4cd2b8 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-f8cec5e2-bbc6-4151-9e24-a55e5e4cd2b8'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 다음은 명시적으로 열을 나누고자 하는 경우이다 즉, 한쪽을 공백으로 둘 경우 1df.iloc[ : , 1:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } B C 2013-01-01 -0.489334 0.807876 2013-01-02 -0.438046 0.593880 2013-01-03 0.081615 0.182117 2013-01-04 -0.853425 1.582471 2013-01-05 -0.526762 0.393856 2013-01-06 0.184903 1.905710 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-e2e93a02-91f2-43f7-a503-bec4339b83b8 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-e2e93a02-91f2-43f7-a503-bec4339b83b8'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 다음은 명시적으로 (특정한) 값을 얻고자 하는 경우이다. 1df.iloc[1, 1] -0.43804562902186034 스칼라 값을 빠르게 얻는 방법 (위의 방식과 동일하다) 1df.iat[1,1] -0.43804562902186034 Boolean Indexing 데이터를 선택하기 위해 단일 열의 값을 사용 1df[df.A &gt; 0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-05 0.394973 -0.526762 0.393856 1.55066 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-4f4aed32-1929-4051-a6c9-8f593fb92c84 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-4f4aed32-1929-4051-a6c9-8f593fb92c84'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Boolean 조건을 충족하는 데이터프레임에서 값을 선택 1df[df &gt; 0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 NaN NaN 0.807876 NaN 2013-01-02 NaN NaN 0.593880 0.671849 2013-01-03 NaN 0.081615 0.182117 NaN 2013-01-04 NaN NaN 1.582471 NaN 2013-01-05 0.394973 NaN 0.393856 1.550660 2013-01-06 NaN 0.184903 1.905710 2.345500 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-35a1e446-5c1c-4a6c-b39d-6ff2b7801761 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-35a1e446-5c1c-4a6c-b39d-6ff2b7801761'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; isin 필터링을 위한 메소드이다. 123df2 = df.copy()df2 = ['one', 'one', 'two', 'three', 'four', 'three']df2 1# df2[df2['E'].isin(['two','four'])] Setting (설정) 새 열을 설정하면 데이터가 인덱스 별로 자동 정렬된다. 12s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))s1 2013-01-02 1 2013-01-03 2 2013-01-04 3 2013-01-05 4 2013-01-06 5 2013-01-07 6 Freq: D, dtype: int64 1df['F'] = s1 라벨에 의해 값을 설정한다. 1df.at[dates[0], 'A'] = 0 위치에 의해 값을 설정한다. 1df.iat[0, 1] = 0 Numpy 배열을 사용한 할당에 의해 값을 설정한다. 1df.loc[:, 'D'] = np.array([5] * len(df)) 위 설정대로 작동한 결과다. 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 0.807876 5 NaN 2013-01-02 -0.018762 -0.438046 0.593880 5 1.0 2013-01-03 -0.596207 0.081615 0.182117 5 2.0 2013-01-04 -2.044753 -0.853425 1.582471 5 3.0 2013-01-05 0.394973 -0.526762 0.393856 5 4.0 2013-01-06 -1.665879 0.184903 1.905710 5 5.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-12bdced2-022e-4cec-87a4-12165a361bd7 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-12bdced2-022e-4cec-87a4-12165a361bd7'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; where 연산을 설정합니다. 123df2 = df.copy()df2[df2 &gt; 0] = -df2df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 -0.807876 -5 NaN 2013-01-02 -0.018762 -0.438046 -0.593880 -5 -1.0 2013-01-03 -0.596207 -0.081615 -0.182117 -5 -2.0 2013-01-04 -2.044753 -0.853425 -1.582471 -5 -3.0 2013-01-05 -0.394973 -0.526762 -0.393856 -5 -4.0 2013-01-06 -1.665879 -0.184903 -1.905710 -5 -5.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-2e3a7cd9-4958-46ba-a9ca-9fb4031816c0 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-2e3a7cd9-4958-46ba-a9ca-9fb4031816c0'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 4.Missing Data (결측치) Pandas는 결측치를 표현하기 위해 주로 np.nan 값을 사용한다. 이 방법은 기본 설정값이지만 계산에는 포함되지 않는다. Reindexing으로 지정된 축 상의 인덱스를 변경 / 추가 / 삭제 가능. Reindexing은 데이터의 복사본을 반환. 123df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])df1.loc[dates[0]:dates[1], 'E'] = 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 0.000000 0.000000 0.807876 5 NaN 1.0 2013-01-02 -0.018762 -0.438046 0.593880 5 1.0 1.0 2013-01-03 -0.596207 0.081615 0.182117 5 2.0 NaN 2013-01-04 -2.044753 -0.853425 1.582471 5 3.0 NaN &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-bd5a580c-316a-44a4-b5af-496ed1ad2f48 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-bd5a580c-316a-44a4-b5af-496ed1ad2f48'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 결측치를 가지고 있는 행들을 지운다. 1df1.dropna(how = 'any') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-02 -0.018762 -0.438046 0.59388 5 1.0 1.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-e2491041-b1d4-4902-9dce-0ef94792d204 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-e2491041-b1d4-4902-9dce-0ef94792d204'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 결측치를 채워 넣는다. 1df1.fillna(value=5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 0.000000 0.000000 0.807876 5 5.0 1.0 2013-01-02 -0.018762 -0.438046 0.593880 5 1.0 1.0 2013-01-03 -0.596207 0.081615 0.182117 5 2.0 5.0 2013-01-04 -2.044753 -0.853425 1.582471 5 3.0 5.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-d9ef038f-e4ba-4702-b903-2a4056ec371e button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-d9ef038f-e4ba-4702-b903-2a4056ec371e'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; nan인 값에 boolean을 통한 표식을 얻는다. 데이터프레임의 모든 값이 boolean 형태로 표시되며, nan 값에만 True를 표시한다. 1pd.isna(df1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 False False False False True False 2013-01-02 False False False False False False 2013-01-03 False False False False False True 2013-01-04 False False False False False True &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-5ac60ecc-0098-4e10-8e23-74a0aa20e121 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-5ac60ecc-0098-4e10-8e23-74a0aa20e121'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 5.Operation (연산)Stats (통계) 일반적으로 결측치를 제외한 후 연산. 기술통계를 수행한다. 1df.mean() A -0.655105 B -0.258619 C 0.910985 D 5.000000 F 3.000000 dtype: float64 다른 축에서도 동일한 연산을 수행. 1df.mean(1) 2013-01-01 1.451969 2013-01-02 1.227414 2013-01-03 1.333505 2013-01-04 1.336858 2013-01-05 1.852413 2013-01-06 2.084947 Freq: D, dtype: float64 정렬이 필요하다. 차원이 다른 객체로 연산해보자. pandas는 지정된 차원을 따라 자동으로 브로드 캐스팅된다. broadcast란 n차원이나 스칼라 값으로 연산을 수행할 때 도출되는 결과의 규칙을 설명하는 것을 의미 12s = pd.Series([1, 3, 4, np.nan, 6, 8], index=dates)s 2013-01-01 1.0 2013-01-02 3.0 2013-01-03 4.0 2013-01-04 NaN 2013-01-05 6.0 2013-01-06 8.0 Freq: D, dtype: float64 위 코드를 shift로 2칸 옮긴 것 12s = pd.Series([1, 3, 4, np.nan, 6, 8], index=dates).shift(2)s 2013-01-01 NaN 2013-01-02 NaN 2013-01-03 1.0 2013-01-04 3.0 2013-01-05 4.0 2013-01-06 NaN Freq: D, dtype: float64 index를 축(axis)으로 실행 1df.sub(s, axis='index') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 NaN NaN NaN NaN NaN 2013-01-02 NaN NaN NaN NaN NaN 2013-01-03 -1.596207 -0.918385 -0.817883 4.0 1.0 2013-01-04 -5.044753 -3.853425 -1.417529 2.0 0.0 2013-01-05 -3.605027 -4.526762 -3.606144 1.0 0.0 2013-01-06 NaN NaN NaN NaN NaN &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-99b442a2-cd95-4ff7-886d-18b60cfb80eb button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-99b442a2-cd95-4ff7-886d-18b60cfb80eb'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Apply (적용) 데이터에 함수를 적용한다. 1df.apply(np.cumsum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 0.807876 5 NaN 2013-01-02 -0.018762 -0.438046 1.401756 10 1.0 2013-01-03 -0.614969 -0.356431 1.583873 15 3.0 2013-01-04 -2.659722 -1.209856 3.166343 20 6.0 2013-01-05 -2.264749 -1.736618 3.560199 25 10.0 2013-01-06 -3.930627 -1.551715 5.465909 30 15.0 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-5f71bb31-515e-4d3e-b14d-f49a6239f43b button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-5f71bb31-515e-4d3e-b14d-f49a6239f43b'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1df.apply(lambda x: x.max() - x.min()) A 2.439726 B 1.038329 C 1.723593 D 0.000000 F 4.000000 dtype: float64 Histogramming (히스토그래밍)12s = pd.Series(np.random.randint(0, 7, size=10)) # 랜덤 생성s 0 1 1 5 2 0 3 1 4 6 5 6 6 5 7 5 8 5 9 1 dtype: int64 1s.value_counts() 5 4 1 3 6 2 0 1 dtype: int64 String Methods (문자열 메소드) Series는 다음의 코드와 같이 문자열 처리 메소드 모음 (set)을 가지고 있다. 이 모음은 배열의 각 요소를 쉽게 조작할 수 있도록 만들어주는 문자열의 속성에 포함되어 있다. 문자열의 패턴 일치 확인은 기본적으로 정규 표현식을 사용. 12s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])s.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 NaN 6 caba 7 dog 8 cat dtype: object 6.Merge (병합)concat (연결) 결합 (join) / 병합 (merge) 형태의 연산에 대한 인덱스, 관계 대수 기능을 위한 다양한 형태의 논리를 포함한 Series, 데이터프레임, Panel 객체를 손쉽게 결합할 수 있도록 하는 다양한 기능을 pandas 에서 제공한다. concat()으로 pandas 객체를 연결한다. 12df = pd.DataFrame(np.random.randn(10, 4))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 -0.639128 -0.371715 -2.320589 0.932025 1 -1.041656 0.646479 1.551379 -0.353387 2 -0.782444 0.677232 -0.050054 -0.054370 3 -0.418260 0.673768 -1.694420 0.193668 4 0.788359 -0.308937 -0.314680 -0.058661 5 0.457466 -2.021977 0.611340 -0.538168 6 1.355963 1.295236 -0.399497 -0.052334 7 -0.324138 -0.165932 0.290442 0.531520 8 -0.386876 0.217569 0.926404 -0.813724 9 -0.452338 -0.259533 -0.810046 1.186298 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-64ce2183-4d4b-4538-857b-4b2f38748c8b button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-64ce2183-4d4b-4538-857b-4b2f38748c8b'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1234# break it into pieces# 조각내고 concat을 통해 다시 연결한다.pieces = [df[ : 3], df[3 : 7], df[7 : ]]pd.concat(pieces) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 -0.639128 -0.371715 -2.320589 0.932025 1 -1.041656 0.646479 1.551379 -0.353387 2 -0.782444 0.677232 -0.050054 -0.054370 3 -0.418260 0.673768 -1.694420 0.193668 4 0.788359 -0.308937 -0.314680 -0.058661 5 0.457466 -2.021977 0.611340 -0.538168 6 1.355963 1.295236 -0.399497 -0.052334 7 -0.324138 -0.165932 0.290442 0.531520 8 -0.386876 0.217569 0.926404 -0.813724 9 -0.452338 -0.259533 -0.810046 1.186298 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-b9f8c250-4e6a-49c3-8b57-729bd58c514f button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-b9f8c250-4e6a-49c3-8b57-729bd58c514f'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Join (결합)SQL 방식으로 병합한다. 123left = pd.DataFrame({'key' : ['foo', 'foo'], 'lval' : [1, 2]})right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})left .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval 0 foo 1 1 foo 2 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-5ee0033f-5dc0-4ee1-a4ae-aab4984c9f56 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-5ee0033f-5dc0-4ee1-a4ae-aab4984c9f56'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key rval 0 foo 4 1 foo 5 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-7b2e03cd-9c2d-471a-aba2-b4a36968ffa5 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-7b2e03cd-9c2d-471a-aba2-b4a36968ffa5'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 위 두 가지를 병합하기 1pd.merge(left, right, on = 'key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-62da57e4-df6e-4fe9-b5a0-3094a8ba0ed2 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-62da57e4-df6e-4fe9-b5a0-3094a8ba0ed2'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Append (추가) 데이터프레임에 행을 추가한다. 12df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 -0.909696 0.146335 -0.568276 -0.434510 1 -0.802681 0.235747 -0.751299 -0.053560 2 2.005541 -1.265754 -1.152046 -0.081151 3 -0.422940 -0.095189 -1.634583 0.180732 4 -1.535375 -0.594391 -1.102247 0.047852 5 0.369960 -0.902356 -1.196501 -0.109521 6 -1.369044 -2.044557 -0.487275 0.267463 7 0.439153 0.003023 -1.716505 -2.119485 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-fb76804e-7023-4762-a17b-9f4e79e4d070 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-fb76804e-7023-4762-a17b-9f4e79e4d070'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 3행의 내용을 복사하여 8행을 추가한다. 12s = df.iloc[3]df.append(s, ignore_index = True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 -0.909696 0.146335 -0.568276 -0.434510 1 -0.802681 0.235747 -0.751299 -0.053560 2 2.005541 -1.265754 -1.152046 -0.081151 3 -0.422940 -0.095189 -1.634583 0.180732 4 -1.535375 -0.594391 -1.102247 0.047852 5 0.369960 -0.902356 -1.196501 -0.109521 6 -1.369044 -2.044557 -0.487275 0.267463 7 0.439153 0.003023 -1.716505 -2.119485 8 -0.422940 -0.095189 -1.634583 0.180732 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-9c5c9e98-661f-4d00-b16c-b0e389424ef0 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-9c5c9e98-661f-4d00-b16c-b0e389424ef0'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 7.Grouping (그룹화) 룹화는 다음 단계 중 하나 이상을 포함하는 과정을 가리킨다. 몇몇 기준에 따라 여러 그룹으로 데이터를 분할 (splitting) 각 그룹에 독립적으로 함수를 적용 (applying) 결과물들을 하나의 데이터 구조로 결합 (combining) 123456789df = pd.DataFrame( { 'A' : ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'], 'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'], 'C' : np.random.randn(8), 'D' : np.random.randn(8) })df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 foo one 0.144726 0.653074 1 bar one -0.590503 0.128616 2 foo two 1.816665 -1.533646 3 bar three -1.574489 -0.140956 4 foo two 0.103910 1.448011 5 bar two -0.610817 0.742873 6 foo one -1.576850 0.444138 7 foo three 0.857080 0.157513 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-eb85beec-778a-44c7-aac7-eb71caf64586 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-eb85beec-778a-44c7-aac7-eb71caf64586'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 생성된 데이터프레임을 그룹화한 후 각 그룹에 sum() 함수를 적용. 1df.groupby('A').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A bar -2.775808 0.730534 foo 1.345531 1.169089 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-1aa22f34-79db-46e3-ae05-1187c99d6af5 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-1aa22f34-79db-46e3-ae05-1187c99d6af5'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 여러 열을 기준으로 그룹화하면 계층적 인덱스가 형성된다. 여기에도 sum 함수를 적용 가능. 1df.groupby(['A', 'B']).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A B bar one -0.590503 0.128616 three -1.574489 -0.140956 two -0.610817 0.742873 foo one -1.432124 1.097212 three 0.857080 0.157513 two 1.920575 -0.085635 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-4d41ac7d-2fef-4b0e-a140-e235f321dab0 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-4d41ac7d-2fef-4b0e-a140-e235f321dab0'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 8.Reshaping (변형)Stack (스택)123456789tuples = list(zip(*[['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]))index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])df2 = df[:4]df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -0.827364 -1.346867 two -1.197194 -0.118960 baz one -1.071918 0.825303 two 0.507340 -1.517231 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-5a082081-c6ac-484f-9748-3682bcfb55a3 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-5a082081-c6ac-484f-9748-3682bcfb55a3'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; stack() 메소드는 데이터프레임 열들의 계층을 “압축” 한다. 12stacked = df2.stack()stacked first second bar one A -0.827364 B -1.346867 two A -1.197194 B -0.118960 baz one A -1.071918 B 0.825303 two A 0.507340 B -1.517231 dtype: float64 “Stack된” 데이터프레임 또는 (MultiIndex를 인덱스로 사용하는) Series인 경우, stack()의 역 연산은 unstack()이며, 기본적으로 마지막 계층을 unstack 한다. 1stacked.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -0.827364 -1.346867 two -1.197194 -0.118960 baz one -1.071918 0.825303 two 0.507340 -1.517231 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-55a6a6ce-eb1f-401f-8bcb-8246e05bc0dd button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-55a6a6ce-eb1f-401f-8bcb-8246e05bc0dd'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1stacked.unstack(1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } second one two first bar A -0.827364 -1.197194 B -1.346867 -0.118960 baz A -1.071918 0.507340 B 0.825303 -1.517231 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-d48353b8-1fdf-416f-b815-fc90f9b22135 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-d48353b8-1fdf-416f-b815-fc90f9b22135'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 1stacked.unstack(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first bar baz second one A -0.827364 -1.071918 B -1.346867 0.825303 two A -1.197194 0.507340 B -0.118960 -1.517231 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-2305db67-99b3-4d0f-94cd-f423b56a95f6 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-2305db67-99b3-4d0f-94cd-f423b56a95f6'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Pivot Tables (피봇 테이블)1234567df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3, 'B' : ['A', 'B', 'C'] * 4, 'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2, 'D' : np.random.randn(12), 'E' : np.random.randn(12)})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 0 one A foo -0.548983 0.943447 1 one B foo -0.400173 1.836891 2 two C foo 0.995067 0.029331 3 three A bar -0.693458 0.457755 4 one B bar 0.786452 -0.665671 5 one C bar -0.686570 -1.718177 6 two A foo 0.338070 0.163933 7 three B foo 1.793455 -0.410172 8 one C foo -0.271664 -0.857467 9 one A bar 0.979950 -1.324755 10 two B bar -0.689860 0.907164 11 three C bar -1.210862 -0.276602 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-b66bc639-fd5d-4d5c-8180-1ed50d78e959 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-b66bc639-fd5d-4d5c-8180-1ed50d78e959'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 이 데이터로부터 피봇 테이블을 매우 쉽게 생성 가능하다. 1pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C bar foo A B one A 0.979950 -0.548983 B 0.786452 -0.400173 C -0.686570 -0.271664 three A -0.693458 NaN B NaN 1.793455 C -1.210862 NaN two A NaN 0.338070 B -0.689860 NaN C NaN 0.995067 &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-3e058eed-2670-412b-9bdb-87227d4add5d button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-3e058eed-2670-412b-9bdb-87227d4add5d'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 9.Time Series (시계열) Pandas는 자주 일어나는 변환 (예시 : 5분마다 일어나는 데이터에 대한 2차 데이터 변환) 사이에 수행하는 리샘플링 연산을 위한 간단하고, 강력하며, 효율적인 함수를 제공. 이는 재무 (금융) 응용에서 매우 일반적이지만 이에 국한되지는 않는다. 123rng = pd.date_range('1/1/2012', periods=100, freq='S')ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)ts.resample('5Min').sum() 2012-01-01 23654 Freq: 5T, dtype: int64 시간대를 표현 123rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')ts = pd.Series(np.random.randn(len(rng)), rng)ts 2012-03-06 -0.480140 2012-03-07 -0.904772 2012-03-08 0.386809 2012-03-09 0.873791 2012-03-10 0.478778 Freq: D, dtype: float64 12ts_utc = ts.tz_localize('UTC')ts_utc 2012-03-06 00:00:00+00:00 -0.480140 2012-03-07 00:00:00+00:00 -0.904772 2012-03-08 00:00:00+00:00 0.386809 2012-03-09 00:00:00+00:00 0.873791 2012-03-10 00:00:00+00:00 0.478778 Freq: D, dtype: float64 다른 시간대로 변환한다. 1ts_utc.tz_convert('US/Eastern') 2012-03-05 19:00:00-05:00 -0.480140 2012-03-06 19:00:00-05:00 -0.904772 2012-03-07 19:00:00-05:00 0.386809 2012-03-08 19:00:00-05:00 0.873791 2012-03-09 19:00:00-05:00 0.478778 Freq: D, dtype: float64 시간 표현 &lt;–&gt; 기간 표현으로 변환한다. 123rng = pd.date_range('1/1/2012', periods=5, freq='M')ts = pd.Series(np.random.randn(len(rng)), index=rng)ts 2012-01-31 -0.914418 2012-02-29 -0.077113 2012-03-31 -0.006825 2012-04-30 0.007167 2012-05-31 -0.733946 Freq: M, dtype: float64 12ps = ts.to_period()ps 2012-01 -0.914418 2012-02 -0.077113 2012-03 -0.006825 2012-04 0.007167 2012-05 -0.733946 Freq: M, dtype: float64 1ps.to_timestamp() 2012-01-01 -0.914418 2012-02-01 -0.077113 2012-03-01 -0.006825 2012-04-01 0.007167 2012-05-01 -0.733946 Freq: MS, dtype: float64 기간 &lt;–&gt; 시간 변환은 편리한 산술 기능들을 사용할 수 있도록 만들어준다. 다음 예제에서, 11월에 끝나는 연말 결산의 분기별 빈도를 분기말 익월의 월말일 오전 9시로 변환한다. 1234prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')ts = pd.Series(np.random.randn(len(prng)), prng)ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9ts.head() 1990-03-01 09:00 -0.685539 1990-06-01 09:00 -1.076153 1990-09-01 09:00 0.737103 1990-12-01 09:00 -1.115201 1991-03-01 09:00 0.680304 Freq: H, dtype: float64 10.Categoricals (범주화) Pandas는 데이터프레임 내에 범주형 데이터를 포함할 수 있다. 1df = pd.DataFrame({&quot;id&quot;:[1,2,3,4,5,6], &quot;raw_grade&quot;:['a', 'b', 'b', 'a', 'a', 'e']}) 가공하지 않은 성적을 범주형 데이터로 변환 12df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)df[&quot;grade&quot;] 0 a 1 b 2 b 3 a 4 a 5 e Name: grade, dtype: category Categories (3, object): ['a', 'b', 'e'] 범주에 더 의미 있는 이름을 붙여야 한다. (Series.cat.categories로 할당하는 것이 적합) 12df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;])df[&quot;grade&quot;] 0 a 1 b 2 b 3 a 4 a 5 e Name: grade, dtype: category Categories (3, object): ['a', 'b', 'e'] 정렬은 사전 순서가 아닌, 해당 범주에서 지정된 순서대로 배열된다. 131번에서 very bad, bad, medium, good, very good 의 순서로 기재되어 있기 때문에 정렬 결과도 해당 순서대로 배열. 1df.sort_values(by=&quot;grade&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id raw_grade grade 0 1 a a 3 4 a a 4 5 a a 1 2 b b 2 3 b b 5 6 e e &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-b7146b32-62f2-46d3-9fd0-73a739ee4d33 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-b7146b32-62f2-46d3-9fd0-73a739ee4d33'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 범주의 열을 기준으로 그룹화하면 빈 범주도 표시된다. 1df.groupby(&quot;grade&quot;).size() grade a 3 b 2 e 1 dtype: int64 11.Plotting (그래프)123ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))ts = ts.cumsum()ts.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f177f1ef3d0&gt; 데이터프레임에서 plot() 메소드는 라벨이 존재하는 모든 열을 그릴 때 편리하다. 12345df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=['A', 'B', 'C', 'D']) df = df.cumsum()plt.figure(); df.plot(); plt.legend(loc='best') &lt;matplotlib.legend.Legend at 0x7f177ebf3a50&gt; &lt;Figure size 432x288 with 0 Axes&gt; 12.Getting Data In / Out (데이터 입/출력)CSV csv 파일에 쓴다. 1df.to_csv('foo.csv') csv 파일을 읽어낸다. 1pd.read_csv('foo.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 A B C D 0 2000-01-01 0.005390 -0.616651 2.261198 -0.868199 1 2000-01-02 -0.084304 -0.247153 0.097660 -0.381440 2 2000-01-03 1.540081 0.806761 0.628394 -0.810376 3 2000-01-04 2.339388 0.573873 2.907442 0.339424 4 2000-01-05 0.938390 2.164131 3.848056 0.158632 ... ... ... ... ... ... 995 2002-09-22 -4.732994 38.365117 10.155791 -34.795312 996 2002-09-23 -7.505606 38.661194 10.837375 -35.956062 997 2002-09-24 -4.967844 37.522602 10.977005 -35.639584 998 2002-09-25 -3.707181 35.950703 11.191352 -36.306747 999 2002-09-26 -1.984682 36.604786 10.741370 -35.995049 1000 rows × 5 columns &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-f2acd47f-3ad2-400d-b1c5-ff10dfa1d025 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-f2acd47f-3ad2-400d-b1c5-ff10dfa1d025'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; HDF5 HDFStores에 읽고 쓴다. 1df.to_hdf('foo.h5','df') HDF5 Store에서 읽어온다. 1pd.read_hdf('foo.h5', 'df') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2000-01-01 0.005390 -0.616651 2.261198 -0.868199 2000-01-02 -0.084304 -0.247153 0.097660 -0.381440 2000-01-03 1.540081 0.806761 0.628394 -0.810376 2000-01-04 2.339388 0.573873 2.907442 0.339424 2000-01-05 0.938390 2.164131 3.848056 0.158632 ... ... ... ... ... 2002-09-22 -4.732994 38.365117 10.155791 -34.795312 2002-09-23 -7.505606 38.661194 10.837375 -35.956062 2002-09-24 -4.967844 37.522602 10.977005 -35.639584 2002-09-25 -3.707181 35.950703 11.191352 -36.306747 2002-09-26 -1.984682 36.604786 10.741370 -35.995049 1000 rows × 4 columns &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-d8254976-8070-4b22-bdc3-11fbbd746968 button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-d8254976-8070-4b22-bdc3-11fbbd746968'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; Excel MS Excel에 읽고 쓴다. 엑셀 파일에 쓴다. 1df.to_excel('foo.xlsx', sheet_name='Sheet1') 엑셀 파일을 읽어온다. 1pd.read_excel('foo.xlsx', 'Sheet1', index_col = None, na_values=['NA']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 A B C D 0 2000-01-01 0.005390 -0.616651 2.261198 -0.868199 1 2000-01-02 -0.084304 -0.247153 0.097660 -0.381440 2 2000-01-03 1.540081 0.806761 0.628394 -0.810376 3 2000-01-04 2.339388 0.573873 2.907442 0.339424 4 2000-01-05 0.938390 2.164131 3.848056 0.158632 ... ... ... ... ... ... 995 2002-09-22 -4.732994 38.365117 10.155791 -34.795312 996 2002-09-23 -7.505606 38.661194 10.837375 -35.956062 997 2002-09-24 -4.967844 37.522602 10.977005 -35.639584 998 2002-09-25 -3.707181 35.950703 11.191352 -36.306747 999 2002-09-26 -1.984682 36.604786 10.741370 -35.995049 1000 rows × 5 columns &lt;svg xmlns=”http://www.w3.org/2000/svg&quot; height=”24px”viewBox=”0 0 24 24” width=”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector('#df-0adace20-cbb2-4908-846b-7f1dd49ea7cb button.colab-df-convert'); buttonEl.style.display = google.colab.kernel.accessAllowed ? 'block' : 'none'; async function convertToInteractive(key) { const element = document.querySelector('#df-0adace20-cbb2-4908-846b-7f1dd49ea7cb'); const dataTable = await google.colab.kernel.invokeFunction('convertToInteractive', [key], {}); if (!dataTable) return; const docLinkHtml = 'Like what you see? Visit the ' + '&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;' + ' to learn more about interactive tables.'; element.innerHTML = ''; dataTable['output_type'] = 'display_data'; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement('div'); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); } &lt;/script&gt; &lt;/div&gt; 13.Gotchas (잡았다!) 연산 수행 시 다음과 같은 예외 상황(Error)을 볼 수도 있다. 12if pd.Series([False, True, False]): print(&quot;I was true&quot;) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-129-5c782b38cd2f&gt; in &lt;module&gt;() ----&gt; 1 if pd.Series([False, True, False]): 2 print(&quot;I was true&quot;) /usr/local/lib/python3.7/dist-packages/pandas/core/generic.py in __nonzero__(self) 1536 def __nonzero__(self): 1537 raise ValueError( -&gt; 1538 f&quot;The truth value of a {type(self).__name__} is ambiguous. &quot; 1539 &quot;Use a.empty, a.bool(), a.item(), a.any() or a.all().&quot; 1540 ) ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). 이런 경우에는 any(), all(), empty 등을 사용해서 무엇을 원하는지를 선택 (반영)해주어야 한다. 12if pd.Series([False, True, False])is not None: print(&quot;I was not None&quot;) I was not None End of document","link":"/2022/03/24/pandas_10minutes/"},{"title":"chapter_9_3","text":"LSTM 신경망 훈련하기 RNN은 실무에서 안씀!!!!!!!!!!! 나온 배경 문장이 길면, 학습 능력이 떨어짐 Long Short-Term Memory 단기 기억을 오래 기억하기 위해 고안됨. 데이터 불러오기12345678from tensorflow.keras.datasets import imdbfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) = imdb.load_data( num_words=500)train_input, val_input, train_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz 17465344/17464789 [==============================] - 0s 0us/step 17473536/17464789 [==============================] - 0s 0us/step padding1234from tensorflow.keras.preprocessing.sequence import pad_sequencestrain_seq = pad_sequences(train_input, maxlen=100)val_seq = pad_sequences(val_input, maxlen=100) 모형 만들기1234567from tensorflow import kerasmodel = keras.Sequential()model.add(keras.layers.Embedding(500, 16, input_length = 100))model.add(keras.layers.LSTM(8)) # SimpleRNNmodel.add(keras.layers.Dense(1, activation='sigmoid'))model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) /images/chapter_9_3/output Shape Param # ================================================================= embedding (Embedding) (None, 100, 16) 8000 lstm (LSTM) (None, 8) 800 dense (Dense) (None, 1) 9 ================================================================= Total params: 8,809 Trainable params: 8,809 Non-trainable params: 0 _________________________________________________________________ 12345678910111213rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)# epochs = 100history = model.fit(train_seq, train_target, epochs=10, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/10 313/313 [==============================] - 13s 36ms/step - loss: 0.6922 - accuracy: 0.5400 - val_loss: 0.6909 - val_accuracy: 0.5952 Epoch 2/10 313/313 [==============================] - 12s 39ms/step - loss: 0.6886 - accuracy: 0.6219 - val_loss: 0.6855 - val_accuracy: 0.6436 Epoch 3/10 313/313 [==============================] - 10s 33ms/step - loss: 0.6778 - accuracy: 0.6671 - val_loss: 0.6655 - val_accuracy: 0.6896 Epoch 4/10 313/313 [==============================] - 11s 35ms/step - loss: 0.6173 - accuracy: 0.7113 - val_loss: 0.5780 - val_accuracy: 0.7118 Epoch 5/10 313/313 [==============================] - 11s 34ms/step - loss: 0.5591 - accuracy: 0.7294 - val_loss: 0.5511 - val_accuracy: 0.7362 Epoch 6/10 313/313 [==============================] - 13s 43ms/step - loss: 0.5346 - accuracy: 0.7499 - val_loss: 0.5300 - val_accuracy: 0.7488 Epoch 7/10 313/313 [==============================] - 10s 33ms/step - loss: 0.5143 - accuracy: 0.7640 - val_loss: 0.5139 - val_accuracy: 0.7618 Epoch 8/10 313/313 [==============================] - 10s 33ms/step - loss: 0.4964 - accuracy: 0.7748 - val_loss: 0.4970 - val_accuracy: 0.7722 Epoch 9/10 313/313 [==============================] - 10s 33ms/step - loss: 0.4816 - accuracy: 0.7828 - val_loss: 0.4844 - val_accuracy: 0.7806 Epoch 10/10 313/313 [==============================] - 11s 35ms/step - loss: 0.4691 - accuracy: 0.7908 - val_loss: 0.4739 - val_accuracy: 0.7808 손실 곡선 추가12345678import matplotlib.pyplot as pltplt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() 순환층에 드롭아웃 적용하기123456789101112131415161718192021222324252627model2 = keras.Sequential()model2.add(keras.layers.Embedding(500, 16, input_length=100))# 드롭아웃 추가model2.add(keras.layers.LSTM(8, dropout=0.3))model2.add(keras.layers.Dense(1, activation='sigmoid'))rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model2.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])checkpoint_cb = keras.callbacks.ModelCheckpoint('best-dropout-model.h5', save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)# epcohs = 100history = model2.fit(train_seq, train_target, epochs=10, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb])plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.legend(['train', 'val'])plt.show() Epoch 1/10 313/313 [==============================] - 14s 37ms/step - loss: 0.6929 - accuracy: 0.5109 - val_loss: 0.6926 - val_accuracy: 0.5336 Epoch 2/10 313/313 [==============================] - 11s 34ms/step - loss: 0.6915 - accuracy: 0.5725 - val_loss: 0.6908 - val_accuracy: 0.5904 Epoch 3/10 313/313 [==============================] - 11s 34ms/step - loss: 0.6887 - accuracy: 0.6108 - val_loss: 0.6868 - val_accuracy: 0.6312 Epoch 4/10 313/313 [==============================] - 13s 40ms/step - loss: 0.6818 - accuracy: 0.6508 - val_loss: 0.6774 - val_accuracy: 0.6510 Epoch 5/10 313/313 [==============================] - 11s 35ms/step - loss: 0.6623 - accuracy: 0.6740 - val_loss: 0.6441 - val_accuracy: 0.6678 Epoch 6/10 313/313 [==============================] - 11s 35ms/step - loss: 0.6024 - accuracy: 0.7145 - val_loss: 0.5710 - val_accuracy: 0.7374 Epoch 7/10 313/313 [==============================] - 12s 38ms/step - loss: 0.5601 - accuracy: 0.7370 - val_loss: 0.5479 - val_accuracy: 0.7512 Epoch 8/10 313/313 [==============================] - 11s 35ms/step - loss: 0.5387 - accuracy: 0.7502 - val_loss: 0.5285 - val_accuracy: 0.7600 Epoch 9/10 313/313 [==============================] - 11s 34ms/step - loss: 0.5189 - accuracy: 0.7624 - val_loss: 0.5089 - val_accuracy: 0.7714 Epoch 10/10 313/313 [==============================] - 11s 35ms/step - loss: 0.5008 - accuracy: 0.7746 - val_loss: 0.4928 - val_accuracy: 0.7758 Reference : 혼자 공부하는 머신러닝 + 딥러닝","link":"/2022/04/12/chapter_9_3/"},{"title":"Anaconda install","text":"Anaconda아나콘다 설치 주소 : Anaconda | Individual Edition → download → 관리자 권한으로 실행 → install직전에 Add Anaconda 3 to the system path…에 체크 → install → anaconda individual edition tutorial 을 체크 해제 → finish anaconda navigator 열기 → JupyterLab → 왼쪽 목록에서 ‘Desktop’으로 이동 → 폴더 생성 ‘AI’ → ‘AI’로 이동 → Notebook 클릭 → 파이썬 편집기 사용하면 됨. pycharm 설치 구글링 : pycharm → ‘Community’ 버전 다운로드 → 관리자 권한으로 실행 → 옵션의 체크 박스를 전부 체크 → install → finish 시스템 환경 변수 편집 → 환경 변수 → 시스템 변수 : path → 편집 → anaconda3\\library, anaconda3\\script 등이 있는지 확인 → 설정 완료 팁 /code 단축키로 코드 입력 창 생성 1$ git clone 주소 캡처 단축키 : window + shift + s → 캡쳐 → ctrl+v (붙여넣기)","link":"/2022/04/13/Anaconda/"},{"title":"WSL2 install","text":"WSL2 and Linux다음 링크 참고 : 반드시 설정 확인 https://www.lainyzine.com/ko/article/how-to-install-wsl2-and-use-linux-on-windows-10/ Microsoft Store → windows terminal 설치 → windows powershell 관리자 권한으로 설치 → [Windows 10] WSL2 설치 및 사용법 - LainyZine 내용 참고하여 명령. → dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart → dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart → 재부팅 → wsl2 Linux 커널 업데이트 패키지 설치 ( 위 링크 참고) 설치 실패 : ( This update only applies to machines with the windows subsystem for Linux) ㄴ [https://goaloflife.tistory.com/192](https://goaloflife.tistory.com/192) 로 해결해본다. → windows Terminal → wsl --set-default-version 2 → Microsoft Store → Ubuntu 설치 → Ubuntu → 설치되기까지 기다린다 → 이름 / 패스워드 입력 ( 이름 : kmk3593 / password : 2016***** ) → windows terminal → wsl -l -v → Ubuntu Running 2 가 출력되면 성공. Linux Shell 프롬프트windows terminal → wsl bash → Bash 셸이 실행됨. 프롬프트 형태가 바뀌면 성공 저자 주: 여기서부터 WSL2 리눅스 셸 프롬프트→ 즉, Windows 10 메인 디스크가 리눅스와 연결되어있으며, WSL2 Linux에서 Windows의 파일을 사용하는 것도 가능한 상태. setting 순서 Nifi → Airflow → Elasticsearch → postgreSQL → VSCord 순으로 세팅을 진행했다. Apache NiFi 설치와 설정 in WSL2 - Data Science | DSChloe Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe ElasticSearch &amp; Kibana 설치 in WSL2 - Data Science | DSChloe PostgreSQL Installation on WSL2 and Windows - Data Science | DSChloe VSCode Remote WLS 연동 - Data Science | DSChloe","link":"/2022/04/14/WSL2/"},{"title":"Apache Nifi Install","text":"Apache NiFiApache NiFi 설치와 설정 in WSL2 - Data Science | DSChloe 설치 wsl2에서 JAVA 설치 한다. 관리자 권한으로 실행 : Ubuntu → ls → cd .. → ls → cd .. → ls // ls 하여 파일 출력 될 때까지 → java --version → 설치 안 되어 있을 시 : sudo apt-get update &amp;&amp; sudo apt-get upgrade → 설치 안 되어 있을 시 : sudo apt install openjdk-11-jdk → vi ~/.bash_profile → vi 편집기로 이동된다. → 내용 추가 : export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 → esc + :wq 하여 저장 source 사용하여 상태 저장 → source ~/.bash_profile → echo $JAVA_HOME → 다음 내용 출력 시 성공 : /usr/lib/jvm/java-11-openjdk-amd64 curl을 이용해서 NiFi를 현재 경로에 내려받는다. 오래 걸린다. → sudo wget https://downloads.apache.org/nifi/1.16.0/nifi-1.16.0-bin.tar.gz → ls → 현재 있는 기본 경로에 nifi 가 출력 됨을 알 수 있다. /mnt/c 경로로 파일을 옮기자. mv 명령이 안 먹혀서 cp 명령 사용 다음 명령을 실행하여 /mnt/c 경로로 복사 붙여넣었다. 참고 자료 : 리눅스 / 명령어 / cp / 복사하는 명령어, mv – 이동하는 명령어 – MANUAL FACTORY →cp nifi-1.16.0-bin.tar.gz mnt/c/nifi-1.16.0-bin.tar.gz → cd mnt → cd c → ls → /mnt/c 경로에 nifi 가 생겼다. .tar.gz 파일의 압축을 푼다 → sudo tar xvaf nifi 까지 타이핑하고 Tab 하여 다음 코드 작성 → sudo tar xvzf nifi-1.16.0-bin.tar.gz 압축파일을 푼 다음에는 cd nifi-1.16.0 폴더에 접속을 한다. → Tab 이용하여 다음 코드 작성하고 실행 → cd nifi-1.16.0/bin ls를 실행해서 nifi-env.sh 파일이 있는지 확인하고 있다면, vi 에디터로 연다. bash_profile에서 한 것처럼 동일하게 자바 환경변수를 잡아준다 → sudo vi nifi-env.sh → 내용 추가 : export JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot; → esc + :wq 하여 저장하고 나온다. 그리고, nifi-env.sh 파일을 실행 → sudo ./nifi.sh start NiFi 화면에 접속한다. https://127.0.0.1:8443/nifi/login → 몇 분간 새로고침한다. ( 계속 안될 경우 : stop하고 기록을 지운 다음 다시 start) → 비공개 화면 … 이라는 문구가 출력된다. → ‘고급’ 선택 → 나타나는 주소를 클릭하여 들어간다. → 다음 화면이 출력된다. 종료 /mnt/c/nifi-1.16.0$ 상태에서 다음 명령 실행해야 한다. → cd .. → sudo ./bin/nifi.sh stop 로그인 준비. 아이디와 비밀번호를 설정한다. ( *비밀번호는 최소 13자리) → sudo ./bin/nifi.sh set-single-user-credentials human 1234567890123 그리고, nifi-env.sh 파일을 실행 단, /bin 경로에서 한다. → cd bin/ → sudo ./nifi.sh start NiFi 화면에 접속한다. https://127.0.0.1:8443/nifi/login → 몇 분간 새로고침한다. → 다음 정보로 로그인 id : human password : 1234567890123 → 다음 화면이 출력되면 성공. 세팅은 끝났으니 일단 종료시켜놓자. 종료 /mnt/c/nifi-1.16.0$ 상태에서 다음 명령 실행해야 한다. → cd .. → sudo ./bin/nifi.sh stop 기록 지우는 법ubuntu에서 다음 명령 실행 cd.. cd.. cd mnt/c ls cd nifi-1/16/0/ ls cd logs ls sudo rm -rf * ls → 삭제 되어 아무것도 출력되지 않는다. NiFi 사용법 Nifi 사용법을 익혀보자 실무 예제로 배우는 데이터 공학 19p 부터 따라해본다. 메뉴바에서 process를 드래그하여 캔버스에 놓는다. → 다음 그림의 우측 상단에서 검색한다. → 검색 : GenerateFlowFile → ADD 버튼 클릭 → 같은 방법으로 검색 → 검색 : putfile → ADD 나타난 박스를 우클릭 → configure → properties → field 를 설정할 수 있다. 설정 후에는 박스끼리 연결할 수 있다. → 박스 하나의 중앙을 드래그하여 다른 박스에 놓는다. → 연결된다. → 이 상태에서 GenerateFlowFile에서 파일을 생성하여 PutFile에 옮길 수 있다. Reference : 실무 예제로 배우는 데이터 공학","link":"/2022/04/15/Apache_NiFi/"},{"title":"Apache Nifi Install","text":"Apache airflowApache-Airflow in windows 설치• Windows WSL2에서 airflow를 설치한다. Step 1. Install pip on WSL • c드라이브에 들어간다. 관리자 권한으로 실행 : Ubuntu → cd.. → cd.. →cd mnt/c • 폴더를 만든다 → mkdir airflow-test → ls → cd airflow-test/ • pip를 설치한다. → sudo apt-get update &amp;&amp; sudo apt-get upgrade → sudo apt install python3-pip Step 2. Install virtualenv package • virtualenv 라이브러리를 설치한다. → sudo pip3 install virtualenv Step 3. Create a virtual environment • 이제 가상환경을 생성한다. → virtualenv venv • 가상환경에 접속을 한다. → airflowtest 경로에서 해야 한다. → source venv/bin/activate → 경로 확인 → pwd • 이번에는 .bashrc 파일을 수정한다. • 파일을 열고, 맨 밑줄에 다음과 같은 코드를 추가한다. → vi ~/.bashrc → 내용 추가 : export AIRFLOW_HOME=/mnt/c/airflow-test → ESC → :wq 하여 저장 • 수정된 코드를 업데이트 하기 위해서는 아래와 같이 반영한다. → source ~/.bashrc • 실제로 코드가 반영되었는지 확인하기 위해서는 다음과 같이 확인해본다. • 다시 가상환경에 접속하고 수행 →source venv/bin/activate → echo $AIRFLOW_HOME → /mnt/c/airflow-test 출력되면 성공. Step 4. Apache Airflow 설치 • PostgreSQL, Slack, Celery 패키지를 동시에 설치하는 코드를 작성한다. → sudo apt-get update &amp;&amp; sudo apt-get upgrade → pip3 install 'apache-airflow[postgres, slack, celery]' • airflow 실행을 위해 DB 초기화를 해줘야 한다. → airflow db init • 실제로 잘 구현이 되었는지 확인하기 위해 webserver를 실행한다 → airflow webserver -p 8081 → port 번호 8081을 뜻한다. • 그리고, 해당 링크 http://localhost:8081/login/ 에 접속하면 아래와 같은 화면이 나타난다. • 그런데, 여기에서 문제는 username을 생성하지 않았다. 따라서, username을 추가하도록 한다 → ctrl + c 로 빠져나온다. → airflow users create --username airflow --password airflow --firstname evan --lastname airflow --role Admin --email your_email@some.com • 다시 웹서버 실행 → airflow webserver -p 8081 • 해당 링크 http://localhost:8081/login/ 에 접속 • 다음 정보로 로그인한다 → id : airflow password : airflow → 다음 화면이 나오면 성공. 설정완료 후에 가상환경 키는 법ubuntu → cd .. → cd .. → cd mnt/c → cd airflow-test → source venv/bin/activate Reference :Setting up Apache-Airflow in Windows using WSL2 - Data Science | DSChloe Airflow 재설치 및 데이터 파이프라인 구축","link":"/2022/04/16/Apache_Airflow_install/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"Notion","slug":"Notion","link":"/tags/Notion/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"github blog","slug":"github-blog","link":"/tags/github-blog/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"생활코딩","slug":"생활코딩","link":"/tags/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"},{"name":"R Markdown","slug":"R-Markdown","link":"/tags/R-Markdown/"},{"name":"anaconda","slug":"anaconda","link":"/tags/anaconda/"},{"name":"wsl2","slug":"wsl2","link":"/tags/wsl2/"},{"name":"setting","slug":"setting","link":"/tags/setting/"},{"name":"NiFi","slug":"NiFi","link":"/tags/NiFi/"},{"name":"apache","slug":"apache","link":"/tags/apache/"},{"name":"airflow","slug":"airflow","link":"/tags/airflow/"}],"categories":[{"name":"python","slug":"python","link":"/categories/python/"},{"name":"R","slug":"R","link":"/categories/R/"},{"name":"machine learning","slug":"python/machine-learning","link":"/categories/python/machine-learning/"},{"name":"기초","slug":"R/기초","link":"/categories/R/%EA%B8%B0%EC%B4%88/"},{"name":"알고리즘","slug":"python/machine-learning/알고리즘","link":"/categories/python/machine-learning/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/"},{"name":"인공신경망","slug":"python/machine-learning/인공신경망","link":"/categories/python/machine-learning/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D/"},{"name":"비지도학습","slug":"python/machine-learning/비지도학습","link":"/categories/python/machine-learning/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/"},{"name":"데이터 전처리","slug":"python/machine-learning/데이터-전처리","link":"/categories/python/machine-learning/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"딥러닝","slug":"python/machine-learning/딥러닝","link":"/categories/python/machine-learning/%EB%94%A5%EB%9F%AC%EB%8B%9D/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"JavaScript","slug":"JavaScript","link":"/categories/JavaScript/"},{"name":"개념","slug":"python/machine-learning/개념","link":"/categories/python/machine-learning/%EA%B0%9C%EB%85%90/"},{"name":"library","slug":"python/library","link":"/categories/python/library/"},{"name":"github blog","slug":"git/github-blog","link":"/categories/git/github-blog/"},{"name":"생활코딩","slug":"JavaScript/생활코딩","link":"/categories/JavaScript/%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9/"},{"name":"pandas","slug":"python/library/pandas","link":"/categories/python/library/pandas/"},{"name":"기초문법","slug":"python/기초문법","link":"/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/"},{"name":"자료형, 반복문, 조건문","slug":"python/기초문법/자료형-반복문-조건문","link":"/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%EC%9E%90%EB%A3%8C%ED%98%95-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8/"},{"name":"numpy","slug":"python/library/numpy","link":"/categories/python/library/numpy/"},{"name":"분석 방법","slug":"R/분석-방법","link":"/categories/R/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95/"},{"name":"함수","slug":"python/기초문법/함수","link":"/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%95%A8%EC%88%98/"},{"name":"visualization","slug":"python/library/visualization","link":"/categories/python/library/visualization/"},{"name":"클래스","slug":"python/기초문법/클래스","link":"/categories/python/%EA%B8%B0%EC%B4%88%EB%AC%B8%EB%B2%95/%ED%81%B4%EB%9E%98%EC%8A%A4/"},{"name":"setting","slug":"setting","link":"/categories/setting/"},{"name":"anaconda","slug":"setting/anaconda","link":"/categories/setting/anaconda/"},{"name":"wsl2","slug":"setting/wsl2","link":"/categories/setting/wsl2/"},{"name":"NiFi","slug":"setting/NiFi","link":"/categories/setting/NiFi/"},{"name":"airflow","slug":"setting/airflow","link":"/categories/setting/airflow/"}]}